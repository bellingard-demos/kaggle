{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style()\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-13T23:29:24.929206Z","iopub.execute_input":"2023-08-13T23:29:24.92963Z","iopub.status.idle":"2023-08-13T23:29:24.942709Z","shell.execute_reply.started":"2023-08-13T23:29:24.929596Z","shell.execute_reply":"2023-08-13T23:29:24.941667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n\nimport warnings\nwarnings.filterwarnings('ignore')\nsns.set_theme(style='darkgrid', palette='colorblind')\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\nfrom sklearn.preprocessing import LabelEncoder \nle = LabelEncoder()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:24.944442Z","iopub.execute_input":"2023-08-13T23:29:24.945167Z","iopub.status.idle":"2023-08-13T23:29:24.958884Z","shell.execute_reply.started":"2023-08-13T23:29:24.945134Z","shell.execute_reply":"2023-08-13T23:29:24.957933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/fast-food/FastFoodNutritionMenu.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:24.960054Z","iopub.execute_input":"2023-08-13T23:29:24.960888Z","iopub.status.idle":"2023-08-13T23:29:24.9821Z","shell.execute_reply.started":"2023-08-13T23:29:24.960855Z","shell.execute_reply":"2023-08-13T23:29:24.979497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:24.984948Z","iopub.execute_input":"2023-08-13T23:29:24.985431Z","iopub.status.idle":"2023-08-13T23:29:25.004076Z","shell.execute_reply.started":"2023-08-13T23:29:24.985387Z","shell.execute_reply":"2023-08-13T23:29:25.003243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:25.005106Z","iopub.execute_input":"2023-08-13T23:29:25.005757Z","iopub.status.idle":"2023-08-13T23:29:25.025956Z","shell.execute_reply.started":"2023-08-13T23:29:25.005708Z","shell.execute_reply":"2023-08-13T23:29:25.024681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:25.027022Z","iopub.execute_input":"2023-08-13T23:29:25.027536Z","iopub.status.idle":"2023-08-13T23:29:25.034511Z","shell.execute_reply.started":"2023-08-13T23:29:25.027504Z","shell.execute_reply":"2023-08-13T23:29:25.033794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe().T","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:25.041594Z","iopub.execute_input":"2023-08-13T23:29:25.042151Z","iopub.status.idle":"2023-08-13T23:29:25.07984Z","shell.execute_reply.started":"2023-08-13T23:29:25.042108Z","shell.execute_reply":"2023-08-13T23:29:25.078818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:25.081462Z","iopub.execute_input":"2023-08-13T23:29:25.08186Z","iopub.status.idle":"2023-08-13T23:29:25.088201Z","shell.execute_reply.started":"2023-08-13T23:29:25.081828Z","shell.execute_reply":"2023-08-13T23:29:25.087159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Company'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:25.136045Z","iopub.execute_input":"2023-08-13T23:29:25.137119Z","iopub.status.idle":"2023-08-13T23:29:25.14533Z","shell.execute_reply.started":"2023-08-13T23:29:25.137077Z","shell.execute_reply":"2023-08-13T23:29:25.144314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:25.147814Z","iopub.execute_input":"2023-08-13T23:29:25.148436Z","iopub.status.idle":"2023-08-13T23:29:25.162388Z","shell.execute_reply.started":"2023-08-13T23:29:25.148395Z","shell.execute_reply":"2023-08-13T23:29:25.161261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum().plot(kind = 'bar')","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:25.163886Z","iopub.execute_input":"2023-08-13T23:29:25.164328Z","iopub.status.idle":"2023-08-13T23:29:25.629566Z","shell.execute_reply.started":"2023-08-13T23:29:25.164288Z","shell.execute_reply":"2023-08-13T23:29:25.628461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# REMOVE NULL","metadata":{}},{"cell_type":"code","source":"df = df.drop('Weight Watchers\\nPnts', axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:25.631031Z","iopub.execute_input":"2023-08-13T23:29:25.632026Z","iopub.status.idle":"2023-08-13T23:29:25.638731Z","shell.execute_reply.started":"2023-08-13T23:29:25.631981Z","shell.execute_reply":"2023-08-13T23:29:25.637691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=df.dropna()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:25.641933Z","iopub.execute_input":"2023-08-13T23:29:25.642694Z","iopub.status.idle":"2023-08-13T23:29:25.656677Z","shell.execute_reply.started":"2023-08-13T23:29:25.642661Z","shell.execute_reply":"2023-08-13T23:29:25.655654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# REMOVE DUPLICATE","metadata":{}},{"cell_type":"code","source":"# Finding duplicate rows\nduplicate_rows = df[df.duplicated(keep='first')]\n# Number of duplicate rows\nnum_duplicates = duplicate_rows.shape[0]\n# Displaying the duplicate rows\nprint(f\"Number of duplicate rows: {num_duplicates}\")\nduplicate_rows","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:25.658245Z","iopub.execute_input":"2023-08-13T23:29:25.6589Z","iopub.status.idle":"2023-08-13T23:29:25.687246Z","shell.execute_reply.started":"2023-08-13T23:29:25.658863Z","shell.execute_reply":"2023-08-13T23:29:25.686128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop_duplicates()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:25.688727Z","iopub.execute_input":"2023-08-13T23:29:25.689785Z","iopub.status.idle":"2023-08-13T23:29:25.69922Z","shell.execute_reply.started":"2023-08-13T23:29:25.68974Z","shell.execute_reply":"2023-08-13T23:29:25.698441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:25.700821Z","iopub.execute_input":"2023-08-13T23:29:25.701858Z","iopub.status.idle":"2023-08-13T23:29:25.714815Z","shell.execute_reply.started":"2023-08-13T23:29:25.701817Z","shell.execute_reply":"2023-08-13T23:29:25.713594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# visualization","metadata":{}},{"cell_type":"code","source":"col_conv = [ 'Calories', 'Calories from\\nFat', 'Total Fat\\n(g)',\n       'Saturated Fat\\n(g)', 'Trans Fat\\n(g)', 'Cholesterol\\n(mg)',\n       'Sodium \\n(mg)', 'Carbs\\n(g)', 'Fiber\\n(g)', 'Sugars\\n(g)',\n       'Protein\\n(g)'] \nfor column in col_conv:\n    df[column] = pd.to_numeric(df[column], errors='coerce')","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:25.716383Z","iopub.execute_input":"2023-08-13T23:29:25.71689Z","iopub.status.idle":"2023-08-13T23:29:25.737083Z","shell.execute_reply.started":"2023-08-13T23:29:25.716845Z","shell.execute_reply":"2023-08-13T23:29:25.73631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(x=df['Company'], y=df['Total Fat\\n(g)'])","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:25.7386Z","iopub.execute_input":"2023-08-13T23:29:25.739255Z","iopub.status.idle":"2023-08-13T23:29:26.298494Z","shell.execute_reply.started":"2023-08-13T23:29:25.739212Z","shell.execute_reply":"2023-08-13T23:29:26.297302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Corr_Matrix = df.corr()\n\n# Set up the figure and plot the heatmap\nplt.figure(figsize=(45, 45))\nsns.heatmap(Corr_Matrix, annot=True, cmap='coolwarm', center=0)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:26.300205Z","iopub.execute_input":"2023-08-13T23:29:26.300693Z","iopub.status.idle":"2023-08-13T23:29:28.039098Z","shell.execute_reply.started":"2023-08-13T23:29:26.300648Z","shell.execute_reply":"2023-08-13T23:29:28.038138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(data=df, y=\"Protein\\n(g)\",  kind=\"box\")#الشكل العادي ","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:28.04072Z","iopub.execute_input":"2023-08-13T23:29:28.04102Z","iopub.status.idle":"2023-08-13T23:29:28.39932Z","shell.execute_reply.started":"2023-08-13T23:29:28.040994Z","shell.execute_reply":"2023-08-13T23:29:28.39832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Distribution of Popularity\nplt.figure(figsize=(10, 6))\nsns.histplot(df['Protein\\n(g)'], kde=True)\nplt.title('Distribution of Protein\\n(g)')\nplt.xlabel('Protein\\n(g)')\nplt.ylabel('Count')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:28.404684Z","iopub.execute_input":"2023-08-13T23:29:28.405084Z","iopub.status.idle":"2023-08-13T23:29:28.847109Z","shell.execute_reply.started":"2023-08-13T23:29:28.405053Z","shell.execute_reply":"2023-08-13T23:29:28.846326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_correlation_heatmaps_by_company(dataframe):\n    \n    companies = df['Company'].unique()\n    \n    for company in companies:\n        company_df = df[df['Company'] == company]\n        corr_matrix = company_df.corr()\n        \n        plt.figure(figsize=(8, 6))\n        \n        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, linewidths=.5)\n        \n        plt.title(f'Correlation Heatmap - {company}')\n        plt.show()\n\nplot_correlation_heatmaps_by_company(df)","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:28.848444Z","iopub.execute_input":"2023-08-13T23:29:28.849029Z","iopub.status.idle":"2023-08-13T23:29:33.747436Z","shell.execute_reply.started":"2023-08-13T23:29:28.848995Z","shell.execute_reply":"2023-08-13T23:29:33.746397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\ncompanies = df['Company'].unique()\n# Define nutritional columns\nnutritional_columns = ['Total Fat\\n(g)', 'Protein\\n(g)', 'Carbs\\n(g)']\n\n# Create box plots for each nutritional column\nfig = px.box(df, x='Company', y=nutritional_columns, title='Nutritional Values by Company',\n             labels={'value': 'Grams'}, category_orders={'Company': companies})\nfig.update_layout(xaxis={'categoryorder': 'array', 'categoryarray': companies},\n                  xaxis_title='Company', yaxis_title='Grams')\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:33.748636Z","iopub.execute_input":"2023-08-13T23:29:33.748944Z","iopub.status.idle":"2023-08-13T23:29:33.832651Z","shell.execute_reply.started":"2023-08-13T23:29:33.748918Z","shell.execute_reply":"2023-08-13T23:29:33.831455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set(style=\"whitegrid\")\n# Creating a FacetGrid\ng = sns.FacetGrid(df, col=\"Company\", col_wrap=2, height=5)\n# Plotting the histogram of Calories for each company\ng.map(plt.hist, 'Calories', bins=20, edgecolor='black')\ng.set_titles(\"Distribution of Calories - {col_name}\")\ng.set_axis_labels(\"Calories\", \"Frequency\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:33.834364Z","iopub.execute_input":"2023-08-13T23:29:33.835498Z","iopub.status.idle":"2023-08-13T23:29:36.19571Z","shell.execute_reply.started":"2023-08-13T23:29:33.835454Z","shell.execute_reply":"2023-08-13T23:29:36.194628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=df.dropna()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:36.196937Z","iopub.execute_input":"2023-08-13T23:29:36.197249Z","iopub.status.idle":"2023-08-13T23:29:36.204565Z","shell.execute_reply.started":"2023-08-13T23:29:36.197222Z","shell.execute_reply":"2023-08-13T23:29:36.20329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# categorical","metadata":{}},{"cell_type":"code","source":"df['Company'] = le.fit_transform(df['Company'])\ndf['Item'] = le.fit_transform(df['Item'])","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:36.206321Z","iopub.execute_input":"2023-08-13T23:29:36.206743Z","iopub.status.idle":"2023-08-13T23:29:36.221081Z","shell.execute_reply.started":"2023-08-13T23:29:36.206703Z","shell.execute_reply":"2023-08-13T23:29:36.219713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:36.222625Z","iopub.execute_input":"2023-08-13T23:29:36.223005Z","iopub.status.idle":"2023-08-13T23:29:36.249412Z","shell.execute_reply.started":"2023-08-13T23:29:36.222967Z","shell.execute_reply":"2023-08-13T23:29:36.24819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Top 5 Most Positively Correlated","metadata":{}},{"cell_type":"code","source":"print('Top 5 Most Positively Correlated to the Target Variable')\nCorr_Matrix['Total Fat\\n(g)'].sort_values(ascending=False).head(5)","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:36.251011Z","iopub.execute_input":"2023-08-13T23:29:36.251366Z","iopub.status.idle":"2023-08-13T23:29:36.265114Z","shell.execute_reply.started":"2023-08-13T23:29:36.251328Z","shell.execute_reply":"2023-08-13T23:29:36.264301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Top 5 Most Negatively Correlated","metadata":{}},{"cell_type":"code","source":"print('Top 5 Most Negatively Correlated to the Target Variable')\nCorr_Matrix['Total Fat\\n(g)'].sort_values(ascending=True).head(5)","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:36.266025Z","iopub.execute_input":"2023-08-13T23:29:36.26639Z","iopub.status.idle":"2023-08-13T23:29:36.280552Z","shell.execute_reply.started":"2023-08-13T23:29:36.266358Z","shell.execute_reply":"2023-08-13T23:29:36.279419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DROP LOW Correlated","metadata":{}},{"cell_type":"code","source":"columns_to_drop = [col for col in Corr_Matrix.columns if abs(Corr_Matrix.loc['Total Fat\\n(g)', col]) < 0.5]\ncolumns_to_drop","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:36.282046Z","iopub.execute_input":"2023-08-13T23:29:36.28247Z","iopub.status.idle":"2023-08-13T23:29:36.293135Z","shell.execute_reply.started":"2023-08-13T23:29:36.28244Z","shell.execute_reply":"2023-08-13T23:29:36.291991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(columns_to_drop, axis=1)\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:36.294654Z","iopub.execute_input":"2023-08-13T23:29:36.295048Z","iopub.status.idle":"2023-08-13T23:29:36.30626Z","shell.execute_reply.started":"2023-08-13T23:29:36.29501Z","shell.execute_reply":"2023-08-13T23:29:36.305093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=df.dropna()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:36.307929Z","iopub.execute_input":"2023-08-13T23:29:36.308321Z","iopub.status.idle":"2023-08-13T23:29:36.317158Z","shell.execute_reply.started":"2023-08-13T23:29:36.30828Z","shell.execute_reply":"2023-08-13T23:29:36.316143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# split ","metadata":{}},{"cell_type":"code","source":"X = df.drop(columns=['Total Fat\\n(g)'])\ny = df['Total Fat\\n(g)']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Display the shapes of the resulting datasets\nprint(\"X_train shape:\", X_train.shape)\nprint(\"X_test shape:\", X_test.shape)\nprint(\"y_train shape:\", y_train.shape)\nprint(\"y_test shape:\", y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:36.318875Z","iopub.execute_input":"2023-08-13T23:29:36.319212Z","iopub.status.idle":"2023-08-13T23:29:36.330438Z","shell.execute_reply.started":"2023-08-13T23:29:36.319183Z","shell.execute_reply":"2023-08-13T23:29:36.329454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MODEL","metadata":{}},{"cell_type":"code","source":"models = {\n    'Linear Regression': LinearRegression(),\n    'Random Forest': RandomForestRegressor(random_state=42),\n    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n}\nbest_model = None\nbest_r2 = 0\n\nfor model_name, model in models.items():\n    model.fit(X_train, y_train)\n    y_pred= model.predict(X_test)\n\n    # Evaluate the model\n    r2 = r2_score(y_test, y_pred)\n    mae = mean_absolute_error(y_test, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    submit = pd.DataFrame()\n    submit['Actual Price'] = y_test\n    submit['Predict_price'] = y_pred\n    submit = submit.reset_index()\n    print(submit.head(8))\n    r2 = r2_score(y_test, y_pred)\n\n    if r2 > best_r2:\n        best_r2 = r2\n        best_model = model.__class__.__name__\n\n    print(f'{model_name}:')\n    print(f'R2 Score: {r2:.2f}')\n    print(f'Mean Absolute Error (MAE): {mae:.2f}')\n    print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')\n    print('----------------------------------------')\nprint(f\"The best performing model is: {best_model} with accuracy: {best_r2:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:36.332043Z","iopub.execute_input":"2023-08-13T23:29:36.33272Z","iopub.status.idle":"2023-08-13T23:29:36.762971Z","shell.execute_reply.started":"2023-08-13T23:29:36.332681Z","shell.execute_reply":"2023-08-13T23:29:36.761934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# feature_importances","metadata":{}},{"cell_type":"code","source":"importances = model.feature_importances_\nfeature_names = X.columns\nfeature_importance_dict = dict(zip(feature_names, importances))\nsorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\nfor feature, importance in sorted_feature_importance:\n    print(f\"{feature}: {importance:.2f}\")\nplt.figure(figsize=(12, 7))\nplt.barh(*zip(*sorted_feature_importance), alpha=0.9, color='teal')\nplt.title('Feature Importance', fontsize=15)\nplt.xlabel(\"Importance\")\nplt.ylabel(\"Feature\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:36.764487Z","iopub.execute_input":"2023-08-13T23:29:36.764893Z","iopub.status.idle":"2023-08-13T23:29:37.112252Z","shell.execute_reply.started":"2023-08-13T23:29:36.764855Z","shell.execute_reply":"2023-08-13T23:29:37.111438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# forward_selection with column (Total Fat\\n(g))","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport statsmodels.api as sm\n\n# Your DataFrame\n# df = ...\n\nX = df.drop(columns=['Total Fat\\n(g)'])\ny = df['Total Fat\\n(g)']\n\ndef forward_selection(df, target, significance_level=0.05):\n    initial_features = df.columns.tolist()\n    best_features = []\n    while len(initial_features) > 0:\n        remaining_features = list(set(initial_features) - set(best_features))\n        new_pval = pd.Series(index=remaining_features)\n        for new_column in remaining_features:\n            model = sm.OLS(target, sm.add_constant(df[best_features + [new_column]])).fit()\n            new_pval[new_column] = model.pvalues[new_column]\n        min_p_value = new_pval.min()\n        if min_p_value < significance_level:\n            best_features.append(new_pval.idxmin())\n        else:\n            break\n    return best_features\n\n# Assuming you have already defined X and y as the features and target variable respectively\nselected_features = forward_selection(X, y)\nprint(\"Selected features:\", selected_features)","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:37.113389Z","iopub.execute_input":"2023-08-13T23:29:37.113948Z","iopub.status.idle":"2023-08-13T23:29:37.218308Z","shell.execute_reply.started":"2023-08-13T23:29:37.113917Z","shell.execute_reply":"2023-08-13T23:29:37.217172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Selected_features = [ 'Saturated Fat\\n(g)', 'Calories', 'Company', 'Sodium \\n(mg)','Calories from\\nFat']\n\nX = df[selected_features]\ny = df['Total Fat\\n(g)']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Display the shapes of the resulting datasets\nprint(\"X_train shape:\", X_train.shape)\nprint(\"X_test shape:\", X_test.shape)\nprint(\"y_train shape:\", y_train.shape)\nprint(\"y_test shape:\", y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:37.219543Z","iopub.execute_input":"2023-08-13T23:29:37.220491Z","iopub.status.idle":"2023-08-13T23:29:37.231927Z","shell.execute_reply.started":"2023-08-13T23:29:37.220447Z","shell.execute_reply":"2023-08-13T23:29:37.230644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = {\n    'Linear Regression': LinearRegression(),\n    'Random Forest': RandomForestRegressor(random_state=42),\n    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n}\nbest_model = None\nbest_r2 = 0\n\nfor model_name, model in models.items():\n    model.fit(X_train, y_train)\n    y_pred= model.predict(X_test)\n\n    # Evaluate the model\n    r2 = r2_score(y_test, y_pred)\n    mae = mean_absolute_error(y_test, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    submit = pd.DataFrame()\n    submit['Actual Price'] = y_test\n    submit['Predict_price'] = y_pred\n    submit = submit.reset_index()\n    print(submit.head(8))\n    r2 = r2_score(y_test, y_pred)\n\n    if r2 > best_r2:\n        best_r2 = r2\n        best_model = model.__class__.__name__\n\n    print(f'{model_name}:')\n    print(f'R2 Score: {r2:.2f}')\n    print(f'Mean Absolute Error (MAE): {mae:.2f}')\n    print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')\n    print('----------------------------------------')\nprint(f\"The best performing model is: {best_model} with accuracy: {best_r2:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:37.233379Z","iopub.execute_input":"2023-08-13T23:29:37.234216Z","iopub.status.idle":"2023-08-13T23:29:37.612383Z","shell.execute_reply.started":"2023-08-13T23:29:37.234183Z","shell.execute_reply":"2023-08-13T23:29:37.611345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# forward_selection with colums( Calories from\\nFat)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport statsmodels.api as sm\n\n# Your DataFrame\n# df = ...\n\nX = df.drop(columns=['Calories from\\nFat'])\ny = df['Calories from\\nFat']\n\ndef forward_selection(df, target, significance_level=0.05):\n    initial_features = df.columns.tolist()\n    best_features = []\n    while len(initial_features) > 0:\n        remaining_features = list(set(initial_features) - set(best_features))\n        new_pval = pd.Series(index=remaining_features)\n        for new_column in remaining_features:\n            model = sm.OLS(target, sm.add_constant(df[best_features + [new_column]])).fit()\n            new_pval[new_column] = model.pvalues[new_column]\n        min_p_value = new_pval.min()\n        if min_p_value < significance_level:\n            best_features.append(new_pval.idxmin())\n        else:\n            break\n    return best_features\n\n# Assuming you have already defined X and y as the features and target variable respectively\nselected_features = forward_selection(X, y)\nprint(\"Selected features:\", selected_features)","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:37.614192Z","iopub.execute_input":"2023-08-13T23:29:37.614609Z","iopub.status.idle":"2023-08-13T23:29:37.719081Z","shell.execute_reply.started":"2023-08-13T23:29:37.614569Z","shell.execute_reply":"2023-08-13T23:29:37.718001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Selected_features = [ 'Total Fat\\n(g)', 'Saturated Fat\\n(g)', 'Sodium \\n(mg)', 'Calories', 'Company']\n\nX = df[selected_features]\ny = df['Calories from\\nFat']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Display the shapes of the resulting datasets\nprint(\"X_train shape:\", X_train.shape)\nprint(\"X_test shape:\", X_test.shape)\nprint(\"y_train shape:\", y_train.shape)\nprint(\"y_test shape:\", y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:37.720969Z","iopub.execute_input":"2023-08-13T23:29:37.721395Z","iopub.status.idle":"2023-08-13T23:29:37.731693Z","shell.execute_reply.started":"2023-08-13T23:29:37.721357Z","shell.execute_reply":"2023-08-13T23:29:37.73059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = {\n    'Linear Regression': LinearRegression(),\n    'Random Forest': RandomForestRegressor(random_state=42),\n    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n}\nbest_model = None\nbest_r2 = 0\n\nfor model_name, model in models.items():\n    model.fit(X_train, y_train)\n    y_pred= model.predict(X_test)\n\n    # Evaluate the model\n    r2 = r2_score(y_test, y_pred)\n    mae = mean_absolute_error(y_test, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    submit = pd.DataFrame()\n    submit['Actual Price'] = y_test\n    submit['Predict_price'] = y_pred\n    submit = submit.reset_index()\n    print(submit.head(8))\n    r2 = r2_score(y_test, y_pred)\n\n    if r2 > best_r2:\n        best_r2 = r2\n        best_model = model.__class__.__name__\n\n    print(f'{model_name}:')\n    print(f'R2 Score: {r2:.2f}')\n    print(f'Mean Absolute Error (MAE): {mae:.2f}')\n    print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')\n    print('----------------------------------------')\nprint(f\"The best performing model is: {best_model} with accuracy: {best_r2:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:37.73345Z","iopub.execute_input":"2023-08-13T23:29:37.733862Z","iopub.status.idle":"2023-08-13T23:29:38.121387Z","shell.execute_reply.started":"2023-08-13T23:29:37.733823Z","shell.execute_reply":"2023-08-13T23:29:38.120288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''from sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Split data into features (X) and target (y)\nX = df.drop(columns=['Item', 'Company'])\ny = df['Item']\n\n# Split data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train a decision tree classifier\nmodel = DecisionTreeClassifier()\nmodel.fit(X_train, y_train)\n\n# Make predictions\npredictions = model.predict(X_test)\n\n# Evaluate model accuracy\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Model Accuracy:\", accuracy)'''","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:38.122973Z","iopub.execute_input":"2023-08-13T23:29:38.123301Z","iopub.status.idle":"2023-08-13T23:29:38.130127Z","shell.execute_reply.started":"2023-08-13T23:29:38.123259Z","shell.execute_reply":"2023-08-13T23:29:38.129018Z"},"trusted":true},"execution_count":null,"outputs":[]}]}