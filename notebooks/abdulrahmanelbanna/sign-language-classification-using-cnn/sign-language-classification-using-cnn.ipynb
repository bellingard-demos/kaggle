{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-19T06:09:53.674257Z","iopub.execute_input":"2023-09-19T06:09:53.674908Z","iopub.status.idle":"2023-09-19T06:10:00.508522Z","shell.execute_reply.started":"2023-09-19T06:09:53.674873Z","shell.execute_reply":"2023-09-19T06:10:00.507461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout,Conv2D,MaxPool2D,Flatten\n\nfrom tensorflow.keras.optimizers import Adam, SGD\n\nfrom keras.callbacks import ReduceLROnPlateau,EarlyStopping\n","metadata":{"execution":{"iopub.status.busy":"2023-09-19T06:10:00.510882Z","iopub.execute_input":"2023-09-19T06:10:00.511907Z","iopub.status.idle":"2023-09-19T06:10:09.529395Z","shell.execute_reply.started":"2023-09-19T06:10:00.51186Z","shell.execute_reply":"2023-09-19T06:10:09.528297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def segmentation(frame,thresshold=30):\n    global background\n    \n    difference = cv2.absdiff(background.astype(\"uint8\"), frame)\n    _,processed_frame=cv2.threshold(difference,thresshold,255,cv2.THRESH_BINARY)\n    contours,_=cv2.findContours(processed_frame,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n    if len(contours) == 0:\n        return None\n    else:\n        contour = max(contours,key = cv2.contourArea)\n    return (processed_frame,contour)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T06:10:26.677557Z","iopub.execute_input":"2023-09-19T06:10:26.678286Z","iopub.status.idle":"2023-09-19T06:10:26.687632Z","shell.execute_reply.started":"2023-09-19T06:10:26.67825Z","shell.execute_reply":"2023-09-19T06:10:26.685528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# collecting data","metadata":{}},{"cell_type":"code","source":"# cam = cv2.VideoCapture(0)\n\n# #roi - region of interest\n# top=50\n# bottom=300\n# right=50\n# left=250\n    \n    \n# background=None\n# count = 0\n\n# digit=0\n\n# sample_number=0\n# while True: \n#     value , frame = cam.read()\n#     framecopy=frame.copy()\n#     framecopy=cv2.flip(framecopy,1)\n#     roi = framecopy[top:bottom,right:left]\n#     roi_gray=cv2.cvtColor(roi,cv2.COLOR_BGR2GRAY)\n#     roi_gray=cv2.GaussianBlur(roi_gray,(9,9),0)\n    \n#     if background is None:\n#         background = roi_gray.copy().astype('float')\n    \n    \n    \n#     cv2.rectangle(framecopy,(left,top),(right,bottom),(0,0,255),3)\n#     if count < 30:\n#         cv2.accumulateWeighted(roi_gray,background,0.5)\n#         cv2.putText(framecopy,'Loading...',(280,200),cv2.FONT_HERSHEY_SIMPLEX,1.5,(255,255,255),3)\n\n#     collection = segmentation(roi_gray)\n#     k = cv2.waitKey(1)\n\n#     if collection is not None:\n#         roi_processed,contour=collection\n#         cv2.drawContours(framecopy,[contour+(right,top)],-1,(0,255,0),3)\n        \n#         if k == ord(\" \"):\n#             cv2.putText(framecopy,str(sample_number)+' Gesture('+str(digit)+' )',(70,45),cv2.FONT_HERSHEY_SIMPLEX,1.5,(255,255,255),3)\n#             cv2.imwrite(\"D:/acpc/train_/\"+str(digit)+'/'+str(digit)+'-'+str(sample_number)+'.jpg',roi_processed)\n#             sample_number+=1\n            \n#         cv2.imshow('Segmantation',roi_processed)\n        \n#     cv2.putText(framecopy,'Gesture( '+str(digit)+' )',(50,340),cv2.FONT_HERSHEY_SIMPLEX,1.5,(255,255,255),1)\n\n#     cv2.imshow('Camera',framecopy)\n\n#     count+=1\n#     if k == 27:\n#         break\n#     elif k == 13:\n#         digit = (digit+1) % 11\n#         sample_number=0\n        \n        \n        \n    \n# cv2.destroyAllWindows()\n# cam.release()","metadata":{"execution":{"iopub.status.busy":"2023-09-19T06:16:19.94337Z","iopub.execute_input":"2023-09-19T06:16:19.943685Z","iopub.status.idle":"2023-09-19T06:16:19.950567Z","shell.execute_reply.started":"2023-09-19T06:16:19.943658Z","shell.execute_reply":"2023-09-19T06:16:19.949364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_path=\"/kaggle/input/sign-language-digits/sign-language-digits/train/\"\ntrain_data_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=train_data_path, target_size=(64,64), class_mode='categorical', batch_size=10, shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-19T06:12:17.200856Z","iopub.execute_input":"2023-09-19T06:12:17.201262Z","iopub.status.idle":"2023-09-19T06:12:17.51895Z","shell.execute_reply.started":"2023-09-19T06:12:17.20123Z","shell.execute_reply":"2023-09-19T06:12:17.517632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_train , labels_train = next(train_data_batches)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T06:12:27.163074Z","iopub.execute_input":"2023-09-19T06:12:27.163878Z","iopub.status.idle":"2023-09-19T06:12:27.225735Z","shell.execute_reply.started":"2023-09-19T06:12:27.16383Z","shell.execute_reply":"2023-09-19T06:12:27.224731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_path = \"/kaggle/input/sign-language-digits/sign-language-digits/test/\"\ntest_data_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=test_data_path, target_size=(64,64), class_mode='categorical', batch_size=10, shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-19T06:13:00.59849Z","iopub.execute_input":"2023-09-19T06:13:00.598873Z","iopub.status.idle":"2023-09-19T06:13:00.837921Z","shell.execute_reply.started":"2023-09-19T06:13:00.598844Z","shell.execute_reply":"2023-09-19T06:13:00.836692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_test , labels_test = next(test_data_batches)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T06:13:06.488597Z","iopub.execute_input":"2023-09-19T06:13:06.488999Z","iopub.status.idle":"2023-09-19T06:13:06.641247Z","shell.execute_reply.started":"2023-09-19T06:13:06.48896Z","shell.execute_reply":"2023-09-19T06:13:06.640373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display(images):\n    fig,axes = plt.subplots(1,10,figsize=(30,20))\n    for image ,ax in zip(images,axes):\n        image=np.clip(image,0,1)\n        ax.imshow(image)\n        ax.axis('off')\n        \n    plt.tight_layout\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-19T06:13:10.721886Z","iopub.execute_input":"2023-09-19T06:13:10.722318Z","iopub.status.idle":"2023-09-19T06:13:10.72959Z","shell.execute_reply.started":"2023-09-19T06:13:10.722282Z","shell.execute_reply":"2023-09-19T06:13:10.728191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(images_train)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T06:13:17.76569Z","iopub.execute_input":"2023-09-19T06:13:17.76607Z","iopub.status.idle":"2023-09-19T06:13:18.231338Z","shell.execute_reply.started":"2023-09-19T06:13:17.766037Z","shell.execute_reply":"2023-09-19T06:13:18.230184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words = {0:'zero',1:'one',2:'two',3:'three',4:'four',5:'five',6:'sex',7:'seven',8:'eight',9:'nine',10:'ten'}","metadata":{"execution":{"iopub.status.busy":"2023-09-19T06:13:24.066044Z","iopub.execute_input":"2023-09-19T06:13:24.06646Z","iopub.status.idle":"2023-09-19T06:13:24.072617Z","shell.execute_reply.started":"2023-09-19T06:13:24.066428Z","shell.execute_reply":"2023-09-19T06:13:24.07111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(images_test)\n\ndef digits(labels):\n    for label in labels:\n        print(words[np.argmax(label)],end=\" \")\n        \ndigits(labels_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T06:13:31.144233Z","iopub.execute_input":"2023-09-19T06:13:31.144636Z","iopub.status.idle":"2023-09-19T06:13:31.811902Z","shell.execute_reply.started":"2023-09-19T06:13:31.144605Z","shell.execute_reply":"2023-09-19T06:13:31.809076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def createModel():\n    model = Sequential()\n    \n    model.add(Conv2D(filters=32,kernel_size=(3,3), activation='relu',input_shape=(64,64,3)))\n    model.add(MaxPool2D(pool_size=(2,2),strides=2))\n    \n    model.add(Conv2D(filters=64,kernel_size=(3,3), activation='relu',padding='same'))\n    model.add(MaxPool2D(pool_size=(2,2),strides=2))\n        \n    model.add(Conv2D(filters=128,kernel_size=(3,3), activation='relu',padding='valid'))\n    model.add(MaxPool2D(pool_size=(2,2),strides=2))\n    \n    model.add(Flatten())\n    \n    model.add(Dense(64,activation='relu'))\n    model.add(Dense(128,activation='relu'))\n    model.add(Dropout(.2))\n    model.add(Dense(128,activation='relu'))\n    model.add(Dense(10,activation='softmax'))\n    \n    return model\n\nmodel=createModel()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-19T06:13:46.568968Z","iopub.execute_input":"2023-09-19T06:13:46.56993Z","iopub.status.idle":"2023-09-19T06:13:46.851249Z","shell.execute_reply.started":"2023-09-19T06:13:46.569882Z","shell.execute_reply":"2023-09-19T06:13:46.850301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=Adam(learning_rate=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n\nreduceLR = ReduceLROnPlateau(monitor='val_loss',factor=0.2,patience=1,min_lr=0.0005)\nearly_stop = EarlyStopping(monitor='val_loss',min_delta=0,patience=1,mode='auto',verbose=0)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T06:13:53.367748Z","iopub.execute_input":"2023-09-19T06:13:53.368177Z","iopub.status.idle":"2023-09-19T06:13:53.389689Z","shell.execute_reply.started":"2023-09-19T06:13:53.368142Z","shell.execute_reply":"2023-09-19T06:13:53.388467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(train_data_batches,epochs=10,callbacks=[reduceLR,early_stop],validation_data=test_data_batches)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T06:14:02.575741Z","iopub.execute_input":"2023-09-19T06:14:02.576174Z","iopub.status.idle":"2023-09-19T06:16:19.941298Z","shell.execute_reply.started":"2023-09-19T06:14:02.576136Z","shell.execute_reply":"2023-09-19T06:16:19.940155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = model.evaluate(images_test,labels_test,verbose=0)\nprint(f'{model.metrics_names[0]} = {score[0]} || {model.metrics_names[1]} = {score[1]*100}%')","metadata":{"execution":{"iopub.status.busy":"2023-09-19T06:16:23.303706Z","iopub.execute_input":"2023-09-19T06:16:23.304204Z","iopub.status.idle":"2023-09-19T06:16:23.472537Z","shell.execute_reply.started":"2023-09-19T06:16:23.304161Z","shell.execute_reply":"2023-09-19T06:16:23.470739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# testing","metadata":{}},{"cell_type":"code","source":"# cam = cv2.VideoCapture(0)\n# #roi - region of interest\n# top=50\n# bottom=300\n# right=50\n# left=250\n    \n    \n# background=None\n# count = 0\n\n# digit=0\n\n# sample_number=0\n# while True: \n#     value , frame = cam.read()\n#     framecopy=frame.copy()\n#     framecopy=cv2.flip(framecopy,1)\n#     roi = framecopy[top:bottom,right:left]\n#     roi_gray=cv2.cvtColor(roi,cv2.COLOR_BGR2GRAY)\n#     roi_gray=cv2.GaussianBlur(roi_gray,(9,9),0)\n    \n#     if background is None:\n#         background = roi_gray.copy().astype('float')\n    \n    \n    \n#     cv2.rectangle(framecopy,(left,top),(right,bottom),(0,0,255),3)\n#     if count < 30:\n#         cv2.accumulateWeighted(roi_gray,background,0.5)\n#         cv2.putText(framecopy,'Loading...',(280,200),cv2.FONT_HERSHEY_SIMPLEX,1.5,(255,255,255),3)\n\n#     collection = segmentation(roi_gray)\n#     k = cv2.waitKey(1)\n\n#     if collection is not None:\n#         roi_processed,contour=collection\n#         cv2.drawContours(framecopy,[contour+(right,top)],-1,(0,255,0),3)\n        \n#         roi_processed = cv2.resize(roi_processed,(64,64))\n#         roi_processed = cv2.cvtColor(roi_processed,cv2.COLOR_GRAY2RGB)\n#         frame = np.reshape(roi_processed,(1,roi_processed.shape[0],roi_processed.shape[1],3))\n        \n#         value = model4.predict(frame)\n#         label = words[np.argmax(value)]\n#         cv2.putText(framecopy,str(label),(370,145),cv2.FONT_HERSHEY_SIMPLEX,1.5,(255,255,255),3)\n#         if k == ord(\" \"):\n#             cv2.putText(framecopy,str(sample_number)+' Gesture('+str(digit)+' )',(70,45),cv2.FONT_HERSHEY_SIMPLEX,1.5,(255,255,255),3)\n#             cv2.imwrite(\"D:/hema/asl_dataset/\"+str(digit)+'/'+str(digit)+'-'+str(sample_number)+'.jpg',roi_processed)\n#             sample_number+=1\n            \n#         cv2.imshow('Segmantation',roi_processed)\n        \n#     cv2.putText(framecopy,'Gesture( '+str(digit)+' )',(50,340),cv2.FONT_HERSHEY_SIMPLEX,1.5,(255,255,255),1)\n\n#     cv2.imshow('Camera',framecopy)\n\n#     count+=1\n#     if k == 27:\n#         break\n#     elif k == 13:\n#         digit = (digit+1) % 11\n#         sample_number=0\n        \n        \n    \n# cv2.destroyAllWindows()\n# cam.release()","metadata":{"execution":{"iopub.status.busy":"2023-09-19T06:17:13.889544Z","iopub.execute_input":"2023-09-19T06:17:13.889914Z","iopub.status.idle":"2023-09-19T06:17:13.897339Z","shell.execute_reply.started":"2023-09-19T06:17:13.889884Z","shell.execute_reply":"2023-09-19T06:17:13.896151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}