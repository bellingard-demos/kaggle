{"cells":[{"metadata":{"_cell_guid":"fa2d52ce-9a59-4fd5-951c-765288cb05ab","_uuid":"07fcca81e3292f6a119b81a396896bf3a263afde"},"cell_type":"markdown","source":"# Predicting the selection of comments on NYT articles as editor's picks"},{"metadata":{"_cell_guid":"3614b3dd-bf93-4a9c-8152-f8006e2f5ccc","_uuid":"ecfc8ce3b2d96d259b1523a06ccc961992728734"},"cell_type":"markdown","source":"For most articles on New York Times articles that are open to comments, there is a selection of comments' called NYT's pick. The [dataset here](https://www.kaggle.com/aashita/nyt-comments) contains the comments' text along with many features including the feature `editorsSelection` that indicates whether a comment was picked by NYT as editor's selection. Two classifiers are trained to predict the probablities for the comments to be selected as NYT's picks.\n\nThe first classifier uses Logistic Regression coupled with Latent Semantic Analysis (LSA) and the second classifier uses NB-Logistic Regression model inspired from the paper [Baselines and Bigrams: Simple, Good Sentiment and Topic Classiﬁcation](https://nlp.stanford.edu/pubs/sidaw12_simple_sentiment.pdf) by Sida Wang and Chris Manning and previously used in [Toxic Comments Classification kernel by Jeremy Howard](https://www.kaggle.com/jhoward/nb-svm-strong-linear-baseline)."},{"metadata":{"_cell_guid":"65a4e40e-37da-4e11-906d-a738c966b15e","_uuid":"b921503a65e32cbf91acbf669aefc84401434d41"},"cell_type":"markdown","source":"First we import the relevant python modules and get the data:"},{"metadata":{"_cell_guid":"c5b13091-99ac-49dc-9db2-8a3a1278470d","_uuid":"06c03262a35c0a9fec6c9748a2052043458fa1f2","collapsed":true,"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.model_selection import GroupKFold, GridSearchCV\nfrom sklearn.metrics import (roc_auc_score, classification_report, log_loss, make_scorer, \n                             recall_score, precision_recall_curve, roc_curve)\n\nimport gc\nfrom time import time\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n%matplotlib inline\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5ccfb988-5ef0-4a7a-892f-968a7f40d403","_uuid":"bd06c1043d7e5ce07cc5ae66bbb4dbd9c1cb1ef1","collapsed":true,"trusted":true},"cell_type":"code","source":"c1 = pd.read_csv('../input/CommentsJan2017.csv')\nc2 = pd.read_csv('../input/CommentsFeb2017.csv')\nc3 = pd.read_csv('../input/CommentsMarch2017.csv')\nc4 = pd.read_csv('../input/CommentsApril2017.csv')\nc5 = pd.read_csv('../input/CommentsMay2017.csv')\nc6 = pd.read_csv('../input/CommentsJan2018.csv')\nc7 = pd.read_csv('../input/CommentsFeb2018.csv')\nc8 = pd.read_csv('../input/CommentsMarch2018.csv')\nc9 = pd.read_csv('../input/CommentsApril2018.csv')\ncomments = pd.concat([c1, c2, c3, c4, c5, c6, c7, c8, c9])\ncomments.drop_duplicates(subset='commentID', inplace=True)\ncomments.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ace911f9-1228-40d7-9cb8-f4b1607b0b26","_uuid":"105a3ac2fb2afb168430ad6419617bacb908aee2","collapsed":true,"trusted":true},"cell_type":"code","source":"comments.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8eb6420e-8090-4370-93fa-cd09e399a1b1","_uuid":"425cde04b4013df05457e2cf583b5d3263c9f079"},"cell_type":"markdown","source":"The comments dataset contains many features, but for the starter model we will use only the text of the comments given by the column `commentBody`."},{"metadata":{"_cell_guid":"d184f5a6-72b1-425d-aabd-70676f4c1ae8","_uuid":"49e9cd5e78b15c03cdd9b0c7a85b01407b907fd9","collapsed":true,"trusted":true},"cell_type":"code","source":"comments.columns","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a9aa796b-2606-4003-baae-7b43cd1adb4f","_uuid":"254c9997ae8a3b538d4afecbfd13c2c68ac91ede"},"cell_type":"markdown","source":"## Steps:\n* Balance the classes to some extent by undersampling the majority class.\n* Obtain the tf-idf vectors for words and character n-grams using `TDIDFVectorizer` and `FeatureUnion`.\n* Train the first classifier that uses Logistic Regression coupled with Latent Semantic Analysis (LSA).\n* Train the second classifier that uses NB-Logistic Regression model inspired from the paper [Baselines and Bigrams: Simple, Good Sentiment and Topic Classiﬁcation](https://nlp.stanford.edu/pubs/sidaw12_simple_sentiment.pdf) by Sida Wang and Chris Manning and previously used in [Toxic Comments Classification kernel by Jeremy Howard](https://www.kaggle.com/jhoward/nb-svm-strong-linear-baseline).\n* Compare the two classifiers by plotting the ROC and Precision-Recall curve."},{"metadata":{"_cell_guid":"1e9e5310-1ffa-4e64-a463-85a2d659ab6d","_uuid":"da5d61a0282e97ef0fdcf71ba8cf91033bce5b96","collapsed":true,"trusted":true},"cell_type":"code","source":"plt.axis('equal')\nplt.pie(comments.editorsSelection.value_counts(), labels=(\"\", \"NYT's pick\"));\nplt.title(\"Before balancing the classes\");","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f8524146-6c9f-4be4-a95f-7acaba0b1eda","_uuid":"dc1564f7d98577a0bb574a7cbd7d25192638051f"},"cell_type":"markdown","source":"The two classes are highly imbalanced with an  approxatimate ratio of 20:1. We will bring it down to less than 3:1 by undersampling the majority class. First we discard all the comments from articles that have no comments picked as Editor's selection. From the remaining articles, we randomly pick comments from the majority class so as to have a ratio of 3:1."},{"metadata":{"_cell_guid":"8028d937-4c05-4df3-b810-89aee6cbb0ad","_uuid":"777188115129f8cccea0874ce61756a5057b7b71","collapsed":true,"trusted":true},"cell_type":"code","source":"ratio = 3\ndef balance_classes(grp):\n    picked = grp.loc[grp.editorsSelection == True]\n    n = round(picked.shape[0]*ratio)\n    if n:        \n        try:\n            not_picked = grp.loc[grp.editorsSelection == False].sample(n)\n        except: # In case, fewer than n comments with `editorsSelection == False`\n            not_picked = grp.loc[grp.editorsSelection == False]\n        balanced_grp = pd.concat([picked, not_picked])\n        return balanced_grp\n    else: # If no editor's pick for an article, dicard all comments from that article\n        return None \n\ncomments = comments.groupby('articleID').apply(balance_classes).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7ab960b5-5fe1-4435-9894-daac0d137d09","_uuid":"84049969de55ce006c98929acce6a0e2fcf8a6d7","collapsed":true,"trusted":true},"cell_type":"code","source":"plt.axis('equal')\nplt.pie(comments.editorsSelection.value_counts(), labels=(\"\", \"NYT's pick\"));\nplt.title(\"After balancing the classes\");","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d43b68b1-a940-4970-90aa-a18697a44b19","_uuid":"6117a80c5fb69bc0dba13603f6956a8d80d8042e","collapsed":true,"trusted":true},"cell_type":"code","source":"comments.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"771bddc9-bbde-4b0c-80c0-428a97eb0522","_uuid":"ca4bfe209a609affb98c4c8bc7aae8e2ce854bf6"},"cell_type":"markdown","source":"Our goal is to predict the probabilty that a given comment is picked by NYT as editor's selection. So the target variable is given by the column `editorsSelection`. We are training the classifier on `commentBody` and keeping `articleID` to partition the comments into train, test, validation sets below such that they do not share comments from the same article. Thus, we need only three features `articleID`, `commentBody` and `editorsSelection`."},{"metadata":{"_cell_guid":"dc8deb6f-22b5-4f70-97b7-f00672d6cb50","_uuid":"4e1f2c01ea77f8aed2a39405b840a75c12703910","collapsed":true,"trusted":true},"cell_type":"code","source":"commentBody = comments.commentBody\nnytpicks = comments.editorsSelection\narticleID = comments.articleID","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"22190628-8a1c-40c2-81c1-87f8e4f416d1","_uuid":"25b901fe684effec89809ff566605dcbfb8020ab"},"cell_type":"markdown","source":"Now we delete the comments dataframe to free up space."},{"metadata":{"_cell_guid":"8f888a0b-357f-4699-954f-70d1365e3e5e","_uuid":"bc1dfab2d66e74a186058df881db6995df3f25fd","collapsed":true,"trusted":true},"cell_type":"code","source":"# Delete comments dataframe since it is no longer needed\ndel comments\n\n# Collect residual garbage\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1f6e71c2-116f-4f4e-b0ed-a11bc9d8574b","_uuid":"ab23bf9899b9c368682d28526e218e5966b22297"},"cell_type":"markdown","source":"We split the data into train and test sets such that the two sets have comments from disjoint set of articles. This is achieved using `GroupKFold`."},{"metadata":{"_cell_guid":"f5427c64-3deb-4477-ac47-05e22e5f3e6d","_uuid":"e7f2a20c93a3ca2ce737e7e159aebf7975c57832","collapsed":true,"trusted":true},"cell_type":"code","source":"for train_index, test_index in GroupKFold(n_splits=5).split(commentBody, nytpicks, groups=articleID):\n    train_text, test_text = commentBody[train_index], commentBody[test_index] \n    train_target, test_target = nytpicks[train_index], nytpicks[test_index]\n    train_groups, test_groups = articleID[train_index], articleID[test_index]\n    \nprint(\"Number of comments for training:\", train_text.shape[0])\nprint(\"Number of comments for testing:\", test_text.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2056c85c-5525-48aa-85a3-53d9628757cd","_uuid":"7b45532d823b45d03ee62ec30ebce9c2d74b48d2"},"cell_type":"markdown","source":"Next we get features using TFIDF for words and character n-grams and combine them using `FeatureUnion`:"},{"metadata":{"_cell_guid":"c81b9656-3cc2-4e0f-97ea-3676a3742dbf","_uuid":"a7a321a0c9457c18e49dc8c19d09a029590b7ee8","collapsed":true,"trusted":true},"cell_type":"code","source":"vectorizer = FeatureUnion([\n    ('word_tfidf', TfidfVectorizer(\n    analyzer='word',\n    token_pattern=r'\\w{1,}',\n    ngram_range=(1, 2),\n    max_features=600,\n    )),\n    \n    ('char_tfidf', TfidfVectorizer(\n    analyzer='char',\n    ngram_range=(2, 4),\n    max_features=600,\n    ))\n])\nstart_vect = time()\nvectorizer.fit(commentBody)\ntrain_text = vectorizer.transform(train_text)\ntest_text = vectorizer.transform(test_text)\n\nprint(\"Vectorization Runtime: %0.2f Minutes\"%((time() - start_vect)/60))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ec021f1e-e2c4-435c-93e4-8504c5585608","_uuid":"ba83c3fffb7aafb7fd8541265d8334eda5cd0ebd"},"cell_type":"markdown","source":"Here we use Latent Semantic Analysis (LSA) to perform dimensionality reduction on the tf-idf vectors and then train the Logistic regression to make predictions. LSA is implemented as `TruncatedSVD` in sklearn. "},{"metadata":{"_cell_guid":"fdbc8b4d-42dc-41f0-9189-a91a5690e6cf","_uuid":"ed8aee510eac7d478e3e5ca32e32926278ba1d27","collapsed":true,"trusted":true},"cell_type":"code","source":"clf_logistic = Pipeline([\n    ('lsa', TruncatedSVD(n_components=1000, random_state=0)), \n    ('logistic', LogisticRegression(C=150))  \n])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ab091ae1-f7ee-452e-b9e2-ff77a6c71017","_uuid":"d5b6c33c0bdb780232d1eed63d17848626e44cbf"},"cell_type":"markdown","source":"Using `GridSearchCV`, we find the optimal parameters for the model. Since the classes are imbalanced, we use `recall_score` as the metric. We again use `GroupKFold` for splitting the data into train and validation sets so that the comments from the same article are not mixed up. On account of the time it takes to run the kernel, the tuned parameters obtained are used in the model below without running the `GridSearchCV` here."},{"metadata":{"_cell_guid":"c40f37e8-adc1-46fc-8212-7bb1e4b18a35","_uuid":"ee948e40dae1cf7c0d8f7318da7867bce7e9ee13","collapsed":true,"trusted":true},"cell_type":"code","source":"# def grid_search_cv(param_grid, clf):\n#     gkf = GroupKFold(n_splits=3).split(train_text, train_target, groups=train_groups)\n#     scorer = make_scorer(recall_score)\n#     \n#     grid_search = GridSearchCV(clf, param_grid=param_grid, cv=gkf, scoring=scorer)\n#     grid_search.fit(train_text, train_target)\n#     `\n#     print(\"Best parameters found:\")\n#     print(grid_search.best_params_)\n#     print()\n#     print(\"Best score:\")\n#     print(grid_search.best_score_)\n#     print()\n#     \n#     test_prediction = grid_search.predict(test_text)\n#     print(\"Classification report:\")\n#     print(classification_report(test_target, test_prediction))\n#     \n#     test_prediction_proba = grid_search.predict_proba(test_text)[:, 1]\n#     score = roc_auc_score(test_target, test_prediction_proba)\n#     print(\"ROC AUC Score: \", round(score, 4)) \n#     \n#     score = log_loss(test_target, test_prediction_proba)\n#     print(\"logloss: \", round(score, 4))\n#     return test_prediction_proba","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2d7fa337-d668-4ecd-bc3d-ab8d972fcde4","_uuid":"d299effdf2ce00edab1c476057a328476bed6888","collapsed":true,"trusted":true},"cell_type":"code","source":"# param_grid = [\n#     {'logistic__C': [150, 200]},\n#     {'logistic__class_weight_balanced': [True, False]},\n# ]\n# \n# start_vect = time()\n# \n# test_prediction_proba_logistic = grid_search_cv(param_grid, clf_logistic)\n# \n# print()\n# print(\"Runtime for running GridSearchCV on logistic regression model and predicting probabilities for the test set is %0.2f Minutes\"%((time() - start_vect)/60))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d691f657-1965-4d61-8c46-597daa25ed63","_uuid":"501afd45218d74c584b9ef5bb0ccbe958e7ea6a0"},"cell_type":"markdown","source":"Now we train the classifier:"},{"metadata":{"_cell_guid":"bdf6e4f1-d870-4237-9313-fafdba545445","_uuid":"1cd1605e8f9ef21f09526967ae651272f39d8c58","collapsed":true,"trusted":true},"cell_type":"code","source":"def train_model(clf):\n    clf.fit(train_text, train_target)\n    \n    test_prediction = clf.predict(test_text)\n    print(\"Classification report:\")\n    print(classification_report(test_target, test_prediction))\n    \n    test_prediction_proba = clf.predict_proba(test_text)[:, 1]\n    score = roc_auc_score(test_target, test_prediction_proba)\n    print(\"ROC AUC Score: \", round(score, 4)) \n    \n    score = log_loss(test_target, test_prediction_proba)\n    print(\"logloss: \", round(score, 4))\n    return test_prediction_proba","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"737b61bb-296d-4425-8d9c-fbe8b126d34a","_uuid":"a6f3ceb9d2b374de2261b289bb17ac9ae268ff54","collapsed":true,"trusted":true},"cell_type":"code","source":"start_vect = time()\n\ntest_prediction_proba_logistic = train_model(clf_logistic)\n\nprint()\nprint(\"Runtime for training logistic regression model and predicting probabilities for the test set is %0.2f Minutes\"%((time() - start_vect)/60))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0ded81f0-e9d8-4340-81a0-1a837cb144dc","_uuid":"ebf58793e15430859bb6418297bc5c0c5c3b6eaa"},"cell_type":"markdown","source":"Next we train another classifier inspired from the paper [Baselines and Bigrams: Simple, Good Sentiment and Topic Classiﬁcation](https://nlp.stanford.edu/pubs/sidaw12_simple_sentiment.pdf) by Sida Wang and Chris Manning and previously used in [Toxic Comments Classification kernel by Jeremy Howard](https://www.kaggle.com/jhoward/nb-svm-strong-linear-baseline) that combines Naive Bayes with Logistic Regression.\n\nWe start by defining a class for the NB-logistic model:"},{"metadata":{"_cell_guid":"905b6d72-1217-47a3-8d65-d78e2c444029","_uuid":"74d124cc58c1d9f67f0dff6efa5ddbf78a655b77","collapsed":true,"trusted":true},"cell_type":"code","source":"class NB_logistic(LogisticRegression, BaseEstimator):\n    def __init__(self, r=None, C=1, solver='sag', class_weight_balanced=False):\n        self.r = r\n        if class_weight_balanced:\n            super().__init__(C=C, solver=solver, class_weight='balanced')\n        else:\n            super().__init__(C=C, solver=solver)\n        \n    def pr(self, X, y, y_i):\n        p = X[np.where(y==y_i)[0]].sum(0)+1\n        return (p+1)/((y==y_i).sum()+1)\n\n    def fit(self, X, y):\n        self.r = np.log(self.pr(X, y, 1) / self.pr(X, y, 0))\n        X_nb = X.multiply(self.r)\n        super().fit(X_nb, y)\n        return self\n    \n    def predict(self, X):\n        X_nb = X.multiply(self.r)\n        return super().predict(X_nb)\n    \n    def predict_proba(self, X):\n        X_nb = X.multiply(self.r)\n        return super().predict_proba(X_nb)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b02f515a-9242-47d6-a3f7-1232d1dd83dd","_uuid":"0615bfb87fc6f1aac4665c3f1409057a39a3778b","collapsed":true,"trusted":true},"cell_type":"code","source":"clf_nb_logistic = NB_logistic()\n\nstart_vect = time()\n\ntest_prediction_proba_nb_logistic = train_model(clf_nb_logistic)\n\nprint(\"Runtime for running GridSearchCV on NB-logistic regression model and predicting probabilities for the test set is %0.2f Minutes\"%((time() - start_vect)/60))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"818eb036-6025-4d9c-b5a8-3fd7cc991107","_uuid":"f2e389878ccd3fa9f17b0c2115b48ac37b106522"},"cell_type":"markdown","source":"Lastly, we compare the two classifier by plotting the respective ROC and Precision-Recall curves:"},{"metadata":{"_cell_guid":"68c22360-7ea3-4ce3-b113-734231bf9ad5","_uuid":"ae6f7aa549c9d56424e3cb80b07c429100b32f14","collapsed":true,"trusted":true},"cell_type":"code","source":"def curves(test_prediction_proba):\n    p, r, _ = precision_recall_curve(test_target, test_prediction_proba)\n    tpr, fpr, _ = roc_curve(test_target, test_prediction_proba)\n    return p, r, tpr, fpr\n\nfig = plt.figure(figsize=(12,24))\n\nax1 = fig.add_subplot(2,1,1)\nax1.set_xlim([-0.05,1.05])\nax1.set_ylim([-0.05,1.05])\nax1.set_xlabel('Recall')\nax1.set_ylabel('Precision')\nax1.set_title('PR Curve')\n\nax2 = fig.add_subplot(2,1,2)\nax2.set_xlim([-0.05,1.05])\nax2.set_ylim([-0.05,1.05])\nax2.set_xlabel('False Positive Rate')\nax2.set_ylabel('True Positive Rate')\nax2.set_title('ROC Curve')\n\n\np, r, tpr, fpr = curves(test_prediction_proba_logistic) \nax1.plot(r, p, c='g', label=\"Logistic with LSA\")\nax2.plot(tpr, fpr, c='g', label=\"Logistic with LSA\")\n\np, r, tpr, fpr = curves(test_prediction_proba_nb_logistic) \nax1.plot(r, p, c='r', label=\"NB-Logistic\")\nax2.plot(tpr, fpr, c='r', label=\"NB-Logistic\") \n\nax1.legend(loc='lower left')    \nax2.legend(loc='lower right')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6c437cc0-dbae-49b6-a69d-28755007b168","_uuid":"b28975f5dffdf9f9cb28425657cbdac549c5b3c9"},"cell_type":"markdown","source":"The two classifiers are very similar in performance and they both form a strong baseline for predicting the selection of comments on NYT articles as editor's picks with reasonably good ROC score of 0.72. In the next kernel, I will use pre-trained word embedding with RNN and try to improve the performance."},{"metadata":{"_cell_guid":"14c8fc8d-be0b-43f0-8dc8-438a98d5f9e0","_uuid":"74f11895dfefe88689bf35835a4831ccc4739856"},"cell_type":"markdown","source":"#### References:\n* https://www.kaggle.com/jhoward/nb-svm-strong-linear-baseline\n* https://www.kaggle.com/metadist/work-like-a-pro-with-pipelines-and-feature-unions\n* https://www.kaggle.com/lct14558/imbalanced-data-why-you-should-not-use-roc-curve/notebook"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}