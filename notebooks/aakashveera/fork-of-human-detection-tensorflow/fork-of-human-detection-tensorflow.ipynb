{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q efficientnet","metadata":{"execution":{"iopub.status.busy":"2022-01-13T02:20:47.874882Z","iopub.execute_input":"2022-01-13T02:20:47.875198Z","iopub.status.idle":"2022-01-13T02:20:56.461591Z","shell.execute_reply.started":"2022-01-13T02:20:47.875116Z","shell.execute_reply":"2022-01-13T02:20:56.460775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nimport random\nimport cv2\nfrom PIL import Image\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nimport efficientnet.tfkeras as efn\n\nfrom sklearn.metrics import classification_report\nfrom tqdm import tqdm\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-13T02:20:56.463524Z","iopub.execute_input":"2022-01-13T02:20:56.463838Z","iopub.status.idle":"2022-01-13T02:21:02.26594Z","shell.execute_reply.started":"2022-01-13T02:20:56.463798Z","shell.execute_reply":"2022-01-13T02:21:02.26526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=2020):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    \nseed_everything(42)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T02:21:02.267154Z","iopub.execute_input":"2022-01-13T02:21:02.267418Z","iopub.status.idle":"2022-01-13T02:21:02.274437Z","shell.execute_reply.started":"2022-01-13T02:21:02.267383Z","shell.execute_reply":"2022-01-13T02:21:02.272812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T02:21:02.276199Z","iopub.execute_input":"2022-01-13T02:21:02.276442Z","iopub.status.idle":"2022-01-13T02:21:02.438248Z","shell.execute_reply.started":"2022-01-13T02:21:02.276405Z","shell.execute_reply":"2022-01-13T02:21:02.437569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg = dict(\n           batch_size=32,\n           img_size=350,\n    \n           lr_start=0.000005,\n           lr_max=0.00000125,\n           lr_min=0.000001,\n           lr_rampup=5,\n           lr_sustain=0,\n           lr_decay=0.8,\n           epochs=12,\n    \n           transform_prob=1.0,\n           rot=180.0,\n           shr=2.0,\n           hzoom=8.0,\n           wzoom=8.0,\n           hshift=8.0,\n           wshift=8.0,\n    \n           optimizer='adam',\n           label_smooth_fac=0.05,\n           tta_steps=20\n            \n        )","metadata":{"execution":{"iopub.status.busy":"2022-01-13T02:21:02.43962Z","iopub.execute_input":"2022-01-13T02:21:02.43996Z","iopub.status.idle":"2022-01-13T02:21:02.447224Z","shell.execute_reply.started":"2022-01-13T02:21:02.439926Z","shell.execute_reply":"2022-01-13T02:21:02.445877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_PATH = '/kaggle/input/human-dataset/data/'\nBASE_PATH = '/kaggle/input/human-dataset-latest/human-dataset/data/'","metadata":{"execution":{"iopub.status.busy":"2022-01-13T02:21:14.213348Z","iopub.execute_input":"2022-01-13T02:21:14.213659Z","iopub.status.idle":"2022-01-13T02:21:14.217284Z","shell.execute_reply.started":"2022-01-13T02:21:14.213627Z","shell.execute_reply":"2022-01-13T02:21:14.216599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lis = os.listdir(BASE_PATH+'train/train/0/')\nlis2 = os.listdir(BASE_PATH+'train/train/1/')","metadata":{"execution":{"iopub.status.busy":"2022-01-13T02:21:14.606651Z","iopub.execute_input":"2022-01-13T02:21:14.60687Z","iopub.status.idle":"2022-01-13T02:21:15.662148Z","shell.execute_reply.started":"2022-01-13T02:21:14.606845Z","shell.execute_reply":"2022-01-13T02:21:15.661406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rows = 3\ncols = 5\nfig,axis = plt.subplots(rows,cols,figsize=(20,15))\n\nfor row in range(rows):\n    for col in range(cols):\n        axis[row][col].imshow(Image.open(BASE_PATH+\"train/train/0/\"+lis[random.randint(0,len(lis))]))","metadata":{"execution":{"iopub.status.busy":"2022-01-13T02:21:28.583098Z","iopub.execute_input":"2022-01-13T02:21:28.583394Z","iopub.status.idle":"2022-01-13T02:21:31.152568Z","shell.execute_reply.started":"2022-01-13T02:21:28.583366Z","shell.execute_reply":"2022-01-13T02:21:31.151963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rows = 3\ncols = 5\nfig,axis = plt.subplots(rows,cols,figsize=(20,15))\n\nfor row in range(rows):\n    for col in range(cols):\n        axis[row][col].imshow(Image.open(BASE_PATH+\"train/train/1/\"+lis2[random.randint(0,len(lis2))]))","metadata":{"execution":{"iopub.status.busy":"2022-01-13T02:21:40.367143Z","iopub.execute_input":"2022-01-13T02:21:40.367423Z","iopub.status.idle":"2022-01-13T02:21:43.152298Z","shell.execute_reply.started":"2022-01-13T02:21:40.367392Z","shell.execute_reply":"2022-01-13T02:21:43.151567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_l = tf.keras.Input(shape=(cfg['img_size'], cfg['img_size'], 3),\n                             name='img_input')\n\n\n\nx = efn.EfficientNetB3(include_top=False,\n                       weights='imagenet',\n                       input_shape=(cfg['img_size'], cfg['img_size'], 3),\n                       pooling='avg')(input_l)\n\noutput = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n\nmodel = tf.keras.Model(input_l,output)\n\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(),\n              metrics=[tf.keras.metrics.Precision(name='Precision'),tf.keras.metrics.Recall(name='recall'),'accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-01-13T02:21:54.602067Z","iopub.execute_input":"2022-01-13T02:21:54.602741Z","iopub.status.idle":"2022-01-13T02:22:00.549945Z","shell.execute_reply.started":"2022-01-13T02:21:54.602704Z","shell.execute_reply":"2022-01-13T02:22:00.549177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n        rescale=1./255,\n        #shear_range=0.2,\n        #zoom_range=0.3,\n        #rotation_range=10,\n        #width_shift_range=[-100,100],\n        #height_shift_range=0.4,\n        #brightness_range=[0.2,0.5],\n        #horizontal_flip=True,\n        validation_split=0.3)\n\ntest_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        BASE_PATH+'train/train',\n        target_size=(350, 350),\n        batch_size=16,\n        class_mode='binary',\n        subset='training')\n\nvalidation_generator = train_datagen.flow_from_directory(\n        BASE_PATH+'train/train',\n        target_size=(350, 350),\n        batch_size=16,\n        subset='validation',\n        class_mode='binary')\n\ntest_generator = test_datagen.flow_from_directory(\n        BASE_PATH+'val/human detection dataset/',\n        target_size=(350, 350),\n        batch_size=16,\n        class_mode='binary')","metadata":{"execution":{"iopub.status.busy":"2022-01-13T02:22:05.127345Z","iopub.execute_input":"2022-01-13T02:22:05.127613Z","iopub.status.idle":"2022-01-13T02:22:09.048412Z","shell.execute_reply.started":"2022-01-13T02:22:05.127584Z","shell.execute_reply":"2022-01-13T02:22:09.047679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir weights","metadata":{"execution":{"iopub.status.busy":"2022-01-13T02:22:25.207507Z","iopub.execute_input":"2022-01-13T02:22:25.20785Z","iopub.status.idle":"2022-01-13T02:22:25.901233Z","shell.execute_reply.started":"2022-01-13T02:22:25.207816Z","shell.execute_reply":"2022-01-13T02:22:25.900061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getLearnRateCallback(cfg):\n    \n    lr_start = cfg['lr_start']\n    lr_max = cfg['lr_max'] * strategy.num_replicas_in_sync * cfg['batch_size']\n    lr_min = cfg['lr_min']\n    lr_rampup = cfg['lr_rampup']\n    lr_sustain = cfg['lr_sustain']\n    lr_decay = cfg['lr_decay']\n\n    def lrfn(epoch):\n        if epoch < lr_rampup:\n            lr = (lr_max - lr_start) / lr_rampup * epoch + lr_start\n        elif epoch < lr_rampup + lr_sustain:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_rampup -\n                                                lr_sustain) + lr_min\n        return lr\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n    return lr_callback\n\nlr_scheduler = getLearnRateCallback(cfg)\n\nearlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=8)\n\ncheckpoint_path = \"weights/\"\n\ncp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                 save_weights_only=True,\n                                                 monitor='val_accuracy',\n                                                 mode='max',\n                                                 save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T02:22:28.362566Z","iopub.execute_input":"2022-01-13T02:22:28.36307Z","iopub.status.idle":"2022-01-13T02:22:28.371782Z","shell.execute_reply.started":"2022-01-13T02:22:28.363032Z","shell.execute_reply":"2022-01-13T02:22:28.371037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_generator,\n        epochs=50,\n        validation_data=validation_generator,\n        callbacks=[lr_scheduler,earlystopping,cp_callback])","metadata":{"execution":{"iopub.status.busy":"2022-01-13T02:22:39.463308Z","iopub.execute_input":"2022-01-13T02:22:39.46357Z","iopub.status.idle":"2022-01-13T02:29:18.022824Z","shell.execute_reply.started":"2022-01-13T02:22:39.463542Z","shell.execute_reply":"2022-01-13T02:29:18.021649Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"model_new_with_test.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-10-26T12:47:27.787761Z","iopub.status.idle":"2021-10-26T12:47:27.788626Z","shell.execute_reply.started":"2021-10-26T12:47:27.788318Z","shell.execute_reply":"2021-10-26T12:47:27.788347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model = tf.keras.models.load_model('/kaggle/input/human-detection-trained-model/model-70-30-split-good valid-accuracy-with-worst-test accuracy.h5')","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:24:41.119192Z","iopub.execute_input":"2021-10-26T13:24:41.119905Z","iopub.status.idle":"2021-10-26T13:24:48.218368Z","shell.execute_reply.started":"2021-10-26T13:24:41.119864Z","shell.execute_reply":"2021-10-26T13:24:48.21763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"actual = []\npredicted = []\n\nfor index in tqdm(range(len(validation_generator))):\n    batch = validation_generator[index]\n    for image in batch[0]:\n        res = 1*(model.predict(np.array([image])) >= 0.49)\n        predicted.append(res)\n    actual.extend(batch[1])\n    \npredicted = [x[0][0] for x in predicted]","metadata":{"execution":{"iopub.status.busy":"2022-01-13T02:29:39.44231Z","iopub.execute_input":"2022-01-13T02:29:39.442818Z","iopub.status.idle":"2022-01-13T02:32:31.587078Z","shell.execute_reply.started":"2022-01-13T02:29:39.44278Z","shell.execute_reply":"2022-01-13T02:32:31.585915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2022-01-13T02:33:16.157323Z","iopub.execute_input":"2022-01-13T02:33:16.157665Z","iopub.status.idle":"2022-01-13T02:33:16.161101Z","shell.execute_reply.started":"2022-01-13T02:33:16.157632Z","shell.execute_reply":"2022-01-13T02:33:16.160436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(actual,predicted))","metadata":{"execution":{"iopub.status.busy":"2022-01-13T02:33:17.15629Z","iopub.execute_input":"2022-01-13T02:33:17.15693Z","iopub.status.idle":"2022-01-13T02:33:17.176136Z","shell.execute_reply.started":"2022-01-13T02:33:17.156873Z","shell.execute_reply":"2022-01-13T02:33:17.175313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"actual = []\npredicted = []\n\nfor index in tqdm(range(len(test_generator))):\n    batch = test_generator[index]\n    for image in batch[0]:\n        res = 1*(model.predict(np.array([image])) >= 0.49)\n        predicted.append(res)\n    actual.extend(batch[1])\n    \npredicted = [x[0][0] for x in predicted]\n\nprint(classification_report(actual,predicted))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -r '/kaggle/input/yolov3' '/kaggle/working/'","metadata":{"execution":{"iopub.status.busy":"2021-10-26T12:58:08.457197Z","iopub.execute_input":"2021-10-26T12:58:08.457885Z","iopub.status.idle":"2021-10-26T12:58:10.573636Z","shell.execute_reply.started":"2021-10-26T12:58:08.457846Z","shell.execute_reply":"2021-10-26T12:58:10.572635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp '/kaggle/input/yolo-v3-weights/yolo.h5' '/kaggle/working/yolov3/YOLOv3/data/'","metadata":{"execution":{"iopub.status.busy":"2021-10-26T12:58:13.421789Z","iopub.execute_input":"2021-10-26T12:58:13.422423Z","iopub.status.idle":"2021-10-26T12:58:19.091036Z","shell.execute_reply.started":"2021-10-26T12:58:13.42238Z","shell.execute_reply":"2021-10-26T12:58:19.090052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd yolov3/YOLOv3","metadata":{"execution":{"iopub.status.busy":"2021-10-26T12:58:19.093213Z","iopub.execute_input":"2021-10-26T12:58:19.094154Z","iopub.status.idle":"2021-10-26T12:58:19.101262Z","shell.execute_reply.started":"2021-10-26T12:58:19.09411Z","shell.execute_reply":"2021-10-26T12:58:19.100477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport time\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom model.yolo_model import YOLO","metadata":{"execution":{"iopub.status.busy":"2021-10-26T12:58:42.840447Z","iopub.execute_input":"2021-10-26T12:58:42.841022Z","iopub.status.idle":"2021-10-26T12:58:42.850251Z","shell.execute_reply.started":"2021-10-26T12:58:42.84098Z","shell.execute_reply":"2021-10-26T12:58:42.849528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_image(img):\n\n    image = cv2.resize(img, (416, 416),interpolation=cv2.INTER_CUBIC)\n    image = np.array(image, dtype='float32')\n    image /= 255.\n    image = np.expand_dims(image, axis=0)\n\n    return image","metadata":{"execution":{"iopub.status.busy":"2021-10-26T12:58:45.999635Z","iopub.execute_input":"2021-10-26T12:58:45.999913Z","iopub.status.idle":"2021-10-26T12:58:46.007366Z","shell.execute_reply.started":"2021-10-26T12:58:45.999882Z","shell.execute_reply":"2021-10-26T12:58:46.006634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def draw(image, boxes, scores, classes, all_classes):\n\n    for box, score, cl in zip(boxes, scores, classes):\n        x, y, w, h = box\n\n        top = max(0, np.floor(x + 0.5).astype(int))\n        left = max(0, np.floor(y + 0.5).astype(int))\n        right = min(image.shape[1], np.floor(x + w + 0.5).astype(int))\n        bottom = min(image.shape[0], np.floor(y + h + 0.5).astype(int))\n\n        cv2.rectangle(image, (top, left), (right, bottom), (255, 0, 0), 2)\n        cv2.putText(image, '{0} {1:.2f}'.format(all_classes[0], score),(top, left - 6),cv2.FONT_HERSHEY_SIMPLEX,0.6, (0, 0, 255), 1,cv2.LINE_AA)\n\n        #print('class: {0}, score: {1:.2f}'.format(all_classes[cl], score))\n     #   print('box coordinate x,y,w,h: {0}'.format(box))\n\n    print()","metadata":{"execution":{"iopub.status.busy":"2021-10-26T12:58:46.198218Z","iopub.execute_input":"2021-10-26T12:58:46.198426Z","iopub.status.idle":"2021-10-26T12:58:46.206776Z","shell.execute_reply.started":"2021-10-26T12:58:46.198401Z","shell.execute_reply":"2021-10-26T12:58:46.20599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-10-26T12:58:47.813473Z","iopub.execute_input":"2021-10-26T12:58:47.814046Z","iopub.status.idle":"2021-10-26T12:58:47.817377Z","shell.execute_reply.started":"2021-10-26T12:58:47.814004Z","shell.execute_reply":"2021-10-26T12:58:47.816629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def detect_image(image, yolo, all_classes):\n    pimage = process_image(image)\n\n    start = time.time()\n    boxes, classes, scores = yolo.predict(pimage, image.shape)\n    end = time.time()\n    \n    res = 0\n    \n    if classes is not None:\n        if 0 in classes:\n            res = 1\n            #print('Intruder Alert')\n\n    #print('time: {0:.2f}s'.format(end - start))\n\n    #if boxes is not None:\n    #    draw(image, boxes, scores, classes, all_classes)\n    return res\n","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:20:29.437912Z","iopub.execute_input":"2021-10-26T13:20:29.438248Z","iopub.status.idle":"2021-10-26T13:20:29.446686Z","shell.execute_reply.started":"2021-10-26T13:20:29.438203Z","shell.execute_reply":"2021-10-26T13:20:29.445156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yolo = YOLO(0.6, 0.5)\nall_classes = ['person']","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:20:31.917697Z","iopub.execute_input":"2021-10-26T13:20:31.917974Z","iopub.status.idle":"2021-10-26T13:20:33.660894Z","shell.execute_reply.started":"2021-10-26T13:20:31.917945Z","shell.execute_reply":"2021-10-26T13:20:33.660147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"actual = []\npredicted = []\n\nfor index in tqdm(range(len(validation_generator))):\n    batch = validation_generator[index]\n    \n    for image in batch[0]:\n        image = ((image - image.min()) * (1/(image.max() - image.min()) * 255)).astype('uint8')\n        res = detect_image(image, yolo, all_classes)\n        predicted.append(res)\n    \n    actual.extend(batch[1])","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:21:01.678423Z","iopub.execute_input":"2021-10-26T13:21:01.678911Z","iopub.status.idle":"2021-10-26T13:21:28.59526Z","shell.execute_reply.started":"2021-10-26T13:21:01.678869Z","shell.execute_reply":"2021-10-26T13:21:28.594274Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(actual,predicted))","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:15:23.397326Z","iopub.execute_input":"2021-10-26T13:15:23.397603Z","iopub.status.idle":"2021-10-26T13:15:23.417913Z","shell.execute_reply.started":"2021-10-26T13:15:23.397555Z","shell.execute_reply":"2021-10-26T13:15:23.417225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"actual = []\npredicted = []\n\nfor index in tqdm(range(len(test_generator))):\n    batch = test_generator[index]\n    \n    for image in batch[0]:\n        image = ((image - image.min()) * (1/(image.max() - image.min()) * 255)).astype('uint8')\n        res = detect_image(image, yolo, all_classes)\n        predicted.append(res)\n    \n    actual.extend(batch[1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(actual,predicted))","metadata":{},"execution_count":null,"outputs":[]}]}