{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this notebook lets explore the data and do the Pre-processing and feature engineering alone. <br>\nPlease check out my another notebook [Modelling Titanic](https://www.kaggle.com/aakashveera/modelling-titanic). It has the modelling section with several Machine Learning Algorithms","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Importing and Reading the Data","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Passenger Id is just a unique Id given to each passengers, so it has no use in Modelling and can be dropped.<br>\nSibSp refers to the siblings and spouses along with the person in the titanic. <br>\nParch refers to the parents/ Childern abroad the titanic.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(\"PassengerId\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA & Visualizations","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['Pclass'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['Survived'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['Survived'],hue=df['Sex'],palette='twilight_shifted_r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['Survived'],hue=df['Pclass'],palette='viridis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['SibSp'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['Parch'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the People were alone on the titanic ship.<br>\nThe below image shows the Age distribution. **Titanic has more people from 18-35 years old**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['Age'],kde=False,bins=40)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The black dots on the right of image represents the outliers in the Age. <br>\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df['Age'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Filling out missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Cabin has most of the values as null.\n* Age is partially missing.\n* Only few columns were missing in Embarked.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Age","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 7))\nsns.boxplot(x='Pclass',y='Age',data=df,palette='winter')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can see that 1st class people were mostly around 30 -50 <br>\n2nd class people were mostly around 28 - 38 and 3rd class people were younger than both. <br>\nSo it will good to fill the null values based on thier class","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def age_fill(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n\n        if Pclass == 1:\n            return 37\n\n        elif Pclass == 2:\n            return 29\n\n        else:\n            return 24\n\n    else:\n        return Age","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Age'] = df[['Age','Pclass']].apply(age_fill,axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cabin and Embarked","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Lets covert all the null values as 0 and cabins as 1 and fill the most repeated values on Embarked","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Cabin'] = df['Cabin'].apply(lambda x: 0 if pd.isnull(x) else 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Embarked'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Embarked'].fillna(value='S',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's Extract out the titles from the Name","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_title(arg):\n    return arg.split(' ')[1]\n\ndf['Title'] = df['Name'].apply(extract_title)\n#df['Title'] = df['Name'].apply(lambda x: x.split(' ')[1])  equivalent lambda function\ndf.drop('Name',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ticket and Fare mostly represents the class of the person. Since it is available as a seperate feature both can be dropped.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['Ticket','Fare'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now lets convert the categorical values into numerical ones.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#you may also use function approach to convert the data. But let's see with LabelEncoder\nfrom sklearn.preprocessing import LabelEncoder\nencoder_sex = LabelEncoder()\nencoder_embarked = LabelEncoder()\nencoder_title = LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Sex'] = encoder_sex.fit_transform(df['Sex'])\ndf['Embarked'] = encoder_embarked.fit_transform(df['Embarked'])\ndf['Title'] = encoder_title.fit_transform(df['Title'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Class_sex'] = df['Pclass'].astype(str) + df['Sex'].astype(str)\nencoder_Class_sex = LabelEncoder()\ndf['Class_sex'] = encoder_Class_sex.fit_transform(df['Class_sex'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's do the same feature Engineering with test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/titanic/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Don't drop the PassengerId is it neccassary for submission\ntest.drop(['Ticket','Fare'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Age'] = test[['Age','Pclass']].apply(age_fill,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Title'] = test['Name'].apply(extract_title)\ntest.drop('Name',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Cabin'] = test['Cabin'].apply(lambda x: 0 if pd.isnull(x) else 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Sex'] = encoder_sex.transform(test['Sex'])\ntest['Embarked'] = encoder_embarked.transform(test['Embarked'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some of the titles in test set were not in training set labelEncoder throws error while transforming a unseen data.<br>\nKhalil,Palmquist,Brito were the three and all three were men lets convert it into Mr","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Title'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.loc[test['Title']=='Khalil,','Title'] = 'Mr.'\ntest.loc[test['Title']=='Palmquist,','Title'] = 'Mr.'\ntest.loc[test['Title']=='Brito,','Title'] = 'Mr.'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Title'] = encoder_title.transform(test['Title'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Class_sex'] = test['Pclass'].astype(str) + test['Sex'].astype(str)\ntest['Class_sex'] = encoder_Class_sex.transform(test['Class_sex'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets save our pre-processed data and publish as a new dataset so next time while modelling we can use this cleaned data instead doing the same from beginning.<br>\n<br>\n**Note for Begginers:**  For publishing our own data hit the Save Version button and hit commit. Now once your notebook is executed you can create a new dataset from the output at the bottom of the notebook","attachments":{},"execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test.to_csv(\"test.csv\",index=False)\ndf.to_csv(\"train.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Continue with  my another notebook [Modelling Titanic](https://www.kaggle.com/aakashveera/modelling-titanic). It has the modelling section with several Machine Learning Algorithms and the submission on kaggle","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}