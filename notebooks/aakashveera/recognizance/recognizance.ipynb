{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing the Basic Libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing the ImageDataGenerator","execution_count":null},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ImageDataGenerator is used to load the images from the respective Directory with the mentioned batch size and Image size, also several augments of the image can also be made with the ImageDataGenerator","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<b>Here the given list of augments has been made to improve the learning.</b>\n\n1)Width Shift (Shifting the Image Horizontally)\n\n2)Height Shift (Shifting the Image Vertically)\n\n3)Rescale (Converting the pixel values from 0 - 255 to 0 - 1)\n\n4)Shear (Shifting one part of a Image) <a href=\"https://docs.gimp.org/2.10/en/gimp-tool-shear.html#:~:text=Shear%20tool%20is%20used%20to,A%20rectangle%20becomes%20a%20diamond.\">Please refer this link for shear Example</a>\n\n5)Zoom","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"image_gen = ImageDataGenerator(\n                               width_shift_range=0.1, \n                               height_shift_range=0.1, \n                               rescale=1/255, \n                               shear_range=0.2, \n                               zoom_range=0.2, \n                               fill_mode='nearest'\n                              )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here all the Images have been resized to 350 x 350 in black and white mode and used <br>\n\nBatch size of 16 is used <br>\n\nThe images have been loaded from the Directory(recognizance/train) in B/W mode with ImageDataGenerator <br>\n\nThe ImageDataGenerator Now reads 16 images in B/W mode each time","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"image_shape = (350,350,1)\nbatch_size = 16\ntrain_image_gen = image_gen.flow_from_directory('../input/recognizance/train',color_mode='grayscale',\n                                               target_size=image_shape[:2],\n                                               batch_size=batch_size,\n                                               class_mode='binary',seed=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The CNN model is implemented using the Keras Library. <br>\n\nLoss Function used - Binary Crossentropy <br>\nOptimizer - Adam <br>\nEpochs Used - 30","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Activation, Flatten, Dense, Conv2D, MaxPool2D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=(350,350,1), activation='relu',))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=128, kernel_size=(3,3),activation='relu',))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu',))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\n\n\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\n\nmodel.fit_generator(generator=train_image_gen,epochs=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(generator=train_image_gen,epochs=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(generator=train_image_gen,epochs=5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predicting the Test Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"All the filenames inside the test folder are read and stored in a array","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfiles = []\n\nfor dirname, _, filenames in os.walk('/kaggle/input/recognizance/test/'):\n    for filename in filenames:\n        files.append(filename)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then each corresponding image is loaded using Keras.image.load_img in B/W mode and with dimension of 350 <br>\n\nThen the class of the Image(Positive/negative) is predicted and the value is appended in a Array","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = []\nfor i in files:\n    img = image.load_img('../input/recognizance/test/'+i, target_size=(350,350,1),color_mode = \"grayscale\")\n    img = image.img_to_array(img)\n    img = np.expand_dims(img, axis=0)\n    img = img/255\n    pred.append(model.predict_classes(img)[0][0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then the File names with their classes are made into a Dataframe for submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame(pred,files).reset_index()\nsub.columns = ['image','label']\nsub.to_csv('sub4.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!gzip sub4.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights(\"modelweights.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'modelweights.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}