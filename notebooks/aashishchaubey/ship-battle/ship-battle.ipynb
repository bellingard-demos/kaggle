{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nfrom glob import glob\nimport pathlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nimport tensorflow as tf\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Flatten, Dropout\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path = \"../input/game-of-deep-learning-ship-datasets/train/images/\"\nshape = (64, 64, 1)\nmapping = {\n    0: 'Cargo', \n    1: 'Military', \n    2: 'Carrier', \n    3: 'Cruise', \n    4: 'Tankers'\n}\nbatch_size = 24","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv_file = \"../input/game-of-deep-learning-ship-datasets/train/train.csv\"\ntrain_csv = pd.read_csv(train_csv_file)\ntrain_csv.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = []\nfor i in tqdm(range(train_csv.shape[0])):\n    img = image.load_img(image_path + train_csv['image'][i], target_size=shape, grayscale=True)\n    img = image.img_to_array(img)\n    img = img.astype(np.float32) / 255.0\n    train_images.append(img)\nX = np.array(train_images)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_val = train_csv['category'].subtract(1).values\ny = to_categorical(y_val, num_classes=len(mapping))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Validating the images","metadata":{}},{"cell_type":"code","source":"Image.open(image_path + train_csv['image'][3254])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(X[3254])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val = train_csv.loc[:, \"category\"].value_counts()\nval = val.rename(index=mapping)\nval.plot.pie(\n    autopct='%.2f'\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Building: ResNet50","metadata":{}},{"cell_type":"code","source":"base_model = ResNet50(\n    include_top=False, weights=None, input_shape=shape\n)\nlayer = base_model.output\nlayer = Flatten()(layer)\nlayer = Dense(512, activation='tanh')(layer)\n# layer = Dropout(0.3)(layer)\nlayer = Dense(128, activation='tanh')(layer)\n# layer = Dropout(0.3)(layer)\nlayer = Dense(len(mapping), activation='softmax')(layer)\nmodel = Model(inputs = base_model.input, outputs = layer)\nmodel.summary()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in base_model.layers:\n    layer.trainable = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer='adam', \n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Performing the test train split","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Perform Image Augmentation","metadata":{}},{"cell_type":"code","source":"args = dict(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2\n)\ndatagen = image.ImageDataGenerator(**args)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = datagen.flow(X_train, y_train, batch_size=batch_size)\ntest_dataset = datagen.flow(X_test, y_test, batch_size=batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"step_size_train=train_dataset.n//train_dataset.batch_size\nstep_size_val=test_dataset.n//test_dataset.batch_size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_dataset,\n    steps_per_epoch=step_size_train,\n    epochs=50,\n    validation_data=test_dataset,\n    validation_steps=step_size_val\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history[\"loss\"], label=\"train_loss\")\nplt.plot(history.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(history.history[\"acc\"], label=\"train_acc\")\nplt.plot(history.history[\"val_acc\"], label=\"val_acc\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}