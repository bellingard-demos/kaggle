{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Description"},{"metadata":{},"cell_type":"markdown","source":"### This code will show you a way to search for the best threshold. You can use this method searching for a better threshold instead of using 0.5 as final threshold."},{"metadata":{},"cell_type":"markdown","source":"### You can find the training code from <br/> https://www.kaggle.com/a763337092/neural-network-starter-pytorch-version/comments and <br/> https://www.kaggle.com/a763337092/pytorch-resnet-starter-training"},{"metadata":{},"cell_type":"markdown","source":"## Upvoting if it helpsðŸ”¥ðŸ”¥ðŸ”¥"},{"metadata":{},"cell_type":"markdown","source":"# Load models"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport time\nimport pickle\nimport random\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.metrics import log_loss, roc_auc_score\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torch.nn import CrossEntropyLoss, MSELoss\nfrom torch.nn.modules.loss import _WeightedLoss\nimport torch.nn.functional as F\n\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 100)\n\nDATA_PATH = '../input/jane-street-market-prediction/'\n\nNFOLDS = 5\n\nTRAIN = False\nCACHE_PATH = '../input/mlp012003weights'\n\ndef save_pickle(dic, save_path):\n    with open(save_path, 'wb') as f:\n    # with gzip.open(save_path, 'wb') as f:\n        pickle.dump(dic, f)\n\ndef load_pickle(load_path):\n    with open(load_path, 'rb') as f:\n    # with gzip.open(load_path, 'rb') as f:\n        message_dict = pickle.load(f)\n    return message_dict\n\nfeat_cols = [f'feature_{i}' for i in range(130)]\n\ntarget_cols = ['action', 'action_1', 'action_2', 'action_3', 'action_4']\n\nf_mean = np.load(f'{CACHE_PATH}/f_mean_online.npy')\n\n##### Making features\nall_feat_cols = [col for col in feat_cols]\nall_feat_cols.extend(['cross_41_42_43', 'cross_1_2'])\n\n##### Model&Data fnc\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.batch_norm0 = nn.BatchNorm1d(len(all_feat_cols))\n        self.dropout0 = nn.Dropout(0.2)\n\n        dropout_rate = 0.2\n        hidden_size = 256\n        self.dense1 = nn.Linear(len(all_feat_cols), hidden_size)\n        self.batch_norm1 = nn.BatchNorm1d(hidden_size)\n        self.dropout1 = nn.Dropout(dropout_rate)\n\n        self.dense2 = nn.Linear(hidden_size+len(all_feat_cols), hidden_size)\n        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n        self.dropout2 = nn.Dropout(dropout_rate)\n\n        self.dense3 = nn.Linear(hidden_size+hidden_size, hidden_size)\n        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n        self.dropout3 = nn.Dropout(dropout_rate)\n\n        self.dense4 = nn.Linear(hidden_size+hidden_size, hidden_size)\n        self.batch_norm4 = nn.BatchNorm1d(hidden_size)\n        self.dropout4 = nn.Dropout(dropout_rate)\n\n        self.dense5 = nn.Linear(hidden_size+hidden_size, len(target_cols))\n\n        self.Relu = nn.ReLU(inplace=True)\n        self.PReLU = nn.PReLU()\n        self.LeakyReLU = nn.LeakyReLU(negative_slope=0.01, inplace=True)\n        # self.GeLU = nn.GELU()\n        self.RReLU = nn.RReLU()\n\n    def forward(self, x):\n        x = self.batch_norm0(x)\n        x = self.dropout0(x)\n\n        x1 = self.dense1(x)\n        x1 = self.batch_norm1(x1)\n        # x = F.relu(x)\n        # x = self.PReLU(x)\n        x1 = self.LeakyReLU(x1)\n        x1 = self.dropout1(x1)\n\n        x = torch.cat([x, x1], 1)\n\n        x2 = self.dense2(x)\n        x2 = self.batch_norm2(x2)\n        # x = F.relu(x)\n        # x = self.PReLU(x)\n        x2 = self.LeakyReLU(x2)\n        x2 = self.dropout2(x2)\n\n        x = torch.cat([x1, x2], 1)\n\n        x3 = self.dense3(x)\n        x3 = self.batch_norm3(x3)\n        # x = F.relu(x)\n        # x = self.PReLU(x)\n        x3 = self.LeakyReLU(x3)\n        x3 = self.dropout3(x3)\n\n        x = torch.cat([x2, x3], 1)\n\n        x4 = self.dense4(x)\n        x4 = self.batch_norm4(x4)\n        # x = F.relu(x)\n        # x = self.PReLU(x)\n        x4 = self.LeakyReLU(x4)\n        x4 = self.dropout4(x4)\n\n        x = torch.cat([x3, x4], 1)\n\n        x = self.dense5(x)\n\n        return x\n\nif True:\n    device = torch.device(\"cuda:0\")\n\n    model_list = []\n    tmp = np.zeros(len(feat_cols))\n    for _fold in range(NFOLDS):\n        torch.cuda.empty_cache()\n        model = Model()\n        model.to(device)\n        model_weights = f\"{CACHE_PATH}/online_model{_fold}.pth\"\n        model.load_state_dict(torch.load(model_weights))\n        model.eval()\n        model_list.append(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get offline predictions"},{"metadata":{},"cell_type":"markdown","source":"For I use the last 50 date data as my offline validation data, so I use the 5 modelsâ€˜ average prediction on last 50 date data to search for the best threshold."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(f'{DATA_PATH}/train.csv')\nvalid = train.loc[(train.date >= 450) & (train.date < 500)].reset_index(drop=True)\nvalid.fillna(train.mean(), inplace=True)\ndel train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid['action'] = (valid['resp'] > 0).astype('int')\nvalid['action_1'] = (valid['resp_1'] > 0).astype('int')\nvalid['action_2'] = (valid['resp_2'] > 0).astype('int')\nvalid['action_3'] = (valid['resp_3'] > 0).astype('int')\nvalid['action_4'] = (valid['resp_4'] > 0).astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid['cross_41_42_43'] = valid['feature_41'] + valid['feature_42'] + valid['feature_43']\nvalid['cross_1_2'] = valid['feature_1'] / (valid['feature_2'] + 1e-5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 8192\n\nclass MarketDataset:\n    def __init__(self, df):\n        self.features = df[all_feat_cols].values\n\n        self.label = df[target_cols].values.reshape(-1, len(target_cols))\n\n    def __len__(self):\n        return len(self.label)\n\n    def __getitem__(self, idx):\n        return {\n            'features': torch.tensor(self.features[idx], dtype=torch.float),\n            'label': torch.tensor(self.label[idx], dtype=torch.float)\n        }\n\nvalid_set = MarketDataset(valid)\nvalid_loader = DataLoader(valid_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def inference_fn(model, dataloader, device):\n    model.eval()\n    preds = []\n\n    for data in dataloader:\n        features = data['features'].to(device)\n\n        with torch.no_grad():\n            outputs = model(features)\n\n        preds.append(outputs.sigmoid().detach().cpu().numpy())\n\n    preds = np.concatenate(preds).reshape(-1, len(target_cols))\n\n    return preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_pred = np.zeros((len(valid), len(target_cols)))\nfor model in model_list:\n    valid_pred += inference_fn(model, valid_loader, device) / len(model_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_pred = np.median(valid_pred, axis=1)\nvalid_pred.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Searching for best threshold"},{"metadata":{"trusted":true},"cell_type":"code","source":"def utility_score_bincount(date, weight, resp, action):\n    count_i = len(np.unique(date))\n    # print('weight: ', weight)\n    # print('resp: ', resp)\n    # print('action: ', action)\n    # print('weight * resp * action: ', weight * resp * action)\n    Pi = np.bincount(date, weight * resp * action)\n    t = np.sum(Pi) / np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 / count_i)\n    u = np.clip(t, 0, 6) * np.sum(Pi)\n    return u","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_threshold, best_u_score = 0.5, 0\nfor i in range(4500, 5500):\n    thres = float(i) / 10000\n    slice_valid_pred = valid_pred.copy()\n    slice_valid_pred = np.where(slice_valid_pred >= thres, 1, 0).astype(int)\n    valid_u_score = utility_score_bincount(date=valid.date.values, weight=valid.weight.values,\n                                           resp=valid.resp.values, action=slice_valid_pred)\n    print(f'thresold={thres:.4f}, valid_u_score={valid_u_score:.4f}')\n    \n    if valid_u_score >= best_u_score:\n        best_u_score = valid_u_score\n        best_threshold = thres","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Best thresold={best_threshold:.4f}, best valid u score={best_u_score:.4f}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict with best threshold"},{"metadata":{"trusted":true},"cell_type":"code","source":"if True:\n    import janestreet\n    env = janestreet.make_env()\n    env_iter = env.iter_test()\n\n    for (test_df, pred_df) in tqdm(env_iter):\n        if test_df['weight'].item() > 0:\n            x_tt = test_df.loc[:, feat_cols].values\n            if np.isnan(x_tt.sum()):\n                x_tt = np.nan_to_num(x_tt) + np.isnan(x_tt) * f_mean\n\n            cross_41_42_43 = x_tt[:, 41] + x_tt[:, 42] + x_tt[:, 43]\n            cross_1_2 = x_tt[:, 1] / (x_tt[:, 2] + 1e-5)\n            feature_inp = np.concatenate((\n                x_tt,\n                np.array(cross_41_42_43).reshape(x_tt.shape[0], 1),\n                np.array(cross_1_2).reshape(x_tt.shape[0], 1),\n            ), axis=1)\n\n            pred = np.zeros((1, len(target_cols)))\n            for model in model_list:\n                pred += model(torch.tensor(feature_inp, dtype=torch.float).to(device)).sigmoid().detach().cpu().numpy() / NFOLDS\n            pred = np.median(pred)\n            pred_df.action = np.where(pred >= best_threshold, 1, 0).astype(int)\n        else:\n            pred_df.action = 0\n        env.predict(pred_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}