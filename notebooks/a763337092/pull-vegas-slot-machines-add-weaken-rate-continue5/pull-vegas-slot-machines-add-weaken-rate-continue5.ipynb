{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Keep pulling same bandit as long as reward keeps coming!"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install kaggle-environments --upgrade","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# observation = {\n#     'remainingOverageTime': 60,\n#     'agentIndex': 1, # 0 or 1\n#     'reward': 92, # total reward\n#     'step': 184, # [0-1999]\n#     'lastActions': [84, 94]\n# }\n\n# configuration:\n# {'episodeSteps': 2000,\n#  'actTimeout': 0.25,\n#  'runTimeout': 1200,\n#  'banditCount': 100,\n#  'decayRate': 0.97,\n#  'sampleResolution': 100}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%%writefile submission.py\n\nimport numpy as np\nimport pandas as pd\nimport random, os, datetime, math\nfrom collections import defaultdict\n\ntotal_reward = 0\nbandit_dict = {}\n\ndef set_seed(my_seed=42):\n    os.environ['PYTHONHASHSEED'] = str(my_seed)\n    random.seed(my_seed)\n    np.random.seed(my_seed)\n\ndef get_next_bandit():\n    best_bandit = 0\n    best_bandit_expected = 0\n    for bnd in bandit_dict:\n        expect = (bandit_dict[bnd]['win'] - bandit_dict[bnd]['loss'] + bandit_dict[bnd]['opp'] - (bandit_dict[bnd]['opp']>0)*1.5 + bandit_dict[bnd]['op_continue']) \\\n                 / (bandit_dict[bnd]['win'] + bandit_dict[bnd]['loss'] + bandit_dict[bnd]['opp']) \\\n                * math.pow(0.97, bandit_dict[bnd]['win'] + bandit_dict[bnd]['loss'] + bandit_dict[bnd]['opp'])\n        if expect > best_bandit_expected:\n            best_bandit_expected = expect\n            best_bandit = bnd\n    return best_bandit\n\nmy_action_list = []\nop_action_list = []\n\nop_continue_cnt_dict = defaultdict(int)\n\ndef multi_armed_probabilities(observation, configuration):\n    global total_reward, bandit_dict\n\n    my_pull = random.randrange(configuration['banditCount'])\n    if 0 == observation['step']:\n        set_seed()\n        total_reward = 0\n        bandit_dict = {}\n        for i in range(configuration['banditCount']):\n            bandit_dict[i] = {'win': 1, 'loss': 0, 'opp': 0, 'my_continue': 0, 'op_continue': 0}\n    else:\n        last_reward = observation['reward'] - total_reward\n        total_reward = observation['reward']\n        \n        my_idx = observation['agentIndex']\n        my_last_action = observation['lastActions'][my_idx]\n        op_last_action = observation['lastActions'][1-my_idx]\n        \n        my_action_list.append(my_last_action)\n        op_action_list.append(op_last_action)\n        \n        if 0 < last_reward:\n            bandit_dict[my_last_action]['win'] = bandit_dict[my_last_action]['win'] +1\n        else:\n            bandit_dict[my_last_action]['loss'] = bandit_dict[my_last_action]['loss'] +1\n        bandit_dict[op_last_action]['opp'] = bandit_dict[op_last_action]['opp'] +1\n        \n        if observation['step'] >= 3:\n            if my_action_list[-1] == my_action_list[-2]:\n                bandit_dict[my_last_action]['my_continue'] += 1\n            else:\n                bandit_dict[my_last_action]['my_continue'] = 0\n            if op_action_list[-1] == op_action_list[-2]:\n                bandit_dict[op_last_action]['op_continue'] += 1\n            else:\n                bandit_dict[op_last_action]['op_continue'] = 0\n        \n        if last_reward > 0:\n            my_pull = my_last_action\n        else:\n            if observation['step'] >= 4:\n                if (my_action_list[-1] == my_action_list[-2]) and (my_action_list[-1] == my_action_list[-3]):\n                    if random.random() < 0.5:\n                        my_pull = my_action_list[-1]\n                    else:\n                        my_pull = get_next_bandit()\n                else:\n                    my_pull = get_next_bandit()\n            else:\n                my_pull = get_next_bandit()\n    \n    return my_pull","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%writefile opponent_agent.py\n\nimport numpy as np\nimport pandas as pd\nimport random, os, datetime, math\n\ntotal_reward = 0\nbandit_dict = {}\n\ndef set_seed(my_seed=42):\n    os.environ['PYTHONHASHSEED'] = str(my_seed)\n    random.seed(my_seed)\n    np.random.seed(my_seed)\n\ndef get_next_bandit():\n    best_bandit = 0\n    best_bandit_expected = 0\n    for bnd in bandit_dict:\n        expect = (bandit_dict[bnd]['win'] - bandit_dict[bnd]['loss'] + bandit_dict[bnd]['opp'] - (bandit_dict[bnd]['opp']>0)*1.5) \\\n                 / (bandit_dict[bnd]['win'] + bandit_dict[bnd]['loss'] + bandit_dict[bnd]['opp']) \\\n                * math.pow(0.97, bandit_dict[bnd]['win'] + bandit_dict[bnd]['loss'] + bandit_dict[bnd]['opp'])\n        if expect > best_bandit_expected:\n            best_bandit_expected = expect\n            best_bandit = bnd\n    return best_bandit\n\nmy_action_list = []\nop_action_list = []\n\n\n\ndef multi_armed_probabilities(observation, configuration):\n    global total_reward, bandit_dict\n\n    my_pull = random.randrange(configuration['banditCount'])\n    if 0 == observation['step']:\n        set_seed()\n        total_reward = 0\n        bandit_dict = {}\n        for i in range(configuration['banditCount']):\n            bandit_dict[i] = {'win': 1, 'loss': 0, 'opp': 0}\n    else:\n        last_reward = observation['reward'] - total_reward\n        total_reward = observation['reward']\n        \n        my_idx = observation['agentIndex']\n        my_last_action = observation['lastActions'][my_idx]\n        op_last_action = observation['lastActions'][1-my_idx]\n        \n        my_action_list.append(my_last_action)\n        op_action_list.append(op_last_action)\n        \n        if 0 < last_reward:\n            bandit_dict[my_last_action]['win'] = bandit_dict[my_last_action]['win'] +1\n        else:\n            bandit_dict[my_last_action]['loss'] = bandit_dict[my_last_action]['loss'] +1\n        bandit_dict[op_last_action]['opp'] = bandit_dict[op_last_action]['opp'] +1\n        \n        if last_reward > 0:\n            my_pull = my_last_action\n        else:\n            if observation['step'] >= 4:\n                if (my_action_list[-1] == my_action_list[-2]) and (my_action_list[-1] == my_action_list[-3]):\n                    if random.random() < 0.5:\n                        my_pull = my_action_list[-1]\n                    else:\n                        my_pull = get_next_bandit()\n                else:\n                    my_pull = get_next_bandit()\n            else:\n                my_pull = get_next_bandit()\n    \n    return my_pull","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle_environments import make\nenv = make(\"mab\", debug=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\n\nenv.reset()\nstart_time = datetime.datetime.now()\nenv.run([\"opponent_agent.py\", \"submission.py\"])\nstop_time = datetime.datetime.now()\nprint('Completed sub vs random:', stop_time-start_time)\nenv.render(mode=\"ipython\", width=800, height=400)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\n\nenv.reset()\nstart_time = datetime.datetime.now()\nenv.run([\"submission.py\", \"submission.py\"])\nstop_time = datetime.datetime.now()\nprint('Completed sub vs sub:', stop_time-start_time)\nenv.render(mode=\"ipython\", width=800, height=400)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}