{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":57236,"databundleVersionId":7056256,"sourceType":"competition"},{"sourceId":7121231,"sourceType":"datasetVersion","datasetId":4107458}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Enefit - Quick EDA with Dash\n[![Screenshot-2023-12-03-at-15-19-31-Enefit-Predict-Energy-Behavior-of-Prosumers-Kaggle.png](https://i.postimg.cc/2jLKqjXb/Screenshot-2023-12-03-at-15-19-31-Enefit-Predict-Energy-Behavior-of-Prosumers-Kaggle.png)](https://postimg.cc/3W7BVhhY)\n\n## About this Competition\nThe energy imbalance problem indicates there exists imbalance between the **production and consumption** of energy. That is, the generated electricity mismatches the demanding side (*e.g.,* unexpected energy consumption behavior). In this competition, energy consumption/production patterns of prosumers are given with the auxiliary features (*e.g.,* weather data, gas and electricity prices, the installed PV capacity), competitors are challenged to predict **electricity produced and consumed by Estonian energy customers** who have installed solar panels, which can be formulated as a time series **regression** problem.\n\n## About this Notebook\nIn this kernel, I will start from raw file exploration. Then, a time series data dashboard is implemented for interactive data exploration. Also, a naive baseline will be provided to see how far we can reach with inspirations from data exploration.\n\n<a id=\"toc\"></a>\n## Table of Contents\n* [1. Data Appearance](#data_appearance)\n    * *[Our Main Target](#tgt)*\n    * *[All about Weather](#wth)*\n* [2. Towards Spatio-Temporal Analysis with Dash](#st_dash)\n    * *[Load Necessary Data](#st_load_data)*\n    * *[Generate Interactive Options](#st_gen_opts)*\n    * *[Define Dashboard Layout](#st_layout)*\n    * *[Define Callbacks](#st_cbs)*\n    * *[Start Exploration](#st_start)* \n* [3. Baseline Model with Local CV](#baseline)\n* [Reference](#ref)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"## Import Packages","metadata":{}},{"cell_type":"code","source":"!pip install dash-bootstrap-components\n!pip uninstall polars -y\n!pip install polars==0.19.16\n!pip install pyngrok","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-04T15:36:54.986458Z","iopub.execute_input":"2023-12-04T15:36:54.987189Z","iopub.status.idle":"2023-12-04T15:37:48.889506Z","shell.execute_reply.started":"2023-12-04T15:36:54.987139Z","shell.execute_reply":"2023-12-04T15:37:48.88804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport math\nimport pickle\nfrom pathlib import Path\nfrom typing import Dict, List, Optional\n\nimport plotly\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport matplotlib.pyplot as plt\nimport plotly\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport dash_bootstrap_components as dbc\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import init_notebook_mode\nfrom pyngrok import ngrok\nfrom dash import Dash, html, dcc, callback, Output, Input\n\npl.Config.set_tbl_hide_dataframe_shape(True)\ninit_notebook_mode(connected=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T15:37:48.892025Z","iopub.execute_input":"2023-12-04T15:37:48.892489Z","iopub.status.idle":"2023-12-04T15:37:50.592839Z","shell.execute_reply.started":"2023-12-04T15:37:48.89244Z","shell.execute_reply":"2023-12-04T15:37:50.59172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nauth_token = user_secrets.get_secret(\"ngrok\")\nngrok.set_auth_token(auth_token)\ntunnel = ngrok.connect(8050)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T15:37:50.594276Z","iopub.execute_input":"2023-12-04T15:37:50.594691Z","iopub.status.idle":"2023-12-04T15:37:51.574875Z","shell.execute_reply.started":"2023-12-04T15:37:50.594653Z","shell.execute_reply":"2023-12-04T15:37:51.571059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define Paths, Metadata and Utilities","metadata":{}},{"cell_type":"code","source":"# Paths\nRAW_DATA_PATH = Path(\"/kaggle/input/predict-energy-behavior-of-prosumers\")\nPROC_DATA_PATH = Path(\"/kaggle/input/enefit-eda/enefit_eda\")\n\n# Metadata\nUNIT_ID_COL = \"prediction_unit_id\"\nTGT_PK_COLS = [\"county\", \"is_business\", \"product_type\"]\nCOORD_COL2ABBR = {\"latitude\": \"lat\", \"longitude\": \"lon\"}","metadata":{"execution":{"iopub.status.busy":"2023-12-04T15:37:51.578075Z","iopub.execute_input":"2023-12-04T15:37:51.578441Z","iopub.status.idle":"2023-12-04T15:37:51.584406Z","shell.execute_reply.started":"2023-12-04T15:37:51.57841Z","shell.execute_reply":"2023-12-04T15:37:51.582903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _summarize(\n    df: pl.DataFrame,\n    file_name: Optional[str] = None,\n    n_rows_to_display: Optional[int] = 5,\n) -> None:\n    \"\"\"Summarize DataFrame.\n\n    Args:\n        df: input data\n        file_name: name of the input file\n        n_rows_to_display: number of rows to display\n    \"\"\"\n    file_name = \"Data\" if file_name is None else file_name\n\n    # Derive NaN ratio for each column\n    nan_ratio = df.null_count() / len(df) * 100\n\n    # Print out summarized information\n    print(f\"===== Summary of {file_name} =====\")\n    display(df.head(n_rows_to_display))\n    print(f\"Shape: {df.shape}\")\n    print(\"NaN ratio:\")\n    display(nan_ratio)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-04T15:37:51.586167Z","iopub.execute_input":"2023-12-04T15:37:51.586888Z","iopub.status.idle":"2023-12-04T15:37:51.595838Z","shell.execute_reply.started":"2023-12-04T15:37:51.586847Z","shell.execute_reply":"2023-12-04T15:37:51.594674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"data_appearance\"></a>\n## 1. Data Appearance\n<a id=\"tgt\"></a>\n### *Our Main Target*\n[**<span style=\"color:#FEF1FE; background-color:#535d70;border-radius: 5px; padding: 2px\">Go to Table of Content</span>**](#toc)\n\nFirst, let's take a look at the main training set. It contains the **electricity consumption and production patterns** of prosumers, which can be determined by a indicator `is_consumption`. Also, the primary key is a composite key `(county, is_business, product_type)`, reduced to a single column `prediction_unit_id`.<br>\nAs can be observed, there exist **missing values** in `target` column, which is our predicting target.","metadata":{}},{"cell_type":"code","source":"# Load train data\ntrain = pl.read_csv(RAW_DATA_PATH / \"train.csv\", try_parse_dates=True)\n\n_summarize(train, \"train.csv\", 1)\nassert len(train.unique(subset=TGT_PK_COLS+[UNIT_ID_COL]))== len(set(train[UNIT_ID_COL]))","metadata":{"execution":{"iopub.status.busy":"2023-12-04T15:37:51.597137Z","iopub.execute_input":"2023-12-04T15:37:51.597999Z","iopub.status.idle":"2023-12-04T15:37:52.434927Z","shell.execute_reply.started":"2023-12-04T15:37:51.59797Z","shell.execute_reply":"2023-12-04T15:37:52.433829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, let's plot and glimpse some randomly sampled consumption and production sequences jointly to observe their interaction. My intuition is that prosumers tend to consume more electricity when they produced more beforehand. However, the following plots seem not to support this assumption.<br>\nSome interesting observations are summarized as follows:\n1. There exist **periodicities** with different granularities (*e.g.,* daily, weekly, monthly).\n2. There exist **breakpoints**, which are missing values.\n3. There exists no negative target value.","metadata":{}},{"cell_type":"code","source":"def _show_targets(df: pl.DataFrame, n_uids: int = 6) -> None:\n    \"\"\"Randomly sample and plot target sequences.\"\"\"\n    n_cols_per_row = 3\n    colors = {0: \"rgba(8, 209, 59, 0.5)\", 1: \"rgba(245, 10, 10, 0.7)\"}\n    sampled_ids = np.random.choice(df[UNIT_ID_COL].unique(), size=n_uids, replace=False)\n    \n    fig = make_subplots(rows=math.ceil(n_uids / n_cols_per_row), cols=n_cols_per_row)\n    for i, uid in enumerate(sampled_ids):\n        train_uid = (\n            train\n            .filter((pl.col(UNIT_ID_COL) == uid))\n            .sort(\"datetime\")\n        )\n        for is_cons in [0, 1]:\n            train_uid_ = train_uid.filter(pl.col(\"is_consumption\") == is_cons)\n            row, col = i//n_cols_per_row + 1, i%n_cols_per_row + 1\n            fig.add_trace(\n                go.Scatter(\n                    x=train_uid_[\"datetime\"],\n                    y=train_uid_[\"target\"], \n                    name=\"Consumption\" if is_cons else \"Production\",\n                    line={\"color\": colors[is_cons]},\n                    legendgroup=i,\n                    legendgrouptitle_text=f\"Plot ({row}, {col}) - UID {uid}\"\n                ),\n                row=row, \n                col=col\n            )\n    \n    fig.update_layout(\n        title_text=f\"Sampled Electricity Sequences\",\n        margin=dict(l=12, r=12, t=50, b=50)\n    )\n    fig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-04T15:37:52.436231Z","iopub.execute_input":"2023-12-04T15:37:52.436537Z","iopub.status.idle":"2023-12-04T15:37:52.448434Z","shell.execute_reply.started":"2023-12-04T15:37:52.436512Z","shell.execute_reply":"2023-12-04T15:37:52.447227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_show_targets(train, n_uids=6)\nassert (train[\"target\"] >= 0).all()","metadata":{"execution":{"iopub.status.busy":"2023-12-04T15:37:52.449778Z","iopub.execute_input":"2023-12-04T15:37:52.450138Z","iopub.status.idle":"2023-12-04T15:37:53.336873Z","shell.execute_reply.started":"2023-12-04T15:37:52.450101Z","shell.execute_reply":"2023-12-04T15:37:53.334553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Diving into primary keys, we can find that,\n1. Prosumers aren't equally distributed among different counties in Estonia.\n2. \\> 50% of prosumers are businesses.\n3. `\"Spot\"` is the major contract type, followed by `\"Fixed\"`.","metadata":{}},{"cell_type":"code","source":"with open(RAW_DATA_PATH / \"county_id_to_name_map.json\", \"r\") as f:\n    county_id2name = json.load(f)\npks = train[TGT_PK_COLS].unique()\n\nfig = make_subplots(\n    rows=1, cols=3, \n    column_widths=[0.6, 0.2, 0.2], \n    specs=[[{\"type\": \"xy\"}, {\"type\": \"domain\"}, {\"type\": \"domain\"}]],\n    subplot_titles=TGT_PK_COLS\n)\n# County ratio\ncounty_ratio = pks[\"county\"].value_counts()\ncounty_ratio = county_ratio.with_columns(\n    (pl.col(\"counts\") / len(pks) * 100).alias(\"ratio\"),\n    (pl.col(\"county\").cast(pl.Utf8).replace(county_id2name).alias(\"county_name\"))\n)\nfig.add_trace(go.Bar(x=county_ratio[\"county_name\"], y=county_ratio[\"ratio\"]), row=1, col=1)\n# Business or not\nbusiness_cnt = pks[\"is_business\"].value_counts()\nfig.add_trace(go.Pie(labels=business_cnt[\"is_business\"], values=business_cnt[\"counts\"], hoverinfo=\"label+percent\"), row=1, col=2)\n# Product types\nprod_type_cnt = pks[\"product_type\"].value_counts()\nprod_type_cnt = prod_type_cnt.with_columns(\n    (pl.col(\"product_type\").replace({0: \"Combined\", 1: \"Fixed\", 2: \"General service\", 3: \"Spot\"}).alias(\"product_name\"))\n)\nfig.add_trace(go.Pie(labels=prod_type_cnt[\"product_name\"], values=prod_type_cnt[\"counts\"], hoverinfo=\"label+percent\"), row=1, col=3)\nfig.update_layout(\n    title_text=\"Primary Keys Individual Distribution\",\n    margin=dict(l=12, r=12, t=75, b=50),\n    showlegend=False\n)\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-04T15:37:53.338654Z","iopub.execute_input":"2023-12-04T15:37:53.339465Z","iopub.status.idle":"2023-12-04T15:37:53.489361Z","shell.execute_reply.started":"2023-12-04T15:37:53.33938Z","shell.execute_reply":"2023-12-04T15:37:53.488095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"wth\"></a>\n### *All about Weather*\n[**<span style=\"color:#FEF1FE; background-color:#535d70;border-radius: 5px; padding: 2px\">Go to Table of Content</span>**](#toc)\n\nEnergy generation is subject to different sources, from which the electricity is produced. Renewable sources (*e.g.,* solar) are also somewhat subject to weather condition (*e.g.,* rainfall and solar radiation). Hence, analyzing target patterns with weather data may provide hidden clues facilitating advanced feature engineering and modeling.<br>\nThere are two weather information provided, namely the **historical and forecast** ones. We should note that there exists missing data in forecast weather data, which can be interpolated based on different techniques (*e.g.,* interpolation from nearest neighbor station).","metadata":{}},{"cell_type":"code","source":"h_wth = pl.read_csv(RAW_DATA_PATH / \"historical_weather.csv\", try_parse_dates=True)\nf_wth = pl.read_csv(RAW_DATA_PATH / \"forecast_weather.csv\", try_parse_dates=True)\n_summarize(h_wth, \"historical_weather.csv\", 1)\n_summarize(f_wth, \"forecast_weather.csv\", 1)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T15:37:53.494608Z","iopub.execute_input":"2023-12-04T15:37:53.495502Z","iopub.status.idle":"2023-12-04T15:38:10.496395Z","shell.execute_reply.started":"2023-12-04T15:37:53.495469Z","shell.execute_reply":"2023-12-04T15:38:10.495296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[![Screenshot-2023-12-03-at-16-15-10-Google.png](https://i.postimg.cc/W3G2mR20/Screenshot-2023-12-03-at-16-15-10-Google.png)](https://postimg.cc/62QJwm4Q)\n\nTo merge target sequences with weather data, the naive method is to consider **when (`datetime`/`data_block_id`) and where (`county`/`lat`/`lon`)** the weather data is recorded and use this information as the key to combine them. Before merging, we need to first align the timeline of information that is available at forecast time, which can help prevent errors during test phase.<br>\n\nThe figure above illustrates the available weather data (other data can be confirmed in the similar way) during test phase. Also, as describe in the [data tab](https://www.kaggle.com/competitions/predict-energy-behavior-of-prosumers/data), forecast is made at **11:00 a.m. each morning**. Suppose we're making prediction for period from 00:00 a.m. to 11:00 p.m. on May 28, 2023 (as shown in the red period above), we have access to historical weather data in the blue period and forecast one in the green period. Moreover, you can cache any past data if you want to use them.<br>\n\nSpecial thanks to valuable discussions and hard works on data block alignment and `datetime` fixing, which are listed as follows,\n1. [Timeline of availability of the data and data_block_id](https://www.kaggle.com/competitions/predict-energy-behavior-of-prosumers/discussion/455833) by @jeanbaptistescellier\n2. [Is the time zone the same for all data?](https://www.kaggle.com/competitions/predict-energy-behavior-of-prosumers/discussion/454145) by @sooyoungher\n3. [Enefit|Polars-preprocessing](https://www.kaggle.com/code/michaelo/enefit-polars-preprocessing/notebook) by @michaelo","metadata":{}},{"cell_type":"code","source":"def _cal_wth_local_mean(df_wth: pl.DataFrame, gp_keys: List[str]) -> pl.DataFrame:\n    \"\"\"Calculate county-level local weather stats.\n    \n    Only mean is derived now.\n\n    Args:\n        df_wth: weather data\n        gp_keys: groupby keys\n\n    Returns:\n        df_wth_local_stats: county-level local weather stats\n    \"\"\"\n    df_wth = df_wth.with_columns(*CAST_COORD)\n    df_wth_local_stats = (\n        df_wth\n        .join(station_latlon_county_map, on=list(COORD_COL2ABBR.values()), how=\"left\")\n        .filter(pl.col(\"county\").is_not_null())\n        .group_by(gp_keys).mean()\n        .select(*gp_keys, pl.exclude(gp_keys).name.suffix(\"_local_mean\"))\n    )\n\n    return df_wth_local_stats","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-04T15:38:10.497916Z","iopub.execute_input":"2023-12-04T15:38:10.498358Z","iopub.status.idle":"2023-12-04T15:38:10.50598Z","shell.execute_reply.started":"2023-12-04T15:38:10.498309Z","shell.execute_reply":"2023-12-04T15:38:10.504845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's load weather station positions which map each weather station to one of the county based on its coordinates (*i.e.,* `latitude` and `longitude` pair).\n\nSpecial thanks to the following excellent works,\n1. [mapping locations and county codes](https://www.kaggle.com/code/fabiendaniel/mapping-locations-and-county-codes) by @fabiendaniel\n2. [fabiendaniels-mapping-locations-and-county-codes](https://www.kaggle.com/datasets/michaelo/fabiendaniels-mapping-locations-and-county-codes) by @michaelo","metadata":{}},{"cell_type":"code","source":"station_latlon_county_map = pl.read_csv(PROC_DATA_PATH / \"county_lat_lon.csv\")\n\nCAST_COORD = [pl.col(\"lat\").cast(pl.Float32), pl.col(\"lon\").cast(pl.Float32)]\nstation_latlon_county_map = (\n    station_latlon_county_map\n    .drop(\"\")\n    .rename(COORD_COL2ABBR)\n    .with_columns(*CAST_COORD)\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T15:38:10.50716Z","iopub.execute_input":"2023-12-04T15:38:10.507571Z","iopub.status.idle":"2023-12-04T15:38:10.837453Z","shell.execute_reply.started":"2023-12-04T15:38:10.507533Z","shell.execute_reply":"2023-12-04T15:38:10.836308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then, let's process the historical weather data first. To align the timeline, the weather data can be shifted based on a specific period. Following the previous work, I take the time gap, 1 day plus 13 hours, as the period for shifting.\n\n> Considering periodicity, it's possible to find a better shifting amount.","metadata":{}},{"cell_type":"code","source":"h_wth = h_wth.with_columns(pl.col(\"datetime\") + pl.duration(days=1, hours=13))\n\nh_wth = h_wth.rename(COORD_COL2ABBR)\ngp_keys_h = [\"datetime\", \"county\"]\nh_wth_local_stats = _cal_wth_local_mean(h_wth, gp_keys=gp_keys_h)\n_summarize(h_wth_local_stats, \"Historical Weather Local Stats\", 1)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T15:38:10.839055Z","iopub.execute_input":"2023-12-04T15:38:10.839441Z","iopub.status.idle":"2023-12-04T15:38:11.126794Z","shell.execute_reply.started":"2023-12-04T15:38:10.839415Z","shell.execute_reply":"2023-12-04T15:38:11.126095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As for forecast weather data, the main issue is the time zone mismatch. I also try to fix it in the same manner as the previous work.","metadata":{}},{"cell_type":"code","source":"f_wth = f_wth.rename(COORD_COL2ABBR)\ngp_keys_f = [\"origin_datetime\", \"hours_ahead\", \"data_block_id\", \"forecast_datetime\"] + [\"county\"]\nf_wth_local_stats = _cal_wth_local_mean(f_wth, gp_keys_f)\n\nf_wth_local_stats = (\n    f_wth_local_stats\n    .with_columns([ \n        pl.col(\"forecast_datetime\")\n        .dt.convert_time_zone(\"Europe/Bucharest\").alias(\"datetime\")\n        .dt.replace_time_zone(None).cast(pl.Datetime(\"us\"))\n    ])\n    .drop(\"forecast_datetime\")\n)\n_summarize(f_wth_local_stats, \"Forecast Weather Local Stats\", 1)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T15:38:11.127927Z","iopub.execute_input":"2023-12-04T15:38:11.128484Z","iopub.status.idle":"2023-12-04T15:38:11.755092Z","shell.execute_reply.started":"2023-12-04T15:38:11.128456Z","shell.execute_reply":"2023-12-04T15:38:11.753899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After weather data is processed, let's go ahead to merge weather with the main training data.\n\n> It's worth noting that **there exist overlappings of forecast weather data for those forecasts made nearby**. Hence `data_block_id` should be provided as another key to avoid errors when merging data. ","metadata":{}},{"cell_type":"code","source":"train = (\n    train\n    .join(h_wth_local_stats, on=gp_keys_h, how=\"left\")\n    .join(f_wth_local_stats, on=[\"data_block_id\", \"datetime\", \"county\"], how=\"left\", suffix=\"_f\")\n)\n_summarize(train, \"Train with Weather\", 1)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T15:38:11.756537Z","iopub.execute_input":"2023-12-04T15:38:11.757056Z","iopub.status.idle":"2023-12-04T15:38:12.741976Z","shell.execute_reply.started":"2023-12-04T15:38:11.757018Z","shell.execute_reply":"2023-12-04T15:38:12.740891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then, you can save the processed data if you want!","metadata":{}},{"cell_type":"code","source":"save_train_with_weather = True\nif save_train_with_weather:\n    train.write_parquet(\"train_with_weather.parquet\")","metadata":{"execution":{"iopub.status.busy":"2023-12-04T15:38:12.743256Z","iopub.execute_input":"2023-12-04T15:38:12.743556Z","iopub.status.idle":"2023-12-04T15:38:14.927652Z","shell.execute_reply.started":"2023-12-04T15:38:12.74353Z","shell.execute_reply":"2023-12-04T15:38:14.92679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"st_dash\"></a>\n## 2. Towards Spatio-Temporal Analysis with Dash \n[**<span style=\"color:#FEF1FE; background-color:#535d70;border-radius: 5px; padding: 2px\">Go to Table of Content</span>**](#toc)\n\nAnalyzing target sequences with weather data can provide hidden clues for advanced feature engineering and modeling. I've spent the past 2+ days to create a naive version of interactive data explorer based on `dash`. The main functionalities are summarized as follows,<br>\n1. Target sequence plot\n    * Select different counties with different target types.\n    * Toggle on/off target sequences of specific `prediction_unit_id`.\n2. Forecast weather plot\n    * Select forecast weather feature, which is aggregated over stations in the same county.\n    * Enable co-analyze with target sequences.\n3. Estonia map with county boundary and central point\n    * Select county to highlight where you're focusing now!\n\nWe can view this challenge as a 2-axis problem, namely **spatial** dimension and **temporal** one. For the former, prosumers in the **neighbor** area might be subject to the similar weather condition, which is an important factor affecting energy production. Hence, there might be **spatial dependency** among these prosumers. As for the latter, there exist **temporal patterns** within target/weather sequences, such as periodicity. Both can be helpful for featue engineering.","metadata":{}},{"cell_type":"code","source":"def _get_colors(n_colors: int = 16) -> List[str]:\n    \"\"\"Reture color list for visualizing categorical column.\"\"\"\n    colors = plotly.colors.sample_colorscale(\"Bluered\", [i / 15 for i in range(16)])\n    \n    # Visualize color palette\n    fig = go.Figure()\n    for i, c in enumerate(colors):\n        fig.add_bar(x=[i], y=[1], marker_color=c, showlegend=False, name=c)\n    fig.update_layout(\n        title={\"text\": f\"Color Palette of {n_colors} Colors\", \"yanchor\": \"top\"},\n        height=50,\n        margin=dict(l=0, r=0, t=30, b=0),\n        bargap=0\n    )\n    fig.update_xaxes(showticklabels=False)\n    fig.update_yaxes(showticklabels=False)\n    fig.show()\n\n    return colors","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-04T15:38:14.928788Z","iopub.execute_input":"2023-12-04T15:38:14.929085Z","iopub.status.idle":"2023-12-04T15:38:14.937175Z","shell.execute_reply.started":"2023-12-04T15:38:14.929058Z","shell.execute_reply":"2023-12-04T15:38:14.936046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"st_load_data\"></a>\n### *Load Necessary Data*\n[**<span style=\"color:#FEF1FE; background-color:#535d70;border-radius: 5px; padding: 2px\">Go to Table of Content</span>**](#toc)","metadata":{}},{"cell_type":"code","source":"with open(PROC_DATA_PATH / \"county_id2name.pkl\", \"rb\") as f:\n    county_id2name = pickle.load(f)\n    county_name2id = {v: k for k, v in county_id2name.items()}\ncounty_name2latlon = pl.read_parquet(PROC_DATA_PATH / \"county_name2latlon.parquet\")\ntrain = train.with_columns(pl.col(\"county\").cast(pl.Utf8).replace(county_id2name).alias(\"county_name\"))","metadata":{"execution":{"iopub.status.busy":"2023-12-04T15:38:14.938863Z","iopub.execute_input":"2023-12-04T15:38:14.939211Z","iopub.status.idle":"2023-12-04T15:38:15.163712Z","shell.execute_reply.started":"2023-12-04T15:38:14.939182Z","shell.execute_reply":"2023-12-04T15:38:15.162927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"st_gen_opts\"></a>\n### *Generate Interactive Options*\n[**<span style=\"color:#FEF1FE; background-color:#535d70;border-radius: 5px; padding: 2px\">Go to Table of Content</span>**](#toc)\n\nAs described above, we need to specify options users can choose from.","metadata":{}},{"cell_type":"code","source":"county_list = [f\"{cid}-{name}\" for cid, name in county_id2name.items()]\ncounty_opts = [{\"label\": c, \"value\": c} for c in [\"All\"] + county_list]\ncounty_opts_map = {c: [c] for c in county_list}\ncounty_opts_map[\"All\"] = county_list\n\n# Colors for county central points\ncolors = _get_colors(16)\ncounty_name2color = dict(zip((county_id2name.values()), colors))","metadata":{"execution":{"iopub.status.busy":"2023-12-04T15:38:15.165144Z","iopub.execute_input":"2023-12-04T15:38:15.165878Z","iopub.status.idle":"2023-12-04T15:38:15.217679Z","shell.execute_reply.started":"2023-12-04T15:38:15.165843Z","shell.execute_reply":"2023-12-04T15:38:15.21665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fwth_feat_list = [\n    \"temperature\",\n    \"dewpoint\",\n    \"cloudcover_high\",\n    \"cloudcover_low\",\n    \"cloudcover_mid\",\n    \"cloudcover_total\",\n    \"10_metre_u_wind_component\",\n    \"10_metre_v_wind_component\",\n    \"direct_solar_radiation\",\n    \"surface_solar_radiation_downwards\",\n    \"snowfall\",\n    \"total_precipitation\"\n]\nfwth_feat_opts = [{\"label\": c, \"value\": c} for c in fwth_feat_list]\nfwth_feat_opts_map = {c: [c] for c in fwth_feat_list}","metadata":{"execution":{"iopub.status.busy":"2023-12-04T15:38:15.218952Z","iopub.execute_input":"2023-12-04T15:38:15.219255Z","iopub.status.idle":"2023-12-04T15:38:15.224788Z","shell.execute_reply.started":"2023-12-04T15:38:15.21923Z","shell.execute_reply":"2023-12-04T15:38:15.223685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"st_layout\"></a>\n### *Define Dashboard Layout*\n[**<span style=\"color:#FEF1FE; background-color:#535d70;border-radius: 5px; padding: 2px\">Go to Table of Content</span>**](#toc)\n\nNext, we need to define the dashboard layout, which is the user interface.","metadata":{}},{"cell_type":"code","source":"app = Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])","metadata":{"execution":{"iopub.status.busy":"2023-12-04T15:38:15.226092Z","iopub.execute_input":"2023-12-04T15:38:15.226451Z","iopub.status.idle":"2023-12-04T15:38:15.248303Z","shell.execute_reply.started":"2023-12-04T15:38:15.226399Z","shell.execute_reply":"2023-12-04T15:38:15.247144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app.layout = html.Div([\n    dbc.Row([\n        html.H1(\"Towards Spatio-Temporal Analysis\", className=\"text-center\")\n    ]),\n\n    dbc.Row([        \n        dbc.Col([\n            html.Div([\n                html.H4(\"Select county:\"),\n                dcc.Dropdown(id=\"county-dropdown\", options=county_opts, value=\"All\", clearable=False)\n            ])\n        ], width=4),\n        dbc.Col([\n            html.Div([\n                html.H4(\"Select target type:\"),\n                dbc.RadioItems(\n                    id=\"target-radio\",\n                    options=[{\"label\": x, \"value\": x} for x in [\"Consumption\", \"Production\"]], \n                    value=\"Consumption\"\n                )\n            ])\n        ], width=4),\n        dbc.Col([\n            html.Div([\n                html.H4(\"Select forecast weather feature:\"),\n                dcc.Dropdown(id=\"fwth-feat-dropdown\", options=fwth_feat_opts, value=fwth_feat_list[0], clearable=False)\n            ])\n        ], width=4),\n\n        html.Hr(),\n\n        dbc.Row([\n            dbc.Col([\n                dcc.Graph(id=\"target\"), \n                dcc.Graph(id=\"wth\")\n            ], width=6),\n            dbc.Col([\n                dcc.Graph(id=\"map\") \n            ], width=6) \n        ]),      \n    ]),\n])\n\nmap_layout = go.Layout(\n    autosize=True,\n    hovermode=\"closest\",\n    mapbox_style=\"open-street-map\",\n    mapbox=dict(\n        bearing=0,\n        center=dict(lat=58.65, lon=24.95),\n        pitch=0,\n        zoom=6\n    ),\n    showlegend=False,\n    margin=dict(l=5, r=20, t=20, b=5, pad=0)\n)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-04T15:38:15.249851Z","iopub.execute_input":"2023-12-04T15:38:15.250159Z","iopub.status.idle":"2023-12-04T15:38:15.281182Z","shell.execute_reply.started":"2023-12-04T15:38:15.250134Z","shell.execute_reply":"2023-12-04T15:38:15.280315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"st_cbs\"></a>\n### *Define Callbacks*\n[**<span style=\"color:#FEF1FE; background-color:#535d70;border-radius: 5px; padding: 2px\">Go to Table of Content</span>**](#toc)\n\nThen, callbacks are defined to support output update (*e.g.,* figure rendering) based on user inputs.","metadata":{}},{"cell_type":"code","source":"@callback(\n    Output(\"target\", \"figure\"),\n    [Input(\"county-dropdown\", \"value\"),\n     Input(\"target-radio\", \"value\")]\n)\ndef update_target(slc_county, slc_target_type):\n    \"\"\"Update target sequences.\"\"\"\n    if slc_county == \"All\":\n        slc_county_list = county_opts_map[county_list[0]] \n    else:\n        slc_county_list = county_opts_map[slc_county]\n    slc_county_name = [\"-\".join(c.split(\"-\")[1:]) for c in slc_county_list]\n    is_cons = 1 if slc_target_type == \"Consumption\" else 0\n    target = (\n        train \n        .filter((pl.col(\"county_name\").is_in(slc_county_name)) & (pl.col(\"is_consumption\") == is_cons))\n        .sort(\"datetime\")\n    )\n    fig = px.line(target, x=\"datetime\", y=\"target\", color=\"prediction_unit_id\")\n    fig.update_layout(\n        margin=dict(l=0, r=0, t=30, b=0),\n        legend=dict(\n            orientation=\"h\",\n            yanchor=\"bottom\",\n            y=1.02,\n            xanchor=\"right\",\n            x=1\n        )\n    )\n    \n    return fig\n\n\n@callback(\n    Output(\"wth\", \"figure\"),\n    [Input(\"county-dropdown\", \"value\"),\n     Input(\"fwth-feat-dropdown\", \"value\")]\n)\ndef update_weather(slc_county, slc_fwth_feat):\n    if slc_county == \"All\":\n        slc_county_list = county_opts_map[county_list[0]] \n    else:\n        slc_county_list = county_opts_map[slc_county]\n    slc_county_name = [\"-\".join(c.split(\"-\")[1:]) for c in slc_county_list]\n\n    slc_fwth_feat_name = fwth_feat_opts_map[slc_fwth_feat][0]\n    if f\"{slc_fwth_feat_name}_local_mean_f\" in train:\n        feat_name_suffix = \"local_mean_f\"\n    else:\n        feat_name_suffix = \"local_mean\"\n    slc_fwth_feat_name = f\"{slc_fwth_feat_name}_{feat_name_suffix}\"\n\n    wth = (\n        train\n        .filter((pl.col(\"county_name\").is_in(slc_county_name)))\n        .select([\"datetime\", slc_fwth_feat_name])\n        .unique()\n        .sort(\"datetime\")\n    )\n    fig = px.line(wth, x=\"datetime\", y=slc_fwth_feat_name)\n    fig.update_layout(\n        margin=dict(l=0, r=0, t=30, b=0)\n    )\n\n    return fig\n\n\n@callback(\n    Output(\"map\", \"figure\"),\n    Input(\"county-dropdown\", \"value\") \n)\ndef update_map(slc_county):\n    slc_county_list = county_opts_map[slc_county]\n    slc_county_name = [\"-\".join(c.split(\"-\")[1:]) for c in slc_county_list]\n\n    data = []\n    # County boundary\n    for r in county_name2latlon.drop_nulls().iter_rows(named=True):\n        data.append(\n            go.Scattermapbox(\n                lat=r[\"lat_bound\"],\n                lon=r[\"lon_bound\"],\n                mode=\"lines\",\n                line=dict(width=1, color=\"gray\"),\n                name=r[\"county_name\"],\n                fill=\"toself\" if r[\"county_name\"] in slc_county_name else None,\n            )\n        )\n\n    # County central point\n    for county_name in sorted(slc_county_name):\n        data.append(\n            go.Scattermapbox(\n                lat=county_name2latlon.filter(pl.col(\"county_name\") == county_name)[\"lat\"],\n                lon=county_name2latlon.filter(pl.col(\"county_name\") == county_name)[\"lon\"],\n                mode=\"markers\",\n                marker=dict(\n                    size=10,\n                    color=county_name2color[county_name],\n                    opacity=0.7\n                ),\n                name=county_name,\n                hoverinfo=\"name\"\n            )\n        )\n\n    return {\n        \"data\": data,\n        \"layout\": map_layout\n    }","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-04T15:38:15.282796Z","iopub.execute_input":"2023-12-04T15:38:15.283273Z","iopub.status.idle":"2023-12-04T15:38:15.299082Z","shell.execute_reply.started":"2023-12-04T15:38:15.283246Z","shell.execute_reply":"2023-12-04T15:38:15.297952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"st_start\"></a>\n### *Start Exploration*\n[**<span style=\"color:#FEF1FE; background-color:#535d70;border-radius: 5px; padding: 2px\">Go to Table of Content</span>**](#toc)\n\nFinally, we can start playing round with this dashboard! You can switch `jupyter_mode` to `\"inline\"` if you want to explore within the notebook. Owing to the `ngrok` session issue, I provide a quick demo below. Please feel free to deploy your own dashboard and play around with it!","metadata":{}},{"cell_type":"code","source":"app.run(jupyter_mode=\"external\", jupyter_server_url=tunnel.public_url)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T15:38:15.323285Z","iopub.execute_input":"2023-12-04T15:38:15.324202Z","iopub.status.idle":"2023-12-04T15:38:15.341928Z","shell.execute_reply.started":"2023-12-04T15:38:15.32416Z","shell.execute_reply":"2023-12-04T15:38:15.340888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExOHBjc2M3ZzdqdmNtdmE5bzV0ejlxMnZzZW8yZHJjaDd2MTI3c3IwaCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/X1NNUk8N3SSprG67Dn/source.gif)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"baseline\"></a>\n## 3. Baseline Model with Local CV\n[**<span style=\"color:#FEF1FE; background-color:#535d70;border-radius: 5px; padding: 2px\">Go to Table of Content</span>**](#toc)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Work in Progress...","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}