{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import OrdinalEncoder, RobustScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.cluster import DBSCAN\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-21T16:48:27.407816Z","iopub.execute_input":"2023-03-21T16:48:27.408221Z","iopub.status.idle":"2023-03-21T16:48:27.422907Z","shell.execute_reply.started":"2023-03-21T16:48:27.408186Z","shell.execute_reply":"2023-03-21T16:48:27.421717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df= pd.read_csv(\"/kaggle/input/iris/Iris.csv\")\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2023-03-21T16:48:27.43097Z","iopub.execute_input":"2023-03-21T16:48:27.431343Z","iopub.status.idle":"2023-03-21T16:48:27.452665Z","shell.execute_reply.started":"2023-03-21T16:48:27.43131Z","shell.execute_reply":"2023-03-21T16:48:27.450753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(columns=[\"Id\",\"Species\"], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-03-21T16:48:27.455781Z","iopub.execute_input":"2023-03-21T16:48:27.457121Z","iopub.status.idle":"2023-03-21T16:48:27.464366Z","shell.execute_reply.started":"2023-03-21T16:48:27.457054Z","shell.execute_reply":"2023-03-21T16:48:27.463212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# algorithme de clustering DBSCAN","metadata":{}},{"cell_type":"markdown","source":"***le paramètre \"eps=0.5\" définit la distance maximale entre deux points pour qu'ils soient considérés comme appartenant au même groupe. Les points situés à une distance supérieure à eps seront considérés comme des points isolés (ou du bruit).\n\n***le min_samples=2 spécifie le nombre minimum de points nécessaires pour former un groupe.","metadata":{}},{"cell_type":"code","source":"dbscan= DBSCAN(eps=0.5, min_samples=2).fit(df)\ndbscan.labels_","metadata":{"execution":{"iopub.status.busy":"2023-03-21T16:48:27.475555Z","iopub.execute_input":"2023-03-21T16:48:27.476252Z","iopub.status.idle":"2023-03-21T16:48:27.489475Z","shell.execute_reply.started":"2023-03-21T16:48:27.476217Z","shell.execute_reply":"2023-03-21T16:48:27.488046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lb=dbscan.labels_\nprint(set(lb))","metadata":{"execution":{"iopub.status.busy":"2023-03-21T16:48:27.491973Z","iopub.execute_input":"2023-03-21T16:48:27.492925Z","iopub.status.idle":"2023-03-21T16:48:27.503956Z","shell.execute_reply.started":"2023-03-21T16:48:27.492882Z","shell.execute_reply":"2023-03-21T16:48:27.502355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"'dbscan.labels_' renvoie les étiquettes de cluster pour chaque point dans le dataframe df. Les étiquettes sont représentées sous forme d'un tableau numpy, où chaque élément du tableau correspond à l'étiquette du cluster pour le point correspondant dans le dataframe df.\n\n***Les étiquettes sont représentées sous forme d'entiers, avec la valeur -1 étant réservée pour les points qui sont considérés comme des points isolés (ou du bruit).\n\n***Les clusters sont représentés par des numéros positifs: {0, 1, 2, 3, 4, 5} Soit 6 clusters.","metadata":{}},{"cell_type":"markdown","source":"# intégrons un score silhouette pour évaluer la qualité des clusters formés par DBSCAN.","metadata":{}},{"cell_type":"code","source":"dbscan = DBSCAN(eps=0.5, min_samples=2)\nlabels = dbscan.fit_predict(df)\nsilhouette_avg = silhouette_score(df, labels)\nprint(\"Le score silhouette moyen est :\", silhouette_avg)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-21T16:48:27.512085Z","iopub.execute_input":"2023-03-21T16:48:27.513389Z","iopub.status.idle":"2023-03-21T16:48:27.545478Z","shell.execute_reply.started":"2023-03-21T16:48:27.513336Z","shell.execute_reply":"2023-03-21T16:48:27.543932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Ici, la méthode fit_predict est utilisée pour appliquer l'algorithme DBSCAN sur les données et renvoyer les étiquettes de cluster pour chaque point. La fonction silhouette_score prend en entrée les données et les étiquettes de cluster et renvoie le score silhouette moyen pour tous les points.","metadata":{}},{"cell_type":"markdown","source":"# Calculons le score silhouette de chaque étiquette dans DBSCAN, on peut utiliser la fonction silhouette_samples de la bibliothèque scikit-learn. ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import silhouette_samples\n\ndbscan = DBSCAN(eps=0.5, min_samples=2)\nlabels = dbscan.fit_predict(df)\nsilhouette_vals = silhouette_samples(df, labels)\n\nfor i in range(len(set(labels))):\n    label_silhouette_vals = silhouette_vals[labels == i]\n    if len(label_silhouette_vals) > 0:\n        print(\"Le score silhouette pour l'étiquette \", i, \"est :\", np.mean(label_silhouette_vals))\n    else:\n        print(\"L'étiquette \", i, \" n'a aucun point.\")","metadata":{"execution":{"iopub.status.busy":"2023-03-21T16:49:02.19917Z","iopub.execute_input":"2023-03-21T16:49:02.199596Z","iopub.status.idle":"2023-03-21T16:49:02.224137Z","shell.execute_reply.started":"2023-03-21T16:49:02.199552Z","shell.execute_reply":"2023-03-21T16:49:02.222775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***la fonction set est utilisée pour obtenir les étiquettes uniques dans labels. Ensuite, pour chaque étiquette unique, la fonction silhouette_samples est utilisée pour calculer le score silhouette pour chaque point qui appartient à cette étiquette. La moyenne de ces scores est ensuite calculée et affichée pour cette étiquette.\n\n\n***L'étiquettes 1 a un score silhouette négatif, ce qui indique que ces points pourraient être mieux regroupés dans un autre cluster.\n\n\n***Le score silhouette mesure la similarité d'un point avec les autres points de son cluster par rapport aux points des clusters voisins. Plus le score silhouette est proche de 1, mieux c'est, car cela signifie que le point est bien ajusté à son cluster et mal ajusté aux clusters voisins. Si le score est proche de -1, cela signifie que le point est mal ajusté à son cluster et bien ajusté aux clusters voisins, et si le score est proche de 0, cela signifie que le point est proche de la limite entre deux clusters.\n\n\n***Dans le résultat donné, les étiquettes 0, 2, 3, 4 et 5 ont des scores silhouette positifs, ce qui est plutôt bon. L'étiquette 6 n'a aucun point, ce qui signifie qu'il n'y a pas assez de données pour calculer un score silhouette.Il s'agit de l'étiquette contenant les points isolés.","metadata":{}}]}