{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","scrolled":true,"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":39,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true},"cell_type":"markdown","source":"In this kernel I'm just going to do some missing value imputation, generate dummy variables when ever required and build some basic models and make a prediction based on models that give good accuracy that are also least correlated."},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"d6dab946849a894402c68f57409c60c04792498b"},"cell_type":"code","source":"# Getting all the required packages\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set_style('whitegrid')\n%matplotlib inline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB ","execution_count":40,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"9061a86732d3a587452b373946be9267811539f0"},"cell_type":"code","source":"# Reading the train and test files\ntrain_data = pd.read_csv('../input/train.csv')\ntest_data = pd.read_csv('../input/test.csv')","execution_count":41,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f51e0dad9dab5cc91ef1ed08506b041ba86f56a"},"cell_type":"code","source":"print('Shape of train data: ', train_data.shape)\nprint('Shape of test data: ', test_data.shape)","execution_count":42,"outputs":[]},{"metadata":{"_uuid":"69a1e2097ea6142ade4b0cd78ae34919d05bba12"},"cell_type":"markdown","source":"So, we are having 11 variables overall, the additional one in the train data is the output variable.\nAnd there are 891 examples in the train dataset and there are 418 examples in the test dataset.\nGenerally for building any ML model (that has good accuracy and less variance) the amount of data requried should be at least in 1000s."},{"metadata":{"_uuid":"e7eff4eebe6ca736fd930f97f161af2053726692"},"cell_type":"markdown","source":"Generally for building any ML model (that has good accuracy and less variance) the amount of data requried should be at least in 1000s."},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"26c0b1a943caad3bd5276ed6d71c637419690faf"},"cell_type":"code","source":"# getting a look at what the train data looks like\n\ntrain_data.head()","execution_count":43,"outputs":[]},{"metadata":{"_uuid":"bde33093e2d4bf79a507ef96b6efc81a3aa848f7"},"cell_type":"markdown","source":"1. By looking at the data all I can clearly see some useless variables - they are Name, Ticket, PassengerID and Cabin. \n2. Ticket and Cabin could be analysed using some NLP, however, I'm not going to do that.\n3. So I'm going to remove those columns from both train and test"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"87f95d63a2db2795747f776b35db675c6baa459d"},"cell_type":"code","source":"# Getting the overall description of the data that we have\ntrain_data.info()\nprint('\\n----------------------------------\\n')\ntest_data.info()","execution_count":44,"outputs":[]},{"metadata":{"_uuid":"40f74e0fb28ee2936335c20f629b75f666fbb293"},"cell_type":"markdown","source":"* Age, Fare and Embarked has to be imputed in the train and test dataset.\n* But, before that let's drop the unnecessary variables"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"dec618da6ebdc873e447547067fdfe08cee7524b"},"cell_type":"code","source":"train_data = train_data.drop(['Name', 'Ticket', 'PassengerId','Cabin'], axis =1)\ntest_data = test_data.drop(['Name', 'Ticket','Cabin'], axis = 1)","execution_count":45,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"b7d71dc26ed2ec456db5b17bdfe3d7ba9ba82009"},"cell_type":"code","source":"# Now its time for imputation\n# Mode for categorical variable and mean for continuous variable\nage_mean = train_data['Age'].mean()\ntrain_data['Age'] = train_data['Age'].fillna(age_mean)\ntest_data['Age'] = test_data['Age'].fillna(age_mean)\n\nfare_mean = train_data['Fare'].mean()\ntest_data['Fare'] = test_data['Fare'].fillna(fare_mean)\n\nembarked_mode = train_data['Embarked'].mode()\ntrain_data['Embarked'] = train_data['Embarked'].fillna(embarked_mode)\ntest_data['Embarked'] = test_data['Embarked'].fillna(embarked_mode)","execution_count":46,"outputs":[]},{"metadata":{"_uuid":"e7eaee3fce91f6b529addd40b9bb046f14506270"},"cell_type":"markdown","source":"* Now it's time to create the dummy variables for the dataset.\n* I think we need dummy variables for Embarked, Sex and PClass\n* But PClass is tagged as an int variable, looks like it has to be manually tagged as categorical variable"},{"metadata":{"trusted":true,"_uuid":"45c62d18f9ebefe6d30006b481adc460cdb4cd34"},"cell_type":"code","source":"# Let's see what's there in the PClass\nsns.distplot(train_data['Pclass'])","execution_count":47,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6536c92650f2b0c454c1f71591c5e91efb61c843"},"cell_type":"code","source":"train_data.Pclass[train_data.Pclass == 1] = 'First'\n\ntrain_data.Pclass[train_data.Pclass == 2] = 'Second'\n\ntrain_data.Pclass[train_data.Pclass == 3] = 'Third'\n\ntest_data.Pclass[test_data.Pclass == 1] = 'First'\n\ntest_data.Pclass[test_data.Pclass == 2] = 'Second'\n\ntest_data.Pclass[test_data.Pclass == 3] = 'Third'","execution_count":48,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"49988d3695a72b48bf462286efd73f226e61acdd"},"cell_type":"code","source":"# Lets create the dummy variables now\n\ntrain_dummy = pd.get_dummies(train_data)\ntest_dummy = pd.get_dummies(test_data)","execution_count":53,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca8d6fe086efdd8dca62f0d19dbbc2bc3262ea67"},"cell_type":"code","source":"train_dummy.info()\nprint('\\n--------------------\\n')\ntest_dummy.info()","execution_count":50,"outputs":[]},{"metadata":{"_uuid":"1a12e318861cf8712a59c1bec1f9b904c5f7b908"},"cell_type":"markdown","source":"* For a variable with k categories we only need (k-1) dummy variables.\n* So let's remove the excess variables from both train and test"},{"metadata":{"trusted":true,"_uuid":"70fa018d24ba6022da06de3d8d0a57e7e302086e"},"cell_type":"code","source":"train_dummy.drop(['Pclass_First','Sex_male','Embarked_C'], axis =1, inplace = True)\ntest_dummy.drop(['Pclass_First','Sex_male','Embarked_C','PassengerId'], axis = 1, inplace = True)","execution_count":54,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"collapsed":true,"_uuid":"6a07f6e520d281f892985439add7d56e6ee11e17"},"cell_type":"code","source":"Train_Y = train_dummy['Survived']\nTrain_X = train_dummy.drop(['Survived'], axis = 1)\nTest_X = test_dummy","execution_count":55,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85245c30592a4df1f16a5bc7758f17679a3f470d"},"cell_type":"code","source":"# Logistic Regression Model\n\nLogReg = LogisticRegression()\nLogReg.fit(Train_X, Train_Y)\nY_Pred = LogReg.predict(Test_X)\nLogReg.score(Train_X, Train_Y)","execution_count":56,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0be7ffff2d71fed9dff58d1d3efec0f4ee972f7"},"cell_type":"code","source":"# Support Vector Machines\n\nsvc = SVC()\nsvc.fit(Train_X, Train_Y)\nY_pred_svm = svc.predict(Test_X)\nsvc.score(Train_X, Train_Y)","execution_count":57,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"090c9b28776902b55378d3e5371935473ad2b5b0"},"cell_type":"code","source":"# Random Forests\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\n\nrandom_forest.fit(Train_X, Train_Y)\n\nY_pred_rf = random_forest.predict(Test_X)\n\nrandom_forest.score(Train_X, Train_Y)","execution_count":58,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"024eed8ab47217701964279a16318682037faad0"},"cell_type":"code","source":"# Using KNN\n\nknn = KNeighborsClassifier(n_neighbors = 1)\n\nknn.fit(Train_X, Train_Y)\n\nY_pred_Knn = knn.predict(Test_X)\n\nknn.score(Train_X, Train_Y)","execution_count":59,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1c39b7626d2117487d9a25ea128e6412fb48a20"},"cell_type":"code","source":"# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\n\ngaussian.fit(Train_X, Train_Y)\n\nY_pred_GNB = gaussian.predict(Test_X)\n\ngaussian.score(Train_X, Train_Y)","execution_count":60,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"1697b583493681d464b149b7922cee205f31f36e"},"cell_type":"code","source":"Y = pd.DataFrame()\nY['Logistic'] = Y_Pred\nY['SVM'] = Y_pred_svm\nY['RF'] = Y_pred_rf\nY['KNN'] = Y_pred_Knn\nY['GNB'] = Y_pred_GNB","execution_count":61,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2fd320fd70d252534bf605163c4db5e58fae091c"},"cell_type":"code","source":"# Now lets see the correlation between all these models\nY.corr()","execution_count":62,"outputs":[]},{"metadata":{"_uuid":"ba0619a314db8ddc089217b53791ba0c1db39231"},"cell_type":"markdown","source":"* It looks like none of the models are highly correlated.\n* The three best models are RF, SVM and KNN.\n* Lets make an ensemble of these three models."},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"cb611f872bb8149b30f1f849b99c65f15a514597"},"cell_type":"code","source":"Final_Pred = (Y_pred_rf + Y_pred_Knn + Y_pred_svm )/3\nFinal_Pred = np.round(Final_Pred)","execution_count":63,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"750b314a10d739a302d7c01c5fe90db62c86133a"},"cell_type":"code","source":"submission = pd.DataFrame({\n        \"PassengerId\": test_data[\"PassengerId\"],\n        \"Survived\": Final_Pred\n    })\n\nsubmission.to_csv('titanic.csv', index=False)","execution_count":64,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}