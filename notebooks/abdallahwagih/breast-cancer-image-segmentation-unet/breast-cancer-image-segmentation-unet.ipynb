{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Import Needed Modules**","metadata":{"id":"g_3rM2Af6CwS"}},{"cell_type":"code","source":"# import system libs \nimport os\nimport time\nimport glob\nimport shutil\n\n# import data handling tools \nimport cv2\nimport PIL\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport matplotlib.pyplot as plt\n\n# import Deep learning Libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.image as tfi\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Model, load_model\nfrom keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.layers import Conv2D,  MaxPool2D, UpSampling2D, concatenate, Activation\nfrom tensorflow.keras.layers import Layer, Input, Add, Multiply, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam, Adamax\n\n# Ignore Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint ('modules loaded')","metadata":{"execution":{"iopub.status.busy":"2023-01-26T22:05:30.593774Z","iopub.execute_input":"2023-01-26T22:05:30.594253Z","iopub.status.idle":"2023-01-26T22:05:36.825837Z","shell.execute_reply.started":"2023-01-26T22:05:30.594151Z","shell.execute_reply":"2023-01-26T22:05:36.824855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Create Needed Functions**","metadata":{}},{"cell_type":"markdown","source":"### **Function to create data**","metadata":{}},{"cell_type":"code","source":"def create_data(data_dir):\n    image_paths = []\n    mask_paths = []\n    classes = sorted(os.listdir(data_dir))\n    \n    single_mask_paths = sorted([sorted(glob.glob(data_dir + name + \"/*mask.png\")) for name in classes])\n    double_mask_paths = sorted([sorted(glob.glob(data_dir + name + \"/*mask_1.png\")) for name in classes])\n    \n    for class_path in single_mask_paths:\n        for path in class_path:\n            img_path = path.replace('_mask', '')\n            image_paths.append(img_path)\n            mask_paths.append(path)\n    \n    return image_paths, mask_paths","metadata":{"execution":{"iopub.status.busy":"2023-01-26T22:05:36.827531Z","iopub.execute_input":"2023-01-26T22:05:36.828047Z","iopub.status.idle":"2023-01-26T22:05:36.837485Z","shell.execute_reply.started":"2023-01-26T22:05:36.828019Z","shell.execute_reply":"2023-01-26T22:05:36.835702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Functions to read images**","metadata":{}},{"cell_type":"code","source":"# function to read an image\ndef load_image(image, SIZE):\n    return np.round(tfi.resize(img_to_array(load_img(image)) / 255., (SIZE, SIZE)), 4)\n\n# function to read multiple images\ndef load_images(image_paths, SIZE, mask=False, trim=None):\n    if trim is not None:\n        image_paths = image_paths[:trim]\n    \n    if mask:\n        images = np.zeros(shape=(len(image_paths), SIZE, SIZE, 1))\n    else:\n        images = np.zeros(shape=(len(image_paths), SIZE, SIZE, 3))\n    \n    for i, image in enumerate(image_paths):\n        img = load_image(image, SIZE)\n        if mask:\n            images[i] = img[:, :, :1]\n        else:\n            images[i] = img\n    \n    return images","metadata":{"id":"Sv5MB-unO3tY","execution":{"iopub.status.busy":"2023-01-26T22:05:36.838952Z","iopub.execute_input":"2023-01-26T22:05:36.839335Z","iopub.status.idle":"2023-01-26T22:05:36.856916Z","shell.execute_reply.started":"2023-01-26T22:05:36.839295Z","shell.execute_reply":"2023-01-26T22:05:36.85595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Function to display data sample**","metadata":{}},{"cell_type":"code","source":"def show_image(image, title=None, cmap=None, alpha=1):\n    plt.imshow(image, cmap=cmap, alpha=alpha)\n    if title is not None:\n        plt.title(title)\n    plt.axis('off')\n\ndef show_mask(image, mask, cmap=None, alpha=0.4):\n    plt.imshow(image)\n    plt.imshow(tf.squeeze(mask), cmap=cmap, alpha=alpha)\n    plt.axis('off')\n\ndef show_images(imgs, msks):\n    plt.figure(figsize=(13,8))\n    \n    for i in range(15):\n        plt.subplot(3,5,i+1)\n        id = np.random.randint(len(imgs))\n        show_mask(imgs[id], msks[id], cmap='binary')\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-26T22:05:36.859469Z","iopub.execute_input":"2023-01-26T22:05:36.860044Z","iopub.status.idle":"2023-01-26T22:05:36.870561Z","shell.execute_reply.started":"2023-01-26T22:05:36.860008Z","shell.execute_reply":"2023-01-26T22:05:36.869602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Encoder**","metadata":{}},{"cell_type":"code","source":"class EncoderBlock(Layer):\n\n    def __init__(self, filters, rate, pooling=True, **kwargs):\n        super(EncoderBlock, self).__init__(**kwargs)\n\n        self.filters = filters\n        self.rate = rate\n        self.pooling = pooling\n\n        self.c1 = Conv2D(filters, kernel_size=3, strides=1, padding='same', activation='relu', kernel_initializer='he_normal')\n        self.drop = Dropout(rate)\n        self.c2 = Conv2D(filters, kernel_size=3, strides=1, padding='same', activation='relu', kernel_initializer='he_normal')\n        self.pool = MaxPool2D()\n\n    def call(self, X):\n        x = self.c1(X)\n        x = self.drop(x)\n        x = self.c2(x)\n        if self.pooling:\n            y = self.pool(x)\n            return y, x\n        else:\n            return x\n\n    def get_config(self):\n        base_config = super().get_config()\n        return {\n            **base_config,\n            \"filters\":self.filters,\n            'rate':self.rate,\n            'pooling':self.pooling\n        }","metadata":{"execution":{"iopub.status.busy":"2023-01-26T22:05:36.872237Z","iopub.execute_input":"2023-01-26T22:05:36.87262Z","iopub.status.idle":"2023-01-26T22:05:36.882438Z","shell.execute_reply.started":"2023-01-26T22:05:36.872563Z","shell.execute_reply":"2023-01-26T22:05:36.881282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Decoder**","metadata":{}},{"cell_type":"code","source":"class DecoderBlock(Layer):\n\n    def __init__(self, filters, rate, **kwargs):\n        super(DecoderBlock, self).__init__(**kwargs)\n\n        self.filters = filters\n        self.rate = rate\n\n        self.up = UpSampling2D()\n        self.net = EncoderBlock(filters, rate, pooling=False)\n\n    def call(self, X):\n        X, skip_X = X\n        x = self.up(X)\n        c_ = concatenate([x, skip_X])\n        x = self.net(c_)\n        return x\n\n    def get_config(self):\n        base_config = super().get_config()\n        return {\n            **base_config,\n            \"filters\":self.filters,\n            'rate':self.rate,\n        }","metadata":{"execution":{"iopub.status.busy":"2023-01-26T22:05:36.883963Z","iopub.execute_input":"2023-01-26T22:05:36.884622Z","iopub.status.idle":"2023-01-26T22:05:36.896268Z","shell.execute_reply.started":"2023-01-26T22:05:36.884588Z","shell.execute_reply":"2023-01-26T22:05:36.895353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **AttentionGate**","metadata":{}},{"cell_type":"code","source":"class AttentionGate(Layer):\n\n    def __init__(self, filters, bn, **kwargs):\n        super(AttentionGate, self).__init__(**kwargs)\n\n        self.filters = filters\n        self.bn = bn\n\n        self.normal = Conv2D(filters, kernel_size=3, padding='same', activation='relu', kernel_initializer='he_normal')\n        self.down = Conv2D(filters, kernel_size=3, strides=2, padding='same', activation='relu', kernel_initializer='he_normal')\n        self.learn = Conv2D(1, kernel_size=1, padding='same', activation='sigmoid')\n        self.resample = UpSampling2D()\n        self.BN = BatchNormalization()\n\n    def call(self, X):\n        X, skip_X = X\n\n        x = self.normal(X)\n        skip = self.down(skip_X)\n        x = Add()([x, skip])\n        x = self.learn(x)\n        x = self.resample(x)\n        f = Multiply()([x, skip_X])\n        if self.bn:\n            return self.BN(f)\n        else:\n            return f\n        # return f\n\n    def get_config(self):\n        base_config = super().get_config()\n        return {\n            **base_config,\n            \"filters\":self.filters,\n            \"bn\":self.bn\n        }","metadata":{"execution":{"iopub.status.busy":"2023-01-26T22:05:36.897809Z","iopub.execute_input":"2023-01-26T22:05:36.898401Z","iopub.status.idle":"2023-01-26T22:05:36.908266Z","shell.execute_reply.started":"2023-01-26T22:05:36.898366Z","shell.execute_reply":"2023-01-26T22:05:36.907567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Callbacks**","metadata":{}},{"cell_type":"code","source":"class MyCallback(keras.callbacks.Callback):\n    def __init__(self, model, epochs, ask_epoch):\n        super(MyCallback, self).__init__()\n        self.model = model\n        self.epochs = epochs\n        self.ask_epoch = ask_epoch\n        self.ask_epoch_initial = ask_epoch # save this value to restore if restarting training\n\n        # callback variables\n        self.best_epoch = 1   # epoch with the lowest loss\n        self.initial_lr = float(tf.keras.backend.get_value(model.optimizer.lr)) # get the initial learning rate and save it\n        self.highest_tracc = 0.0 # set highest training accuracy to 0 initially\n        self.lowest_vloss = np.inf # set lowest validation loss to infinity initially\n        self.best_weights = self.model.get_weights() # set best weights to model's initial weights\n        self.initial_weights = self.model.get_weights()   # save initial weights if they have to get restored\n\n    # Define a function that will run when train begins\n    def on_train_begin(self, logs= None):\n        msg = 'Do you want model asks you to halt the training [y/n] ?'\n        print(msg)\n        ans = input('')\n        if ans == 'Y' or ans == 'y':\n            self.ask_permission = 1\n        elif ans == 'N' or ans == 'n':\n            self.ask_permission = 0\n        \n        msg = '{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^8s}'.format('Epoch', 'Loss', 'Accuracy', 'V_loss', 'V_acc', 'Duration')\n        print(msg)\n        self.start_time = time.time()\n\n\n    def on_train_end(self, logs= None):\n        stop_time = time.time()\n        tr_duration = stop_time - self.start_time\n        hours = tr_duration // 3600\n        minutes = (tr_duration - (hours * 3600)) // 60\n        seconds = tr_duration - ((hours * 3600) + (minutes * 60))\n\n        msg = f'training elapsed time was {str(hours)} hours, {minutes:4.1f} minutes, {seconds:4.2f} seconds)'\n        print(msg)\n\n        # set the weights of the model to the best weights\n        self.model.set_weights(self.best_weights) \n\n\n    def on_train_batch_end(self, batch, logs= None):\n        # get batch accuracy and loss\n        acc = logs.get('accuracy') * 100 \n        loss = logs.get('loss')\n        \n        # prints over on the same line to show running batch count\n        msg = '{0:20s}processing batch {1:}  -   accuracy=  {2:5.3f}   -   loss: {3:8.5f}'.format(' ', str(batch),  acc, loss)\n        print(msg, '\\r', end= '') \n\n\n    def on_epoch_begin(self, epoch, logs= None):\n        self.ep_start = time.time()\n\n\n    # Define method runs on the end of each epoch\n    def on_epoch_end(self, epoch, logs= None):\n        ep_end = time.time()\n        duration = ep_end - self.ep_start\n\n        acc = logs.get('accuracy')  # get training accuracy\n        v_acc = logs.get('val_accuracy')  # get validation accuracy\n        loss = logs.get('loss')  # get training loss for this epoch\n        v_loss = logs.get('val_loss')  # get the validation loss for this epoch\n\n        print('\\n')\n        msg = f'{str(epoch + 1):^3s}/{str(self.epochs):4s} {loss:^9.3f}{acc * 100:^9.3f}{v_loss:^9.5f}{v_acc * 100:^9.3f}{duration:^8.2f}'\n        print(msg)\n\n        if self.ask_epoch != None and self.ask_permission != 0:\n            if epoch + 1 >= self.ask_epoch:\n                msg = 'enter H to halt training or an integer for number of epochs to run then ask again'\n                print(msg)\n                ans = input('')\n                if ans == 'H' or ans == 'h':\n                    msg = f'training has been halted at epoch {epoch + 1} due to user input'\n                    print(msg)\n                    self.model.stop_training = True # stop training\n                else:\n                    try:\n                        ans = int(ans)\n                        self.ask_epoch += ans\n                        msg = f' training will continue until epoch ' + str(self.ask_epoch)\n                        print(msg)\n                        msg = '{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^8s}'.format('Epoch', 'Loss', 'Accuracy', 'V_loss', 'V_acc', 'Duration')\n                        print(msg)\n                    except:\n                        print('Invalid')","metadata":{"execution":{"iopub.status.busy":"2023-01-26T22:05:36.909594Z","iopub.execute_input":"2023-01-26T22:05:36.910206Z","iopub.status.idle":"2023-01-26T22:05:36.92781Z","shell.execute_reply.started":"2023-01-26T22:05:36.910173Z","shell.execute_reply":"2023-01-26T22:05:36.926869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Function to plot training history**","metadata":{}},{"cell_type":"code","source":"def plot_training(hist):\n    '''\n    This function take training model and plot history of accuracy and losses with the best epoch in both of them.\n    '''\n\n    # Define needed variables\n    tr_acc = hist.history['accuracy']\n    tr_loss = hist.history['loss']\n    val_acc = hist.history['val_accuracy']\n    val_loss = hist.history['val_loss']\n    index_loss = np.argmin(val_loss)\n    val_lowest = val_loss[index_loss]\n    index_acc = np.argmax(val_acc)\n    acc_highest = val_acc[index_acc]\n    Epochs = [i+1 for i in range(len(tr_acc))]\n    loss_label = f'best epoch= {str(index_loss + 1)}'\n    acc_label = f'best epoch= {str(index_acc + 1)}'\n\n    # Plot training history\n    plt.figure(figsize= (20, 8))\n    plt.style.use('fivethirtyeight')\n\n    plt.subplot(1, 2, 1)\n    plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n    plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n    plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    plt.subplot(1, 2, 2)\n    plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n    plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n    plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n\n    plt.tight_layout\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-26T22:05:36.929056Z","iopub.execute_input":"2023-01-26T22:05:36.929495Z","iopub.status.idle":"2023-01-26T22:05:36.942517Z","shell.execute_reply.started":"2023-01-26T22:05:36.929423Z","shell.execute_reply":"2023-01-26T22:05:36.941633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model Structure**","metadata":{}},{"cell_type":"markdown","source":"### **Get Data**","metadata":{}},{"cell_type":"code","source":"SIZE = 256\n\n# get data\ndata_dir = '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/'\nimage_paths, mask_paths = create_data(data_dir)\n\n# load images and masks\nimgs = load_images(image_paths, SIZE)\nmsks = load_images(mask_paths, SIZE, mask=True)\n\n# show sample\nshow_images(imgs, msks)","metadata":{"id":"wP8jF-PHO9Ch","outputId":"f8dc581b-0a21-494b-8a74-73ce6fe5b9a3","execution":{"iopub.status.busy":"2023-01-26T22:05:36.94575Z","iopub.execute_input":"2023-01-26T22:05:36.9466Z","iopub.status.idle":"2023-01-26T22:06:05.293513Z","shell.execute_reply.started":"2023-01-26T22:05:36.946556Z","shell.execute_reply":"2023-01-26T22:06:05.292708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Create Model**","metadata":{}},{"cell_type":"code","source":"# Inputs\ninput_layer = Input(shape= imgs.shape[-3:])\n\n# Encoder\np1, c1 = EncoderBlock(32, 0.1, name=\"Encoder1\")(input_layer)\np2, c2 = EncoderBlock(64, 0.1, name=\"Encoder2\")(p1)\np3, c3 = EncoderBlock(128, 0.2, name=\"Encoder3\")(p2)\np4, c4 = EncoderBlock(256, 0.2, name=\"Encoder4\")(p3)\n\n# Encoding\nencoding = EncoderBlock(512, 0.3, pooling=False, name=\"Encoding\")(p4)\n\n# Attention + Decoder\na1 = AttentionGate(256, bn=True, name=\"Attention1\")([encoding, c4])\nd1 = DecoderBlock(256, 0.2, name=\"Decoder1\")([encoding, a1])\n\na2 = AttentionGate(128, bn=True, name=\"Attention2\")([d1, c3])\nd2 = DecoderBlock(128, 0.2, name=\"Decoder2\")([d1, a2])\n\na3 = AttentionGate(64, bn=True, name=\"Attention3\")([d2, c2])\nd3 = DecoderBlock(64, 0.1, name=\"Decoder3\")([d2, a3])\n\na4 = AttentionGate(32, bn=True, name=\"Attention4\")([d3, c1])\nd4 = DecoderBlock(32,0.1, name=\"Decoder4\")([d3, a4])\n\n# Output \noutput_layer = Conv2D(1, kernel_size=1, activation='sigmoid', padding='same')(d4)\n\n# Model\nmodel = Model(inputs= [input_layer], outputs= [output_layer])\n\n# Compile\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-01-26T22:06:05.294476Z","iopub.execute_input":"2023-01-26T22:06:05.29482Z","iopub.status.idle":"2023-01-26T22:06:05.839984Z","shell.execute_reply.started":"2023-01-26T22:06:05.294784Z","shell.execute_reply":"2023-01-26T22:06:05.839007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 40     # set batch size for training\nepochs = 40         # number of all epochs in training\nask_epoch = 5\t\t    # number of epochs to run before asking if you want to halt training\n\ncallbacks = [MyCallback(model= model, epochs= epochs, ask_epoch= ask_epoch )]","metadata":{"execution":{"iopub.status.busy":"2023-01-26T22:06:05.841376Z","iopub.execute_input":"2023-01-26T22:06:05.842887Z","iopub.status.idle":"2023-01-26T22:06:05.958997Z","shell.execute_reply.started":"2023-01-26T22:06:05.842849Z","shell.execute_reply":"2023-01-26T22:06:05.957799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Train Model**","metadata":{}},{"cell_type":"code","source":"# Config Training\nSPE = len(imgs)//batch_size\n\n# Training\nhistory = model.fit(\n    imgs, msks,\n    validation_split=0.2,\n    epochs=epochs,\n    verbose=0,\n    steps_per_epoch=SPE,\n    batch_size=batch_size,\n    callbacks=callbacks    \n)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T22:06:05.960395Z","iopub.execute_input":"2023-01-26T22:06:05.960768Z","iopub.status.idle":"2023-01-26T22:13:34.635909Z","shell.execute_reply.started":"2023-01-26T22:06:05.960729Z","shell.execute_reply":"2023-01-26T22:13:34.634834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_training(history)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T22:13:34.640901Z","iopub.execute_input":"2023-01-26T22:13:34.643063Z","iopub.status.idle":"2023-01-26T22:13:35.141817Z","shell.execute_reply.started":"2023-01-26T22:13:34.643025Z","shell.execute_reply":"2023-01-26T22:13:35.140848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Evaluation**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,25))\nn=0\nfor i in range(1,(5*3)+1):\n    plt.subplot(5,3,i)\n    if n==0:\n        id = np.random.randint(len(imgs))\n        image = imgs[id]\n        mask = msks[id]\n        pred_mask = model.predict(image[np.newaxis,...])\n\n        plt.title(\"Original Mask\")\n        show_mask(image, mask)\n        n+=1\n    elif n==1:\n        plt.title(\"Predicted Mask\")\n        show_mask(image, pred_mask)\n        n+=1\n    elif n==2:\n        pred_mask = (pred_mask>0.5).astype('float')\n        plt.title(\"Processed Mask\")\n        show_mask(image, pred_mask)\n        n=0\nplt.tight_layout()\nplt.show()","metadata":{"id":"fvjqCPIMW2XG","outputId":"070d77c1-5f7a-4261-f74f-9b70484f58fc","execution":{"iopub.status.busy":"2023-01-26T22:13:35.146254Z","iopub.execute_input":"2023-01-26T22:13:35.147903Z","iopub.status.idle":"2023-01-26T22:13:38.915155Z","shell.execute_reply.started":"2023-01-26T22:13:35.147854Z","shell.execute_reply":"2023-01-26T22:13:38.911721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Thank You..","metadata":{}}]}