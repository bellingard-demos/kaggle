{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_style('whitegrid')\nimport matplotlib.pyplot as plt\nplt.style.use(\"fivethirtyeight\")\n\nfrom keras.models import Sequential\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import Dense, LSTM, GRU, Dropout","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr_df = pd.read_csv('/kaggle/input/time-series-practice-dataset/train.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr_df.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr_df['Date'] = pd.to_datetime(tr_df['Date'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr_df.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr_df['store'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr_df['product'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## We will deal with each store indivedually","metadata":{}},{"cell_type":"markdown","source":"# Store 1","metadata":{}},{"cell_type":"code","source":"tr_df.set_index('Date', inplace= True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1st Product","metadata":{}},{"cell_type":"code","source":"# Store 1 with product 1\ns1p1 = tr_df[(tr_df['store'] == 0) & (tr_df['product'] == 0)]\ns1p1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15, 6))\nplt.plot(s1p1.index, s1p1['number_sold'])\nplt.xlabel('Date', {'fontsize': 12})\nplt.ylabel('Number Sold', {'fontsize': 12})\nplt.title('Number Sold Of Product 1 In The First Store')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"_\"number_sold\"_ is our target","metadata":{}},{"cell_type":"code","source":"n_cols = 1\ndataset = s1p1[\"number_sold\"]\ndataset = pd.DataFrame(dataset)\ndata = dataset.values\n\ndata.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's rescale the values to make it easy for the model","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range= (0, 1))\nscaled_data = scaler.fit_transform(np.array(data))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Splitting data to train and test data to make training [75% to Train , 25% to Test]","metadata":{}},{"cell_type":"code","source":"train_size = int(len(data) * 0.75)\ntest_size = len(data) - train_size\nprint(\"Train Size :\",train_size,\"Test Size :\",test_size)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = scaled_data[0:train_size, :]\ntrain_data.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LSTM takes a 3D input (num_samples, num_timesteps, num_features), so we will split data according that.","metadata":{}},{"cell_type":"code","source":"# Creating a Training set with 60 time-steps and 1 target\nx_train = []\ny_train = []\ntime_steps = 60\nn_cols = 1\n\nfor i in range(time_steps, len(train_data)):\n    x_train.append(train_data[i-time_steps:i, :n_cols])\n    y_train.append(train_data[i, :n_cols])\n    if i<=time_steps:\n        print('X_train: ', x_train)\n        print('y_train:' , y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert to numpy array\nx_train, y_train = np.array(x_train), np.array(y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reshaping the input to (n_samples, time_steps, n_feature)\nx_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], n_cols))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.shape , y_train.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Structure","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n    LSTM(50, return_sequences= True, input_shape= (x_train.shape[1], n_cols)),\n    LSTM(64, return_sequences= False),\n    Dense(32),\n    Dense(16),\n    Dense(n_cols)\n])\n\nmodel.compile(optimizer= 'adam', loss= 'mse' , metrics= \"mean_absolute_error\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I train the model with train data for 100 epoch and batch_size = 32.\n\nTo avoid overfitting, I set an _EarlyStoping_ to stop training when \"val_loss\" has not improved after 10 epochs _(patience = 10).","metadata":{}},{"cell_type":"code","source":"# Fitting the LSTM to the Training set\ncallbacks = [EarlyStopping(monitor= 'loss', patience= 10 , restore_best_weights= True)]\nhistory = model.fit(x_train, y_train, epochs= 100, batch_size= 32 , callbacks= callbacks )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Evaluation","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nplt.plot(history.history[\"loss\"])\nplt.plot(history.history[\"mean_absolute_error\"])\nplt.legend(['Mean Squared Error','Mean Absolute Error'])\nplt.title(\"Losses\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's split test data to the same format (num_samples, num_timesteps, num_features)","metadata":{}},{"cell_type":"code","source":"# Creating a testing set with 60 time-steps and 1 output\ntime_steps = 60\ntest_data = scaled_data[train_size - time_steps:, :]\n\nx_test = []\ny_test = []\nn_cols = 1\n\nfor i in range(time_steps, len(test_data)):\n    x_test.append(test_data[i-time_steps:i, 0:n_cols])\n    y_test.append(test_data[i, 0:n_cols])\nx_test, y_test = np.array(x_test), np.array(y_test)\nx_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test.shape , y_test.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Get Prediction","metadata":{}},{"cell_type":"code","source":"predictions = model.predict(x_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#inverse predictions scaling\npredictions = scaler.inverse_transform(predictions)\npredictions.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction Evaluation With Root Mean Square Error","metadata":{}},{"cell_type":"code","source":"#inverse y_test scaling\ny_test = scaler.inverse_transform(y_test)\n\nRMSE = np.sqrt(np.mean( y_test - predictions )**2).round(2)\nRMSE","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})\npreds_acts","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = dataset.iloc[:train_size , 0:1]\ntest = dataset.iloc[train_size: , 0:1]\ntest['Predictions'] = predictions\n\nplt.figure(figsize= (16, 6))\nplt.title('Number Sold Prediction', fontsize= 18)\nplt.xlabel('Date', fontsize= 18)\nplt.ylabel('Number Sold', fontsize= 18)\nplt.plot(train['number_sold'], linewidth= 3)\nplt.plot(test['number_sold'], linewidth= 3)\nplt.plot(test[\"Predictions\"], linewidth= 3)\nplt.legend(['Train', 'Test', 'Predictions'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Forecast Next 60 Days","metadata":{}},{"cell_type":"code","source":"from datetime import timedelta","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Function to store next value with old value","metadata":{}},{"cell_type":"code","source":"def insert_end(Xin, new_input):\n    timestep = 60\n    for i in range(timestep - 1):\n        Xin[:, i, :] = Xin[:, i+1, :]\n    Xin[:, timestep - 1, :] = new_input\n    return Xin","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"create time and forecasted data","metadata":{}},{"cell_type":"code","source":"future = 30 * 2\nforcast = []\nXin = x_test[-1 :, :, :]\ntime = []\nfor i in range(0, future):\n    out = model.predict(Xin, batch_size=5)\n    forcast.append(out[0, 0]) \n    print(forcast)\n    Xin = insert_end(Xin, out[0, 0]) \n    time.append(pd.to_datetime(s1p1.index[-1]) + timedelta(days=i))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"create _forecasted dataframe_","metadata":{}},{"cell_type":"code","source":"forcasted_output = np.asanyarray(forcast)   \nforcasted_output = forcasted_output.reshape(-1, 1) \nforcasted_output = scaler.inverse_transform(forcasted_output) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"forcasted_output = pd.DataFrame(forcasted_output)\ndate = pd.DataFrame(time)\ndf_result = pd.concat([date,forcasted_output], axis=1)\ndf_result.columns = \"Date\", \"Forecasted\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_result","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16,8))\nplt.title('Number Sold Forecasting For Next 60 Days')\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Number Sold' ,fontsize=18)\nplt.plot(s1p1['number_sold'])\nplt.plot(df_result.set_index('Date')[['Forecasted']])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2nd Product\nWe will repeat the previous steps but in the data of product 2","metadata":{}},{"cell_type":"code","source":"# Store 1 with product 2\ns1p2 = tr_df[(tr_df['store'] == 0) & (tr_df['product'] == 1)]\ns1p2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15, 6))\nplt.plot(s1p2.index, s1p2['number_sold'])\nplt.xlabel('Date', {'fontsize': 12})\nplt.ylabel('Number Sold', {'fontsize': 12})\nplt.title('Number Sold Of Product 2 In The First Store')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_cols = 1\ndataset = s1p2[\"number_sold\"]\ndataset = pd.DataFrame(dataset)\ndata = dataset.values\n\ndata.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range= (0, 1))\nscaled_data = scaler.fit_transform(np.array(data))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 75% to Train , 25% to Test\ntrain_size = int(len(data) * 0.75)\ntest_size = len(data) - train_size\nprint(\"Train Size :\",train_size,\"Test Size :\",test_size)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = scaled_data[0:train_size, :]\ntrain_data.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a Training set with 60 time-steps\nx_train = []\ny_train = []\ntime_steps = 60\nn_cols = 1\n\nfor i in range(time_steps, len(train_data)):\n    x_train.append(train_data[i-time_steps:i, :n_cols])\n    y_train.append(train_data[i, :n_cols])\n    if i<=time_steps:\n        print('X_train: ', x_train)\n        print('y_train:' , y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert to numpy array\nx_train, y_train = np.array(x_train), np.array(y_train)\n\n# Reshaping the input to (n_samples, time_steps, n_feature)\nx_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], n_cols))\nx_train.shape , y_train.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential([\n    LSTM(50, return_sequences= True, input_shape= (x_train.shape[1], n_cols)),\n    LSTM(64, return_sequences= False),\n    Dense(32),\n    Dense(16),\n    Dense(n_cols)\n])\n\nmodel.compile(optimizer= 'adam', loss= 'mse' , metrics= \"mean_absolute_error\")\nmodel.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting the LSTM to the Training set\ncallbacks = [EarlyStopping(monitor= 'loss', patience= 10 , restore_best_weights= True)]\nhistory = model.fit(x_train, y_train, epochs= 100, batch_size= 32 , callbacks= callbacks )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nplt.plot(history.history[\"loss\"])\nplt.plot(history.history[\"mean_absolute_error\"])\nplt.legend(['Mean Squared Error','Mean Absolute Error'])\nplt.title(\"Losses\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a testing set with 60 time-steps and 1 output\ntime_steps = 60\ntest_data = scaled_data[train_size - time_steps:, :]\n\nx_test = []\ny_test = []\nn_cols = 1\n\nfor i in range(time_steps, len(test_data)):\n    x_test.append(test_data[i-time_steps:i, 0:n_cols])\n    y_test.append(test_data[i, 0:n_cols])\nx_test, y_test = np.array(x_test), np.array(y_test)\nx_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))\n\nx_test.shape , y_test.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get Prediction\npredictions = model.predict(x_test)\n\n#inverse predictions scaling\npredictions = scaler.inverse_transform(predictions)\npredictions.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#inverse y_test scaling\ny_test = scaler.inverse_transform(y_test)\n\nRMSE = np.sqrt(np.mean( y_test - predictions )**2).round(2)\nRMSE","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})\npreds_acts","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = dataset.iloc[:train_size , 0:1]\ntest = dataset.iloc[train_size: , 0:1]\ntest['Predictions'] = predictions\n\nplt.figure(figsize= (16, 6))\nplt.title('Number Sold Prediction', fontsize= 18)\nplt.xlabel('Date', fontsize= 18)\nplt.ylabel('Number Sold', fontsize= 18)\nplt.plot(train['number_sold'], linewidth= 3)\nplt.plot(test['number_sold'], linewidth= 3)\nplt.plot(test[\"Predictions\"], linewidth= 3)\nplt.legend(['Train', 'Test', 'Predictions'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datetime import timedelta","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def insert_end(Xin, new_input):\n    timestep = 60\n    for i in range(timestep - 1):\n        Xin[:, i, :] = Xin[:, i+1, :]\n    Xin[:, timestep - 1, :] = new_input\n    return Xin","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"future = 30 * 2\nforcast = []\nXin = x_test[-1 :, :, :]\ntime = []\nfor i in range(0, future):\n    out = model.predict(Xin, batch_size=5)\n    forcast.append(out[0, 0]) \n    print(forcast)\n    Xin = insert_end(Xin, out[0, 0]) \n    time.append(pd.to_datetime(s1p1.index[-1]) + timedelta(days=i))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"forcasted_output = np.asanyarray(forcast)   \nforcasted_output = forcasted_output.reshape(-1, 1) \nforcasted_output = scaler.inverse_transform(forcasted_output) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"forcasted_output = pd.DataFrame(forcasted_output)\ndate = pd.DataFrame(time)\ndf_result = pd.concat([date,forcasted_output], axis=1)\ndf_result.columns = \"Date\", \"Forecasted\"\ndf_result","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16,8))\nplt.title('Number Sold Forecasting For Next 60 Days')\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Number Sold' ,fontsize=18)\nplt.plot(s1p2['number_sold'])\nplt.plot(df_result.set_index('Date')[['Forecasted']])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The next 60 days is not enough to show a good graph, so you can increase the time, but make sure that more needed days for forecasting, less accuracy will happen.","metadata":{}},{"cell_type":"markdown","source":"## 3rd Product","metadata":{}},{"cell_type":"code","source":"# Store 1 with product 3\ns1p3 = tr_df[(tr_df['store'] == 0) & (tr_df['product'] == 2)]\ns1p3","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15, 6))\nplt.plot(s1p3.index, s1p3['number_sold'])\nplt.xlabel('Date', {'fontsize': 12})\nplt.ylabel('Number Sold', {'fontsize': 12})\nplt.title('Number Sold Of Product 3 In The First Store')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_cols = 1\ndataset = s1p3[\"number_sold\"]\ndataset = pd.DataFrame(dataset)\ndata = dataset.values\n\ndata.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range= (0, 1))\nscaled_data = scaler.fit_transform(np.array(data))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 75% to Train , 25% to Test\ntrain_size = int(len(data) * 0.75)\ntest_size = len(data) - train_size\nprint(\"Train Size :\",train_size,\"Test Size :\",test_size)\n\ntrain_data = scaled_data[0:train_size, :]\ntrain_data.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a Training set with 60 time-steps\nx_train = []\ny_train = []\ntime_steps = 60\nn_cols = 1\n\nfor i in range(time_steps, len(train_data)):\n    x_train.append(train_data[i-time_steps:i, :n_cols])\n    y_train.append(train_data[i, :n_cols])\n    if i<=time_steps:\n        print('X_train: ', x_train)\n        print('y_train:' , y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert to numpy array\nx_train, y_train = np.array(x_train), np.array(y_train)\n# Reshaping the input to (n_samples, time_steps, n_feature)\nx_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], n_cols))\nx_train.shape , y_train.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential([\n    LSTM(50, return_sequences= True, input_shape= (x_train.shape[1], n_cols)),\n    LSTM(64, return_sequences= False),\n    Dense(32),\n    Dense(16),\n    Dense(n_cols)\n])\n\nmodel.compile(optimizer= 'adam', loss= 'mse' , metrics= \"mean_absolute_error\")\nmodel.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting the LSTM to the Training set\ncallbacks = [EarlyStopping(monitor= 'loss', patience= 10 , restore_best_weights= True)]\nhistory = model.fit(x_train, y_train, epochs= 100, batch_size= 32 , callbacks= callbacks )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nplt.plot(history.history[\"loss\"])\nplt.plot(history.history[\"mean_absolute_error\"])\nplt.legend(['Mean Squared Error','Mean Absolute Error'])\nplt.title(\"Losses\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a testing set with 60 time-steps and 1 output\ntime_steps = 60\ntest_data = scaled_data[train_size - time_steps:, :]\n\nx_test = []\ny_test = []\nn_cols = 1\n\nfor i in range(time_steps, len(test_data)):\n    x_test.append(test_data[i-time_steps:i, 0:n_cols])\n    y_test.append(test_data[i, 0:n_cols])\nx_test, y_test = np.array(x_test), np.array(y_test)\nx_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_cols))\n\nx_test.shape , y_test.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get Prediction\npredictions = model.predict(x_test)\n#inverse predictions scaling\npredictions = scaler.inverse_transform(predictions)\npredictions.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#inverse y_test scaling\ny_test = scaler.inverse_transform(y_test)\n\nRMSE = np.sqrt(np.mean( y_test - predictions )**2).round(2)\nRMSE","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_acts = pd.DataFrame(data={'Predictions':predictions.flatten(), 'Actuals':y_test.flatten()})\npreds_acts","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = dataset.iloc[:train_size , 0:1]\ntest = dataset.iloc[train_size: , 0:1]\ntest['Predictions'] = predictions\n\nplt.figure(figsize= (16, 6))\nplt.title('Number Sold Prediction', fontsize= 18)\nplt.xlabel('Date', fontsize= 18)\nplt.ylabel('Number Sold', fontsize= 18)\nplt.plot(train['number_sold'], linewidth= 3)\nplt.plot(test['number_sold'], linewidth= 3)\nplt.plot(test[\"Predictions\"], linewidth= 3)\nplt.legend(['Train', 'Test', 'Predictions'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datetime import timedelta","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def insert_end(Xin, new_input):\n    timestep = 60\n    for i in range(timestep - 1):\n        Xin[:, i, :] = Xin[:, i+1, :]\n    Xin[:, timestep - 1, :] = new_input\n    return Xin","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"future = 30 * 2\nforcast = []\nXin = x_test[-1 :, :, :]\ntime = []\nfor i in range(0, future):\n    out = model.predict(Xin, batch_size=5)\n    forcast.append(out[0, 0]) \n    print(forcast)\n    Xin = insert_end(Xin, out[0, 0]) \n    time.append(pd.to_datetime(s1p1.index[-1]) + timedelta(days=i))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"forcasted_output = np.asanyarray(forcast)   \nforcasted_output = forcasted_output.reshape(-1, 1) \nforcasted_output = scaler.inverse_transform(forcasted_output) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"forcasted_output = pd.DataFrame(forcasted_output)\ndate = pd.DataFrame(time)\ndf_result = pd.concat([date,forcasted_output], axis=1)\ndf_result.columns = \"Date\", \"Forecasted\"\ndf_result","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16,8))\nplt.title('Number Sold Forecasting For Next 60 Days')\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Number Sold' ,fontsize=18)\nplt.plot(s1p3['number_sold'])\nplt.plot(df_result.set_index('Date')[['Forecasted']])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## It will take a time to try all the data ! If you want to do that, you won't find any error but take care when you chose the product data..","metadata":{}},{"cell_type":"markdown","source":"## If you find this notebook make sense, please upvote it and follow me.\n## THANK YOU..","metadata":{}}]}