{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing The libraries","metadata":{"id":"YU9HH9t5rMt9"}},{"cell_type":"code","source":"# import system libs\nimport os\nimport time\nimport random\nimport pathlib\nimport itertools\nfrom glob import glob\nfrom tqdm import tqdm_notebook, tnrange\n\n# import data handling tools\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom skimage.color import rgb2gray\nfrom skimage.morphology import label\nfrom skimage.transform import resize\nfrom sklearn.model_selection import train_test_split\nfrom skimage.io import imread, imshow, concatenate_images\n\n# import Deep learning Libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Model, load_model, save_model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate\n\n# Ignore Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint ('modules loaded')","metadata":{"id":"62z-OunarXX3","outputId":"3590ca2d-93f8-417a-bc8d-4d087777da52","execution":{"iopub.status.busy":"2023-07-11T15:45:32.578188Z","iopub.execute_input":"2023-07-11T15:45:32.578536Z","iopub.status.idle":"2023-07-11T15:45:40.573664Z","shell.execute_reply.started":"2023-07-11T15:45:32.578457Z","shell.execute_reply":"2023-07-11T15:45:40.572468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_CHANNELS, IMG_WIDTH, IMG_HEIGHT = 3, 512, 512","metadata":{"id":"AWC-0x5jqHOX","execution":{"iopub.status.busy":"2023-07-11T15:45:40.575808Z","iopub.execute_input":"2023-07-11T15:45:40.5775Z","iopub.status.idle":"2023-07-11T15:45:40.582718Z","shell.execute_reply.started":"2023-07-11T15:45:40.577459Z","shell.execute_reply":"2023-07-11T15:45:40.581613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Getting name of image files and appending it to a list.","metadata":{"id":"03MRfuQ3rMuD"}},{"cell_type":"code","source":"X = next(os.walk('/kaggle/input/kvasir-dataset-for-classification-and-segmentation/kvasir-seg/Kvasir-SEG/images'))[2]\ny = next(os.walk('/kaggle/input/kvasir-dataset-for-classification-and-segmentation/kvasir-seg/Kvasir-SEG/masks'))[2]","metadata":{"id":"X2xvVxTCqHOY","execution":{"iopub.status.busy":"2023-07-11T15:45:40.585757Z","iopub.execute_input":"2023-07-11T15:45:40.586181Z","iopub.status.idle":"2023-07-11T15:45:41.297838Z","shell.execute_reply.started":"2023-07-11T15:45:40.586136Z","shell.execute_reply":"2023-07-11T15:45:41.296807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_ids = X[:-10]\ny_ids = y[:-10]","metadata":{"id":"r-ZKlOokrMuF","execution":{"iopub.status.busy":"2023-07-11T15:45:41.30087Z","iopub.execute_input":"2023-07-11T15:45:41.301639Z","iopub.status.idle":"2023-07-11T15:45:41.306722Z","shell.execute_reply.started":"2023-07-11T15:45:41.30156Z","shell.execute_reply":"2023-07-11T15:45:41.305723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_tr = np.zeros((len(X_ids), 256, 256, 3), dtype=np.float32)\ny_tr = np.zeros((len(y_ids), 256, 256, 1), dtype=np.bool)","metadata":{"id":"HBthST0EALBu","outputId":"910f6a98-722b-4b7d-cbc6-e2f47756e6d4","execution":{"iopub.status.busy":"2023-07-11T15:45:41.308395Z","iopub.execute_input":"2023-07-11T15:45:41.309168Z","iopub.status.idle":"2023-07-11T15:45:41.317261Z","shell.execute_reply.started":"2023-07-11T15:45:41.309084Z","shell.execute_reply":"2023-07-11T15:45:41.316434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pre-processing:\n","metadata":{"id":"qs7pK4LqrMuG"}},{"cell_type":"code","source":"X_train = np.zeros((len(X_ids), 256, 256, 3), dtype=np.float32)\ny_train = np.zeros((len(y_ids), 256, 256, 1), dtype=np.bool)\n\nfor n, id_ in enumerate(X_ids):\n    image = tf.keras.preprocessing.image.load_img(f'/kaggle/input/kvasir-dataset-for-classification-and-segmentation/kvasir-seg/Kvasir-SEG/images/{id_}', target_size=(IMG_HEIGHT, IMG_WIDTH))\n    input_arr = tf.keras.preprocessing.image.img_to_array(image)[90:450,150:406]\n    image = tf.keras.preprocessing.image.array_to_img(input_arr, ).resize((256, 256))\n    X_train[n] = np.array(image)\n\nfor n, id_ in enumerate(y_ids):\n    image = tf.keras.preprocessing.image.load_img(f'/kaggle/input/kvasir-dataset-for-classification-and-segmentation/kvasir-seg/Kvasir-SEG/masks/{id_}', \n                                                  target_size=(IMG_HEIGHT, IMG_WIDTH), color_mode=\"grayscale\")\n    input_arr = tf.keras.preprocessing.image.img_to_array(image)[90:450,150:406]\n    image = tf.keras.preprocessing.image.array_to_img(input_arr).resize((256, 256))\n    y_train[n] = np.array(image)[:, :, np.newaxis]","metadata":{"id":"xhN2sGRgqHOY","outputId":"0a12479f-1c1d-4bca-9d2b-ce795f5b197a","execution":{"iopub.status.busy":"2023-07-11T15:45:41.318857Z","iopub.execute_input":"2023-07-11T15:45:41.319608Z","iopub.status.idle":"2023-07-11T15:46:01.024128Z","shell.execute_reply.started":"2023-07-11T15:45:41.31957Z","shell.execute_reply":"2023-07-11T15:46:01.023009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Image view after pre-processing.","metadata":{"id":"oscUIPDerMuJ"}},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nimg=cv2.imread('/kaggle/input/kvasir-dataset-for-classification-and-segmentation/kvasir-seg/Kvasir-SEG/images/cju0qkwl35piu0993l0dewei2.jpg')\nmsk=cv2.imread('/kaggle/input/kvasir-dataset-for-classification-and-segmentation/kvasir-seg/Kvasir-SEG/masks/cju0qkwl35piu0993l0dewei2.jpg')\n\nplt.subplot(1, 3, 1)\nplt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\nplt.axis(False)\n\nplt.subplot(1, 3, 2)\nplt.imshow(cv2.cvtColor(msk, cv2.COLOR_BGR2RGB))\nplt.axis(False)\n\nplt.subplot(1, 3, 3)\nplt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\nplt.imshow(cv2.cvtColor(msk, cv2.COLOR_BGR2RGB),alpha=0.5)\nplt.axis(False)\nplt.show()","metadata":{"id":"ZvH5LaR8yuKw","outputId":"d79a48c9-0f91-4578-9104-4c84fcf1209a","execution":{"iopub.status.busy":"2023-07-11T15:46:01.025807Z","iopub.execute_input":"2023-07-11T15:46:01.02651Z","iopub.status.idle":"2023-07-11T15:46:01.630852Z","shell.execute_reply.started":"2023-07-11T15:46:01.026467Z","shell.execute_reply":"2023-07-11T15:46:01.629853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MODEL:","metadata":{"id":"YaKez28pqHOZ"}},{"cell_type":"markdown","source":"## UNet model for image segmentation [Semantic].\n\n[Paper](https://arxiv.org/abs/1505.04597)\n","metadata":{"id":"ukJswm05rMuL"}},{"cell_type":"code","source":"def unet(input_size=(256, 256, 3)):\n    inputs = Input(input_size)\n\n    # First DownConvolution / Encoder Leg will begin, so start with Conv2D\n    conv1 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(inputs)\n    bn1 = Activation(\"relu\")(conv1)\n    conv1 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(bn1)\n    bn1 = BatchNormalization(axis=3)(conv1)\n    bn1 = Activation(\"relu\")(bn1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)\n\n    conv2 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(pool1)\n    bn2 = Activation(\"relu\")(conv2)\n    conv2 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(bn2)\n    bn2 = BatchNormalization(axis=3)(conv2)\n    bn2 = Activation(\"relu\")(bn2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)\n\n    conv3 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(pool2)\n    bn3 = Activation(\"relu\")(conv3)\n    conv3 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(bn3)\n    bn3 = BatchNormalization(axis=3)(conv3)\n    bn3 = Activation(\"relu\")(bn3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(bn3)\n\n    conv4 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(pool3)\n    bn4 = Activation(\"relu\")(conv4)\n    conv4 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(bn4)\n    bn4 = BatchNormalization(axis=3)(conv4)\n    bn4 = Activation(\"relu\")(bn4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(bn4)\n\n    conv5 = Conv2D(filters=1024, kernel_size=(3, 3), padding=\"same\")(pool4)\n    bn5 = Activation(\"relu\")(conv5)\n    conv5 = Conv2D(filters=1024, kernel_size=(3, 3), padding=\"same\")(bn5)\n    bn5 = BatchNormalization(axis=3)(conv5)\n    bn5 = Activation(\"relu\")(bn5)\n\n    \"\"\" Now UpConvolution / Decoder Leg will begin, so start with Conv2DTranspose\n    The gray arrows (in the above image) indicate the skip connections that concatenate the encoder feature map with the decoder, which helps the backward flow of gradients for improved training. \"\"\"\n    \"\"\" After every concatenation we again apply two consecutive regular convolutions so that the model can learn to assemble a more precise output \"\"\"\n\n    up6 = concatenate([Conv2DTranspose(512, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(bn5), conv4], axis=3)\n    conv6 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(up6)\n    bn6 = Activation(\"relu\")(conv6)\n    conv6 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(bn6)\n    bn6 = BatchNormalization(axis=3)(conv6)\n    bn6 = Activation(\"relu\")(bn6)\n\n    up7 = concatenate([Conv2DTranspose(256, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(bn6), conv3], axis=3)\n    conv7 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(up7)\n    bn7 = Activation(\"relu\")(conv7)\n    conv7 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(bn7)\n    bn7 = BatchNormalization(axis=3)(conv7)\n    bn7 = Activation(\"relu\")(bn7)\n\n    up8 = concatenate([Conv2DTranspose(128, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(bn7), conv2], axis=3)\n    conv8 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(up8)\n    bn8 = Activation(\"relu\")(conv8)\n    conv8 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(bn8)\n    bn8 = BatchNormalization(axis=3)(conv8)\n    bn8 = Activation(\"relu\")(bn8)\n\n    up9 = concatenate([Conv2DTranspose(64, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(bn8), conv1], axis=3)\n    conv9 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(up9)\n    bn9 = Activation(\"relu\")(conv9)\n    conv9 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(bn9)\n    bn9 = BatchNormalization(axis=3)(conv9)\n    bn9 = Activation(\"relu\")(bn9)\n\n    conv10 = Conv2D(filters=1, kernel_size=(1, 1), activation=\"sigmoid\")(bn9)\n\n    return Model(inputs=[inputs], outputs=[conv10])","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:46:01.632168Z","iopub.execute_input":"2023-07-11T15:46:01.633114Z","iopub.status.idle":"2023-07-11T15:46:01.664469Z","shell.execute_reply.started":"2023-07-11T15:46:01.633072Z","shell.execute_reply":"2023-07-11T15:46:01.663352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function to create dice coefficient\ndef dice_coef(y_true, y_pred, smooth=100):\n    y_true_flatten = K.flatten(y_true)\n    y_pred_flatten = K.flatten(y_pred)\n\n    intersection = K.sum(y_true_flatten * y_pred_flatten)\n    union = K.sum(y_true_flatten) + K.sum(y_pred_flatten)\n    return (2 * intersection + smooth) / (union + smooth)\n\n# function to create dice loss\ndef dice_loss(y_true, y_pred, smooth=100):\n    return -dice_coef(y_true, y_pred, smooth)\n\n# function to create iou coefficient\ndef iou_coef(y_true, y_pred, smooth=100):\n    intersection = K.sum(y_true * y_pred)\n    sum = K.sum(y_true + y_pred)\n    iou = (intersection + smooth) / (sum - intersection + smooth)\n    return iou","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:46:01.666117Z","iopub.execute_input":"2023-07-11T15:46:01.666558Z","iopub.status.idle":"2023-07-11T15:46:01.678318Z","shell.execute_reply.started":"2023-07-11T15:46:01.66652Z","shell.execute_reply":"2023-07-11T15:46:01.677364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = unet()\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', iou_coef, dice_coef])\n# model.compile(Adamax(learning_rate= 0.001), loss= dice_loss, metrics= ['accuracy', iou_coef, dice_coef])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-11T15:46:01.683688Z","iopub.execute_input":"2023-07-11T15:46:01.685374Z","iopub.status.idle":"2023-07-11T15:46:05.078334Z","shell.execute_reply.started":"2023-07-11T15:46:01.685341Z","shell.execute_reply":"2023-07-11T15:46:05.075996Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training the model.","metadata":{"id":"m1lIduVNrMuN"}},{"cell_type":"code","source":"history = model.fit(X_train, y_train, validation_split=0.1, batch_size=16, epochs=120)","metadata":{"id":"2PsXG0POqHOa","outputId":"547c5272-7fcf-431f-cbe6-007c29ac6355","execution":{"iopub.status.busy":"2023-07-11T15:46:05.079821Z","iopub.execute_input":"2023-07-11T15:46:05.080189Z","iopub.status.idle":"2023-07-11T16:29:30.526275Z","shell.execute_reply.started":"2023-07-11T15:46:05.080159Z","shell.execute_reply":"2023-07-11T16:29:30.525195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plotting history:","metadata":{"id":"oqR9hlQ4rMuO"}},{"cell_type":"code","source":"def plot_training(hist):\n    '''\n    This function take training model and plot history of accuracy and losses with the best epoch in both of them.\n    '''\n\n    # Define needed variables\n    tr_acc = hist.history['accuracy']\n    tr_iou = hist.history['iou_coef']\n    tr_dice = hist.history['dice_coef']\n    tr_loss = hist.history['loss']\n\n    val_acc = hist.history['val_accuracy']\n    val_iou = hist.history['val_iou_coef']\n    val_dice = hist.history['val_dice_coef']\n    val_loss = hist.history['val_loss']\n\n    index_acc = np.argmax(val_acc)\n    acc_highest = val_acc[index_acc]\n    index_iou = np.argmax(iou_coef)\n    iou_highest = val_iou[index_iou]\n    index_dice = np.argmax(dice_coef)\n    dice_highest = val_dice[index_dice]\n    index_loss = np.argmin(val_loss)\n    val_lowest = val_loss[index_loss]\n\n    Epochs = [i+1 for i in range(len(tr_acc))]\n\n    acc_label = f'best epoch= {str(index_acc + 1)}'\n    iou_label = f'best epoch= {str(index_iou + 1)}'\n    dice_label = f'best epoch= {str(index_dice + 1)}'\n    loss_label = f'best epoch= {str(index_loss + 1)}'\n\n    # Plot training history\n    plt.figure(figsize= (20, 20))\n    plt.style.use('fivethirtyeight')\n\n    # Training Accuracy\n    plt.subplot(2, 2, 1)\n    plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n    plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n    plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n\n    # Training IoU\n    plt.subplot(2, 2, 2)\n    plt.plot(Epochs, tr_iou, 'r', label= 'Training IoU')\n    plt.plot(Epochs, val_iou, 'g', label= 'Validation IoU')\n    plt.scatter(index_iou + 1 , iou_highest, s= 150, c= 'blue', label= iou_label)\n    plt.title('Training and Validation IoU Coefficient')\n    plt.xlabel('Epochs')\n    plt.ylabel('IoU')\n    plt.legend()\n\n    # Training Dice\n    plt.subplot(2, 2, 3)\n    plt.plot(Epochs, tr_dice, 'r', label= 'Training Dice')\n    plt.plot(Epochs, val_dice, 'g', label= 'Validation Dice')\n    plt.scatter(index_dice + 1 , dice_highest, s= 150, c= 'blue', label= dice_label)\n    plt.title('Training and Validation Dice Coefficient')\n    plt.xlabel('Epochs')\n    plt.ylabel('Dice')\n    plt.legend()\n\n    # Training Loss\n    plt.subplot(2, 2, 4)\n    plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n    plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n    plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    plt.tight_layout\n    plt.show()","metadata":{"id":"u8nlTz60cXLF","execution":{"iopub.status.busy":"2023-07-11T16:29:30.528114Z","iopub.execute_input":"2023-07-11T16:29:30.528425Z","iopub.status.idle":"2023-07-11T16:29:30.553089Z","shell.execute_reply.started":"2023-07-11T16:29:30.528391Z","shell.execute_reply":"2023-07-11T16:29:30.551934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_training(history)","metadata":{"id":"R--nfXGRcZMA","outputId":"69cb933d-5db3-47db-99c8-6212c29cf89b","execution":{"iopub.status.busy":"2023-07-11T16:29:30.55456Z","iopub.execute_input":"2023-07-11T16:29:30.554892Z","iopub.status.idle":"2023-07-11T16:29:31.770052Z","shell.execute_reply.started":"2023-07-11T16:29:30.554865Z","shell.execute_reply":"2023-07-11T16:29:31.769017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PREDICTED IMAGE:","metadata":{"id":"4jfWjPOhrMuQ"}},{"cell_type":"code","source":"img = tf.keras.preprocessing.image.load_img(r\"/kaggle/input/kvasir-dataset-for-classification-and-segmentation/kvasir-seg/Kvasir-SEG/images/cju0s2a9ekvms080138tjjpxr.jpg\", target_size=(256, 256))\ninput_array = tf.keras.preprocessing.image.img_to_array(img)\ninput_array = np.array([input_array])  # Convert single image to a batch.\npredictions = model.predict(input_array)","metadata":{"id":"pTwXieNUCm01","execution":{"iopub.status.busy":"2023-07-11T16:29:31.771666Z","iopub.execute_input":"2023-07-11T16:29:31.772319Z","iopub.status.idle":"2023-07-11T16:29:32.63765Z","shell.execute_reply.started":"2023-07-11T16:29:31.772279Z","shell.execute_reply":"2023-07-11T16:29:32.636543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 12))\nplt.subplot(1, 3, 1)\nplt.imshow(np.squeeze(img))\nplt.axis(False)\nplt.subplot(1, 3, 2)\nplt.imshow(np.squeeze(predictions))\nplt.axis(False)\nplt.subplot(1, 3, 3)\nplt.imshow(np.squeeze(img))\n# plt.imshow(msk,alpha=0.5)\nplt.imshow(np.squeeze(predictions), alpha=0.5)\nplt.axis(False)\nplt.show()","metadata":{"id":"_3Pdy-gsgAhu","outputId":"e28a1d31-664e-4aa1-a019-45caa8212700","execution":{"iopub.status.busy":"2023-07-11T16:29:32.646595Z","iopub.execute_input":"2023-07-11T16:29:32.646933Z","iopub.status.idle":"2023-07-11T16:29:33.13328Z","shell.execute_reply.started":"2023-07-11T16:29:32.646886Z","shell.execute_reply":"2023-07-11T16:29:33.132369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subject = 'Kvasir Segmentation'\nsave_path = './'\n\n\nsave_id = str(f'{subject} model.h5')\nmodel_save_loc = os.path.join(save_path, save_id)\nmodel.save(model_save_loc)\nprint(f'model was saved as {model_save_loc}')","metadata":{"id":"sYqWDItIpUiF","outputId":"b26ac350-948d-41cc-a755-559a2dbca3cb","execution":{"iopub.status.busy":"2023-07-11T16:29:33.134666Z","iopub.execute_input":"2023-07-11T16:29:33.136213Z","iopub.status.idle":"2023-07-11T16:29:33.949953Z","shell.execute_reply.started":"2023-07-11T16:29:33.136172Z","shell.execute_reply":"2023-07-11T16:29:33.948708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Testing","metadata":{}},{"cell_type":"code","source":"segmentation_model = load_model('Kvasir Segmentation model.h5', compile=False)\nsegmentation_model.compile(Adamax(learning_rate=0.001), loss=dice_loss, metrics=['accuracy', iou_coef, dice_coef])","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:45:40.454654Z","iopub.execute_input":"2023-07-11T16:45:40.455102Z","iopub.status.idle":"2023-07-11T16:45:40.94842Z","shell.execute_reply.started":"2023-07-11T16:45:40.455066Z","shell.execute_reply":"2023-07-11T16:45:40.947387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess the image for segmentation\ndef preprocess_segmentation_image(image):\n    img_array = tf.keras.preprocessing.image.img_to_array(image)\n    image = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n    img = cv2.resize(image, (256, 256))\n    img = img / 255\n    img = img[np.newaxis, :, :, :]","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:47:07.676908Z","iopub.execute_input":"2023-07-11T16:47:07.677821Z","iopub.status.idle":"2023-07-11T16:47:07.684271Z","shell.execute_reply.started":"2023-07-11T16:47:07.677784Z","shell.execute_reply":"2023-07-11T16:47:07.683149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:48:55.018495Z","iopub.execute_input":"2023-07-11T16:48:55.018997Z","iopub.status.idle":"2023-07-11T16:48:55.024896Z","shell.execute_reply.started":"2023-07-11T16:48:55.018913Z","shell.execute_reply":"2023-07-11T16:48:55.023978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the image using PIL\nimage_file = r\"/kaggle/input/kvasir-dataset-for-classification-and-segmentation/kvasir-seg/Kvasir-SEG/images/cju0s2a9ekvms080138tjjpxr.jpg\"\npil_image = Image.open(image_file).convert('RGB')\nopen_cv_image = np.array(pil_image)\n\n# Convert RGB to BGR\nopen_cv_image = open_cv_image[:, :, ::-1].copy()\n\n# Perform image preprocessing\nimage = preprocess_segmentation_image(open_cv_image)\n\n# Perform image segmentation\nsegmented_image = segmentation_model.predict(image)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T16:49:06.653273Z","iopub.execute_input":"2023-07-11T16:49:06.65365Z","iopub.status.idle":"2023-07-11T16:49:06.713054Z","shell.execute_reply.started":"2023-07-11T16:49:06.653617Z","shell.execute_reply":"2023-07-11T16:49:06.711617Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = tf.keras.preprocessing.image.load_img(r\"/kaggle/input/kvasir-dataset-for-classification-and-segmentation/kvasir-seg/Kvasir-SEG/images/cju0s2a9ekvms080138tjjpxr.jpg\", target_size=(256, 256))\ninput_array = tf.keras.preprocessing.image.img_to_array(img)\ninput_array = np.array([input_array])  # Convert single image to a batch.\npredictions = segmentation_model.predict(input_array)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T17:50:43.40803Z","iopub.execute_input":"2023-07-11T17:50:43.40907Z","iopub.status.idle":"2023-07-11T17:50:43.485493Z","shell.execute_reply.started":"2023-07-11T17:50:43.409031Z","shell.execute_reply":"2023-07-11T17:50:43.484514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 12))\nplt.subplot(1, 3, 1)\nplt.imshow(np.squeeze(img))\nplt.axis(False)\nplt.subplot(1, 3, 2)\nplt.imshow(np.squeeze(predictions))\nplt.axis(False)\nplt.subplot(1, 3, 3)\nplt.imshow(np.squeeze(img))\n# plt.imshow(msk,alpha=0.5)\nplt.imshow(np.squeeze(predictions), alpha=0.5)\nplt.axis(False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-11T17:50:44.359725Z","iopub.execute_input":"2023-07-11T17:50:44.36011Z","iopub.status.idle":"2023-07-11T17:50:44.853778Z","shell.execute_reply.started":"2023-07-11T17:50:44.360076Z","shell.execute_reply":"2023-07-11T17:50:44.852784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}