{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import needed modules","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, random_split\nfrom torch.utils.data import DataLoader\nfrom torchvision.models import resnet18\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.utils import make_grid\nimport torchvision.transforms.functional as F\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-13T22:54:01.401516Z","iopub.execute_input":"2023-08-13T22:54:01.40194Z","iopub.status.idle":"2023-08-13T22:54:03.064083Z","shell.execute_reply.started":"2023-08-13T22:54:01.40191Z","shell.execute_reply":"2023-08-13T22:54:03.063111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the device for training\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-08-13T22:54:03.070247Z","iopub.execute_input":"2023-08-13T22:54:03.070585Z","iopub.status.idle":"2023-08-13T22:54:03.098132Z","shell.execute_reply.started":"2023-08-13T22:54:03.070552Z","shell.execute_reply":"2023-08-13T22:54:03.09722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get Data","metadata":{}},{"cell_type":"code","source":"# Data preprocessing and augmentation\ndata_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n\ntrain_dataset = ImageFolder('/kaggle/input/brain-tumor-mri-dataset/Training', transform=data_transforms)\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n\nval_dataset = ImageFolder('/kaggle/input/brain-tumor-mri-dataset/Testing', transform=data_transforms)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-13T22:54:03.099422Z","iopub.execute_input":"2023-08-13T22:54:03.099782Z","iopub.status.idle":"2023-08-13T22:54:03.98533Z","shell.execute_reply.started":"2023-08-13T22:54:03.099745Z","shell.execute_reply":"2023-08-13T22:54:03.984318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load a batch of images and labels for visualization\ndata_iter = iter(train_loader)\nimages, labels = next(data_iter)\n\n# Convert images to numpy arrays and denormalize\nmean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\nimages = (images.numpy().transpose((0, 2, 3, 1)) * std + mean).clip(0, 1)\n\n# Create a grid of images\nnum_images = len(images)\nrows = int(np.ceil(num_images / 4))\nfig, axes = plt.subplots(rows, 4, figsize=(15, 15))\n\n# Plot images with labels\nfor i, ax in enumerate(axes.flat):\n    if i < num_images:\n        ax.imshow(images[i])\n        ax.set_title(f'Label: {train_dataset.classes[labels[i]]}')\n    ax.axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T22:54:03.988383Z","iopub.execute_input":"2023-08-13T22:54:03.988996Z","iopub.status.idle":"2023-08-13T22:54:06.286406Z","shell.execute_reply.started":"2023-08-13T22:54:03.988957Z","shell.execute_reply":"2023-08-13T22:54:06.285225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Architecture","metadata":{}},{"cell_type":"code","source":"class TumorClassifier(nn.Module):\n    def __init__(self, num_classes):\n        super(TumorClassifier, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        self.classifier = nn.Sequential(\n            nn.Linear(32 * 56 * 56, 128),\n            nn.ReLU(inplace=True),\n            nn.Linear(128, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\nmodel = TumorClassifier(num_classes=4)\n# Load a pre-trained ResNet model and modify the classifier\nmodel.to(device)","metadata":{"_kg_hide-output":true,"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-08-13T22:54:06.287492Z","iopub.execute_input":"2023-08-13T22:54:06.287817Z","iopub.status.idle":"2023-08-13T22:54:07.866333Z","shell.execute_reply.started":"2023-08-13T22:54:06.287789Z","shell.execute_reply":"2023-08-13T22:54:07.865205Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2023-08-13T22:54:07.867909Z","iopub.execute_input":"2023-08-13T22:54:07.86829Z","iopub.status.idle":"2023-08-13T22:54:07.873806Z","shell.execute_reply.started":"2023-08-13T22:54:07.868256Z","shell.execute_reply":"2023-08-13T22:54:07.872693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"# Initialize lists to store training history\ntrain_losses = []\nval_losses = []\ntrain_accuracies = []\nval_accuracies = []","metadata":{"execution":{"iopub.status.busy":"2023-08-13T22:54:07.876232Z","iopub.execute_input":"2023-08-13T22:54:07.876823Z","iopub.status.idle":"2023-08-13T22:54:07.884669Z","shell.execute_reply.started":"2023-08-13T22:54:07.876787Z","shell.execute_reply":"2023-08-13T22:54:07.883679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training loop\nnum_epochs = 20\nbest_val_accuracy = 0.0\n\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0.0\n    correct = 0\n    total = 0\n    \n    for batch_idx, (inputs, labels) in enumerate(train_loader):\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n    \n    train_accuracy = correct / total\n    train_losses.append(train_loss)\n    train_accuracies.append(train_accuracy)\n    \n    # Validation\n    model.eval()\n    val_loss = 0.0\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            \n            val_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n    val_loss /= len(val_loader)\n    val_accuracy = correct / total\n    val_losses.append(val_loss)\n    val_accuracies.append(val_accuracy)\n    \n    print(f'Epoch [{epoch+1}/{num_epochs}], '\n          f'Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.2%}, '\n          f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2%}')\n\n    \n    # Save the best model\n    if val_accuracy > best_val_accuracy:\n        best_val_accuracy = val_accuracy\n        torch.save(model.state_dict(), 'best_model.pth')\n","metadata":{"execution":{"iopub.status.busy":"2023-08-13T22:54:07.886814Z","iopub.execute_input":"2023-08-13T22:54:07.887788Z","iopub.status.idle":"2023-08-13T23:06:43.673624Z","shell.execute_reply.started":"2023-08-13T22:54:07.887755Z","shell.execute_reply":"2023-08-13T23:06:43.672602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{}},{"cell_type":"code","source":"accuracy = correct / total\nprint(f'Validation Accuracy: {accuracy:.2%}')","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:06:43.675022Z","iopub.execute_input":"2023-08-13T23:06:43.675674Z","iopub.status.idle":"2023-08-13T23:06:43.681819Z","shell.execute_reply.started":"2023-08-13T23:06:43.675637Z","shell.execute_reply":"2023-08-13T23:06:43.680914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize training history\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, label='Training Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Loss History')\n\nplt.subplot(1, 2, 2)\nplt.plot(train_accuracies, label='Training Accuracy')\nplt.plot(val_accuracies, label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.title('Accuracy History')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:06:43.68324Z","iopub.execute_input":"2023-08-13T23:06:43.683876Z","iopub.status.idle":"2023-08-13T23:06:44.309024Z","shell.execute_reply.started":"2023-08-13T23:06:43.683843Z","shell.execute_reply":"2023-08-13T23:06:44.307973Z"},"trusted":true},"execution_count":null,"outputs":[]}]}