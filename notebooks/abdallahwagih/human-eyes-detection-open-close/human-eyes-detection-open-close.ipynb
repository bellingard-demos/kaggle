{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import needed modules","metadata":{"id":"CKeVGxZ5GG6o"}},{"cell_type":"code","source":"!pip install tensorflow==2.9.1","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-05-26T16:32:42.153047Z","iopub.execute_input":"2023-05-26T16:32:42.154052Z","iopub.status.idle":"2023-05-26T16:34:42.421603Z","shell.execute_reply.started":"2023-05-26T16:32:42.154006Z","shell.execute_reply":"2023-05-26T16:34:42.420504Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import system libs\nimport os\nimport time\nimport shutil\nimport pathlib\nimport itertools\n\n# import data handling tools\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# import Deep learning Libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\nfrom tensorflow.keras import regularizers\n\n# Ignore Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint ('modules loaded')","metadata":{"id":"CeMcAy_5GG6s","outputId":"8e007371-6c2c-492c-99bb-172286922ae2","execution":{"iopub.status.busy":"2023-05-26T16:34:42.423824Z","iopub.execute_input":"2023-05-26T16:34:42.42447Z","iopub.status.idle":"2023-05-26T16:34:46.92229Z","shell.execute_reply.started":"2023-05-26T16:34:42.424427Z","shell.execute_reply":"2023-05-26T16:34:46.920476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Preprocessing**","metadata":{"id":"SA_gwvwnGG6v"}},{"cell_type":"markdown","source":"### **Read data and store it in dataframe**","metadata":{"id":"e4reLHLHabWD"}},{"cell_type":"code","source":"# Generate data paths with labels\ndata_dir = '/kaggle/input/mrl-eye-dataset/data/train'\nfilepaths = []\nlabels = []\n\nfolds = os.listdir(data_dir)\nfor fold in folds:\n    foldpath = os.path.join(data_dir, fold)\n    filelist = os.listdir(foldpath)\n    for file in filelist:\n        fpath = os.path.join(foldpath, file)\n        filepaths.append(fpath)\n        labels.append(fold)\n\n# Concatenate data paths with labels into one dataframe\nFseries = pd.Series(filepaths, name= 'filepaths')\nLseries = pd.Series(labels, name='labels')\ndf = pd.concat([Fseries, Lseries], axis= 1)","metadata":{"execution":{"iopub.status.busy":"2023-05-26T16:34:46.923548Z","iopub.execute_input":"2023-05-26T16:34:46.924323Z","iopub.status.idle":"2023-05-26T16:34:48.031323Z","shell.execute_reply.started":"2023-05-26T16:34:46.924287Z","shell.execute_reply":"2023-05-26T16:34:48.030408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-05-26T16:34:48.033805Z","iopub.execute_input":"2023-05-26T16:34:48.034157Z","iopub.status.idle":"2023-05-26T16:34:48.78798Z","shell.execute_reply.started":"2023-05-26T16:34:48.034125Z","shell.execute_reply":"2023-05-26T16:34:48.787094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Split dataframe into train, valid, and test**","metadata":{}},{"cell_type":"code","source":"# train dataframe\ntrain_df, valid_df = train_test_split(df,  train_size= 0.8, shuffle= True, random_state= 123)","metadata":{"execution":{"iopub.status.busy":"2023-05-26T16:34:48.78952Z","iopub.execute_input":"2023-05-26T16:34:48.789834Z","iopub.status.idle":"2023-05-26T16:34:48.80838Z","shell.execute_reply.started":"2023-05-26T16:34:48.789804Z","shell.execute_reply":"2023-05-26T16:34:48.807558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Read test data and store it in dataframe","metadata":{}},{"cell_type":"code","source":"# Generate data paths with labels\ndata_dir = '/kaggle/input/mrl-eye-dataset/data/test'\nfilepaths = []\nlabels = []\n\nfolds = os.listdir(data_dir)\nfor fold in folds:\n    foldpath = os.path.join(data_dir, fold)\n    filelist = os.listdir(foldpath)\n    for file in filelist:\n        fpath = os.path.join(foldpath, file)\n        filepaths.append(fpath)\n        labels.append(fold)\n\n# Concatenate data paths with labels into one dataframe\nFseries = pd.Series(filepaths, name= 'filepaths')\nLseries = pd.Series(labels, name='labels')\ntest_df = pd.concat([Fseries, Lseries], axis= 1)","metadata":{"execution":{"iopub.status.busy":"2023-05-26T16:34:48.80959Z","iopub.execute_input":"2023-05-26T16:34:48.809981Z","iopub.status.idle":"2023-05-26T16:34:48.980533Z","shell.execute_reply.started":"2023-05-26T16:34:48.80995Z","shell.execute_reply":"2023-05-26T16:34:48.979451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Create image data generator**","metadata":{}},{"cell_type":"code","source":"# crobed image size\nbatch_size = 16\nimg_size = (224, 224)\nchannels = 3\nimg_shape = (img_size[0], img_size[1], channels)\n\n# Recommended : use custom function for test data batch size, else we can use normal batch size.\nts_length = len(test_df)\ntest_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\ntest_steps = ts_length // test_batch_size\n\n# This function which will be used in image data generator for data augmentation, it just take the image and return it again.\ndef scalar(img):\n    return img\n\ntr_gen = ImageDataGenerator(preprocessing_function= scalar)\nts_gen = ImageDataGenerator(preprocessing_function= scalar)\n\ntrain_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n\nvalid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n\n# Note: we will use custom test_batch_size, and make shuffle= false\ntest_gen = ts_gen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n                                    color_mode= 'rgb', shuffle= False, batch_size= test_batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-05-26T16:34:48.982124Z","iopub.execute_input":"2023-05-26T16:34:48.982686Z","iopub.status.idle":"2023-05-26T16:36:16.396077Z","shell.execute_reply.started":"2023-05-26T16:34:48.982651Z","shell.execute_reply":"2023-05-26T16:36:16.39512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Show sample from train data**","metadata":{}},{"cell_type":"code","source":"g_dict = train_gen.class_indices      # defines dictionary {'class': index}\nclasses = list(g_dict.keys())       # defines list of dictionary's kays (classes), classes names : string\nimages, labels = next(train_gen)      # get a batch size samples from the generator\n\nplt.figure(figsize= (20, 20))\n\nfor i in range(16):\n    plt.subplot(4, 4, i + 1)\n    image = images[i] / 255       # scales data to range (0 - 255)\n    plt.imshow(image)\n    index = np.argmax(labels[i])  # get image index\n    class_name = classes[index]   # get class of image\n    plt.title(class_name, color= 'blue', fontsize= 12)\n    plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-26T16:36:16.397675Z","iopub.execute_input":"2023-05-26T16:36:16.398033Z","iopub.status.idle":"2023-05-26T16:36:19.702064Z","shell.execute_reply.started":"2023-05-26T16:36:16.39799Z","shell.execute_reply":"2023-05-26T16:36:19.701242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model Structure**","metadata":{"id":"57eDFl3oGG65"}},{"cell_type":"markdown","source":"#### **Generic Model Creation**","metadata":{"id":"3wvOKjeRGG65"}},{"cell_type":"code","source":"# Create Model Structure\nimg_size = (224, 224)\nchannels = 3\nimg_shape = (img_size[0], img_size[1], channels)\nclass_count = len(list(train_gen.class_indices.keys())) # to define number of classes in dense layer\n\n# create pre-trained model (you can built on pretrained model such as :  efficientnet, VGG , Resnet )\n# we will use efficientnetb3 from EfficientNet family.\nbase_model = tf.keras.applications.efficientnet.EfficientNetB0(include_top= False, weights= \"imagenet\", input_shape= img_shape, pooling= 'max')\n# base_model.trainable = False\n\nmodel = Sequential([\n    base_model,\n    BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n    Dense(256, kernel_regularizer= regularizers.l2(l= 0.016), activity_regularizer= regularizers.l1(0.006),\n                bias_regularizer= regularizers.l1(0.006), activation= 'relu'),\n    Dropout(rate= 0.45, seed= 123),\n    Dense(class_count, activation= 'softmax')\n])\n\nmodel.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n\nmodel.summary()","metadata":{"id":"kDT4CV15abWT","outputId":"365637a8-7535-4ac4-90ea-700f6eb5769e","execution":{"iopub.status.busy":"2023-05-26T16:36:19.703044Z","iopub.execute_input":"2023-05-26T16:36:19.703381Z","iopub.status.idle":"2023-05-26T16:36:25.80505Z","shell.execute_reply.started":"2023-05-26T16:36:19.703348Z","shell.execute_reply":"2023-05-26T16:36:25.804143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Train model**","metadata":{"id":"ap89fjdxGG67"}},{"cell_type":"code","source":"batch_size = 16   # set batch size for training\nepochs = 10   # number of all epochs in training\n\nhistory = model.fit(x= train_gen, epochs= epochs, verbose= 1, validation_data= valid_gen, \n                    validation_steps= None, shuffle= False)","metadata":{"id":"0Uk3BTERGG67","outputId":"ec610f68-a1a5-4c7d-9969-26dfab2d0305","execution":{"iopub.status.busy":"2023-05-26T16:36:25.808598Z","iopub.execute_input":"2023-05-26T16:36:25.8095Z","iopub.status.idle":"2023-05-26T18:13:32.341363Z","shell.execute_reply.started":"2023-05-26T16:36:25.809465Z","shell.execute_reply":"2023-05-26T18:13:32.340416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Display model performance**","metadata":{"id":"dNKq6ebOGG67"}},{"cell_type":"code","source":"# Define needed variables\ntr_acc = history.history['accuracy']\ntr_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\nindex_loss = np.argmin(val_loss)\nval_lowest = val_loss[index_loss]\nindex_acc = np.argmax(val_acc)\nacc_highest = val_acc[index_acc]\nEpochs = [i+1 for i in range(len(tr_acc))]\nloss_label = f'best epoch= {str(index_loss + 1)}'\nacc_label = f'best epoch= {str(index_acc + 1)}'\n\n# Plot training history\nplt.figure(figsize= (20, 8))\nplt.style.use('fivethirtyeight')\n\nplt.subplot(1, 2, 1)\nplt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\nplt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\nplt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\nplt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\nplt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout\nplt.show()","metadata":{"id":"L0Bj0Sp_GG68","outputId":"663963ec-ea21-4272-8dda-a16c5f5e2ce5","execution":{"iopub.status.busy":"2023-05-26T18:14:19.745151Z","iopub.execute_input":"2023-05-26T18:14:19.746142Z","iopub.status.idle":"2023-05-26T18:14:20.488718Z","shell.execute_reply.started":"2023-05-26T18:14:19.746106Z","shell.execute_reply":"2023-05-26T18:14:20.4878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Evaluate model**","metadata":{"id":"MySXhfAJGG68"}},{"cell_type":"code","source":"ts_length = len(test_df)\ntest_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\ntest_steps = ts_length // test_batch_size\n\ntrain_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\nvalid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\ntest_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n\nprint(\"Train Loss: \", train_score[0])\nprint(\"Train Accuracy: \", train_score[1])\nprint('-' * 20)\nprint(\"Validation Loss: \", valid_score[0])\nprint(\"Validation Accuracy: \", valid_score[1])\nprint('-' * 20)\nprint(\"Test Loss: \", test_score[0])\nprint(\"Test Accuracy: \", test_score[1])","metadata":{"id":"wSKDkyXXGG68","outputId":"b521980b-a33b-421b-8cdf-4d92fb0f304a","execution":{"iopub.status.busy":"2023-05-26T18:13:33.073574Z","iopub.execute_input":"2023-05-26T18:13:33.074285Z","iopub.status.idle":"2023-05-26T18:14:10.56725Z","shell.execute_reply.started":"2023-05-26T18:13:33.074253Z","shell.execute_reply":"2023-05-26T18:14:10.566244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Get Predictions**","metadata":{"id":"4l-DABtFGG68"}},{"cell_type":"code","source":"preds = model.predict_generator(test_gen)\ny_pred = np.argmax(preds, axis=1)","metadata":{"id":"GDFj7MZdGG69","outputId":"6dbce8ed-fc8c-4398-b8bd-1ce8cb403727","execution":{"iopub.status.busy":"2023-05-26T18:14:10.568551Z","iopub.execute_input":"2023-05-26T18:14:10.568911Z","iopub.status.idle":"2023-05-26T18:14:17.697204Z","shell.execute_reply.started":"2023-05-26T18:14:10.568879Z","shell.execute_reply":"2023-05-26T18:14:17.696146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Confusion Matrics and Classification Report**","metadata":{"id":"aJscUTF6GG69"}},{"cell_type":"code","source":"g_dict = test_gen.class_indices\nclasses = list(g_dict.keys())\n\n# Confusion matrix\ncm = confusion_matrix(test_gen.classes, y_pred)\n\nplt.figure(figsize= (10, 10))\nplt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.colorbar()\n\ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes, rotation= 45)\nplt.yticks(tick_marks, classes)\n\n\nthresh = cm.max() / 2.\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n\nplt.tight_layout()\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-26T18:14:17.698754Z","iopub.execute_input":"2023-05-26T18:14:17.699129Z","iopub.status.idle":"2023-05-26T18:14:18.101921Z","shell.execute_reply.started":"2023-05-26T18:14:17.699095Z","shell.execute_reply":"2023-05-26T18:14:18.101031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification report\nprint(classification_report(test_gen.classes, y_pred, target_names= classes))","metadata":{"id":"tQR-UlD6GG69","outputId":"09ac1d97-2053-4633-e066-ca11540a2e27","execution":{"iopub.status.busy":"2023-05-26T18:14:18.103241Z","iopub.execute_input":"2023-05-26T18:14:18.104983Z","iopub.status.idle":"2023-05-26T18:14:18.122083Z","shell.execute_reply.started":"2023-05-26T18:14:18.104957Z","shell.execute_reply":"2023-05-26T18:14:18.121099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Save model**","metadata":{"id":"SsIK5v0lGG69"}},{"cell_type":"code","source":"model_name = model.input_names[0][:-6]\nsubject = 'EyeDetection'\nacc = test_score[1] * 100\nsave_path = ''\n\n# Save model\nsave_id = str(f'{model_name}-{subject}-{\"%.2f\" %round(acc, 2)}.h5')\nmodel_save_loc = os.path.join(save_path, save_id)\nmodel.save(model_save_loc)\nprint(f'model was saved as {model_save_loc}')\n\n# Save weights\nweight_save_id = str(f'{model_name}-{subject}-weights.h5')\nweights_save_loc = os.path.join(save_path, weight_save_id)\nmodel.save_weights(weights_save_loc)\nprint(f'weights were saved as {weights_save_loc}')","metadata":{"id":"oy5ShUciGG6-","outputId":"6122a45f-351d-4cb4-f046-d141ab2f9a5e","execution":{"iopub.status.busy":"2023-05-26T18:14:18.123397Z","iopub.execute_input":"2023-05-26T18:14:18.123809Z","iopub.status.idle":"2023-05-26T18:14:18.975307Z","shell.execute_reply.started":"2023-05-26T18:14:18.123777Z","shell.execute_reply":"2023-05-26T18:14:18.974299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Generate CSV files containing classes indicies & image size**","metadata":{"id":"q2fsiEtEGG6-"}},{"cell_type":"code","source":"class_dict = train_gen.class_indices\nimg_size = train_gen.image_shape\nheight = []\nwidth = []\nfor _ in range(len(class_dict)):\n    height.append(img_size[0])\n    width.append(img_size[1])\n\nIndex_series = pd.Series(list(class_dict.values()), name= 'class_index')\nClass_series = pd.Series(list(class_dict.keys()), name= 'class')\nHeight_series = pd.Series(height, name= 'height')\nWidth_series = pd.Series(width, name= 'width')\nclass_df = pd.concat([Index_series, Class_series, Height_series, Width_series], axis= 1)\ncsv_name = f'{subject}-class_dict.csv'\ncsv_save_loc = os.path.join(save_path, csv_name)\nclass_df.to_csv(csv_save_loc, index= False)\nprint(f'class csv file was saved as {csv_save_loc}')","metadata":{"id":"UiHQzq8XGG6-","outputId":"e2daeab5-c65c-495c-ffde-be259c917c07","execution":{"iopub.status.busy":"2023-05-26T18:14:18.976754Z","iopub.execute_input":"2023-05-26T18:14:18.97711Z","iopub.status.idle":"2023-05-26T18:14:18.993985Z","shell.execute_reply.started":"2023-05-26T18:14:18.977078Z","shell.execute_reply":"2023-05-26T18:14:18.993135Z"},"trusted":true},"execution_count":null,"outputs":[]}]}