{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import needed modules","metadata":{"id":"CKeVGxZ5GG6o"}},{"cell_type":"code","source":"!pip install tensorflow==2.9.1","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-05-01T20:36:01.905875Z","iopub.execute_input":"2023-05-01T20:36:01.906237Z","iopub.status.idle":"2023-05-01T20:37:07.444512Z","shell.execute_reply.started":"2023-05-01T20:36:01.906208Z","shell.execute_reply":"2023-05-01T20:37:07.443249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import system libs\nimport os\nimport time\nimport shutil\nimport pathlib\nimport itertools\n\n# import data handling tools\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# import Deep learning Libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\nfrom tensorflow.keras import regularizers\n\n# Ignore Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint ('modules loaded')","metadata":{"id":"CeMcAy_5GG6s","outputId":"8e007371-6c2c-492c-99bb-172286922ae2","execution":{"iopub.status.busy":"2023-05-01T20:37:07.446818Z","iopub.execute_input":"2023-05-01T20:37:07.447227Z","iopub.status.idle":"2023-05-01T20:37:11.511084Z","shell.execute_reply.started":"2023-05-01T20:37:07.447187Z","shell.execute_reply":"2023-05-01T20:37:11.510202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Preprocessing**","metadata":{"id":"SA_gwvwnGG6v"}},{"cell_type":"markdown","source":"### **Read data and store it in dataframe**","metadata":{"id":"e4reLHLHabWD"}},{"cell_type":"code","source":"# Generate data paths with labels\ndata_dir = '/kaggle/input/5-flower-types-classification-dataset/flower_images'\nfilepaths = []\nlabels = []\n\nfolds = os.listdir(data_dir)\nfor fold in folds:\n    foldpath = os.path.join(data_dir, fold)\n    filelist = os.listdir(foldpath)\n    for file in filelist:\n        fpath = os.path.join(foldpath, file)\n        filepaths.append(fpath)\n        labels.append(fold)\n\n# Concatenate data paths with labels into one dataframe\nFseries = pd.Series(filepaths, name= 'filepaths')\nLseries = pd.Series(labels, name='labels')\ndf = pd.concat([Fseries, Lseries], axis= 1)","metadata":{"execution":{"iopub.status.busy":"2023-05-01T20:37:11.512489Z","iopub.execute_input":"2023-05-01T20:37:11.5132Z","iopub.status.idle":"2023-05-01T20:37:12.038448Z","shell.execute_reply.started":"2023-05-01T20:37:11.513165Z","shell.execute_reply":"2023-05-01T20:37:12.03753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-05-01T20:37:12.041817Z","iopub.execute_input":"2023-05-01T20:37:12.042118Z","iopub.status.idle":"2023-05-01T20:37:12.820797Z","shell.execute_reply.started":"2023-05-01T20:37:12.042094Z","shell.execute_reply":"2023-05-01T20:37:12.819933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Split dataframe into train, valid, and test**","metadata":{}},{"cell_type":"code","source":"# train dataframe\ntrain_df, dummy_df = train_test_split(df,  train_size= 0.8, shuffle= True, random_state= 123)\n\n# valid and test dataframe\nvalid_df, test_df = train_test_split(dummy_df,  train_size= 0.6, shuffle= True, random_state= 123)","metadata":{"execution":{"iopub.status.busy":"2023-05-01T20:37:12.822672Z","iopub.execute_input":"2023-05-01T20:37:12.823624Z","iopub.status.idle":"2023-05-01T20:37:12.832932Z","shell.execute_reply.started":"2023-05-01T20:37:12.823589Z","shell.execute_reply":"2023-05-01T20:37:12.832041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Create image data generator**","metadata":{}},{"cell_type":"code","source":"# crobed image size\nbatch_size = 16\nimg_size = (224, 224)\nchannels = 3\nimg_shape = (img_size[0], img_size[1], channels)\n\n# Recommended : use custom function for test data batch size, else we can use normal batch size.\nts_length = len(test_df)\ntest_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\ntest_steps = ts_length // test_batch_size\n\n# This function which will be used in image data generator for data augmentation, it just take the image and return it again.\ndef scalar(img):\n    return img\n\ntr_gen = ImageDataGenerator(preprocessing_function= scalar)\nts_gen = ImageDataGenerator(preprocessing_function= scalar)\n\ntrain_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n\nvalid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n\n# Note: we will use custom test_batch_size, and make shuffle= false\ntest_gen = ts_gen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n                                    color_mode= 'rgb', shuffle= False, batch_size= test_batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-05-01T20:37:12.83444Z","iopub.execute_input":"2023-05-01T20:37:12.834914Z","iopub.status.idle":"2023-05-01T20:37:13.310861Z","shell.execute_reply.started":"2023-05-01T20:37:12.834826Z","shell.execute_reply":"2023-05-01T20:37:13.309954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Show sample from train data**","metadata":{}},{"cell_type":"code","source":"g_dict = train_gen.class_indices      # defines dictionary {'class': index}\nclasses = list(g_dict.keys())       # defines list of dictionary's kays (classes), classes names : string\nimages, labels = next(train_gen)      # get a batch size samples from the generator\n\nplt.figure(figsize= (20, 20))\n\nfor i in range(16):\n    plt.subplot(4, 4, i + 1)\n    image = images[i] / 255       # scales data to range (0 - 255)\n    plt.imshow(image)\n    index = np.argmax(labels[i])  # get image index\n    class_name = classes[index]   # get class of image\n    plt.title(class_name, color= 'blue', fontsize= 12)\n    plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-01T20:37:13.312268Z","iopub.execute_input":"2023-05-01T20:37:13.312588Z","iopub.status.idle":"2023-05-01T20:37:16.427653Z","shell.execute_reply.started":"2023-05-01T20:37:13.312557Z","shell.execute_reply":"2023-05-01T20:37:16.426485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model Structure**","metadata":{"id":"57eDFl3oGG65"}},{"cell_type":"markdown","source":"#### **Generic Model Creation**","metadata":{"id":"3wvOKjeRGG65"}},{"cell_type":"code","source":"# Create Model Structure\nimg_size = (224, 224)\nchannels = 3\nimg_shape = (img_size[0], img_size[1], channels)\nclass_count = len(list(train_gen.class_indices.keys())) # to define number of classes in dense layer\n\n# create pre-trained model (you can built on pretrained model such as :  efficientnet, VGG , Resnet )\n# we will use efficientnetb3 from EfficientNet family.\nbase_model = tf.keras.applications.efficientnet.EfficientNetB5(include_top= False, weights= \"imagenet\", input_shape= img_shape, pooling= 'max')\nbase_model.trainable = False\n\nmodel = Sequential([\n    base_model,\n    BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n    Dense(256, kernel_regularizer= regularizers.l2(l= 0.016), activity_regularizer= regularizers.l1(0.006),\n                bias_regularizer= regularizers.l1(0.006), activation= 'relu'),\n    Dropout(rate= 0.45, seed= 123),\n    Dense(class_count, activation= 'softmax')\n])\n\nmodel.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n\nmodel.summary()","metadata":{"id":"kDT4CV15abWT","outputId":"365637a8-7535-4ac4-90ea-700f6eb5769e","execution":{"iopub.status.busy":"2023-05-01T20:37:16.429001Z","iopub.execute_input":"2023-05-01T20:37:16.429416Z","iopub.status.idle":"2023-05-01T20:37:24.020897Z","shell.execute_reply.started":"2023-05-01T20:37:16.429375Z","shell.execute_reply":"2023-05-01T20:37:24.019955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Train model**","metadata":{"id":"ap89fjdxGG67"}},{"cell_type":"code","source":"batch_size = 16   # set batch size for training\nepochs = 20   # number of all epochs in training\n\nhistory = model.fit(x= train_gen, epochs= epochs, verbose= 1, validation_data= valid_gen, \n                    validation_steps= None, shuffle= False)","metadata":{"id":"0Uk3BTERGG67","outputId":"ec610f68-a1a5-4c7d-9969-26dfab2d0305","execution":{"iopub.status.busy":"2023-05-01T20:37:24.022226Z","iopub.execute_input":"2023-05-01T20:37:24.02266Z","iopub.status.idle":"2023-05-01T20:46:41.376731Z","shell.execute_reply.started":"2023-05-01T20:37:24.022627Z","shell.execute_reply":"2023-05-01T20:46:41.37572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Display model performance**","metadata":{"id":"dNKq6ebOGG67"}},{"cell_type":"code","source":"# Define needed variables\ntr_acc = history.history['accuracy']\ntr_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\nindex_loss = np.argmin(val_loss)\nval_lowest = val_loss[index_loss]\nindex_acc = np.argmax(val_acc)\nacc_highest = val_acc[index_acc]\nEpochs = [i+1 for i in range(len(tr_acc))]\nloss_label = f'best epoch= {str(index_loss + 1)}'\nacc_label = f'best epoch= {str(index_acc + 1)}'\n\n# Plot training history\nplt.figure(figsize= (20, 8))\nplt.style.use('fivethirtyeight')\n\nplt.subplot(1, 2, 1)\nplt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\nplt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\nplt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\nplt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\nplt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout\nplt.show()","metadata":{"id":"L0Bj0Sp_GG68","outputId":"663963ec-ea21-4272-8dda-a16c5f5e2ce5","execution":{"iopub.status.busy":"2023-05-01T20:46:41.380446Z","iopub.execute_input":"2023-05-01T20:46:41.380755Z","iopub.status.idle":"2023-05-01T20:46:42.005492Z","shell.execute_reply.started":"2023-05-01T20:46:41.380729Z","shell.execute_reply":"2023-05-01T20:46:42.004586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Evaluate model**","metadata":{"id":"MySXhfAJGG68"}},{"cell_type":"code","source":"ts_length = len(test_df)\ntest_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\ntest_steps = ts_length // test_batch_size\n\ntrain_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\nvalid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\ntest_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n\nprint(\"Train Loss: \", train_score[0])\nprint(\"Train Accuracy: \", train_score[1])\nprint('-' * 20)\nprint(\"Validation Loss: \", valid_score[0])\nprint(\"Validation Accuracy: \", valid_score[1])\nprint('-' * 20)\nprint(\"Test Loss: \", test_score[0])\nprint(\"Test Accuracy: \", test_score[1])","metadata":{"id":"wSKDkyXXGG68","outputId":"b521980b-a33b-421b-8cdf-4d92fb0f304a","execution":{"iopub.status.busy":"2023-05-01T20:46:42.006713Z","iopub.execute_input":"2023-05-01T20:46:42.007502Z","iopub.status.idle":"2023-05-01T20:46:47.58077Z","shell.execute_reply.started":"2023-05-01T20:46:42.007468Z","shell.execute_reply":"2023-05-01T20:46:47.579446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Get Predictions**","metadata":{"id":"4l-DABtFGG68"}},{"cell_type":"code","source":"preds = model.predict_generator(test_gen)\ny_pred = np.argmax(preds, axis=1)","metadata":{"id":"GDFj7MZdGG69","outputId":"6dbce8ed-fc8c-4398-b8bd-1ce8cb403727","execution":{"iopub.status.busy":"2023-05-01T20:46:47.582417Z","iopub.execute_input":"2023-05-01T20:46:47.58276Z","iopub.status.idle":"2023-05-01T20:46:53.223228Z","shell.execute_reply.started":"2023-05-01T20:46:47.582725Z","shell.execute_reply":"2023-05-01T20:46:53.222262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Confusion Matrics and Classification Report**","metadata":{"id":"aJscUTF6GG69"}},{"cell_type":"code","source":"g_dict = test_gen.class_indices\nclasses = list(g_dict.keys())\n\n# Confusion matrix\ncm = confusion_matrix(test_gen.classes, y_pred)\n\nplt.figure(figsize= (10, 10))\nplt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.colorbar()\n\ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes, rotation= 45)\nplt.yticks(tick_marks, classes)\n\n\nthresh = cm.max() / 2.\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n\nplt.tight_layout()\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-01T20:46:53.224481Z","iopub.execute_input":"2023-05-01T20:46:53.224832Z","iopub.status.idle":"2023-05-01T20:46:53.683639Z","shell.execute_reply.started":"2023-05-01T20:46:53.224802Z","shell.execute_reply":"2023-05-01T20:46:53.682777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification report\nprint(classification_report(test_gen.classes, y_pred, target_names= classes))","metadata":{"id":"tQR-UlD6GG69","outputId":"09ac1d97-2053-4633-e066-ca11540a2e27","execution":{"iopub.status.busy":"2023-05-01T20:46:53.685219Z","iopub.execute_input":"2023-05-01T20:46:53.685873Z","iopub.status.idle":"2023-05-01T20:46:53.698501Z","shell.execute_reply.started":"2023-05-01T20:46:53.68584Z","shell.execute_reply":"2023-05-01T20:46:53.697582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Save model**","metadata":{"id":"SsIK5v0lGG69"}},{"cell_type":"code","source":"model_name = model.input_names[0][:-6]\nsubject = 'Flower Types'\nacc = test_score[1] * 100\nsave_path = ''\n\n# Save model\nsave_id = str(f'{model_name}-{subject}-{\"%.2f\" %round(acc, 2)}.h5')\nmodel_save_loc = os.path.join(save_path, save_id)\nmodel.save(model_save_loc)\nprint(f'model was saved as {model_save_loc}')\n\n# Save weights\nweight_save_id = str(f'{model_name}-{subject}-weights.h5')\nweights_save_loc = os.path.join(save_path, weight_save_id)\nmodel.save_weights(weights_save_loc)\nprint(f'weights were saved as {weights_save_loc}')","metadata":{"id":"oy5ShUciGG6-","outputId":"6122a45f-351d-4cb4-f046-d141ab2f9a5e","execution":{"iopub.status.busy":"2023-05-01T20:46:53.700557Z","iopub.execute_input":"2023-05-01T20:46:53.700962Z","iopub.status.idle":"2023-05-01T20:46:55.104069Z","shell.execute_reply.started":"2023-05-01T20:46:53.700929Z","shell.execute_reply":"2023-05-01T20:46:55.102747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Generate CSV files containing classes indicies & image size**","metadata":{"id":"q2fsiEtEGG6-"}},{"cell_type":"code","source":"class_dict = train_gen.class_indices\nimg_size = train_gen.image_shape\nheight = []\nwidth = []\nfor _ in range(len(class_dict)):\n    height.append(img_size[0])\n    width.append(img_size[1])\n\nIndex_series = pd.Series(list(class_dict.values()), name= 'class_index')\nClass_series = pd.Series(list(class_dict.keys()), name= 'class')\nHeight_series = pd.Series(height, name= 'height')\nWidth_series = pd.Series(width, name= 'width')\nclass_df = pd.concat([Index_series, Class_series, Height_series, Width_series], axis= 1)\ncsv_name = f'{subject}-class_dict.csv'\ncsv_save_loc = os.path.join(save_path, csv_name)\nclass_df.to_csv(csv_save_loc, index= False)\nprint(f'class csv file was saved as {csv_save_loc}')","metadata":{"id":"UiHQzq8XGG6-","outputId":"e2daeab5-c65c-495c-ffde-be259c917c07","execution":{"iopub.status.busy":"2023-05-01T20:46:55.105339Z","iopub.execute_input":"2023-05-01T20:46:55.106208Z","iopub.status.idle":"2023-05-01T20:46:55.122525Z","shell.execute_reply.started":"2023-05-01T20:46:55.106174Z","shell.execute_reply":"2023-05-01T20:46:55.121543Z"},"trusted":true},"execution_count":null,"outputs":[]}]}