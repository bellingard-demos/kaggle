{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import needed modules","metadata":{"id":"CKeVGxZ5GG6o"}},{"cell_type":"code","source":"!pip install tensorflow==2.9.1","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-03-11T18:20:29.495742Z","iopub.execute_input":"2023-03-11T18:20:29.496248Z","iopub.status.idle":"2023-03-11T18:21:39.276587Z","shell.execute_reply.started":"2023-03-11T18:20:29.496203Z","shell.execute_reply":"2023-03-11T18:21:39.275387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import system libs\nimport os\nimport time\nimport shutil\nimport pathlib\nimport itertools\n\n# import data handling tools\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# import Deep learning Libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\nfrom tensorflow.keras import regularizers\n\n# Ignore Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint ('modules loaded')","metadata":{"id":"CeMcAy_5GG6s","outputId":"8e007371-6c2c-492c-99bb-172286922ae2","execution":{"iopub.status.busy":"2023-03-11T18:21:39.279879Z","iopub.execute_input":"2023-03-11T18:21:39.280289Z","iopub.status.idle":"2023-03-11T18:21:44.398995Z","shell.execute_reply.started":"2023-03-11T18:21:39.280242Z","shell.execute_reply":"2023-03-11T18:21:44.39778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Preprocessing**","metadata":{"id":"SA_gwvwnGG6v"}},{"cell_type":"markdown","source":"### **Read data and store it in dataframe**","metadata":{"id":"e4reLHLHabWD"}},{"cell_type":"code","source":"# Generate data paths with labels\ndata_dir = '/kaggle/input/diabetic-retinopathy-224x224-gaussian-filtered/gaussian_filtered_images/gaussian_filtered_images'\nfilepaths = []\nlabels = []\n\nfolds = os.listdir(data_dir)\nfor fold in folds:\n    foldpath = os.path.join(data_dir, fold)  \n    # skip export.pkl file\n    if pathlib.Path(foldpath).suffix == '':\n        filelist = os.listdir(foldpath)\n\n        for file in filelist:\n            fpath = os.path.join(foldpath, file)\n            filepaths.append(fpath)\n            labels.append(fold)\n\n# Concatenate data paths with labels into one dataframe\nFseries = pd.Series(filepaths, name= 'filepaths')\nLseries = pd.Series(labels, name='labels')\ndf = pd.concat([Fseries, Lseries], axis= 1)","metadata":{"execution":{"iopub.status.busy":"2023-03-11T18:21:44.400638Z","iopub.execute_input":"2023-03-11T18:21:44.401853Z","iopub.status.idle":"2023-03-11T18:21:44.749513Z","shell.execute_reply.started":"2023-03-11T18:21:44.401781Z","shell.execute_reply":"2023-03-11T18:21:44.748524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Split dataframe into train, valid, and test**","metadata":{}},{"cell_type":"code","source":"# train dataframe\ntrain_df, dummy_df = train_test_split(df,  train_size= 0.8, shuffle= True, random_state= 123)\n\n# valid and test dataframe\nvalid_df, test_df = train_test_split(dummy_df,  train_size= 0.6, shuffle= True, random_state= 123)","metadata":{"execution":{"iopub.status.busy":"2023-03-11T18:21:44.752458Z","iopub.execute_input":"2023-03-11T18:21:44.752898Z","iopub.status.idle":"2023-03-11T18:21:45.949413Z","shell.execute_reply.started":"2023-03-11T18:21:44.752858Z","shell.execute_reply":"2023-03-11T18:21:45.948268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Create image data generator**","metadata":{}},{"cell_type":"code","source":"# crobed image size\nbatch_size = 32\nimg_size = (224, 224)\nchannels = 3\nimg_shape = (img_size[0], img_size[1], channels)\n\n# Recommended : use custom function for test data batch size, else we can use normal batch size.\nts_length = len(test_df)\ntest_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\ntest_steps = ts_length // test_batch_size\n\n# This function which will be used in image data generator for data augmentation, it just take the image and return it again.\ndef scalar(img):\n    return img\n\ntr_gen = ImageDataGenerator(preprocessing_function= scalar)\nts_gen = ImageDataGenerator(preprocessing_function= scalar)\n\ntrain_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n\nvalid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n\n# Note: we will use custom test_batch_size, and make shuffle= false\ntest_gen = ts_gen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n                                    color_mode= 'rgb', shuffle= False, batch_size= test_batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-03-11T18:21:45.951032Z","iopub.execute_input":"2023-03-11T18:21:45.951922Z","iopub.status.idle":"2023-03-11T18:21:46.95734Z","shell.execute_reply.started":"2023-03-11T18:21:45.951882Z","shell.execute_reply":"2023-03-11T18:21:46.956203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Show sample from train data**","metadata":{}},{"cell_type":"code","source":"g_dict = train_gen.class_indices      # defines dictionary {'class': index}\nclasses = list(g_dict.keys())       # defines list of dictionary's kays (classes), classes names : string\nimages, labels = next(train_gen)      # get a batch size samples from the generator\n\n# calculate number of displayed samples\nlength = len(labels)        # length of batch size\nsample = min(length, 25)    # check if sample less than 25 images\n\nplt.figure(figsize= (20, 20))\n\nfor i in range(sample):\n    plt.subplot(5, 5, i + 1)\n    image = images[i] / 255       # scales data to range (0 - 255)\n    plt.imshow(image)\n    index = np.argmax(labels[i])  # get image index\n    class_name = classes[index]   # get class of image\n    plt.title(class_name, color= 'blue', fontsize= 12)\n    plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-11T18:21:46.959393Z","iopub.execute_input":"2023-03-11T18:21:46.959973Z","iopub.status.idle":"2023-03-11T18:21:50.139621Z","shell.execute_reply.started":"2023-03-11T18:21:46.959929Z","shell.execute_reply":"2023-03-11T18:21:50.138298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Callbacks** \n<br> \nCallbacks : Helpful functions to help optimize model training  <br> \nExamples: stop model training after specfic time, stop training if no improve in accuracy and so on.","metadata":{"id":"_K-ryg0DGG6z"}},{"cell_type":"code","source":"class MyCallback(keras.callbacks.Callback):\n    def __init__(self, model, patience, stop_patience, threshold, factor, batches, epochs, ask_epoch):\n        super(MyCallback, self).__init__()\n        self.model = model\n        self.patience = patience # specifies how many epochs without improvement before learning rate is adjusted\n        self.stop_patience = stop_patience # specifies how many times to adjust lr without improvement to stop training\n        self.threshold = threshold # specifies training accuracy threshold when lr will be adjusted based on validation loss\n        self.factor = factor # factor by which to reduce the learning rate\n        self.batches = batches # number of training batch to run per epoch\n        self.epochs = epochs\n        self.ask_epoch = ask_epoch\n        self.ask_epoch_initial = ask_epoch # save this value to restore if restarting training\n\n        # callback variables\n        self.count = 0 # how many times lr has been reduced without improvement\n        self.stop_count = 0\n        self.best_epoch = 1   # epoch with the lowest loss\n        self.initial_lr = float(tf.keras.backend.get_value(model.optimizer.lr)) # get the initial learning rate and save it\n        self.highest_tracc = 0.0 # set highest training accuracy to 0 initially\n        self.lowest_vloss = np.inf # set lowest validation loss to infinity initially\n        self.best_weights = self.model.get_weights() # set best weights to model's initial weights\n        self.initial_weights = self.model.get_weights()   # save initial weights if they have to get restored\n\n    # Define a function that will run when train begins\n    def on_train_begin(self, logs= None):\n        msg = 'Do you want model asks you to halt the training [y/n] ?'\n        print(msg)\n        ans = input('')\n        if ans in ['Y', 'y']:\n            self.ask_permission = 1\n        elif ans in ['N', 'n']:\n            self.ask_permission = 0\n\n        msg = '{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^10s}{8:10s}{9:^8s}'.format('Epoch', 'Loss', 'Accuracy', 'V_loss', 'V_acc', 'LR', 'Next LR', 'Monitor','% Improv', 'Duration')\n        print(msg)\n        self.start_time = time.time()\n\n\n    def on_train_end(self, logs= None):\n        stop_time = time.time()\n        tr_duration = stop_time - self.start_time\n        hours = tr_duration // 3600\n        minutes = (tr_duration - (hours * 3600)) // 60\n        seconds = tr_duration - ((hours * 3600) + (minutes * 60))\n\n        msg = f'training elapsed time was {str(hours)} hours, {minutes:4.1f} minutes, {seconds:4.2f} seconds)'\n        print(msg)\n\n        # set the weights of the model to the best weights\n        self.model.set_weights(self.best_weights)\n\n\n    def on_train_batch_end(self, batch, logs= None):\n        # get batch accuracy and loss\n        acc = logs.get('accuracy') * 100\n        loss = logs.get('loss')\n\n        # prints over on the same line to show running batch count\n        msg = '{0:20s}processing batch {1:} of {2:5s}-   accuracy=  {3:5.3f}   -   loss: {4:8.5f}'.format(' ', str(batch), str(self.batches), acc, loss)\n        print(msg, '\\r', end= '')\n\n\n    def on_epoch_begin(self, epoch, logs= None):\n        self.ep_start = time.time()\n\n\n    # Define method runs on the end of each epoch\n    def on_epoch_end(self, epoch, logs= None):\n        ep_end = time.time()\n        duration = ep_end - self.ep_start\n\n        lr = float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n        current_lr = lr\n        acc = logs.get('accuracy')  # get training accuracy\n        v_acc = logs.get('val_accuracy')  # get validation accuracy\n        loss = logs.get('loss')  # get training loss for this epoch\n        v_loss = logs.get('val_loss')  # get the validation loss for this epoch\n\n        if acc < self.threshold: # if training accuracy is below threshold adjust lr based on training accuracy\n            monitor = 'accuracy'\n            if epoch == 0:\n                pimprov = 0.0\n            else:\n                pimprov = (acc - self.highest_tracc ) * 100 / self.highest_tracc # define improvement of model progres\n\n            if acc > self.highest_tracc: # training accuracy improved in the epoch\n                self.highest_tracc = acc # set new highest training accuracy\n                self.best_weights = self.model.get_weights() # training accuracy improved so save the weights\n                self.count = 0 # set count to 0 since training accuracy improved\n                self.stop_count = 0 # set stop counter to 0\n                if v_loss < self.lowest_vloss:\n                    self.lowest_vloss = v_loss\n                self.best_epoch = epoch + 1  # set the value of best epoch for this epoch\n\n            else:\n                # training accuracy did not improve check if this has happened for patience number of epochs\n                # if so adjust learning rate\n                if self.count >= self.patience - 1: # lr should be adjusted\n                    lr = lr * self.factor # adjust the learning by factor\n                    tf.keras.backend.set_value(self.model.optimizer.lr, lr) # set the learning rate in the optimizer\n                    self.count = 0 # reset the count to 0\n                    self.stop_count = self.stop_count + 1 # count the number of consecutive lr adjustments\n                    self.count = 0 # reset counter\n                    if v_loss < self.lowest_vloss:\n                        self.lowest_vloss = v_loss\n                else:\n                    self.count = self.count + 1 # increment patience counter\n\n        else: # training accuracy is above threshold so adjust learning rate based on validation loss\n            monitor = 'val_loss'\n            if epoch == 0:\n                pimprov = 0.0\n\n            else:\n                pimprov = (self.lowest_vloss - v_loss ) * 100 / self.lowest_vloss\n\n            if v_loss < self.lowest_vloss: # check if the validation loss improved\n                self.lowest_vloss = v_loss # replace lowest validation loss with new validation loss\n                self.best_weights = self.model.get_weights() # validation loss improved so save the weights\n                self.count = 0 # reset count since validation loss improved\n                self.stop_count = 0\n                self.best_epoch = epoch + 1 # set the value of the best epoch to this epoch\n\n            else: # validation loss did not improve\n                if self.count >= self.patience - 1: # need to adjust lr\n                    lr = lr * self.factor # adjust the learning rate\n                    self.stop_count = self.stop_count + 1 # increment stop counter because lr was adjusted\n                    self.count = 0 # reset counter\n                    tf.keras.backend.set_value(self.model.optimizer.lr, lr) # set the learning rate in the optimizer\n\n                else:\n                    self.count = self.count + 1 # increment the patience counter\n\n                if acc > self.highest_tracc:\n                    self.highest_tracc = acc\n\n        msg = f'{str(epoch + 1):^3s}/{str(self.epochs):4s} {loss:^9.3f}{acc * 100:^9.3f}{v_loss:^9.5f}{v_acc * 100:^9.3f}{current_lr:^9.5f}{lr:^9.5f}{monitor:^11s}{pimprov:^10.2f}{duration:^8.2f}'\n        print(msg)\n\n        if self.stop_count > self.stop_patience - 1: # check if learning rate has been adjusted stop_count times with no improvement\n            msg = f' training has been halted at epoch {epoch + 1} after {self.stop_patience} adjustments of learning rate with no improvement'\n            print(msg)\n            self.model.stop_training = True # stop training\n\n        else:\n            if self.ask_epoch != None and self.ask_permission != 0:\n                if epoch + 1 >= self.ask_epoch:\n                    msg = 'enter H to halt training or an integer for number of epochs to run then ask again'\n                    print(msg)\n\n                    ans = input('')\n                    if ans == 'H' or ans == 'h':\n                        msg = f'training has been halted at epoch {epoch + 1} due to user input'\n                        print(msg)\n                        self.model.stop_training = True # stop training\n\n                    else:\n                        try:\n                            ans = int(ans)\n                            self.ask_epoch += ans\n                            msg = f' training will continue until epoch {str(self.ask_epoch)}'\n                            print(msg)\n                            msg = '{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^10s}{8:10s}{9:^8s}'.format('Epoch', 'Loss', 'Accuracy', 'V_loss', 'V_acc', 'LR', 'Next LR', 'Monitor', '% Improv', 'Duration')\n                            print(msg)\n\n                        except Exception:\n                            print('Invalid')","metadata":{"id":"d5HiN8XDGG60","execution":{"iopub.status.busy":"2023-03-11T18:21:50.141196Z","iopub.execute_input":"2023-03-11T18:21:50.141649Z","iopub.status.idle":"2023-03-11T18:21:50.179716Z","shell.execute_reply.started":"2023-03-11T18:21:50.141598Z","shell.execute_reply":"2023-03-11T18:21:50.178878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model Structure**","metadata":{"id":"57eDFl3oGG65"}},{"cell_type":"markdown","source":"#### **Generic Model Creation**","metadata":{"id":"3wvOKjeRGG65"}},{"cell_type":"code","source":"# Create Model Structure\nimg_size = (224, 224)\nchannels = 3\nimg_shape = (img_size[0], img_size[1], channels)\nclass_count = len(list(train_gen.class_indices.keys())) # to define number of classes in dense layer\n\n# create pre-trained model (you can built on pretrained model such as :  efficientnet, VGG , Resnet )\n# we will use efficientnetb3 from EfficientNet family.\nbase_model = tf.keras.applications.efficientnet.EfficientNetB3(include_top= False, weights= \"imagenet\", input_shape= img_shape, pooling= 'max')\n\nmodel = Sequential([\n    base_model,\n    BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n    Dense(256, kernel_regularizer= regularizers.l2(l= 0.016), activity_regularizer= regularizers.l1(0.006),\n                bias_regularizer= regularizers.l1(0.006), activation= 'relu'),\n    Dropout(rate= 0.45, seed= 123),\n    Dense(class_count, activation= 'softmax')\n])\n\nmodel.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n\nmodel.summary()","metadata":{"id":"kDT4CV15abWT","outputId":"365637a8-7535-4ac4-90ea-700f6eb5769e","execution":{"iopub.status.busy":"2023-03-11T18:21:50.181493Z","iopub.execute_input":"2023-03-11T18:21:50.182109Z","iopub.status.idle":"2023-03-11T18:21:56.221742Z","shell.execute_reply.started":"2023-03-11T18:21:50.182068Z","shell.execute_reply":"2023-03-11T18:21:56.220633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Set Callback Parameters**","metadata":{"id":"TciwhdM1GG66"}},{"cell_type":"code","source":"batch_size = 32   # set batch size for training\nepochs = 40   # number of all epochs in training\npatience = 1   #number of epochs to wait to adjust lr if monitored value does not improve\nstop_patience = 3   # number of epochs to wait before stopping training if monitored value does not improve\nthreshold = 0.9   # if train accuracy is < threshold adjust monitor accuracy, else monitor validation loss\nfactor = 0.5   # factor to reduce lr by\nask_epoch = 5   # number of epochs to run before asking if you want to halt training\nbatches = int(np.ceil(len(train_gen.labels) / batch_size))    # number of training batch to run per epoch\n\ncallbacks = [MyCallback(model= model, patience= patience, stop_patience= stop_patience, threshold= threshold,\n            factor= factor, batches= batches, epochs= epochs, ask_epoch= ask_epoch )]","metadata":{"id":"7abvdv7mGG66","execution":{"iopub.status.busy":"2023-03-11T18:21:56.223505Z","iopub.execute_input":"2023-03-11T18:21:56.223907Z","iopub.status.idle":"2023-03-11T18:21:56.512541Z","shell.execute_reply.started":"2023-03-11T18:21:56.223869Z","shell.execute_reply":"2023-03-11T18:21:56.511498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Train model**","metadata":{"id":"ap89fjdxGG67"}},{"cell_type":"code","source":"history = model.fit(x= train_gen, epochs= epochs, verbose= 0, callbacks= callbacks,\n                    validation_data= valid_gen, validation_steps= None, shuffle= False)","metadata":{"id":"0Uk3BTERGG67","outputId":"ec610f68-a1a5-4c7d-9969-26dfab2d0305","execution":{"iopub.status.busy":"2023-03-11T18:21:56.515948Z","iopub.execute_input":"2023-03-11T18:21:56.516236Z","iopub.status.idle":"2023-03-11T18:39:10.050593Z","shell.execute_reply.started":"2023-03-11T18:21:56.516209Z","shell.execute_reply":"2023-03-11T18:39:10.049503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Display model performance**","metadata":{"id":"dNKq6ebOGG67"}},{"cell_type":"code","source":"# Define needed variables\ntr_acc = history.history['accuracy']\ntr_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\n\nindex_loss = np.argmin(val_loss)\nval_lowest = val_loss[index_loss]\nindex_acc = np.argmax(val_acc)\nacc_highest = val_acc[index_acc]\nEpochs = [i+1 for i in range(len(tr_acc))]\nloss_label = f'best epoch= {str(index_loss + 1)}'\nacc_label = f'best epoch= {str(index_acc + 1)}'\n\n# Plot training history\nplt.figure(figsize= (20, 8))\nplt.style.use('fivethirtyeight')\n\nplt.subplot(1, 2, 1)\nplt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\nplt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\nplt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\nplt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\nplt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout\nplt.show()","metadata":{"id":"L0Bj0Sp_GG68","outputId":"663963ec-ea21-4272-8dda-a16c5f5e2ce5","execution":{"iopub.status.busy":"2023-03-11T18:39:10.052273Z","iopub.execute_input":"2023-03-11T18:39:10.052667Z","iopub.status.idle":"2023-03-11T18:39:26.799984Z","shell.execute_reply.started":"2023-03-11T18:39:10.052628Z","shell.execute_reply":"2023-03-11T18:39:26.798966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Evaluate model**","metadata":{"id":"MySXhfAJGG68"}},{"cell_type":"code","source":"ts_length = len(test_df)\ntest_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\ntest_steps = ts_length // test_batch_size\n\ntrain_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\nvalid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\ntest_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n\nprint(\"Train Loss: \", train_score[0])\nprint(\"Train Accuracy: \", train_score[1])\nprint('-' * 20)\nprint(\"Validation Loss: \", valid_score[0])\nprint(\"Validation Accuracy: \", valid_score[1])\nprint('-' * 20)\nprint(\"Test Loss: \", test_score[0])\nprint(\"Test Accuracy: \", test_score[1])","metadata":{"id":"wSKDkyXXGG68","outputId":"b521980b-a33b-421b-8cdf-4d92fb0f304a","execution":{"iopub.status.busy":"2023-03-11T18:39:26.801319Z","iopub.execute_input":"2023-03-11T18:39:26.802402Z","iopub.status.idle":"2023-03-11T18:39:31.700758Z","shell.execute_reply.started":"2023-03-11T18:39:26.802363Z","shell.execute_reply":"2023-03-11T18:39:31.699749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Get Predictions**","metadata":{"id":"4l-DABtFGG68"}},{"cell_type":"code","source":"preds = model.predict_generator(test_gen)\ny_pred = np.argmax(preds, axis=1)","metadata":{"id":"GDFj7MZdGG69","outputId":"6dbce8ed-fc8c-4398-b8bd-1ce8cb403727","execution":{"iopub.status.busy":"2023-03-11T18:39:31.703845Z","iopub.execute_input":"2023-03-11T18:39:31.704143Z","iopub.status.idle":"2023-03-11T18:39:35.552716Z","shell.execute_reply.started":"2023-03-11T18:39:31.704115Z","shell.execute_reply":"2023-03-11T18:39:35.551676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Confusion Matrics and Classification Report**","metadata":{"id":"aJscUTF6GG69"}},{"cell_type":"code","source":"g_dict = test_gen.class_indices\nclasses = list(g_dict.keys())\n\n# Confusion matrix\ncm = confusion_matrix(test_gen.classes, y_pred)\n\nplt.figure(figsize= (10, 10))\nplt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.colorbar()\n\ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes, rotation= 45)\nplt.yticks(tick_marks, classes)\n\n\nthresh = cm.max() / 2.\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n\nplt.tight_layout()\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-11T18:39:35.554415Z","iopub.execute_input":"2023-03-11T18:39:35.554778Z","iopub.status.idle":"2023-03-11T18:39:35.950958Z","shell.execute_reply.started":"2023-03-11T18:39:35.554741Z","shell.execute_reply":"2023-03-11T18:39:35.949894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification report\nprint(classification_report(test_gen.classes, y_pred, target_names= classes))","metadata":{"id":"tQR-UlD6GG69","outputId":"09ac1d97-2053-4633-e066-ca11540a2e27","execution":{"iopub.status.busy":"2023-03-11T18:39:35.952512Z","iopub.execute_input":"2023-03-11T18:39:35.952913Z","iopub.status.idle":"2023-03-11T18:39:35.965406Z","shell.execute_reply.started":"2023-03-11T18:39:35.952874Z","shell.execute_reply":"2023-03-11T18:39:35.96438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Save model**","metadata":{"id":"SsIK5v0lGG69"}},{"cell_type":"code","source":"model_name = model.input_names[0][:-6]\nsubject = 'Diabetic Retinopathy Detection'\nacc = test_score[1] * 100\n\n# Save model\nsave_id = str(f'{model_name}-{subject}-{\"%.2f\" %round(acc, 2)}.h5')\nmodel_save_loc = os.path.join('', save_id)\nmodel.save(model_save_loc)\nprint(f'model was saved as {model_save_loc}')\n\n# Save weights\nweight_save_id = str(f'{model_name}-{subject}-weights.h5')\nweights_save_loc = os.path.join('', weight_save_id)\nmodel.save_weights(weights_save_loc)\nprint(f'weights were saved as {weights_save_loc}')","metadata":{"id":"oy5ShUciGG6-","outputId":"6122a45f-351d-4cb4-f046-d141ab2f9a5e","execution":{"iopub.status.busy":"2023-03-11T18:39:35.966905Z","iopub.execute_input":"2023-03-11T18:39:35.967464Z","iopub.status.idle":"2023-03-11T18:39:37.363704Z","shell.execute_reply.started":"2023-03-11T18:39:35.967416Z","shell.execute_reply":"2023-03-11T18:39:37.362465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Generate CSV files containing classes indicies & image size**","metadata":{"id":"q2fsiEtEGG6-"}},{"cell_type":"code","source":"class_dict = train_gen.class_indices\nimg_size = train_gen.image_shape\nheight = []\nwidth = []\nfor _ in range(len(class_dict)):\n    height.append(img_size[0])\n    width.append(img_size[1])\n\nIndex_series = pd.Series(list(class_dict.values()), name= 'class_index')\nClass_series = pd.Series(list(class_dict.keys()), name= 'class')\nHeight_series = pd.Series(height, name= 'height')\nWidth_series = pd.Series(width, name= 'width')\nclass_df = pd.concat([Index_series, Class_series, Height_series, Width_series], axis= 1)\ncsv_name = f'{subject}-class_dict.csv'\ncsv_save_loc = os.path.join(save_path, csv_name)\nclass_df.to_csv(csv_save_loc, index= False)\nprint(f'class csv file was saved as {csv_save_loc}')","metadata":{"id":"UiHQzq8XGG6-","outputId":"e2daeab5-c65c-495c-ffde-be259c917c07","execution":{"iopub.status.busy":"2023-03-11T18:39:37.365364Z","iopub.execute_input":"2023-03-11T18:39:37.36576Z","iopub.status.idle":"2023-03-11T18:39:37.381623Z","shell.execute_reply.started":"2023-03-11T18:39:37.36572Z","shell.execute_reply":"2023-03-11T18:39:37.380452Z"},"trusted":true},"execution_count":null,"outputs":[]}]}