{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Import Needed Modules**","metadata":{"id":"g_3rM2Af6CwS"}},{"cell_type":"code","source":"# import system libs \nimport os\nimport time\nimport glob\nimport shutil\n\n# import data handling tools \nimport cv2\nimport PIL\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport matplotlib.pyplot as plt\n\n# import Deep learning Libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.image as tfi\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Model, load_model\nfrom keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.layers import Conv2D,  MaxPool2D, UpSampling2D, concatenate, Activation\nfrom tensorflow.keras.layers import Layer, Input, Add, Multiply, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam, Adamax\n\n# Ignore Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint ('modules loaded')","metadata":{"execution":{"iopub.status.busy":"2023-02-02T12:57:55.39456Z","iopub.execute_input":"2023-02-02T12:57:55.394986Z","iopub.status.idle":"2023-02-02T12:57:57.534526Z","shell.execute_reply.started":"2023-02-02T12:57:55.394902Z","shell.execute_reply":"2023-02-02T12:57:57.533235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Create Needed Functions**","metadata":{}},{"cell_type":"markdown","source":"### **Function to create data**","metadata":{}},{"cell_type":"code","source":"def create_data(data_dir):\n    image_paths = []\n    mask_paths = []\n    \n    folds = sorted(os.listdir(data_dir))\n    for fold in folds:\n        foldpath = os.path.join(data_dir, fold)\n        if fold in ['image', 'Image', 'images', 'Images', 'IMAGES']:\n            images = sorted(os.listdir(foldpath))\n            for image in images:\n                fpath = os.path.join(foldpath, image)\n                image_paths.append(fpath)\n\n        elif fold in ['mask', 'Mask', 'masks', 'Masks', 'MASKS']:\n            masks = sorted(os.listdir(foldpath))\n            for mask in masks:\n                fpath = os.path.join(foldpath, mask)\n                mask_paths.append(fpath)\n        else:\n            continue\n        \n    return image_paths, mask_paths","metadata":{"execution":{"iopub.status.busy":"2023-02-02T12:57:57.536627Z","iopub.execute_input":"2023-02-02T12:57:57.53765Z","iopub.status.idle":"2023-02-02T12:57:57.547292Z","shell.execute_reply.started":"2023-02-02T12:57:57.53761Z","shell.execute_reply":"2023-02-02T12:57:57.546173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Functions to read images**","metadata":{}},{"cell_type":"code","source":"# function to read an image\ndef load_image(image, SIZE):\n    return np.round(tfi.resize(img_to_array(load_img(image)) / 255., (SIZE, SIZE)), 4)\n\n# function to read multiple images\ndef load_images(image_paths, SIZE, mask=False, trim=None):\n    if trim is not None:\n        image_paths = image_paths[:trim]\n    \n    if mask:\n        images = np.zeros(shape=(len(image_paths), SIZE, SIZE, 1))\n    else:\n        images = np.zeros(shape=(len(image_paths), SIZE, SIZE, 3))\n    \n    for i, image in enumerate(image_paths):\n        img = load_image(image, SIZE)\n        if mask:\n            images[i] = img[:, :, :1]\n        else:\n            images[i] = img\n    \n    return images","metadata":{"id":"Sv5MB-unO3tY","execution":{"iopub.status.busy":"2023-02-02T12:57:57.550645Z","iopub.execute_input":"2023-02-02T12:57:57.550937Z","iopub.status.idle":"2023-02-02T12:57:57.562199Z","shell.execute_reply.started":"2023-02-02T12:57:57.55091Z","shell.execute_reply":"2023-02-02T12:57:57.561007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Function to display data sample**","metadata":{}},{"cell_type":"code","source":"def show_image(image, title=None, cmap=None, alpha=1):\n    plt.imshow(image, cmap=cmap, alpha=alpha)\n    if title is not None:\n        plt.title(title)\n    plt.axis('off')\n\ndef show_mask(image, mask, cmap=None, alpha=0.4):\n    plt.imshow(image)\n    plt.imshow(tf.squeeze(mask), cmap=cmap, alpha=alpha)\n    plt.axis('off')\n\ndef show_images(imgs, msks):\n    plt.figure(figsize=(13,8))\n    \n    for i in range(15):\n        plt.subplot(3,5,i+1)\n        id = np.random.randint(len(imgs))\n        show_mask(imgs[id], msks[id], cmap='binary')\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-02T12:57:57.565922Z","iopub.execute_input":"2023-02-02T12:57:57.566342Z","iopub.status.idle":"2023-02-02T12:57:57.575408Z","shell.execute_reply.started":"2023-02-02T12:57:57.566307Z","shell.execute_reply":"2023-02-02T12:57:57.574303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Encoder**","metadata":{}},{"cell_type":"code","source":"class EncoderBlock(Layer):\n\n    def __init__(self, filters, rate, pooling=True, **kwargs):\n        super(EncoderBlock, self).__init__(**kwargs)\n\n        self.filters = filters\n        self.rate = rate\n        self.pooling = pooling\n\n        self.c1 = Conv2D(filters, kernel_size=3, strides=1, padding='same', activation='relu', kernel_initializer='he_normal')\n        self.drop = Dropout(rate)\n        self.c2 = Conv2D(filters, kernel_size=3, strides=1, padding='same', activation='relu', kernel_initializer='he_normal')\n        self.pool = MaxPool2D()\n\n    def call(self, X):\n        x = self.c1(X)\n        x = self.drop(x)\n        x = self.c2(x)\n        if self.pooling:\n            y = self.pool(x)\n            return y, x\n        else:\n            return x\n\n    def get_config(self):\n        base_config = super().get_config()\n        return {\n            **base_config,\n            \"filters\":self.filters,\n            'rate':self.rate,\n            'pooling':self.pooling\n        }","metadata":{"execution":{"iopub.status.busy":"2023-02-02T12:57:57.576832Z","iopub.execute_input":"2023-02-02T12:57:57.578543Z","iopub.status.idle":"2023-02-02T12:57:57.588207Z","shell.execute_reply.started":"2023-02-02T12:57:57.578506Z","shell.execute_reply":"2023-02-02T12:57:57.587072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Decoder**","metadata":{}},{"cell_type":"code","source":"class DecoderBlock(Layer):\n\n    def __init__(self, filters, rate, **kwargs):\n        super(DecoderBlock, self).__init__(**kwargs)\n\n        self.filters = filters\n        self.rate = rate\n\n        self.up = UpSampling2D()\n        self.net = EncoderBlock(filters, rate, pooling=False)\n\n    def call(self, X):\n        X, skip_X = X\n        x = self.up(X)\n        c_ = concatenate([x, skip_X])\n        x = self.net(c_)\n        return x\n\n    def get_config(self):\n        base_config = super().get_config()\n        return {\n            **base_config,\n            \"filters\":self.filters,\n            'rate':self.rate,\n        }","metadata":{"execution":{"iopub.status.busy":"2023-02-02T12:57:57.590108Z","iopub.execute_input":"2023-02-02T12:57:57.590476Z","iopub.status.idle":"2023-02-02T12:57:57.601397Z","shell.execute_reply.started":"2023-02-02T12:57:57.590439Z","shell.execute_reply":"2023-02-02T12:57:57.600483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **AttentionGate**","metadata":{}},{"cell_type":"code","source":"class AttentionGate(Layer):\n\n    def __init__(self, filters, bn, **kwargs):\n        super(AttentionGate, self).__init__(**kwargs)\n\n        self.filters = filters\n        self.bn = bn\n\n        self.normal = Conv2D(filters, kernel_size=3, padding='same', activation='relu', kernel_initializer='he_normal')\n        self.down = Conv2D(filters, kernel_size=3, strides=2, padding='same', activation='relu', kernel_initializer='he_normal')\n        self.learn = Conv2D(1, kernel_size=1, padding='same', activation='sigmoid')\n        self.resample = UpSampling2D()\n        self.BN = BatchNormalization()\n\n    def call(self, X):\n        X, skip_X = X\n\n        x = self.normal(X)\n        skip = self.down(skip_X)\n        x = Add()([x, skip])\n        x = self.learn(x)\n        x = self.resample(x)\n        f = Multiply()([x, skip_X])\n        if self.bn:\n            return self.BN(f)\n        else:\n            return f\n        # return f\n\n    def get_config(self):\n        base_config = super().get_config()\n        return {\n            **base_config,\n            \"filters\":self.filters,\n            \"bn\":self.bn\n        }","metadata":{"execution":{"iopub.status.busy":"2023-02-02T12:57:57.603196Z","iopub.execute_input":"2023-02-02T12:57:57.603628Z","iopub.status.idle":"2023-02-02T12:57:57.614846Z","shell.execute_reply.started":"2023-02-02T12:57:57.603596Z","shell.execute_reply":"2023-02-02T12:57:57.613911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Function to plot training history**","metadata":{}},{"cell_type":"code","source":"def plot_training(hist):\n    '''\n    This function take training model and plot history of accuracy and losses with the best epoch in both of them.\n    '''\n\n    # Define needed variables\n    tr_acc = hist.history['accuracy']\n    tr_loss = hist.history['loss']\n    val_acc = hist.history['val_accuracy']\n    val_loss = hist.history['val_loss']\n    index_loss = np.argmin(val_loss)\n    val_lowest = val_loss[index_loss]\n    index_acc = np.argmax(val_acc)\n    acc_highest = val_acc[index_acc]\n    Epochs = [i+1 for i in range(len(tr_acc))]\n    loss_label = f'best epoch= {str(index_loss + 1)}'\n    acc_label = f'best epoch= {str(index_acc + 1)}'\n\n    # Plot training history\n    plt.figure(figsize= (20, 8))\n    plt.style.use('fivethirtyeight')\n\n    plt.subplot(1, 2, 1)\n    plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n    plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n    plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    plt.subplot(1, 2, 2)\n    plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n    plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n    plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n\n    plt.tight_layout\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-02T12:57:57.64162Z","iopub.execute_input":"2023-02-02T12:57:57.641954Z","iopub.status.idle":"2023-02-02T12:57:57.653985Z","shell.execute_reply.started":"2023-02-02T12:57:57.641926Z","shell.execute_reply":"2023-02-02T12:57:57.653374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model Structure**","metadata":{}},{"cell_type":"markdown","source":"### **Get Data**","metadata":{}},{"cell_type":"code","source":"SIZE = 256\n\n# get data\ndata_dir = '/kaggle/input/flood-area-segmentation'\nimage_paths, mask_paths = create_data(data_dir)\n\n# load images and masks\nimgs = load_images(image_paths, SIZE)\nmsks = load_images(mask_paths, SIZE, mask=True)\n\n# show sample\nshow_images(imgs, msks)","metadata":{"id":"wP8jF-PHO9Ch","outputId":"f8dc581b-0a21-494b-8a74-73ce6fe5b9a3","execution":{"iopub.status.busy":"2023-02-02T12:57:57.657689Z","iopub.execute_input":"2023-02-02T12:57:57.658329Z","iopub.status.idle":"2023-02-02T12:58:25.295459Z","shell.execute_reply.started":"2023-02-02T12:57:57.65829Z","shell.execute_reply":"2023-02-02T12:58:25.294352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Create Model**","metadata":{}},{"cell_type":"code","source":"# Inputs\ninput_layer = Input(shape= imgs.shape[-3:])\n\n# Encoder\np1, c1 = EncoderBlock(32, 0.1, name=\"Encoder1\")(input_layer)\np2, c2 = EncoderBlock(64, 0.1, name=\"Encoder2\")(p1)\np3, c3 = EncoderBlock(128, 0.2, name=\"Encoder3\")(p2)\np4, c4 = EncoderBlock(256, 0.2, name=\"Encoder4\")(p3)\n\n# Encoding\nencoding = EncoderBlock(512, 0.3, pooling=False, name=\"Encoding\")(p4)\n\n# Attention + Decoder\na1 = AttentionGate(256, bn=True, name=\"Attention1\")([encoding, c4])\nd1 = DecoderBlock(256, 0.2, name=\"Decoder1\")([encoding, a1])\n\na2 = AttentionGate(128, bn=True, name=\"Attention2\")([d1, c3])\nd2 = DecoderBlock(128, 0.2, name=\"Decoder2\")([d1, a2])\n\na3 = AttentionGate(64, bn=True, name=\"Attention3\")([d2, c2])\nd3 = DecoderBlock(64, 0.1, name=\"Decoder3\")([d2, a3])\n\na4 = AttentionGate(32, bn=True, name=\"Attention4\")([d3, c1])\nd4 = DecoderBlock(32,0.1, name=\"Decoder4\")([d3, a4])\n\n# Output \noutput_layer = Conv2D(1, kernel_size=1, activation='sigmoid', padding='same')(d4)\n\n# Model\nmodel = Model(inputs= [input_layer], outputs= [output_layer])\n\n# Compile\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-02-02T12:58:25.296502Z","iopub.execute_input":"2023-02-02T12:58:25.297469Z","iopub.status.idle":"2023-02-02T12:58:26.006748Z","shell.execute_reply.started":"2023-02-02T12:58:25.297431Z","shell.execute_reply":"2023-02-02T12:58:26.005666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 40     # set batch size for training\nepochs = 100         # number of all epochs in training\nask_epoch = 5\t\t    # number of epochs to run before asking if you want to halt training\n\ncallbacks = [MyCallback(model= model, epochs= epochs, ask_epoch= ask_epoch )]","metadata":{"execution":{"iopub.status.busy":"2023-02-02T12:58:26.010942Z","iopub.execute_input":"2023-02-02T12:58:26.011829Z","iopub.status.idle":"2023-02-02T12:58:26.141516Z","shell.execute_reply.started":"2023-02-02T12:58:26.011788Z","shell.execute_reply":"2023-02-02T12:58:26.1398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Train Model**","metadata":{}},{"cell_type":"code","source":"# Config Training\nSPE = len(imgs)//batch_size\n\n# Training\nhistory = model.fit(\n    imgs, msks,\n    validation_split=0.2,\n    epochs=epochs,\n    verbose=1,\n    steps_per_epoch=SPE,\n    batch_size=batch_size\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-02T12:58:26.143606Z","iopub.execute_input":"2023-02-02T12:58:26.144272Z","iopub.status.idle":"2023-02-02T13:04:23.006403Z","shell.execute_reply.started":"2023-02-02T12:58:26.144234Z","shell.execute_reply":"2023-02-02T13:04:23.00532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_training(history)","metadata":{"execution":{"iopub.status.busy":"2023-02-02T13:04:23.008496Z","iopub.execute_input":"2023-02-02T13:04:23.008852Z","iopub.status.idle":"2023-02-02T13:04:23.539143Z","shell.execute_reply.started":"2023-02-02T13:04:23.00882Z","shell.execute_reply":"2023-02-02T13:04:23.536586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Evaluation**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,25))\nn=0\nfor i in range(1,(5*3)+1):\n    plt.subplot(5,3,i)\n    if n==0:\n        id = np.random.randint(len(imgs))\n        image = imgs[id]\n        mask = msks[id]\n        pred_mask = model.predict(image[np.newaxis,...])\n\n        plt.title(\"Original Mask\")\n        show_mask(image, mask)\n        n+=1\n    elif n==1:\n        plt.title(\"Predicted Mask\")\n        show_mask(image, pred_mask)\n        n+=1\n    elif n==2:\n        pred_mask = (pred_mask>0.5).astype('float')\n        plt.title(\"Processed Mask\")\n        show_mask(image, pred_mask)\n        n=0\nplt.tight_layout()\nplt.show()","metadata":{"id":"fvjqCPIMW2XG","outputId":"070d77c1-5f7a-4261-f74f-9b70484f58fc","execution":{"iopub.status.busy":"2023-02-02T13:04:23.540835Z","iopub.execute_input":"2023-02-02T13:04:23.541433Z","iopub.status.idle":"2023-02-02T13:04:27.369203Z","shell.execute_reply.started":"2023-02-02T13:04:23.541396Z","shell.execute_reply":"2023-02-02T13:04:27.368018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Thank You..\n## If you found it a good notebook, pleas upvote it..","metadata":{}}]}