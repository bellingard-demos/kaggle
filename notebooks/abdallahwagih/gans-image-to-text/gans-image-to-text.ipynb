{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **Import Needed Libraries**","metadata":{}},{"cell_type":"code","source":"import cv2\nimport torch\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer","metadata":{"id":"SeT-a9Byby1n","execution":{"iopub.status.busy":"2023-11-03T18:47:43.620628Z","iopub.execute_input":"2023-11-03T18:47:43.6209Z","iopub.status.idle":"2023-11-03T18:47:49.589096Z","shell.execute_reply.started":"2023-11-03T18:47:43.620867Z","shell.execute_reply":"2023-11-03T18:47:49.5883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Load Model**","metadata":{}},{"cell_type":"code","source":"# Get Model\nmodel = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n# Get Image Feature Extractor\nfeature_extractor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n# Get Tokenizer Model\ntokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n\n# Apply model on GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"id":"Gh2jscQnot8g","outputId":"fe64ca40-7f91-4cd4-8967-5c00bb0ce857","_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-11-03T18:47:49.590061Z","iopub.execute_input":"2023-11-03T18:47:49.59031Z","iopub.status.idle":"2023-11-03T18:47:58.472202Z","shell.execute_reply.started":"2023-11-03T18:47:49.590287Z","shell.execute_reply":"2023-11-03T18:47:58.471245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The maximum length the generated tokens can have\nmax_length = 16\n#  Number of beams for beam search\nnum_beams = 4\n# Generation Config\ngen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}","metadata":{"id":"hm6EtiPoot27","execution":{"iopub.status.busy":"2023-11-03T18:47:58.473652Z","iopub.execute_input":"2023-11-03T18:47:58.474298Z","iopub.status.idle":"2023-11-03T18:47:58.47944Z","shell.execute_reply.started":"2023-11-03T18:47:58.47426Z","shell.execute_reply":"2023-11-03T18:47:58.478412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Prediction Function**","metadata":{}},{"cell_type":"code","source":"def predict_step(image_paths):\n    images = []\n    for image_path in image_paths:\n        img = Image.open(image_path)\n        if img.mode != \"RGB\":\n            img = img.convert(mode=\"RGB\")\n\n        images.append(img)\n\n    # Feature Extractor\n    pixel_values = feature_extractor(images=images, return_tensors=\"pt\").pixel_values\n    pixel_values = pixel_values.to(device)\n\n    # Apply model\n    output_ids = model.generate(pixel_values, **gen_kwargs)\n\n    # Get text tokens\n    preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n    preds = [pred.strip() for pred in preds]\n    return preds","metadata":{"id":"FQ298E4gotu-","execution":{"iopub.status.busy":"2023-11-03T18:47:58.482079Z","iopub.execute_input":"2023-11-03T18:47:58.482376Z","iopub.status.idle":"2023-11-03T18:47:58.490911Z","shell.execute_reply.started":"2023-11-03T18:47:58.482347Z","shell.execute_reply":"2023-11-03T18:47:58.489872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Test Model**","metadata":{}},{"cell_type":"code","source":"image = '/kaggle/input/test-image/image.jpg'\nimg = cv2.imread(image)\nplt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:47:58.492329Z","iopub.execute_input":"2023-11-03T18:47:58.493006Z","iopub.status.idle":"2023-11-03T18:47:58.932214Z","shell.execute_reply.started":"2023-11-03T18:47:58.492969Z","shell.execute_reply":"2023-11-03T18:47:58.930555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_step([image])","metadata":{"id":"u5ajgeTho6G_","outputId":"e6f62aa7-b0b7-4eff-947f-85a3a84e87ce","execution":{"iopub.status.busy":"2023-11-03T18:48:09.437138Z","iopub.execute_input":"2023-11-03T18:48:09.437809Z","iopub.status.idle":"2023-11-03T18:48:09.733353Z","shell.execute_reply.started":"2023-11-03T18:48:09.437774Z","shell.execute_reply":"2023-11-03T18:48:09.732439Z"},"trusted":true},"execution_count":null,"outputs":[]}]}