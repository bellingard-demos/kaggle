{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Object Detection Using Custom YOLOv8 Object Detector","metadata":{}},{"cell_type":"markdown","source":"Import needed modules","metadata":{}},{"cell_type":"code","source":"import os\nimport glob as glob\nimport matplotlib.pyplot as plt\nimport cv2\nimport requests\nimport random\nimport numpy as np\n\nnp.random.seed(42)","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2023-08-06T20:36:48.615153Z","iopub.execute_input":"2023-08-06T20:36:48.615431Z","iopub.status.idle":"2023-08-06T20:36:48.787171Z","shell.execute_reply.started":"2023-08-06T20:36:48.615408Z","shell.execute_reply":"2023-08-06T20:36:48.786093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The dataset is structured in the following manner:\n\n```\n├── data.yaml\n├── test\n│   ├── images\n│   └── labels\n├── train\n│   ├── images\n│   └── labels\n└── valid\n    ├── images\n    └── labels\n\n```\n\n### The Dataset YAML File\n\nThe dataset YAML (`data.yaml`) file containing the path to the training and validation images and labels is already provided. This file will also contain the class names from the dataset.\n\nThe dataset contains number of classes: [ ... ]\n\nThe following block shows the contents of the `data.yaml` file.\n\n```yaml\npath: ../Cars Detection\ntrain: train/images\nval: valid/images\n\nnc: 5\nnames: ['Ambulance', 'Bus', 'Car', 'Motorcycle', 'Truck']\n```","metadata":{}},{"cell_type":"markdown","source":"----------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"# Create needed functions","metadata":{}},{"cell_type":"markdown","source":"### Function to convert bounding boxes in YOLO format to xmin, ymin, xmax, ymax.","metadata":{}},{"cell_type":"code","source":"'''The current annotations in the text files are in normalized `[x_center, y_center, width, height]` format.\n    Let's write a function that will convert it back to `[x_min, y_min, x_max, y_max]` format to check these annotations'''\n\ndef yolo2bbox(bboxes):\n    xmin, ymin = bboxes[0]-bboxes[2] / 2, bboxes[1] - bboxes[3] / 2\n    xmax, ymax = bboxes[0]+bboxes[2] / 2, bboxes[1] + bboxes[3] / 2\n    return xmin, ymin, xmax, ymax","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2023-08-06T20:36:48.788931Z","iopub.execute_input":"2023-08-06T20:36:48.789277Z","iopub.status.idle":"2023-08-06T20:36:48.797491Z","shell.execute_reply.started":"2023-08-06T20:36:48.789252Z","shell.execute_reply":"2023-08-06T20:36:48.796113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = ['Ambulance', 'Bus', 'Car', 'Motorcycle', 'Truck']\ncolors = np.random.uniform(0, 255, size=(len(class_names), 3))\n\ndef plot_box(image, bboxes, labels):\n    # Need the image height and width to denormalize\n    # the bounding box coordinates\n    h, w, _ = image.shape\n    for box_num, box in enumerate(bboxes):\n        x1, y1, x2, y2 = yolo2bbox(box)\n        \n        # denormalize the coordinates\n        xmin = int(x1 * w)\n        ymin = int(y1 * h)\n        xmax = int(x2 * w)\n        ymax = int(y2 * h)\n        width = xmax - xmin\n        height = ymax - ymin\n        \n        class_name = class_names[int(labels[box_num])]\n        \n        cv2.rectangle(\n            image, \n            (xmin, ymin), (xmax, ymax),\n            color=colors[class_names.index(class_name)],\n            thickness=2\n        ) \n\n        font_scale = min(1,max(3,int(w/500)))\n        font_thickness = min(2, max(10,int(w/50)))\n        \n        p1, p2 = (int(xmin), int(ymin)), (int(xmax), int(ymax))\n        \n        # Text width and height\n        tw, th = cv2.getTextSize(class_name, 0, fontScale=font_scale, thickness=font_thickness)[0]\n        p2 = p1[0] + tw, p1[1] + -th - 10\n        cv2.rectangle(\n            image, \n            p1, p2,\n            color=colors[class_names.index(class_name)],\n            thickness=-1,\n        )\n        cv2.putText(\n            image, \n            class_name,\n            (xmin+1, ymin-10),\n            cv2.FONT_HERSHEY_SIMPLEX,\n            font_scale,\n            (255, 255, 255),\n            font_thickness\n        )\n    return image","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2023-08-06T20:37:07.972706Z","iopub.execute_input":"2023-08-06T20:37:07.973076Z","iopub.status.idle":"2023-08-06T20:37:07.987028Z","shell.execute_reply.started":"2023-08-06T20:37:07.973044Z","shell.execute_reply":"2023-08-06T20:37:07.985578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Function to plot images with the bounding boxes.","metadata":{}},{"cell_type":"code","source":"# Function to plot images with the bounding boxes.\ndef plot(image_paths, label_paths, num_samples):\n    all_training_images = glob.glob(image_paths)\n    all_training_labels = glob.glob(label_paths)\n    all_training_images.sort()\n    all_training_labels.sort()\n    \n    num_images = len(all_training_images)\n    \n    plt.figure(figsize=(15, 12))\n    for i in range(num_samples):\n        j = random.randint(0,num_images-1)\n        image = cv2.imread(all_training_images[j])\n        with open(all_training_labels[j], 'r') as f:\n            bboxes = []\n            labels = []\n            label_lines = f.readlines()\n            for label_line in label_lines:\n                label = label_line[0]\n                bbox_string = label_line[2:]\n                x_c, y_c, w, h = bbox_string.split(' ')\n                x_c = float(x_c)\n                y_c = float(y_c)\n                w = float(w)\n                h = float(h)\n                bboxes.append([x_c, y_c, w, h])\n                labels.append(label)\n        result_image = plot_box(image, bboxes, labels)\n        plt.subplot(2, 2, i+1)\n        plt.imshow(result_image[:, :, ::-1])\n        plt.axis('off')\n    plt.subplots_adjust(wspace=0)\n    plt.tight_layout()\n    plt.show()","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2023-08-06T20:37:14.815902Z","iopub.execute_input":"2023-08-06T20:37:14.816289Z","iopub.status.idle":"2023-08-06T20:37:14.826947Z","shell.execute_reply.started":"2023-08-06T20:37:14.816259Z","shell.execute_reply":"2023-08-06T20:37:14.825894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualize images sample.","metadata":{}},{"cell_type":"code","source":"plot(image_paths='/kaggle/input/cars-detection/Cars Detection/train/images/*',\n    label_paths='/kaggle/input/cars-detection/Cars Detection/train/labels/*',\n    num_samples=4,\n)","metadata":{"vscode":{"languageId":"plaintext"},"execution":{"iopub.status.busy":"2023-08-06T20:37:20.081969Z","iopub.execute_input":"2023-08-06T20:37:20.08234Z","iopub.status.idle":"2023-08-06T20:37:21.518721Z","shell.execute_reply.started":"2023-08-06T20:37:20.082311Z","shell.execute_reply":"2023-08-06T20:37:21.517647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# YOLOV8","metadata":{}},{"cell_type":"code","source":"!pip install ultralytics","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-08-06T20:37:29.816937Z","iopub.execute_input":"2023-08-06T20:37:29.817334Z","iopub.status.idle":"2023-08-06T20:37:43.253994Z","shell.execute_reply.started":"2023-08-06T20:37:29.817303Z","shell.execute_reply":"2023-08-06T20:37:43.252803Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nfrom ultralytics import YOLO\n\n\n# Load a model\nmodel = YOLO(\"yolov8n.yaml\")  # build a new model from scratch","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-08-06T20:37:43.256574Z","iopub.execute_input":"2023-08-06T20:37:43.25695Z","iopub.status.idle":"2023-08-06T20:37:47.9913Z","shell.execute_reply.started":"2023-08-06T20:37:43.256912Z","shell.execute_reply":"2023-08-06T20:37:47.990309Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use the model\nresults = model.train(data=\"/kaggle/input/yamlfile/data.yaml\", epochs=100)  # train the model","metadata":{"execution":{"iopub.status.busy":"2023-08-06T20:37:54.892813Z","iopub.execute_input":"2023-08-06T20:37:54.893461Z","iopub.status.idle":"2023-08-06T21:16:42.534201Z","shell.execute_reply.started":"2023-08-06T20:37:54.893424Z","shell.execute_reply":"2023-08-06T21:16:42.532628Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Evaluation","metadata":{}},{"cell_type":"code","source":"metrics = model.val()","metadata":{"execution":{"iopub.status.busy":"2023-08-06T21:16:50.30271Z","iopub.execute_input":"2023-08-06T21:16:50.303121Z","iopub.status.idle":"2023-08-06T21:17:00.895823Z","shell.execute_reply.started":"2023-08-06T21:16:50.303072Z","shell.execute_reply":"2023-08-06T21:17:00.893816Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predict Images","metadata":{}},{"cell_type":"code","source":"!yolo task=detect mode=predict model=/kaggle/working/runs/detect/train/weights/best.pt source='/kaggle/input/cars-detection/Cars Detection/test/images/3429c6851095a4c3_jpg.rf.2921b5c17bda3bda8b69e0f8b5e44894.jpg'","metadata":{"execution":{"iopub.status.busy":"2023-08-06T21:22:10.96839Z","iopub.execute_input":"2023-08-06T21:22:10.968781Z","iopub.status.idle":"2023-08-06T21:22:27.981128Z","shell.execute_reply.started":"2023-08-06T21:22:10.968749Z","shell.execute_reply":"2023-08-06T21:22:27.979377Z"},"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path = '/kaggle/working/runs/detect/predict2/3429c6851095a4c3_jpg.rf.2921b5c17bda3bda8b69e0f8b5e44894.jpg'\nimg = plt.imread(img_path)\n\nplt.figure(figsize=(10, 8))\nplt.imshow(img)\nplt.axis(False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-06T21:24:44.03325Z","iopub.execute_input":"2023-08-06T21:24:44.033631Z","iopub.status.idle":"2023-08-06T21:24:44.438382Z","shell.execute_reply.started":"2023-08-06T21:24:44.033594Z","shell.execute_reply":"2023-08-06T21:24:44.437337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predict Videos","metadata":{}},{"cell_type":"code","source":"!yolo task=detect mode=predict model=/kaggle/working/runs/detect/train/weights/best.pt source='/kaggle/input/testvideo/Input.mp4'","metadata":{"execution":{"iopub.status.busy":"2023-08-06T21:25:54.652108Z","iopub.execute_input":"2023-08-06T21:25:54.652506Z","iopub.status.idle":"2023-08-06T21:26:26.332438Z","shell.execute_reply.started":"2023-08-06T21:25:54.652477Z","shell.execute_reply":"2023-08-06T21:26:26.330966Z"},"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define helper function to display videos","metadata":{}},{"cell_type":"code","source":"import io \nfrom IPython.display import HTML\nfrom base64 import b64encode\ndef show_video(file_name, width=640):\n  # show resulting deepsort video\n  mp4 = open(file_name,'rb').read()\n  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n  return HTML(\"\"\"\n  <video width=\"{0}\" controls>\n        <source src=\"{1}\" type=\"video/mp4\">\n  </video>\n  \"\"\".format(width, data_url))","metadata":{"execution":{"iopub.status.busy":"2023-08-06T21:27:05.529676Z","iopub.execute_input":"2023-08-06T21:27:05.530091Z","iopub.status.idle":"2023-08-06T21:27:05.540752Z","shell.execute_reply.started":"2023-08-06T21:27:05.530055Z","shell.execute_reply":"2023-08-06T21:27:05.538644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Convert resulting video from avi to mp4 file format","metadata":{}},{"cell_type":"code","source":"# Convert avi to mp4\n!ffmpeg -y -loglevel panic -i /kaggle/working/runs/detect/predict3/Input.avi output.mp4\n\n# output object tracking video\npath_output = \"output.mp4\"\nshow_video(path_output, width=960)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T21:29:13.227276Z","iopub.execute_input":"2023-08-06T21:29:13.227666Z","iopub.status.idle":"2023-08-06T21:29:54.381106Z","shell.execute_reply.started":"2023-08-06T21:29:13.227631Z","shell.execute_reply":"2023-08-06T21:29:54.377247Z"},"trusted":true},"execution_count":null,"outputs":[]}]}