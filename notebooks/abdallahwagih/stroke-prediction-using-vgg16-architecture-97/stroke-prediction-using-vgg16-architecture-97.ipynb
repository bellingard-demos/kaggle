{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import system libs \nimport os\nimport itertools\n\n# import data handling tools \nimport cv2\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\n# import Deep learning Libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adamax\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# Ignore Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint ('modules loaded')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-23T22:55:29.84774Z","iopub.execute_input":"2022-12-23T22:55:29.848024Z","iopub.status.idle":"2022-12-23T22:55:29.855399Z","shell.execute_reply.started":"2022-12-23T22:55:29.847994Z","shell.execute_reply":"2022-12-23T22:55:29.854644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def define_paths(dir):\n    filepaths = []\n    labels = []\n    folds = os.listdir(dir)\n    for fold in folds:\n        foldpath = os.path.join(dir, fold)\n        filelist = os.listdir(foldpath)\n        for file in filelist:\n            fpath = os.path.join(foldpath, file)\n            filepaths.append(fpath)\n            labels.append(fold)\n    return filepaths, labels\n\ndef define_df(files, classes):\n    Fseries = pd.Series(files, name= 'filepaths')\n    Lseries = pd.Series(classes, name='labels')\n    return pd.concat([Fseries, Lseries], axis= 1)\n\ndef create_df(tr_dir, val_dir, ts_dir):\n    # train dataframe \n    files, classes = define_paths(tr_dir)\n    train_df = define_df(files, classes)\n\n    # validation dataframe\n    files, classes = define_paths(val_dir)\n    valid_df = define_df(files, classes)\n\n    # test dataframe\n    files, classes = define_paths(ts_dir)\n    test_df = define_df(files, classes)\n    return train_df, valid_df, test_df","metadata":{"execution":{"iopub.status.busy":"2022-12-23T22:36:30.045448Z","iopub.execute_input":"2022-12-23T22:36:30.045712Z","iopub.status.idle":"2022-12-23T22:36:30.053536Z","shell.execute_reply.started":"2022-12-23T22:36:30.045678Z","shell.execute_reply":"2022-12-23T22:36:30.052505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_gens(train_df, valid_df, test_df, batch_size):\n    img_size = (224, 224)\n    channels = 3\n    img_shape = (img_size[0], img_size[1], channels)\n    ts_length = len(test_df)\n    test_batch_size = test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n    test_steps = ts_length // test_batch_size\n    def scalar(img):\n        return img\n    tr_gen = ImageDataGenerator(preprocessing_function= scalar, horizontal_flip= True)\n    ts_gen = ImageDataGenerator(preprocessing_function= scalar)\n    train_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n                                        color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n    valid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n                                        color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n    test_gen = ts_gen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n                                        color_mode= 'rgb', shuffle= False, batch_size= test_batch_size)\n    return train_gen, valid_gen, test_gen","metadata":{"execution":{"iopub.status.busy":"2022-12-23T22:36:30.05499Z","iopub.execute_input":"2022-12-23T22:36:30.055274Z","iopub.status.idle":"2022-12-23T22:36:30.074097Z","shell.execute_reply.started":"2022-12-23T22:36:30.055234Z","shell.execute_reply":"2022-12-23T22:36:30.073365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_images(gen):\n    g_dict = gen.class_indices        # defines dictionary {'class': index}\n    classes = list(g_dict.keys())     # defines list of dictionary's kays (classes)\n    images, labels = next(gen)        # get a batch size samples from the generator\n    plt.figure(figsize= (20, 20))\n    length = len(labels)              # length of batch size\n    sample = min(length, 25)          # check if sample less than 25 images\n    for i in range(sample):\n        plt.subplot(5, 5, i + 1)\n        image = images[i] / 255       # scales data to range (0 - 255)\n        plt.imshow(image)\n        index = np.argmax(labels[i])  # get image index\n        class_name = classes[index]   # get class of image\n        plt.title(class_name, color= 'blue', fontsize= 12)\n        plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-23T22:36:30.077566Z","iopub.execute_input":"2022-12-23T22:36:30.07869Z","iopub.status.idle":"2022-12-23T22:36:30.100007Z","shell.execute_reply.started":"2022-12-23T22:36:30.078629Z","shell.execute_reply":"2022-12-23T22:36:30.09917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_training(hist):\n    tr_acc = hist.history['accuracy']\n    tr_loss = hist.history['loss']\n    val_acc = hist.history['val_accuracy']\n    val_loss = hist.history['val_loss']\n    index_loss = np.argmin(val_loss)     # get number of epoch with the lowest validation loss\n    val_lowest = val_loss[index_loss]    # get the loss value of epoch with the lowest validation loss\n    index_acc = np.argmax(val_acc)       # get number of epoch with the highest validation accuracy\n    acc_highest = val_acc[index_acc]     # get the loss value of epoch with the highest validation accuracy\n\n    plt.figure(figsize= (20, 8))\n    plt.style.use('fivethirtyeight')\n    Epochs = [i+1 for i in range(len(tr_acc))]\t       # create x-axis by epochs count\n    loss_label = f'best epoch= {str(index_loss + 1)}'  # label of lowest val_loss\n    acc_label = f'best epoch= {str(index_acc + 1)}'    # label of highest val_accuracy\n    plt.subplot(1, 2, 1)\n    plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n    plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n    plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.subplot(1, 2, 2)\n    plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n    plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n    plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.tight_layout\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-23T22:36:30.103304Z","iopub.execute_input":"2022-12-23T22:36:30.103924Z","iopub.status.idle":"2022-12-23T22:36:30.126465Z","shell.execute_reply.started":"2022-12-23T22:36:30.10388Z","shell.execute_reply":"2022-12-23T22:36:30.125419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes, normalize= False, title= 'Confusion Matrix', cmap= plt.cm.Blues):\n\tplt.figure(figsize= (10, 10))\n\tplt.imshow(cm, interpolation= 'nearest', cmap= cmap)\n\tplt.title(title)\n\tplt.colorbar()\n\ttick_marks = np.arange(len(classes))\n\tplt.xticks(tick_marks, classes, rotation= 45)\n\tplt.yticks(tick_marks, classes)\n\tif normalize:\n\t\tcm = cm.astype('float') / cm.sum(axis= 1)[:, np.newaxis]\n\t\tprint('Normalized Confusion Matrix')\n\telse:\n\t\tprint('Confusion Matrix, Without Normalization')\n\tprint(cm)\n\tthresh = cm.max() / 2.\n\tfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n\t\tplt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n\tplt.tight_layout()\n\tplt.ylabel('True Label')\n\tplt.xlabel('Predicted Label')","metadata":{"execution":{"iopub.status.busy":"2022-12-23T22:36:30.127662Z","iopub.execute_input":"2022-12-23T22:36:30.128287Z","iopub.status.idle":"2022-12-23T22:36:30.139539Z","shell.execute_reply.started":"2022-12-23T22:36:30.128253Z","shell.execute_reply":"2022-12-23T22:36:30.138641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get Dataframes\ntrain_dir = r'../input/brain-stroke-prediction-ct-scan-image-dataset/Brain_Stroke_CT-SCAN_image/Train'\nvalid_dir = r'../input/brain-stroke-prediction-ct-scan-image-dataset/Brain_Stroke_CT-SCAN_image/Test'\ntest_dir = r'../input/brain-stroke-prediction-ct-scan-image-dataset/Brain_Stroke_CT-SCAN_image/Validation'\ntrain_df, valid_df, test_df = create_df(train_dir, valid_dir, test_dir)\n\n# Get Generators\nbatch_size = 40\ntrain_gen, valid_gen, test_gen = create_gens(train_df, valid_df, test_df, batch_size)\n\nshow_images(train_gen)","metadata":{"execution":{"iopub.status.busy":"2022-12-23T22:36:30.142804Z","iopub.execute_input":"2022-12-23T22:36:30.144108Z","iopub.status.idle":"2022-12-23T22:36:33.23821Z","shell.execute_reply.started":"2022-12-23T22:36:30.144069Z","shell.execute_reply":"2022-12-23T22:36:33.237508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create Model Structure\nimg_size = (224, 224)\nchannels = 3\nimg_shape = (img_size[0], img_size[1], channels)\nclass_count = len(list(train_gen.class_indices.keys()))\n\nmodel = Sequential([\n    Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\", input_shape= img_shape),\n    Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n    MaxPooling2D((2, 2)),\n    \n    Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n    Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n    MaxPooling2D((2, 2)),\n    \n    Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n    Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n    Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n    MaxPooling2D((2, 2)),\n    \n    Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n    Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n    Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n    MaxPooling2D((2, 2)),\n    \n    Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n    Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n    Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n    MaxPooling2D((2, 2)),\n    \n    Flatten(),\n    Dense(256,activation = \"relu\"),\n    Dense(64,activation = \"relu\"),\n    Dense(class_count, activation = \"softmax\")\n])\n\nmodel.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-12-23T22:38:50.05023Z","iopub.execute_input":"2022-12-23T22:38:50.051111Z","iopub.status.idle":"2022-12-23T22:38:52.368455Z","shell.execute_reply.started":"2022-12-23T22:38:50.051074Z","shell.execute_reply":"2022-12-23T22:38:52.367747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x= train_gen, epochs= 40, verbose= 1, validation_data= valid_gen, \n                    validation_steps= None, shuffle= False, initial_epoch= 0)","metadata":{"execution":{"iopub.status.busy":"2022-12-23T22:39:09.528618Z","iopub.execute_input":"2022-12-23T22:39:09.528889Z","iopub.status.idle":"2022-12-23T22:48:53.639049Z","shell.execute_reply.started":"2022-12-23T22:39:09.528861Z","shell.execute_reply":"2022-12-23T22:48:53.638251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_training(history)","metadata":{"execution":{"iopub.status.busy":"2022-12-23T22:49:49.235621Z","iopub.execute_input":"2022-12-23T22:49:49.235928Z","iopub.status.idle":"2022-12-23T22:49:49.79475Z","shell.execute_reply.started":"2022-12-23T22:49:49.235893Z","shell.execute_reply":"2022-12-23T22:49:49.794051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ts_length = len(test_df)\ntest_batch_size = test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\ntest_steps = ts_length // test_batch_size\ntrain_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\nvalid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\ntest_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n\nprint(\"Train Loss: \", train_score[0])\nprint(\"Train Accuracy: \", train_score[1])\nprint('-' * 20)\nprint(\"Validation Loss: \", valid_score[0])\nprint(\"Validation Accuracy: \", valid_score[1])\nprint('-' * 20)\nprint(\"Test Loss: \", test_score[0])\nprint(\"Test Accuracy: \", test_score[1])","metadata":{"execution":{"iopub.status.busy":"2022-12-23T22:51:58.179043Z","iopub.execute_input":"2022-12-23T22:51:58.179825Z","iopub.status.idle":"2022-12-23T22:52:06.09489Z","shell.execute_reply.started":"2022-12-23T22:51:58.179787Z","shell.execute_reply":"2022-12-23T22:52:06.093737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict_generator(test_gen)\ny_pred = np.argmax(preds, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-12-23T22:53:02.533288Z","iopub.execute_input":"2022-12-23T22:53:02.533576Z","iopub.status.idle":"2022-12-23T22:53:03.587472Z","shell.execute_reply.started":"2022-12-23T22:53:02.533546Z","shell.execute_reply":"2022-12-23T22:53:03.58666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_names = ['Normal', 'Stroke']\n\n# Confusion matrix\ncm = confusion_matrix(test_gen.classes, y_pred)\nplot_confusion_matrix(cm= cm, classes= target_names, title = 'Confusion Matrix')\n\n# Classification report\nprint(classification_report(test_gen.classes, y_pred, target_names= target_names))","metadata":{"execution":{"iopub.status.busy":"2022-12-23T22:55:35.415686Z","iopub.execute_input":"2022-12-23T22:55:35.415979Z","iopub.status.idle":"2022-12-23T22:55:35.986854Z","shell.execute_reply.started":"2022-12-23T22:55:35.415947Z","shell.execute_reply":"2022-12-23T22:55:35.986183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}