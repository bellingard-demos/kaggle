{"cells":[{"metadata":{},"cell_type":"markdown","source":"We create models to predict and compare them based on F1 score to find the most suitable model:\n\n1. Random Forest\n\n2. Logistic Regression\n\n3. Adaboost\n\n4. Gradient boosting"},{"metadata":{},"cell_type":"markdown","source":"Random Forest Classifier"},{"metadata":{},"cell_type":"markdown","source":"Import libraries and read training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndf_train=pd.read_csv('../input/predictive-equipment-failures/equip_failures_training_set.csv')\n\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the description and information from training data to analyze it"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check for null values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Replace na values with 0 "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train=df_train.replace('na',0)\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read and clean test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test=pd.read_csv('../input/predictive-equipment-failures/equip_failures_test_set.csv')\n\ndf_test=df_test.replace('na',0)\n\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train the model with 70% training data and 30% testing data and predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nmodel = RandomForestClassifier(n_estimators=200,bootstrap=True,max_features='sqrt')\nX = df_train.iloc[:, 2:].values\ny = df_train.iloc[:, 1].values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\ny_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get the F1 score of the predicted values"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred,digits=4))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logistic Regression"},{"metadata":{},"cell_type":"markdown","source":"Get the location of .csv file from local machine and store it in a variable called train"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/predictive-equipment-failures/equip_failures_training_set.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"type() method returns class type of the argument(object) passed as parameter"},{"metadata":{"trusted":true},"cell_type":"code","source":"type(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pandas head() method is used to return top n (5 by default) rows of a data frame or series"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below functions are used to obtain more information about the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.count())\nprint(train.info())\nprint(train.describe())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data in dataset is checked for any missing or wrong values"},{"metadata":{"trusted":true},"cell_type":"code","source":"descriptive_stats = train.describe()\ndescriptive_stats","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All 'na' values are replaced with 0 and stored in a new variable "},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train = train.replace({'na':0})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The training dataset is split for validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(new_train.drop('target',axis=1), new_train['target'], test_size=0.10, \nrandom_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logistic Regression is performed on the data and the accuracy is predicted"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\n\ny_pred = logreg.predict(X_test)\n\nprint('Accuracy of logistic regression classifier on test set: {:.4f}'.format(logreg.score(X_test, y_test)))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"F1-score, precision, recall and support is calculated by importing a library function"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Adaboost"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.read_csv('../input/predictive-equipment-failures/equip_failures_training_set.csv')\ny = pd.read_csv('../input/predictive-equipment-failures/equip_failures_test_set.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training Predictors and Response Values/Replacing na string to 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import resample\n#separate training\nnew_X = X.replace('na',0)\nnew_y = y.replace('na',0)\ndf_major = new_X[new_X.target==0]\ndf_minor = new_X[new_X.target==1]\n\ndf_major_downsampled = resample(df_major, replace=False,n_samples=1000, random_state=123)\n\n#combine minor class with downsampled majority class\ndf_downsampled = pd.concat([df_major_downsampled, df_minor])\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_downsampled\n#print(df_downsampled.target.value_counts())\n#X_train = df_downsampled.iloc[:,2:]\n#y_train = df_downsampled.iloc[:,1]\n#X_test = new_y.iloc[:,1:]\n\nX_train, X_test, y_train, y_test = train_test_split(df_downsampled.drop('target',axis = 1), df_downsampled['target'], test_size = 0.20, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Implementing AdaBoost with Decision Tree with Number of trees 250 and maximum depth of 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nclassifier = AdaBoostClassifier(\n    DecisionTreeClassifier(max_depth=1),\n    n_estimators=250\n)\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Classification report displaying F-score"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Gradient Boosting\n\nImplementing GradientBoosting with Number of trees 300 and maximum depth of 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ngb = GradientBoostingClassifier(n_estimators=300, max_depth = 1)\ngb.fit(X_train, y_train)\npredictions = gb.predict(X_test)\n\nprint(\"Classification Report\")\nprint(classification_report(y_test, y_pred,digits=4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"Finally, we decide and use random forest because of the highest f1 score "},{"metadata":{},"cell_type":"markdown","source":"Write the final dataframe to csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = model.predict(df_test.iloc[:, 1:].values)\n\ndf_final=pd.DataFrame(df_test['id'])\ndf_final['target']=prediction\n\ndf_final.to_csv('final.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}