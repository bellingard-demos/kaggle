{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-27T13:21:47.477566Z","iopub.execute_input":"2022-07-27T13:21:47.478763Z","iopub.status.idle":"2022-07-27T13:21:47.509317Z","shell.execute_reply.started":"2022-07-27T13:21:47.478645Z","shell.execute_reply":"2022-07-27T13:21:47.508423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# Import libraries and read the data","metadata":{}},{"cell_type":"code","source":"import random\nimport pandas as pd \nimport numpy as np\nimport math as ma\nimport tensorflow as tf\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix,recall_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\n\n#Read the Data\ndf=pd.read_csv('../input/titanic/train.csv')\ndf_test=pd.read_csv('../input/titanic/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-27T13:21:47.510992Z","iopub.execute_input":"2022-07-27T13:21:47.511633Z","iopub.status.idle":"2022-07-27T13:21:57.602903Z","shell.execute_reply.started":"2022-07-27T13:21:47.511599Z","shell.execute_reply":"2022-07-27T13:21:57.601694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Do some analysis on data\n * show the number of null samples in train , test datasets.\n * we will notice here that columns (age,cabin) have a great number of null values so we will    drop it.\n ","metadata":{}},{"cell_type":"code","source":"print(df.isna().sum())\nprint(df_test.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2022-07-27T13:21:57.604382Z","iopub.execute_input":"2022-07-27T13:21:57.605513Z","iopub.status.idle":"2022-07-27T13:21:57.616872Z","shell.execute_reply.started":"2022-07-27T13:21:57.60546Z","shell.execute_reply":"2022-07-27T13:21:57.615643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Describe the data and show some statstics.","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-27T13:21:57.619976Z","iopub.execute_input":"2022-07-27T13:21:57.620439Z","iopub.status.idle":"2022-07-27T13:21:57.708833Z","shell.execute_reply.started":"2022-07-27T13:21:57.620396Z","shell.execute_reply":"2022-07-27T13:21:57.707663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Do some preprocessing on train and test datasets\n* drop unimportant columns.\n* fill null values in embarked column with random choice.\n* divide my data to trainning features and label.\n* scale my data for easy trainig and convergence.","metadata":{}},{"cell_type":"code","source":"#preprocessing on main df \ndf.drop(columns=['Cabin','Age', 'PassengerId','Name','Ticket','Parch','SibSp'],inplace=True)\n\n\n\ndf[\"Embarked\"].fillna( random.choice(df[df['Embarked'] != np.nan][\"Embarked\"]), inplace =True)\n\n\nfrom sklearn.preprocessing import LabelEncoder\ndf=df.apply(LabelEncoder().fit_transform)\n\n\n#divide data to training and label\nX=df.iloc[ : ,1:].values\ny=df.iloc[:,0]\n\n\n\nsc = StandardScaler()\nX = sc.fit_transform(X)\nprint(X)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-27T13:21:57.710238Z","iopub.execute_input":"2022-07-27T13:21:57.711054Z","iopub.status.idle":"2022-07-27T13:21:57.726719Z","shell.execute_reply.started":"2022-07-27T13:21:57.711023Z","shell.execute_reply":"2022-07-27T13:21:57.725338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Repeat the same steps on testset.","metadata":{}},{"cell_type":"code","source":"#preprocessing on test df \n\ndf_test.drop(columns=['Cabin','Age', 'PassengerId','Name','Ticket','Parch','SibSp'],inplace=True)\n\n\ndf_test['Fare'].fillna((df_test['Fare'].mean()), inplace=True)\ndf_test[\"Embarked\"].fillna( random.choice(df_test[df_test['Embarked'] != np.nan][\"Embarked\"]), inplace =True)\n\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-27T13:21:57.728014Z","iopub.execute_input":"2022-07-27T13:21:57.729118Z","iopub.status.idle":"2022-07-27T13:21:57.738537Z","shell.execute_reply.started":"2022-07-27T13:21:57.729084Z","shell.execute_reply":"2022-07-27T13:21:57.737314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\n\nfrom sklearn.preprocessing import LabelEncoder\ndf_test=df_test.apply(LabelEncoder().fit_transform)\n\n# Feature Scaling\nsc = StandardScaler()\ndf_test = sc.fit_transform(df_test)\nprint(df_test)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-27T13:21:57.73972Z","iopub.execute_input":"2022-07-27T13:21:57.740505Z","iopub.status.idle":"2022-07-27T13:21:57.764783Z","shell.execute_reply.started":"2022-07-27T13:21:57.740469Z","shell.execute_reply":"2022-07-27T13:21:57.763809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Do some visulization on tra","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nsns.pairplot(df)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-27T13:21:57.766069Z","iopub.execute_input":"2022-07-27T13:21:57.766929Z","iopub.status.idle":"2022-07-27T13:22:02.581374Z","shell.execute_reply.started":"2022-07-27T13:21:57.76689Z","shell.execute_reply":"2022-07-27T13:22:02.580165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"boxplot = df.boxplot(column=[ 'Fare']) ","metadata":{"execution":{"iopub.status.busy":"2022-07-27T13:22:02.583284Z","iopub.execute_input":"2022-07-27T13:22:02.584073Z","iopub.status.idle":"2022-07-27T13:22:02.753747Z","shell.execute_reply.started":"2022-07-27T13:22:02.584026Z","shell.execute_reply":"2022-07-27T13:22:02.752605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2022-07-27T13:22:02.757895Z","iopub.execute_input":"2022-07-27T13:22:02.758288Z","iopub.status.idle":"2022-07-27T13:22:02.766073Z","shell.execute_reply.started":"2022-07-27T13:22:02.758252Z","shell.execute_reply":"2022-07-27T13:22:02.764815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\n\nbagging = BaggingClassifier(AdaBoostClassifier(n_estimators=3),max_samples=0.5, max_features=0.5)\nbagging.fit(X_train,y_train)\nad_y_pred = bagging.predict(X_test)\n# Making the Confusion Matrix\ncm = confusion_matrix(y_test, ad_y_pred)\nprint(cm)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-27T13:33:12.803968Z","iopub.execute_input":"2022-07-27T13:33:12.804652Z","iopub.status.idle":"2022-07-27T13:33:12.889547Z","shell.execute_reply.started":"2022-07-27T13:33:12.804597Z","shell.execute_reply":"2022-07-27T13:33:12.88791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nRF=RandomForestClassifier()\nRF.fit(X_train,y_train)\nrf_y_pred=RF.predict(X_test)\ncm = confusion_matrix(y_test, rf_y_pred)\nprint(cm)","metadata":{"execution":{"iopub.status.busy":"2022-07-27T13:33:17.786928Z","iopub.execute_input":"2022-07-27T13:33:17.787366Z","iopub.status.idle":"2022-07-27T13:33:17.992638Z","shell.execute_reply.started":"2022-07-27T13:33:17.787327Z","shell.execute_reply":"2022-07-27T13:33:17.991399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_test=(rf_y_pred+ad_y_pred)/2\nfinal_test = (final_test > 0.5)\nfinal_test\n\ncm = confusion_matrix(y_test, final_test)\nprint(cm)","metadata":{"execution":{"iopub.status.busy":"2022-07-27T13:33:23.507445Z","iopub.execute_input":"2022-07-27T13:33:23.507854Z","iopub.status.idle":"2022-07-27T13:33:23.516815Z","shell.execute_reply.started":"2022-07-27T13:33:23.507821Z","shell.execute_reply":"2022-07-27T13:33:23.515542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score,recall_score\nrecall=recall_score(y_pred,final_test)\nprecision=precision_score(y_pred,final_test)\nprint('recall is '+ str(recall))\nprint('precision is '+ str(precision))\n","metadata":{"execution":{"iopub.status.busy":"2022-07-27T13:33:46.412867Z","iopub.execute_input":"2022-07-27T13:33:46.413271Z","iopub.status.idle":"2022-07-27T13:33:46.42439Z","shell.execute_reply.started":"2022-07-27T13:33:46.413238Z","shell.execute_reply":"2022-07-27T13:33:46.423127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test","metadata":{"execution":{"iopub.status.busy":"2022-07-27T13:22:02.9698Z","iopub.execute_input":"2022-07-27T13:22:02.970632Z","iopub.status.idle":"2022-07-27T13:22:02.979149Z","shell.execute_reply.started":"2022-07-27T13:22:02.970556Z","shell.execute_reply":"2022-07-27T13:22:02.978232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final=(bagging.predict(df_test)+RF.predict(df_test))/2\nfinal=np.where(final >.5 , final , 0)\nfinal","metadata":{"execution":{"iopub.status.busy":"2022-07-27T13:49:32.022383Z","iopub.execute_input":"2022-07-27T13:49:32.022777Z","iopub.status.idle":"2022-07-27T13:49:32.065015Z","shell.execute_reply.started":"2022-07-27T13:49:32.022747Z","shell.execute_reply":"2022-07-27T13:49:32.06378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(r\"../input/titanic/test.csv\")\nsubmission = pd.DataFrame({\n    \"PassengerId\" : test[\"PassengerId\"],\n    \"Survived\" : final\n})\nsubmission.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-07-27T13:49:36.424796Z","iopub.execute_input":"2022-07-27T13:49:36.425223Z","iopub.status.idle":"2022-07-27T13:49:36.44402Z","shell.execute_reply.started":"2022-07-27T13:49:36.425181Z","shell.execute_reply":"2022-07-27T13:49:36.442995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index = False)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-27T13:49:41.017122Z","iopub.execute_input":"2022-07-27T13:49:41.017547Z","iopub.status.idle":"2022-07-27T13:49:41.024253Z","shell.execute_reply.started":"2022-07-27T13:49:41.017512Z","shell.execute_reply":"2022-07-27T13:49:41.023166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}