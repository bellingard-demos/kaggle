{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":310927,"sourceType":"datasetVersion","datasetId":130081}],"dockerImageVersionId":28450,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PAINTER IDENTIFICATION USING DEEP LEARNING\n\n<img src=\"https://www.vincentvangogh.org/images/paintings/self-portrait-with-straw-hat.jpg\" width=\"400px\" height=\"200px\"/>","metadata":{}},{"cell_type":"markdown","source":"# High-level approach to solution:\n## Data processing:\n* There are paintings of 50 artists in the dataset. However only 11 artists have more than 200 paintings available here.\n* To reduce computation and better training, I decided to use the paintings of these 11 artists only.\n* Since this is an imbalanced datset (Van Gogh has 877 paintings whereas Marc Chagall has only 239), `class_weight` is important. Infact, it improved model performance substantially.\n* I used Keras `ImageDataGenerator` for data augmentation. This is not a traditional object detection problem, hence the augmentation approch should be used very carefully.\n* I couldn't experiment in detail, but so far `zoom_range` worked well. \n\n## Modelling and Training:\n* Use convolutional neural network based approach, with a pre-defined architecture as baseline.\n* I tried multiple architectures, however `ResNet50` worked well so far.\n* Pretrained weights on `imagenet` helped the model train better.\n* The objective is to identify artist and not objects in the images. So the model should understand the style of the image better rather than the final output. Hence, training of shallow layers is more important than the deeper layers.\n* The above statement is based on my understanding of the problem and experiments and observations.\n* Training the model for more iterations might improve the performance, at the cost of computation resource.\n\n## Predictions:\n* <b>The final model could identify the artists with an approximate accuracy of 99% on training set and 85% on cross-validation set.</b> ","metadata":{}},{"cell_type":"markdown","source":"## Read data","metadata":{}},{"cell_type":"code","source":"# Import libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport json\nimport os\nfrom tqdm import tqdm, tqdm_notebook\nimport random\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.applications import *\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras.initializers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom numpy.random import seed\nseed(1)\nfrom tensorflow import set_random_seed\nset_random_seed(1)","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-04T15:46:35.502803Z","iopub.execute_input":"2023-12-04T15:46:35.503174Z","iopub.status.idle":"2023-12-04T15:46:37.019284Z","shell.execute_reply.started":"2023-12-04T15:46:35.503098Z","shell.execute_reply":"2023-12-04T15:46:37.018333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(os.listdir(\"../input\"))","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-04T15:46:45.744846Z","iopub.execute_input":"2023-12-04T15:46:45.745165Z","iopub.status.idle":"2023-12-04T15:46:45.759543Z","shell.execute_reply.started":"2023-12-04T15:46:45.745105Z","shell.execute_reply":"2023-12-04T15:46:45.758713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"artists = pd.read_csv('../input/artists.csv')\nartists.shape","metadata":{"_uuid":"e3e1d6335355d0c30e566597c839a5b3ece5d94a","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-04T15:46:48.912419Z","iopub.execute_input":"2023-12-04T15:46:48.912771Z","iopub.status.idle":"2023-12-04T15:46:48.946523Z","shell.execute_reply.started":"2023-12-04T15:46:48.912711Z","shell.execute_reply":"2023-12-04T15:46:48.945773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Processing","metadata":{}},{"cell_type":"code","source":"# Sort artists by number of paintings\nartists = artists.sort_values(by=['paintings'], ascending=False)\n\n# Create a dataframe with artists having more than 200 paintings\nartists_top = artists[artists['paintings'] >= 200].reset_index()\nartists_top = artists_top[['name', 'paintings']]\n#artists_top['class_weight'] = max(artists_top.paintings)/artists_top.paintings\nartists_top['class_weight'] = artists_top.paintings.sum() / (artists_top.shape[0] * artists_top.paintings)\nartists_top","metadata":{"_uuid":"6b074e12d27e326be77c2e045b0f0c1f9ae26822","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-04T15:46:52.897116Z","iopub.execute_input":"2023-12-04T15:46:52.897457Z","iopub.status.idle":"2023-12-04T15:46:53.084746Z","shell.execute_reply.started":"2023-12-04T15:46:52.897401Z","shell.execute_reply":"2023-12-04T15:46:53.083804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set class weights - assign higher weights to underrepresented classes\nclass_weights = artists_top['class_weight'].to_dict()\nclass_weights","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-04T15:47:18.919365Z","iopub.execute_input":"2023-12-04T15:47:18.919714Z","iopub.status.idle":"2023-12-04T15:47:18.92674Z","shell.execute_reply.started":"2023-12-04T15:47:18.919665Z","shell.execute_reply":"2023-12-04T15:47:18.925526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# There is some problem recognizing 'Albrecht_Dürer' (don't know why, worth exploring)\n# So I'll update this string as directory name to df's\nupdated_name = \"Albrecht_Dürer\".replace(\"_\", \" \")\nartists_top.iloc[4, 0] = updated_name","metadata":{"_uuid":"1572ec7821c7520ff56c95a9fddb29e7b3211d72","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-04T15:47:36.763076Z","iopub.execute_input":"2023-12-04T15:47:36.763428Z","iopub.status.idle":"2023-12-04T15:47:36.768912Z","shell.execute_reply.started":"2023-12-04T15:47:36.763372Z","shell.execute_reply":"2023-12-04T15:47:36.767924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Explore images of top artists\nimages_dir = '../input/images/images'\nartists_dirs = os.listdir(images_dir)\nartists_top_name = artists_top['name'].str.replace(' ', '_').values\n\n# See if all directories exist\nfor name in artists_top_name:\n    if os.path.exists(os.path.join(images_dir, name)):\n        print(\"Found -->\", os.path.join(images_dir, name))\n    else:\n        print(\"Did not find -->\", os.path.join(images_dir, name))","metadata":{"_uuid":"56cb379b335dd98d09038a6a2a0a4c674cf85435","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-04T15:47:38.941447Z","iopub.execute_input":"2023-12-04T15:47:38.94175Z","iopub.status.idle":"2023-12-04T15:47:38.99426Z","shell.execute_reply.started":"2023-12-04T15:47:38.941707Z","shell.execute_reply":"2023-12-04T15:47:38.993497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Print few random paintings","metadata":{}},{"cell_type":"code","source":"# Print few random paintings\nn = 5\nfig, axes = plt.subplots(1, n, figsize=(20,10))\n\nfor i in range(n):\n    random_artist = random.choice(artists_top_name)\n    random_image = random.choice(os.listdir(os.path.join(images_dir, random_artist)))\n    random_image_file = os.path.join(images_dir, random_artist, random_image)\n    image = plt.imread(random_image_file)\n    axes[i].imshow(image)\n    axes[i].set_title(\"Artist: \" + random_artist.replace('_', ' '))\n    axes[i].axis('off')\n\nplt.show()","metadata":{"_uuid":"6e9a979dcc6c7d65e76bb9ad7cbe0af46210835c","_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-04T15:47:42.030379Z","iopub.execute_input":"2023-12-04T15:47:42.03068Z","iopub.status.idle":"2023-12-04T15:47:44.278884Z","shell.execute_reply.started":"2023-12-04T15:47:42.030636Z","shell.execute_reply":"2023-12-04T15:47:44.277863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Augmentation","metadata":{"_uuid":"698097f73386d42c88605975b1c0624c5b810828"}},{"cell_type":"code","source":"# Augment data\nbatch_size = 16\ntrain_input_shape = (224, 224, 3)\nn_classes = artists_top.shape[0]\n\ntrain_datagen = ImageDataGenerator(validation_split=0.2,\n                                   rescale=1./255.,\n                                   #rotation_range=45,\n                                   #width_shift_range=0.5,\n                                   #height_shift_range=0.5,\n                                   shear_range=5,\n                                   #zoom_range=0.7,\n                                   horizontal_flip=True,\n                                   vertical_flip=True,\n                                  )\n\ntrain_generator = train_datagen.flow_from_directory(directory=images_dir,\n                                                    class_mode='categorical',\n                                                    target_size=train_input_shape[0:2],\n                                                    batch_size=batch_size,\n                                                    subset=\"training\",\n                                                    shuffle=True,\n                                                    classes=artists_top_name.tolist()\n                                                   )\n\nvalid_generator = train_datagen.flow_from_directory(directory=images_dir,\n                                                    class_mode='categorical',\n                                                    target_size=train_input_shape[0:2],\n                                                    batch_size=batch_size,\n                                                    subset=\"validation\",\n                                                    shuffle=True,\n                                                    classes=artists_top_name.tolist()\n                                                   )\n\nSTEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\nprint(\"Total number of batches =\", STEP_SIZE_TRAIN, \"and\", STEP_SIZE_VALID)","metadata":{"_uuid":"c0dc10a5ef7bf1c7b4d4d219f0b5e5fe168c1200","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-04T15:47:54.599769Z","iopub.execute_input":"2023-12-04T15:47:54.600097Z","iopub.status.idle":"2023-12-04T15:47:55.661895Z","shell.execute_reply.started":"2023-12-04T15:47:54.600042Z","shell.execute_reply":"2023-12-04T15:47:55.661082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Print a random paintings and it's random augmented version","metadata":{}},{"cell_type":"code","source":"# Print a random paintings and it's random augmented version\nfig, axes = plt.subplots(1, 2, figsize=(20,10))\n\nrandom_artist = random.choice(artists_top_name)\nrandom_image = random.choice(os.listdir(os.path.join(images_dir, random_artist)))\nrandom_image_file = os.path.join(images_dir, random_artist, random_image)\n\n# Original image\nimage = plt.imread(random_image_file)\naxes[0].imshow(image)\naxes[0].set_title(\"An original Image of \" + random_artist.replace('_', ' '))\naxes[0].axis('off')\n\n# Transformed image\naug_image = train_datagen.random_transform(image)\naxes[1].imshow(aug_image)\naxes[1].set_title(\"A transformed Image of \" + random_artist.replace('_', ' '))\naxes[1].axis('off')\n\nplt.show()","metadata":{"_uuid":"215b02db59c36acee06eb148ab061cb30b1d4a04","_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-04T15:48:02.410665Z","iopub.execute_input":"2023-12-04T15:48:02.410987Z","iopub.status.idle":"2023-12-04T15:48:04.103702Z","shell.execute_reply.started":"2023-12-04T15:48:02.41094Z","shell.execute_reply":"2023-12-04T15:48:04.102772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build Model","metadata":{"_uuid":"6c14ac6b596ba8035bfb6aa23080f9e792ab16a7"}},{"cell_type":"code","source":"# Load pre-trained model\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=train_input_shape)\n\nfor layer in base_model.layers:\n    layer.trainable = True","metadata":{"_uuid":"217cffe30d19bbcd8ad2db5f088efeca507b9105","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-04T15:48:21.525558Z","iopub.execute_input":"2023-12-04T15:48:21.525853Z","iopub.status.idle":"2023-12-04T15:48:32.4Z","shell.execute_reply.started":"2023-12-04T15:48:21.52581Z","shell.execute_reply":"2023-12-04T15:48:32.399117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add layers at the end\nX = base_model.output\nX = Flatten()(X)\n\nX = Dense(512, kernel_initializer='he_uniform')(X)\n#X = Dropout(0.5)(X)\nX = BatchNormalization()(X)\nX = Activation('relu')(X)\n\nX = Dense(16, kernel_initializer='he_uniform')(X)\n#X = Dropout(0.5)(X)\nX = BatchNormalization()(X)\nX = Activation('relu')(X)\n\noutput = Dense(n_classes, activation='softmax')(X)\n\nmodel = Model(inputs=base_model.input, outputs=output)","metadata":{"_uuid":"7418f1308e35730185e027cdba1aa76ca825a922","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-04T15:48:53.278978Z","iopub.execute_input":"2023-12-04T15:48:53.279344Z","iopub.status.idle":"2023-12-04T15:48:53.532195Z","shell.execute_reply.started":"2023-12-04T15:48:53.279298Z","shell.execute_reply":"2023-12-04T15:48:53.531424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = Adam(lr=0.0001)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizer, \n              metrics=['accuracy'])","metadata":{"_uuid":"53800d997e58514ae857fb0286c5ea89eed90eef","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-04T15:48:55.805336Z","iopub.execute_input":"2023-12-04T15:48:55.805655Z","iopub.status.idle":"2023-12-04T15:48:55.921854Z","shell.execute_reply.started":"2023-12-04T15:48:55.805611Z","shell.execute_reply":"2023-12-04T15:48:55.920919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_epoch = 10\n\nearly_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=1, \n                           mode='auto', restore_best_weights=True)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, \n                              verbose=1, mode='auto')","metadata":{"_uuid":"78ed50a86faf5e1621dd6f8273dbfb6803c74a44","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-04T15:49:00.324428Z","iopub.execute_input":"2023-12-04T15:49:00.324797Z","iopub.status.idle":"2023-12-04T15:49:00.330633Z","shell.execute_reply.started":"2023-12-04T15:49:00.324737Z","shell.execute_reply":"2023-12-04T15:49:00.32957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model - all layers\nhistory1 = model.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN,\n                              validation_data=valid_generator, validation_steps=STEP_SIZE_VALID,\n                              epochs=n_epoch,\n                              shuffle=True,\n                              verbose=1,\n                              callbacks=[reduce_lr],\n                              use_multiprocessing=True,\n                              workers=16,\n                              class_weight=class_weights\n                             )","metadata":{"_uuid":"51535a7919f1972b1ea8eb45019380e8cd31074d","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-04T15:49:03.041479Z","iopub.execute_input":"2023-12-04T15:49:03.041808Z","iopub.status.idle":"2023-12-04T16:03:20.94752Z","shell.execute_reply.started":"2023-12-04T15:49:03.041757Z","shell.execute_reply":"2023-12-04T16:03:20.946584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Freeze core ResNet layers and train again \nfor layer in model.layers:\n    layer.trainable = False\n\nfor layer in model.layers[:50]:\n    layer.trainable = True\n\noptimizer = Adam(lr=0.0001)\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizer, \n              metrics=['accuracy'])\n\nn_epoch = 50\nhistory2 = model.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN,\n                              validation_data=valid_generator, validation_steps=STEP_SIZE_VALID,\n                              epochs=n_epoch,\n                              shuffle=True,\n                              verbose=1,\n                              callbacks=[reduce_lr, early_stop],\n                              use_multiprocessing=True,\n                              workers=16,\n                              class_weight=class_weights\n                             )","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-04T16:12:54.725635Z","iopub.execute_input":"2023-12-04T16:12:54.725963Z","iopub.status.idle":"2023-12-04T17:19:23.985337Z","shell.execute_reply.started":"2023-12-04T16:12:54.725917Z","shell.execute_reply":"2023-12-04T17:19:23.984269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training graph","metadata":{}},{"cell_type":"code","source":"# Merge history1 and history2\nhistory = {}\nhistory['loss'] = history1.history['loss'] + history2.history['loss']\nhistory['acc'] = history1.history['acc'] + history2.history['acc']\nhistory['val_loss'] = history1.history['val_loss'] + history2.history['val_loss']\nhistory['val_acc'] = history1.history['val_acc'] + history2.history['val_acc']\nhistory['lr'] = history1.history['lr'] + history2.history['lr']","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-04T17:19:37.581722Z","iopub.execute_input":"2023-12-04T17:19:37.582036Z","iopub.status.idle":"2023-12-04T17:19:37.590215Z","shell.execute_reply.started":"2023-12-04T17:19:37.581991Z","shell.execute_reply":"2023-12-04T17:19:37.58917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the training graph\ndef plot_training(history):\n    acc = history['acc']\n    val_acc = history['val_acc']\n    loss = history['loss']\n    val_loss = history['val_loss']\n    epochs = range(len(acc))\n\n    fig, axes = plt.subplots(1, 2, figsize=(15,5))\n    \n    axes[0].plot(epochs, acc, 'r-', label='Training Accuracy')\n    axes[0].plot(epochs, val_acc, 'b--', label='Validation Accuracy')\n    axes[0].set_title('Training and Validation Accuracy')\n    axes[0].legend(loc='best')\n\n    axes[1].plot(epochs, loss, 'r-', label='Training Loss')\n    axes[1].plot(epochs, val_loss, 'b--', label='Validation Loss')\n    axes[1].set_title('Training and Validation Loss')\n    axes[1].legend(loc='best')\n    \n    plt.show()\n    \nplot_training(history)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-04T17:19:41.161748Z","iopub.execute_input":"2023-12-04T17:19:41.162087Z","iopub.status.idle":"2023-12-04T17:19:41.677381Z","shell.execute_reply.started":"2023-12-04T17:19:41.162027Z","shell.execute_reply":"2023-12-04T17:19:41.676286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate performance","metadata":{}},{"cell_type":"code","source":"# Prediction accuracy on train data\nscore = model.evaluate_generator(train_generator, verbose=1)\nprint(\"Prediction accuracy on train data =\", score[1])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-04T17:19:46.722365Z","iopub.execute_input":"2023-12-04T17:19:46.722663Z","iopub.status.idle":"2023-12-04T17:21:22.271055Z","shell.execute_reply.started":"2023-12-04T17:19:46.722622Z","shell.execute_reply":"2023-12-04T17:21:22.270163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prediction accuracy on CV data\nscore = model.evaluate_generator(valid_generator, verbose=1)\nprint(\"Prediction accuracy on CV data =\", score[1])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-04T17:22:25.417046Z","iopub.execute_input":"2023-12-04T17:22:25.417418Z","iopub.status.idle":"2023-12-04T17:22:49.362711Z","shell.execute_reply.started":"2023-12-04T17:22:25.417357Z","shell.execute_reply":"2023-12-04T17:22:49.361691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Confusion Matrix. Look at the style of the artists which the model thinks are almost similar. ","metadata":{}},{"cell_type":"code","source":"# Classification report and confusion matrix\nfrom sklearn.metrics import *\nimport seaborn as sns\n\ntick_labels = artists_top_name.tolist()\n\ndef showClassficationReport_Generator(model, valid_generator, STEP_SIZE_VALID):\n    # Loop on each generator batch and predict\n    y_pred, y_true = [], []\n    for i in range(STEP_SIZE_VALID):\n        (X,y) = next(valid_generator)\n        y_pred.append(model.predict(X))\n        y_true.append(y)\n    \n    # Create a flat list for y_true and y_pred\n    y_pred = [subresult for result in y_pred for subresult in result]\n    y_true = [subresult for result in y_true for subresult in result]\n    \n    # Update Truth vector based on argmax\n    y_true = np.argmax(y_true, axis=1)\n    y_true = np.asarray(y_true).ravel()\n    \n    # Update Prediction vector based on argmax\n    y_pred = np.argmax(y_pred, axis=1)\n    y_pred = np.asarray(y_pred).ravel()\n    \n    # Confusion Matrix\n    fig, ax = plt.subplots(figsize=(10,10))\n    conf_matrix = confusion_matrix(y_true, y_pred, labels=np.arange(n_classes))\n    conf_matrix = conf_matrix/np.sum(conf_matrix, axis=1)\n    sns.heatmap(conf_matrix, annot=True, fmt=\".2f\", square=True, cbar=False, \n                cmap=plt.cm.jet, xticklabels=tick_labels, yticklabels=tick_labels,\n                ax=ax)\n    ax.set_ylabel('Actual')\n    ax.set_xlabel('Predicted')\n    ax.set_title('Confusion Matrix')\n    plt.show()\n    \n    print('Classification Report:')\n    print(classification_report(y_true, y_pred, labels=np.arange(n_classes), target_names=artists_top_name.tolist()))\n\nshowClassficationReport_Generator(model, valid_generator, STEP_SIZE_VALID)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-04T17:22:58.038305Z","iopub.execute_input":"2023-12-04T17:22:58.038628Z","iopub.status.idle":"2023-12-04T17:23:38.858712Z","shell.execute_reply.started":"2023-12-04T17:22:58.038582Z","shell.execute_reply":"2023-12-04T17:23:38.857821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate performance by predicting on random images from dataset","metadata":{}},{"cell_type":"code","source":"# Prediction\nfrom keras.preprocessing import *\n\nn = 5\nfig, axes = plt.subplots(1, n, figsize=(25,10))\n\nfor i in range(n):\n    random_artist = random.choice(artists_top_name)\n    random_image = random.choice(os.listdir(os.path.join(images_dir, random_artist)))\n    random_image_file = os.path.join(images_dir, random_artist, random_image)\n\n    # Original image\n\n    test_image = image.load_img(random_image_file, target_size=(train_input_shape[0:2]))\n\n    # Predict artist\n    test_image = image.img_to_array(test_image)\n    test_image /= 255.\n    test_image = np.expand_dims(test_image, axis=0)\n\n    prediction = model.predict(test_image)\n    prediction_probability = np.amax(prediction)\n    prediction_idx = np.argmax(prediction)\n\n    labels = train_generator.class_indices\n    labels = dict((v,k) for k,v in labels.items())\n\n    #print(\"Actual artist =\", random_artist.replace('_', ' '))\n    #print(\"Predicted artist =\", labels[prediction_idx].replace('_', ' '))\n    #print(\"Prediction probability =\", prediction_probability*100, \"%\")\n\n    title = \"Actual artist = {}\\nPredicted artist = {}\\nPrediction probability = {:.2f} %\" \\\n                .format(random_artist.replace('_', ' '), labels[prediction_idx].replace('_', ' '),\n                        prediction_probability*100)\n\n    # Print image\n    axes[i].imshow(plt.imread(random_image_file))\n    axes[i].set_title(title)\n    axes[i].axis('off')\n\nplt.show()","metadata":{"_uuid":"fcd185d451d3b9f2484b58ace18a5466524c2ab4","_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-04T17:24:46.422269Z","iopub.execute_input":"2023-12-04T17:24:46.422639Z","iopub.status.idle":"2023-12-04T17:24:47.87557Z","shell.execute_reply.started":"2023-12-04T17:24:46.422575Z","shell.execute_reply":"2023-12-04T17:24:47.874678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Replace the variable `url` with an image of one of the 11 artists above and run this cell.","metadata":{}},{"cell_type":"code","source":"# Predict from web - this is an image of Titian.\n# Replace 'url' with any image of one of the 11 artists above and run this cell.\nurl = 'https://www.gpsmycity.com/img/gd/2081.jpg'\n\nimport imageio\nimport cv2\n\nweb_image = imageio.imread(url)\nweb_image = cv2.resize(web_image, dsize=train_input_shape[0:2], )\nweb_image = image.img_to_array(web_image)\nweb_image /= 255.\nweb_image = np.expand_dims(web_image, axis=0)\n\n\nprediction = model.predict(web_image)\nprediction_probability = np.amax(prediction)\nprediction_idx = np.argmax(prediction)\n\nprint(\"Predicted artist =\", labels[prediction_idx].replace('_', ' '))\nprint(\"Prediction probability =\", prediction_probability*100, \"%\")\n\nplt.imshow(imageio.imread(url))\nplt.axis('off')\nplt.show()","metadata":{"_uuid":"c4f0217bee7b62f835645372f4107c803d7ede2b","_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]}]}