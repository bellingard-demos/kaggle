{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning and Data Analysis on Covid-19 dataset (India).\n\n![corona](https://c.files.bbci.co.uk/14A35/production/_115033548_gettyimages-1226314512.jpg)\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport geopandas as gpd\nimport missingno\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading the dataset."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/covid19-in-india/covid_19_india.csv\",index_col=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **We will be analyzing the data of Covid-19 spread over the Indian states. The data ranges from 01-January-2020 to 26-November-2020.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.iloc[:8835]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Exploring the missing values in the dataset using missingno package and info of the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"missingno.matrix(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking duplicated values in the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now we are looking for unique timestamps given in the dataset, further we will merge the ***date*** and the ***time*** columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Time'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.rename(columns={\"Date\" : \"Datetime\"},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Convert the Datetime column to dtype of datetime64[ns]"},{"metadata":{"trusted":true},"cell_type":"code","source":"def timeconv(df):\n    alltime = []\n    for i in df[\"Time\"]:\n        mer = i[-2:]\n        \n        time = i[:-3]\n        if len(time) ==4:\n            time = \"0\"+time\n        if mer == \"PM\":\n            time = str(12+int(time[:2]))+time[-3:]\n        alltime.append(time)\n    assert df.shape[0] == len(alltime)\n    df['Datetime'] = df['Datetime'] +\" \"+ pd.Series(alltime)\n            \n       \n        \n        \ntimeconv(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop([\"Time\"],axis=1,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Datetime\"] = pd.to_datetime(data[\"Datetime\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"timest = data.iloc[-2][\"Datetime\"]\ndata.iloc[-1,0] = timest","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We discovered that there are several missing values marked as \"-\", let's take a look."},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l = data.groupby('State/UnionTerritory')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.replace(\"-\",np.nan)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missingno.matrix(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Whoa! most of the values are missing in 3rd and 4th column, we better drop those columns for now."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(list(data.columns)[2:4],axis=1,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Moving forward, let's take a look at distinct state names for further analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"data['State/UnionTerritory'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Keeping it simple, we will drop the rows with state name ending with \"***\" as it is seems to be rows with incomplete values."},{"metadata":{"trusted":true},"cell_type":"code","source":"def drop_star(df):\n    for i in df['State/UnionTerritory'].iteritems():\n        if i[1][-3:] == \"***\":\n            df.drop(i[0],inplace=True)\n        \ndrop_star(data)\ndata['State/UnionTerritory'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### There are still several typos in state names, we will deal with this manually."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(data[(data['State/UnionTerritory']=='Telangana')|(data['State/UnionTerritory']=='Daman & Diu')|(data['State/UnionTerritory']=='Dadar Nagar Haveli')].index,inplace=True)\ndata['State/UnionTerritory'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['State/UnionTerritory']=='Tripura']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extracting the latest insights from the data, we will later visualize the trends."},{"metadata":{"trusted":true},"cell_type":"code","source":"l = data.groupby('State/UnionTerritory')\ncurrent = l.last()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"current","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualization"},{"metadata":{},"cell_type":"markdown","source":"### Plotting a bar plot to show the spread of Covid-19 across the states in decreasing order."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig ,ax = plt.subplots(figsize= (12,8))\nfig.set_facecolor(\"white\")\ncurrent = current.sort_values(\"Confirmed\",ascending=False)\np = sns.barplot(ax=ax,x= current.index,y=current['Confirmed'])\np.set_xticklabels(labels = current.index,rotation=90)\n\np.set_yticklabels(labels=(p.get_yticks()*1).astype(int))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now let's look at the Cured/Death ratio of these states using pie plot."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(12,3, figsize=(16,30))\nfig.delaxes(axs[11,2])\nfig.set_facecolor(\"white\")\ndef plotpie(ax,cplot,data,state):\n    labels = ['Cured', 'Deaths','Ambiguous']\n    colors = ['green', 'red','gray']\n    amb = data.loc[state]['Confirmed'] - data.loc[state]['Cured']+data.loc[state]['Deaths']\n    size = [data.loc[state]['Cured'],data.loc[state]['Deaths'],amb]\n    x = cplot//3\n    y = cplot%3\n    ax[x,y].pie(size,labels=labels, colors=colors, startangle=0, autopct='%1.1f%%')\n    ax[x,y].set_title(state+'\\n'+\"Total cases : {}\".format(data.loc[state]['Confirmed']))\n    ax[x,y].axis('equal')\n\ncplot = 0\nfor i in sorted(list(current.index)):\n    if i in ['Cases being reassigned to states', 'Unassigned'] :\n        continue\n    plotpie(axs,cplot,current,i)\n    cplot+=1\nfig.tight_layout()\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Zooming to the span of 21 days lockdown from 25-March-2020. \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\nimport matplotlib.dates as mdates\nfig, axs = plt.subplots(18,2, figsize=(16,100))\nfig.set_facecolor(\"white\")\nfig.delaxes(axs[17,1])\n\ndef statewise_timeplot(ax,cplot,data,state):\n    toplot = data[data[\"State/UnionTerritory\"] == state]\n    x = cplot//2\n    y = cplot%2\n    sd = pd.to_datetime('2020-3-25') \n    td = datetime.timedelta(days=21)\n    ed = sd+td\n    #print(sd,ed)\n    \n    #toplot = toplot.set_index(\"Datetime\")\n    toplot = toplot.loc[(toplot[\"Datetime\"] > sd) & (toplot['Datetime']< ed)]\n    #print(toplot)\n    toplot = toplot.set_index(\"Datetime\")\n    sns.lineplot(data=toplot,x=toplot.index,y=toplot[\"Confirmed\"],ax= ax[x,y],label='Confirmed')\n    sns.lineplot(data=toplot,x=toplot.index,y=toplot[\"Cured\"],ax= ax[x,y],label=\"Cured\")\n    sns.lineplot(data=toplot,x=toplot.index,y=toplot[\"Deaths\"],ax= ax[x,y],label=\"Deaths\")\n    ax[x,y].set_title(state)\n    ax[x,y].set_xlim(pd.Timestamp('2020-3-25'),pd.Timestamp(\"2020-04-11\"))\n    ax[x,y].set_ylim(0,1000000)\n    ax[x,y].xaxis.set_major_formatter(mdates.DateFormatter(\"%m-%d\"))\n    ax[x,y].xaxis.set_minor_formatter(mdates.DateFormatter(\"%m-%d\"))\n    ax[x,y].tick_params(axis='x', rotation=45)\n    ax[x,y].legend()\n\n\n\ncplot = 0\nfor i in sorted(list(current.index)):\n    if i in ['Cases being reassigned to states', 'Unassigned'] :\n        continue\n    statewise_timeplot(axs,cplot,data,i)\n    cplot+=1\n    \nfig.tight_layout()\nplt.plot()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prepariing data for geoplot using geopandas. "},{"metadata":{"trusted":true},"cell_type":"code","source":"fp = \"/kaggle/input/india-states/Igismap/Indian_States.shp\"\nmap_df = gpd.read_file(fp)\ndisplay(map_df)\ncurrent\ncurrent.rename(index={\"Andaman and Nicobar Islands\":\"Andaman & Nicobar Island\",\"Delhi\":\"NCT of Delhi\",\"Arunachal Pradesh\":\"Arunanchal Pradesh\",\"Dadra and Nagar Haveli and Daman and Diu\":\"Dadara & Nagar Havelli\",\"Jammu and Kashmir\":\"Jammu & Kashmir\",\"Telengana\":\"Telangana\"},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"current.drop(['Cases being reassigned to states', 'Unassigned'], axis = 0).reset_index()\nmerged = map_df.merge(current, left_on = 'st_nm', right_on = 'State/UnionTerritory', how = 'left')\nmerged = merged[~merged['Datetime'].isna()]\nmerged.reset_index().drop('index', axis = 1)\nmerged\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Finally, here is the geoplot showing the Covid-19 spread across the Indian states with severity."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, figsize=(10, 10))\nax.axis('off')\nax.set_title('Covid-19 data', fontdict={'fontsize': '25', 'fontweight' : '10'})\n\nmerged.plot(column='Confirmed',cmap='YlOrRd', linewidth=0.8, ax=ax, edgecolor='0', legend=True,markersize=[39.739192, -104.990337])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}