{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Titanic Dataset : AdaBoost\n\n\n\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\n\n\n## VARIABLE DESCRIPTIONS\n\n- Pclass : Passenger Class  (1 = 1st; 2 = 2nd; 3 = 3rd)\n- Survival  :  Survival  (0 = No; 1 = Yes)\n- Name  : Name\n- Sex  : Sex\n- Age  : Age\n- SibSp :  Number of Siblings/Spouses Aboard\n- Parch  : Number of Parents/Children Aboard\n- Ticket :  Ticket Number\n- Fare  :  Passenger Fare (British pound)\n- Cabin  :  Cabin\n- Embarked  :  Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport missingno\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"white\")\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load DataSet\n\n> Take a look over some summaries."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/titanic/train.csv\",index_col = 0)\ndisplay(data.head())\ndisplay(data.info())\ndisplay(data.describe())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### First things first, let's look over the missing values and relation between them."},{"metadata":{"trusted":true},"cell_type":"code","source":"display(data.isnull().sum())\nmissingno.matrix(data)\nmissingno.heatmap(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Column \"Cabin\" contains massive Null values, so it's a good idea to drop that column."},{"metadata":{"trusted":true},"cell_type":"code","source":"org = data.copy()\ndata.drop(\"Cabin\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The colums \"SibSp\" and \"Parch\" refers to the number of Siblings/Spouses and Parents/Childrens respectively. So they must be in Discrete amount and column \"Embarked\" contains Nominal data."},{"metadata":{"trusted":true},"cell_type":"code","source":"display(data[\"Embarked\"].unique())\ndisplay(data[\"SibSp\"].unique())\ndata['Parch'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking if there are any duplicate samples."},{"metadata":{"trusted":true},"cell_type":"code","source":"display(data.duplicated().sum())\ndata[data.duplicated([\"Ticket\",\"Fare\"])].sort_values(\"Ticket\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### No duplicate values so far.\n### Column \"Embarked\" has only 2 missing values. So, we can impute them manually."},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data[\"Embarked\"].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(data[data[\"Ticket\"]==\"113572\"])\ndata[data['Fare']==80]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### As there are only 2 missing values in \"Embarked\" column. Simply impute them with mode of the column."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[data[\"Embarked\"].isna(),\"Embarked\"] =  data[\"Embarked\"].value_counts().index[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Calculating the survival rate."},{"metadata":{"trusted":true},"cell_type":"code","source":"survival_rate = data['Survived'].astype('int32').sum()/data.shape[0]\nsurvival_rate","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extremes of \"Age\" column(Should be between 0 - 110)."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data[\"Age\"].min(),data[\"Age\"].max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating a categorical column from \"Age\" column of analysis.\n\nThis is quite useful when you want to compare another continous variable against, it gives you better insights."},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"AgeGrp\"] = pd.cut(data[\"Age\"],bins=[0,18,55,100],labels=[\"Child\",\"Adult\",\"Senior\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fixing Nulls in \"Age\"column\n\n#### There are 177 of them, at this amount it's suggested to come up with a strategy to impute them."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = data.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Strategy to impute missing data in \"Age\" column:\n\n> Observe the \"Name\" column, if contains name with salutations:\n- Mr., Ms., Master, Miss.\n\n> They all specify to a specific age range, for example, \"Master\" coresponds to Male of age between 0-18.\n\n#### Now we can simply substitute Non-Null values from these salutations and can replace missing ones with mode(maximum frequency element) of substituted data."},{"metadata":{"trusted":true},"cell_type":"code","source":"def fillAge(sal):\n    \n    \n    mode = data[data[\"Name\"].map(lambda x : sal in x)][\"Age\"].value_counts().reset_index().sort_values([\"Age\",\"index\"],ascending = [False,False]).iloc[0,0]\n    \n    condition = (data[\"Name\"].map(lambda x : sal in x)) & (data[\"Age\"].isna())\n    \n    data.loc[condition,'Age'] = mode\n\nsalutation = [\"Master.\",\"Mrs.\",\"Mr.\",\"Miss.\"]\n\nfor i in salutation:\n    fillAge(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[data.Age.isna(),\"Age\"] = data.Age.mean()\ndisplay(data.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualisation"},{"metadata":{},"cell_type":"markdown","source":"### As we know the survival rate is around 38%, We might want to look hhow does other factors like Gender and Traveling Class effect the survival outcomes."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.facecolor':'white'})\nsns.catplot(x=\"Pclass\",col='Survived',hue=\"Sex\",data=data,kind=\"count\",aspect=0.9)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pretty straightforward, there is less chance of surviving if the passanger is male and belong to 3rd class, Womens and that's too of 1st class were given higher priority on lifeboat rescues.\n\n### Moreover if look at the distribution of the Passenger's age, We discovered:\n\n- Majority of the passengers were in the age range of 15-30.\n- Majority of 3rd Class passengers died.\n- Childs were of top priority too."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(\"Survived\",\"Age\",hue='Pclass',data=data,kind=\"swarm\",aspect=1.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We only have 2 continuous features : \"Age\" and \"Fare\", is there any correlation between them? Well, it's sounds like there might be, specially childs could have lower fare for their tickets."},{"metadata":{"trusted":true},"cell_type":"code","source":"display(np.corrcoef(data[\"Age\"],data[\"Fare\"]))\nunder18 = data[data[\"Age\"]<=18]\nnp.corrcoef(under18[\"Age\"],under18[\"Fare\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### On contrary, it appears that there is no linear or minor relation between these two variables. The graph says the same."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(\"Age\",'Fare',kind = \"reg\",joint_kws={\"line_kws\":{\"color\":\"black\"}},data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### As discussed above:\n\n> The colums \"SibSp\" and \"Parch\" refers to the number of Siblings/Spouses and Parents/Childrens respectively. So they must be in Discrete amount and column \"Embarked\" contains Nominal data.\n\n### PMF would be good option to get insights about their distribution.\n\n#### *Read more about PMF [here](https://en.wikipedia.org/wiki/Probability_mass_function).*"},{"metadata":{"trusted":true},"cell_type":"code","source":"def pmf(d):\n    x = d.value_counts().sort_index() / len(d)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,2,figsize = (10,5))\nparch_pmf = pmf(data[\"Parch\"])\nsns.barplot(parch_pmf.index,parch_pmf,ax=ax[0])\nax[0].set_ylim(0,1)\nsibsp_pmf = pmf(data[\"SibSp\"])\nsns.barplot(sibsp_pmf.index,sibsp_pmf,ax=ax[1])\nax[1].set_ylim(0,1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Looks like they are exponetially distributed. Next we will be looking for some other important insights like where are more people embarked for.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(\"Embarked\",data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Majority of the passengers were embarked for Southampton \n\n### Next, by plotting \"AgeGrp\"(The column we formed earlier) with \"Survived\" we sense a hint that child were given priority while rescuing."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(\"AgeGrp\",hue=\"Survived\",data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### \"Fare\" vs Count comparision of Destinations:\n\n### Important insights:\n1. Majority of the passengers were bound for Southampton.\n2. Fare were pretty high for Cherbourg.\n3. Womens were charged more than mens."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style(\"white\")\nfig, ax = plt.subplots(figsize=(8,6))\nax = sns.countplot(\"Embarked\",data=data,palette=[\"#69e0cb\"])\nax2 = ax.twinx()\n\nax3 = sns.pointplot(\"Embarked\",\"Fare\",data=data,hue=\"Sex\",capsize=0.05,ax= ax2)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### By looking at the value distribution of \"Age\" column it looks like they are normally distributed.\n\n### We can ensure that by plotting the CDF of the \"Age\" column over the actuall generated normal data with same mean and standard deviation. *Read more about CDF [here](https://en.wikipedia.org/wiki/Cumulative_distribution_function).*\n\n- ### Observation : Data seems to be bit skewed toward a mid point. "},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(1,2,figsize=(12,5))\ndef ecdf(ser):\n    xs = ser.sort_values(ascending=True)\n    ys = np.linspace(0,1,num=xs.shape[0])\n    xsn = np.random.normal(ser.mean(),ser.std(),ser.shape[0])\n    \n    ax[0].plot(xs,ys,marker='.',linestyle='none',ms=3)\n    ax[0].plot(sorted(xsn),ys,marker='.',linestyle='none',ms=1.5,c='gray')\n    sns.distplot(ser,ax=ax[1])\n    ax[1].get_yaxis().set_ticks([])\necdf(data[\"Age\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(\"SibSp\",\"Parch\",marker=\"+\",data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### How much of these factors really affects the survival chances?\n\n### To answer this, we can quickly look over the logistic curves of \"Age\" and \"Fare\" columns, putting \"Survived\" as a target."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(1,2,figsize = (18,6))\n\nsns.regplot(x=\"Fare\",y=\"Survived\",logistic = True,y_jitter=.04,data=data,ax=ax[0])\nsns.regplot(x=\"Age\",y=\"Survived\",logistic = True,y_jitter=.04,data=data,ax=ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Observations : \n- Plot 1 (\"Fare\") column: The curve is steep. Survival rate is pretty high for riches(i.e. higher class).\n\n- Plot 2 (\"Age\") column: Slight negetive curve. Gives hint about younger ones were rescued first.\n\n### Follow up: There are couple of high values in \"Fare\" column(Near 500 british pounds). What the curve will look like if we exclude those values?"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(x=\"Fare\",y=\"Survived\",logistic = True,y_jitter=.04,data=data[data[\"Fare\"]<200])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cool, the curve is still steep. Now, it's time to train a model for this data."},{"metadata":{},"cell_type":"markdown","source":"# Predictive modeling"},{"metadata":{},"cell_type":"markdown","source":"## We will be using AdaBoot (Adaptive Boost) algorithm for this task.\n\n### Firstly what is AdaBoost?\n\n> AdaBoost is an ensemble learning method (also known as “meta-learning”) which was initially created to increase the efficiency of binary classifiers. AdaBoost uses an iterative approach to learn from the mistakes of weak classifiers, and turn them into strong ones.\n\n![AdaBoost](https://miro.medium.com/proxy/1*m2UHkzWWJ0kfQyL5tBFNsQ.png)\n\n### Here, weak learner combines to create a powerfull strong learner.\n\n### Now what is a weak learner in this case?\n\n- Usually we use Decision Tree stump as a weak learner. Which just answer the single condition. Then combines the multiple Stumps to create boosted algorithm. Remember, the order of stumps matter!.\n\n![Stump](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAQYAAADBCAMAAAAace62AAABIFBMVEX///9bm9Xe6/fp8fmjuc23zuHO2+aRrcf1+P35+/3x9/uftcudscbN2+nj7vi0wtCEqM7x7+1intO60euQu+NUmNW8xc9xqtxspdnAydDW1dTG0t8eX5FylbUtZ5a4ydlFdZ/i6O/DxN1apN2DoL2HyfPg3OVztOrZ9ffM8Pisyuj///yepdewsdrW7/icwORKeKA5bpvV2t/z///Tx9xhh6tqjrB3pdG66/6mtNhHkdJPoOCO1vmzt9d7rt3/9fR4pt3t4+djueuMpr+QsdCHotGd0PCjttpslNOAxOO67/zb0OCn3/PS2O6Im9SFpNPr5O2r2fZpqeO2xuxfr93E6fz/4+bG3/bFutjs2eOMqOGstNaBv+662PSfz+q3xt/PFxMCAAAM5UlEQVR4nO2dDVvayBbHw8sGEiwBylS4AUIE1IKVtwKW1SiC1l1tqe322nbdvd//W9xzJqAokBdCguj8n6eYl2Fm8ss5Z04SMuU4JqYHEvgXK1W4xxAsBl+qWuoEBt57C3wi2pjAEHnBGPz3XvGSMbwS7zgwDFQMAxXDQMUwUDEMVHcYBFVVRaNviUpgckWdX1JXmJdNy6xUMzH087VaLZ9VhDlf4pRM5H6FzxSN2xAiWB0maoI4t8rVaiaGbF7hlWA2k513CtXgxB5RMnGmYL3P80oRSvG5iHHRVWk2hhoepRDMFZdx8sRsPozVQV1qfa0w5PWTnc3I8Mln8/mWjKXCSitT70PU4FsyYmrV6xGBU1sK7pNgrY3FhH5RDOXrxXF0AQyjiou1OrgHz6l5rDfcb0PhjawYqkOl4WCuXsSIE8yqUj2HDXgoQwwyhgC5npXlUA4PtZgrKsFWH7bhaiQXlJWiCpYehMMp5vqKlMVFMVtrt6WNenbMITg+KHkjn5Uk+EYGawM8+L1ati31c9lsa/SVSL7VkoCp4hkDzgSDmslyYoseTqsmApAN7L06wlCDk8kJnI5BoV4vtsGdxGx9A75SrN8NPBu5epvGW153igcYciERFnMYh/r4lUguC0ah5mveANBlgqHIyfkQDJ9qKKNyG2Pj1jH0cxItRjG08/TcK7ADrEGgi/d2rYZqmXZgNoYM7QatWkEnjNBFoZ/xclAxxMCDUyh1XYChWBtnCxRDoJ9rhdQRhnybYuBz0iwMAKKP8XYuBv3Y5XsM3EbGy0zDEEMIjkSuBwUqTCfGPaMY4Ng2MOBRDLWWqO+YgwGcC/zlDoPEmWEIZQwTuCXLYMCETkNY4PP9u/162BLuMOABBbkGYijm6FdCMAY8xqDXL7QhfxpVJmZC8Km2ajMx0FaEVt2tQ56lOdbAqyofqdG+ZenoFuDRpFvgFcENHYOAQU+Bs0+tgc+h7yv5LDeFQc3S0bUOuaZaa4UBi5DPB4BCbjaGXB6HIeC7agxFDAa1VgizHrTdeqtGxzKllqvnaoqOQaSb+0gHe0z35bHUFIZ2PZfJ1bK0iXodN8tQOB/pz8aQL9ZyuXzfS5+YjUGVQfy4HwKvSJK+pioSvY4S8UoJViR5vKLv4/Xy9PgD8jigirI02sUJsqSItDBsUGlypkcZGbcG8IoNiKhQ3NuLj6d3oR3Jr6AbTw/DRp1hAGF+7rmeHgZuFbckniCGVYhhoGIYqBgGKoaBimGgYhioGAYqhoGKYaBiGKgYBiqGgYphoHoaGOIjreyx/+oxxBvpdHAw6HRig4GUTjfiq+jEajEIcTk4SBGUz+ejfzqh4ApIrBJDRZViKR8CmBSQGKS9BrFCDKrUeYzgTjGPQawMQ1yJzWOAJpEYyF6CWBWGRiwx1xR0JSIeclgNBiFtBgEtItbwqj+rwRBXEqYQkENH9iqRWAUGdWAFAnJISR5xWAEGdWDuEHfyiIP3GOJB6xAgUHrjF55jEBQbtgDqePIDSc8xyJai471Ix4snu15jaHTsUQAOAw/yB48xxCP2XAKVmP9L/qXJYwwNmy5BFXPfLbzFELeaMTyU+6OmtxjSixgDjBauZ9WeYojbSZwmRCS3fx3oKYb0QhDQHFSX3cJLDPHgYsYAg4Xb0cFTDLZzhrFIxGWv8BLDQqOlrk7DXXPwEIO9a6pHSj8fDIslDVTkjbtvcHqIQTW6B4uHahBAScTdscJDDDOuqkj39qw7Xj7/OJ8DialhN/vmIYY3UxGSnIuBQPxitHKwRR9dzebQaTwXDNJjDOS2ctbt/nHhI4UqIRQDIVUffhZOHpVN/OfZYHh8hrt/XhI8/d0rkVM/dAFD9zzAiVvd0qfdsY3cY1iX2CCWk4bqPLaG33ePqBuU4hfd0+MTwHDa/Nz9vXJ2eDx87BuJgWHdVYeQlojBn3ptqKnxcozhCoziqzgEDKVtsJHdo8PtqQiRiJQNqi4Th1nmMjFsGp+SKacgB9QpyMF7wBBFDOeI4e1MDIYhUkytEYapEHlaOYLoeHHY83VLcXSKW3HYPQWnmIUhYFB7YI0wzBgwr7hX/t5J4eDLq+YehsjCdfxV8+/uDAydZ4Nh1k3pRCqFf1KpBPEl9KUULE0DizWMsul1wmCWTBsJkunngsHZpVXAKESuEwbRwYV2Iv1sMAgObrvEGs8Ig4ObcKrRQLFeGERp0VuyKSVqeNtlnTDgL54WxAA+8YwwqKEFzUFSDUPDmmEIy6lFIEDuFDUMDeuFgQvb+tnThDFEjX1izTAI4kJj5oA3MYa1wxBY4PldQvGbGMOaYYDo0IjZ5UAiYAwmNyLXDAMnBGS7ORTGR7NnNWuHQQxM3YQyVkf2m0UGrzDQWS/HDb0vbd82Z5WygoGGBxsQSAophO1gCG8nTbFNyQqGY98BFx9ej9YAw87iGLiwqEasY0gpfnOXmMRQOdKq1ers82QgS9bwoyT8PIWaK6+bdxi+XD8uZQ2DEA6oVu2BWKQwgeHy6y6uw1d6b2HhE35wlW8US+X13AosYaic7J99B9Cb2smBjqHyWdNS37njswPuZ2Gf2zq0jAHdwuj1okl1Gn7TsfIhhsqv0dnZ+mt426xcaNrtbmUrpZ1ccZd//cIuO8DAXXbAGL6AEfx3p4kYuB+3HLe9I1R+lCrvCgeVve/WMSCHqGyFw4C3SOEew/HwgPtSLt9wP9B6f8DZObqKa7vc8dfmT7AT3OAAA551btunacOvu4ih8u4KrO6ryP3cqfz67Ty+uW8DA+XAh+Y9tB07RELirXnEAwxgrmH/+53mjxKYxt6mpvkOe9DvDtm93EGHnlOdVQx/AoZbunyPYUcEd3ldOtYuS5wtDIIoRlXDt61IKgIOYZXCRGzAw4eTM8JwgJt6ekS/hD/LwNA7gXjjpxi492Bz77DFI9/V8cdN2pxlDAgiEI02pMEci8D37lS/lZFypHsMvRPo1cgagEmTE8PxXwfY72VgGGLEvdQ07XyUN0C4pKNSz/e2skWjsx0MwCEMIPg3g1mXWp1ImkcIVm3hQd7wJQbB+5rbOseVvze1HT+3Df0ucZfQ38tDRxgsyQ4GOnCiRTSUQayToO8l46vJiU4skm6gJaBDWK5v3ZLpCWGECET9frUhS8FgMBSJwKckIwMKIWydwjpj0D0DTcKPUlX/SFHqDrbqWmsM6BkimASQoPLTT2AgWg2NY605BrQIRBG4E2AR7FkCau0xoBCFEA6HhfG83rb1LDBQOfrx0vPB4EgMAxXDQMUwUDEMVAwDFcNAxTBQMQxUTwlDdNNZVxxITDk8A8vCEK1Wkwn4twKDEKFZX7VajTqoY1kYRI3+GD7poCuLSkgSfCEn5aSOpTnFDb2N6HfSl0Xlpzc0b5xUsTQM4iZYwyp8ApQES9QcBcnlhcgbsiJjgMBEHBrDMkeK1EoiA1WSOBysl4jhpuskVjuSnzgzBnsY4oZSfzPe72jeIpOqyw6btoUhHXOi/zjB4Kxp07lhbGF4s+hPv+mDSWcYTB6AGzdtOu2BHQyCQwx2nz48xOCk6bTZ01AvMTiZguEZYbD/A7WlYTBrmmFgGBgGhoFhYBgYBoaBYWAYGAaG4WVjsNAndzHYg7J8DLT9QnXFGArfz+zQWDqGwvUenVfu84ox7O7RNjT9/6TaJPgPqWiEPsjzPXxfYvkY3r7TpxQkJJHQ24ZFbcZZcR8Duf2n+WlITr9dC9+S/4hHvu4fN8Knj6RQ/fcm+mGyvEsYNsuJ6r9+dXje3BpCb26arx5PLugFhsL+N+18+6J0/D9t9zhZan4+be5p572Twtuedv5gmj+XMJzGT/Z72nX4k/b9khT2P0JvpuzBfQw7u9XqeeVzqdclV1uksPv5fLtLfm9+KOzvkYK45wEG8WT/jJzGL8jh5cWtCr2JTwUL1zGQW/F1uVy+KPUuRhiucbq7/Y+F/Q/eYfgwwkBKAehMdcor3MZAyI447HZ95B7DYQ82xoceYSBkEgNYg6/bnS7pMoZP5fLwartclruI4eA9Yvjr7XZ5F4AgBsFlDNg+xgbAUAEM2xeFA9gkexsbfMlqtToswOdHspmEcXIIm3xkE7ZCueSJr5CcfKFs+emTprevNwVjRgyTqWp1euo5l5NpoicI9HNy64wuu5JMk+mmZmx6GdcUVppmGBgGhoFhYBgYBoaBYWAYGAaGgWFgGBgGhuHpYvAlFpfPGQYHLSd8y8WQlpzI8D/aMFPD3aZtYQgHov6FFTWfBNStps3nH7WLwYGsT+o1Qy43bet9Cjo/0eJaaPaa5TRt9g6DvXetBGdanILbTXv9n8s/UTEMVAwDFcNANYlBKoZeqtoTGALyby9W/nsMgugkU1trTSZYwsSEhS9Nk2mmgNMVvkw5y+2YmJ6t/g814irxDeNvpwAAAABJRU5ErkJggg==)\n\n### Whichever stump gives the less error. They get more say in the algorithm, The error is obtained by Impurity Criterions like Gini, entropy etc.\n\n![Impurity Criterion](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSkpyIpicBxFvKFMnmbhS58jJulREcyLteYhA&usqp=CAU)\n\n#### *Read more about AdaBoost [here](https://machinelearningmastery.com/boosting-and-adaboost-for-machine-learning/)*.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparing the data:\n\n### Firstly, remove the features which seems not that usefull for modeling, like \"Name\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = data.drop([\"Name\",\"Ticket\",\"AgeGrp\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading important libraries and determining the Feature and Target variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\nX = dt.drop(\"Survived\",axis=1)\ny = dt[\"Survived\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test-train split"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Looking at the distribution of target classes over the train and test variables. Looks good!"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(1,2,figsize=(10,4))\nsns.countplot(y_train,ax=ax[0])\nsns.countplot(y_test,ax=ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Encoding the categorical data."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = pd.get_dummies(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training the AdaBoost with 1000 estimators and 025 LR."},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = AdaBoostClassifier(n_estimators=1000,learning_rate = 0.25,random_state=21)\nclf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = pd.get_dummies(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Score over the test data."},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model score over the train data."},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.score(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extracting the probabilities."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = clf.predict(X_test)\ny_pred_proba = clf.predict_proba(X_test)[:,1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classification report."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ns_probs = [0 for _ in range(len(y_test))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ROC score, read more about ROC [here](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)."},{"metadata":{"trusted":true},"cell_type":"code","source":"display(roc_auc_score(y_test,y_pred_proba))\nroc_auc_score(y_test,ns_probs)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Obtaining ROC curve."},{"metadata":{"trusted":true},"cell_type":"code","source":"ns_fpr, ns_tpr, _ = roc_curve(y_test,ns_probs)\nfpr, tpr, _ = roc_curve(y_test,y_pred_proba)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting ROC curve."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(ns_fpr,ns_tpr,linestyle=\"--\",label=\"No Skill\")\nplt.plot(fpr,tpr,marker=\".\",label=\"AdaBoost\")\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}