{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Breast Cancer EDAðŸ“Š + Predictive ModellingðŸŽ®","metadata":{}},{"cell_type":"markdown","source":"![Breast Cancer](https://images.newscientist.com/wp-content/uploads/2019/06/06165424/c0462719-cervical_cancer_cell_sem-spl.jpg?width=1200)","metadata":{}},{"cell_type":"markdown","source":"Dataset Description\n\nThe Breast Cancer datasets is available UCI machine learning repository maintained by the University of California, Irvine. The dataset contains 569 samples of malignant and benign tumor cells.\n\nThe first two columns in the dataset store the unique ID numbers of the samples and the corresponding diagnosis (M=malignant, B=benign), respectively. The columns 3-32 contain 30 real-value features that have been computed from digitized images of the cell nuclei, which can be used to build a model to predict whether a tumor is benign or malignant.\n\n* 1= Malignant (Cancerous) - Present (M)\n* 0= Benign (Not Cancerous) - Absent (B)\n\n\nColumn names and meanings:\n\n* id: ID number\n* diagnosis: The diagnosis of breast tissues (M = malignant, B = benign)\n* radius_mean: mean of distances from center to points on the perimeter\n* texture_mean: standard deviation of gray-scale values\n* perimeter_mean: mean size of the core tumor\n* area_mean: area of the tumor\n* smoothness_mean: mean of local variation in radius lengths\n* compactness_mean: mean of perimeter^2 / area - 1.0\n* concavity_mean: mean of severity of concave portions of the contour\n* concave_points_mean: mean for number of concave portions of the contour\n* symmetry_mean\n* fractal_dimension_mean: mean for \"coastline approximation\" - 1\n* radius_se: standard error for the mean of distances from center to points on the perimeter\n* texture_se: standard error for standard deviation of gray-scale values\n* perimeter_se\n* area_se\n* smoothness_se: standard error for local variation in radius lengths\n* compactness_se: standard error for perimeter^2 / area - 1.0\n* concavity_se: standard error for severity of concave portions of the contour\n* concave_points_se: standard error for number of concave portions of the contour\n* symmetry_se\n* fractal_dimension_se: standard error for \"coastline approximation\" - 1\n* radius_worst: \"worst\" or largest mean value for mean of distances from center to points on the perimeter\n* texture_worst: \"worst\" or largest mean value for standard deviation of gray-scale values\n* perimeter_worst\n* area_worst\n* smoothness_worst: \"worst\" or largest mean value for local variation in radius lengths\n* compactness_worst: \"worst\" or largest mean value for perimeter^2 / area - 1.0\n* concavity_worst: \"worst\" or largest mean value for severity of concave portions of the contour\n* concave_points_worst: \"worst\" or largest mean value for number of concave portions of the contour\n* symmetry_worst\n* fractal_dimension_worst: \"worst\" or largest mean value for \"coastline approximation\" - 1","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries ðŸ“š","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport missingno\nfrom pandas_profiling import ProfileReport\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import f1_score,confusion_matrix\nfrom sklearn import metrics\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import HTML\nf = open(\"../input/ocean2/ocean.css\").read()\nHTML(f\"<style>{f}</style>\")","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the Dataset.","metadata":{}},{"cell_type":"markdown","source":"### Clearing the useless columns.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/breast-cancer-wisconsin-data/data.csv')\ndf.drop(['Unnamed: 32','id'] ,axis=1, inplace=True)\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checking the missing values in the dataset.","metadata":{}},{"cell_type":"code","source":"missingno.matrix(df)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### This shows that the dataset having 0 missing values.","metadata":{}},{"cell_type":"markdown","source":"## Checking the duplicate values in the dataset.","metadata":{}},{"cell_type":"code","source":"df.duplicated().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### This shows that the dataset having 0 duplicate values.","metadata":{}},{"cell_type":"markdown","source":"## Describing the dataset.","metadata":{}},{"cell_type":"code","source":"df.describe().T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA (Exploratory Data Analysis)ðŸ“Š","metadata":{}},{"cell_type":"markdown","source":"## Let's check that, how the dataset is divided into two type of diagnosis.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nsns.countplot(x=df['diagnosis'], palette='RdBu')\n\nbenign, malignant = df['diagnosis'].value_counts()\nprint('Number of cells labeled Benign : ', benign)\nprint('Number of cells labeled Malignant : ', malignant)\nprint('')\nprint('% of cells labeled Benign', round(benign / len(df) * 100, 2), '%')\nprint('% of cells labeled Malignant', round(malignant / len(df) * 100, 2), '%')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### This plot shows that the Malignant (Cancerous) type result of diagnosis are 212. And This plot shows that the Benign (Not Cancerous) type result of diagnosis are 357.","metadata":{}},{"cell_type":"markdown","source":"## Let's check the correlation between the dataset.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20, 20))\nsns.heatmap(df.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### This correlation shows pretty much good relationship between dataset.","metadata":{}},{"cell_type":"markdown","source":"## Clustermapping the datasets correlation for better understanding the relationship of data.","metadata":{}},{"cell_type":"code","source":"sns.clustermap(df.corr())\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checking the relationship between the specific data for understanding the relationship.","metadata":{}},{"cell_type":"code","source":"sns.jointplot(x=df.loc[:,'concavity_worst'], y=df.loc[:,'concave points_worst'], kind=\"reg\", color=\"#ce1414\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictive Modelling ðŸŽ®","metadata":{}},{"cell_type":"markdown","source":"### Let's get to know about the columns of the dataset. So, that we can know better about the features of our model.","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## We have categorical data, but our model needs something numerical. So, that our model works perfectly fine and predicts with best  accuracy.","metadata":{}},{"cell_type":"code","source":"df['diagnosis']=df['diagnosis'].map({'M':1,'B':0})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### By mapping the Malignant diagnosis as 1 and Benign diagnosis as 0. We are making our dataset to be perfect fit for our model.","metadata":{}},{"cell_type":"markdown","source":"## Separating the features and the target value for our model.","metadata":{}},{"cell_type":"code","source":"X = df.drop([\"diagnosis\"], axis = 1)\ny = df.diagnosis.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing the feature values for better accuracy of the model.","metadata":{}},{"cell_type":"code","source":"X = (X - np.min(X))/(np.max(X) - np.min(X)).values\nX","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Here, we separating the data in two parts - Training & Testing. Then we calling the Logistic Regression and fitting the data in our model. We predict the predictions and then checking the accuracy of our model.","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\nlogistic = LogisticRegression()\nlogistic.fit(X_train,y_train)\ny_pred = logistic.predict(X_test)\nac = accuracy_score(y_test,y_pred)\nprint('Accuracy is: ',ac)\nconm = confusion_matrix(y_test,y_pred)\nsns.heatmap(conm,annot=True,fmt=\"d\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We got the accuracy of 0.98% on our this Logistic Regression model.","metadata":{}},{"cell_type":"markdown","source":"## Checking the Classification Report for better understanding the accuracy and score of our model.","metadata":{}},{"cell_type":"code","source":"print(metrics.classification_report(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checking the roc_aur_score and the f1 score of our model.","metadata":{}},{"cell_type":"code","source":"print(\"roc_auc_score: \", roc_auc_score(y_test, y_pred))\nprint(\"f1 score: \", f1_score(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}