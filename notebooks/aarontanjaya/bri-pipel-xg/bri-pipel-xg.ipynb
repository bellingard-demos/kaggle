{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport pandas\ndata=pd.read_csv(\"/kaggle/input/bri-data-hackathon-pa/train.csv\")\ndatatest=pd.read_csv(\"/kaggle/input/bri-data-hackathon-pa/test.csv\")\ndata=data.dropna()\nprint(datatest.head())\nprint(data.isna().sum())\nprint(data.columns.tolist())\nprint(datatest.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.dtypes)\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datadrop=data['GPA'][(data['GPA']>0)&(data['GPA']<4)]\n#data['GPA'][data['GPA']==0]=datadrop.median()\n#data['GPA'][data['GPA']>4]=datadrop.median()\ndata.loc[data['GPA']==0,'GPA']=datadrop.median()\ndata.loc[data['GPA']>4,'GPA']=datadrop.median()\nprint(data['GPA'])\nprint(datadrop.median())\ndata['GPA'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datadroptes=datadrop.append(datatest['GPA'][(datatest['GPA']>0)&(datatest['GPA']<4)])\n\n#data['GPA'][data['GPA']==0]=datadrop.median()\n#data['GPA'][data['GPA']>4]=datadrop.median()\ndatatest.loc[datatest['GPA']==0,'GPA']=datadroptes.median()\ndatatest.loc[datatest['GPA']>4,'GPA']=datadroptes.median()\nprint(datatest['GPA'])\nprint(datadroptes)\nprint(datadroptes.median())\ndatatest['GPA'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.distplot(data['GPA'],hist=False)\nsns.distplot(data['GPA'][data['Best Performance']==1],hist=False,color='g')\nplt.title(\"gpa\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datates=data.dropna(axis=0)\n#dropin data yang dtypenya object (string)\ndatates=datates.drop(['job_level','person_level','Employee_type','marital_status_maried(Y/N)','Education_level'],axis=1)\nXnya=datates.drop('Best Performance',axis=1)\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nkbes=SelectKBest()\nhasil=kbes.fit(Xnya,datates['Best Performance'])\nresult=pd.concat([pd.DataFrame(Xnya.columns),pd.DataFrame(hasil.scores_)],axis=1)\nresult.columns=['Parameter','Score']\nprint('with f classif (ANOVA)')\nprint(result.sort_values('Score',ascending=False))\n\nkbes=SelectKBest(score_func=chi2)\nhasil1=kbes.fit(Xnya,datates['Best Performance'])\nresult1=pd.concat([pd.DataFrame(Xnya.columns),pd.DataFrame(hasil.scores_)],axis=1)\nresult1.columns=['Parameter','Score']\nprint('with chi squared')\nprint(result1.sort_values('Score',ascending=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\ntree=ExtraTreesClassifier(n_estimators=200)\ntree.fit(Xnya,datates['Best Performance'])\nhasilnya=pd.concat([pd.DataFrame(Xnya.columns),pd.DataFrame(tree.feature_importances_)],axis=1)\nhasilnya.columns=['Parameter','Scores']\nprint(hasilnya.sort_values('Scores',ascending=False))\n\nfrom sklearn.preprocessing import StandardScaler\nss=StandardScaler()\nXX=ss.fit_transform(Xnya)\ntree=ExtraTreesClassifier(n_estimators=200)\ntree.fit(XX,datates['Best Performance'])\nhasilnya=pd.concat([pd.DataFrame(Xnya.columns),pd.DataFrame(tree.feature_importances_)],axis=1)\nhasilnya.columns=['Parameter','Scores']\nprint(hasilnya.sort_values('Scores',ascending=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ntarget=data.loc[:,'Best Performance']\nkey1=['Last_achievement_%','job_duration_from_training','age','gender','job_duration_in_current_branch','GPA','annual leave','number_of_dependences','branch_rotation']\nkey2=['job_duration_in_current_branch','job_duration_from_training','Achievement_above_100%_during3quartal','number_of_dependences','branch_rotation','job_rotation']\nkeycontinuous=key1\nfor item in keycontinuous:\n    plt.boxplot(data[item])\n    plt.title(item)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for item in data['Education_level'].unique():\n    print(item,data['GPA'][data['Education_level']==item].median())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"education level agak pengaruh (dri eda) jdi ambil 3 kelas besarnya dicoba one hot encoder, "},{"metadata":{"trusted":true},"cell_type":"code","source":"datax=pd.concat([data.loc[:,keycontinuous],pd.get_dummies(data['Education_level']).drop(['level_0','level_2','level_5'],axis=1)],axis=1)\ndatax=data.loc[:,keycontinuous]\n#datax.loc[:,'age']=datax['age'].apply(lambda x:2020-x)\nprint(datax)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataxtes=pd.concat([datatest.loc[:,keycontinuous],pd.get_dummies(datatest['Education_level']).drop(['level_0','level_2','level_5'],axis=1)],axis=1)\ndataxtes=datatest.loc[:,keycontinuous]\n#dataxtes.loc[:,'age']=dataxtes['age'].apply(lambda x:2020-x)\nprint(dataxtes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nss=StandardScaler()\nx1=ss.fit_transform(datax)\nx1test=ss.fit_transform(dataxtes)\nfrom sklearn.model_selection import train_test_split\nxtrain,xtest,ytrain,ytest=train_test_split(x1,target,stratify=target,random_state=123,test_size=0.3)\nprint((ytrain==1).sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import plot_precision_recall_curve\nxg=xgb.XGBClassifier(n_estimators=100)\nxg.fit(xtrain,ytrain)\nprint(classification_report(ytest,xg.predict(xtest)))\nprint(roc_auc_score(ytest,xg.predict_proba(xtest)[:,1]))\nplot_precision_recall_curve(xg,xtest,ytest)\nTPtes=pd.DataFrame(xtest[(ytest==1)&(xg.predict(xtest)==1),:],columns=datax.columns.tolist())\nFPtes=pd.DataFrame(xtest[(ytest==0)&(xg.predict(xtest)==1),:],columns=datax.columns.tolist())\nTNtes=pd.DataFrame(xtest[(ytest==0)&(xg.predict(xtest)==0),:],columns=datax.columns.tolist())\nFNtes=pd.DataFrame(xtest[(ytest==1)&(xg.predict(xtest)==0),:],columns=datax.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint((xg.predict(x1)==1).sum())\nprint(((xg.predict(x1)==1)&(target==1)).sum())\nprint('precision:',((xg.predict(x1)==1)&(target==1)).sum()/(xg.predict(x1)==1).sum())\nprint('recall:',((xg.predict(x1)==1)&(target==1)).sum()/(target==1).sum())\nprint((ytrain==1).sum())\nprint((target==1).sum())\nprint(data[xg.predict(x1)==1])\nprint(classification_report(target,xg.predict(x1)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nxg.fit(x1,target)\nsubmit=pd.DataFrame({'index':np.arange(0,6000,1)})\nsubmit['Best Performance']=xg.predict_proba(x1test)[:,1]\nsubmit.set_index('index',inplace=True)\nprint(submit)\nsubmit.to_csv('resul.csv')\nprint((xg.predict(x1test)==1).sum())\nprint((submit['Best Performance']>0.5).sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(Xnya.columns.tolist()),',',len(xg.feature_importances_))\nimportance=pd.DataFrame({'Columns':datax.columns.tolist(),'Importance':xg.feature_importances_})\nprint(importance)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfor item in datax.columns.tolist():\n    print(item)\n    sns.distplot(TPtes[item],hist=False,color='g')\n    sns.distplot(TNtes[item],hist=False,color='b')\n    sns.distplot(FPtes[item],hist=False,color='y')\n    sns.distplot(FNtes[item],hist=False,color='r')\n    plt.title(item)\n    plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}