{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport numpy as np\nwarnings.filterwarnings(\"ignore\")\nplt.style.use('ggplot')\npd.set_option('display.max_columns', None)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('data.csv').drop(['Unnamed: 0', 'Population', 'Crime Cnt', 'Crime Rate'], axis=1)\n\n#import data_prediction.csv. it's subset of the original file and will be be sufficient for testing.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Year'] = data['Year'].astype(str)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Vict Sex'].unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Spliting data into data_num and data_cat\n\ndata_cat = data[[x for x in data.columns if data[x].dtype == 'O']]\ndata_num = data[[x for x in data.columns if data[x].dtype != 'O']]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Label encoder the Vict Sex\n\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\n\ndata_cat['Vict Sex'] = label_encoder.fit_transform(data_cat['Vict Sex'])\n\ndata_cat['Vict Sex'].unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Feature Engineering to calculate the mean \n\nfor x in data_cat.columns:\n    if x != 'Vict Sex':\n        dict1=data_cat.groupby([x])['Vict Sex'].mean().to_dict()\n        data_cat[x] = data_cat[x].map(dict1)\n        \ndf = pd.concat([data_cat, data_num], axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Correlation\n\ndf.corr()['Vict Sex'].sort_values(ascending=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(17, 7))\nsns.heatmap(df.corr(), annot=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Select the best column use for analysis \n\n\nX = df.drop('Vict Sex', axis=1)\ny = df.loc[:, 'Vict Sex']\n\nfrom sklearn.linear_model import Lasso\nfrom sklearn.feature_selection import SelectFromModel\n\nmodel = SelectFromModel(Lasso(0.005))\nmodel.fit(X, y)\nmodel.get_support()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X[X.columns[model.get_support()]]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest\n\nfrom sklearn.feature_selection import chi2\n\norderd_rank_features = SelectKBest(score_func=chi2, k='all')\n\nordered_feature = orderd_rank_features.fit(X.drop(['LON'], axis=1), y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ordered_feature.scores_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = pd.concat([pd.DataFrame(X.drop('LON', axis=1).columns), \n            pd.DataFrame(ordered_feature.scores_, columns=['score']),\n          ], axis=1).sort_values('score', ascending=False)\nfeatures ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = X[features[0][:8].tolist()]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix\nfrom sklearn.model_selection import cross_val_score","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Display score\n\ndef display_scores(scores):\n    print('===============================================')\n    print('Scores: {}'.format(scores))\n    print('===============================================')\n    print('Mean Score: {}'.format(scores.mean()))\n    print('===============================================')\n    print('Standard Deviation of Scores: {}'.format(scores.std()))\n    print('===============================================')\n    \n    return None\n\n\n#Creat the predict function \n\ndef predict(ml_model):\n    model = ml_model.fit(X_train, y_train)\n    pred = model.predict(X_test)\n    print(f'Predictions: {pred}')\n    print(f'Training Score: {model.score(X_train, y_train)}')\n    print('\\n')\n    print(f'{confusion_matrix(pred, y_test)}')\n    print('\\n')\n    print(f'Accuracy Score: {accuracy_score(pred, y_test)}')\n    print(f'Mean Squared Error: {mean_squared_error(pred, y_test)}')\n    \n    scores = cross_val_score(model,\n               X_train,\n               y_train,\n#                scoring='neg_mean_squared_error',\n               cv=10)\n    print('\\n')\n    display_scores(scores)\n    \n    plt.figure(figsize=(4,2))\n    sns.kdeplot(pred, shade=True)\n    sns.kdeplot(y_test, shade=True)\n    plt.legend(['pred', 'y_test'])\n    \n    print('\\n')\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predictions - Tree\n\nfrom sklearn.tree import DecisionTreeClassifier\n\ntree = DecisionTreeClassifier()\n\npredict(tree)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predictions - forest\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nforest = RandomForestClassifier()\n\npredict(forest)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predictions - KNN\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\n\npredict(knn)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\nxgb = XGBClassifier()\n\npredict(xgb)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}