{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"padding:20px;color:#DEB078;margin:0;font-size:300%;text-align:center;display:fill;border-radius:5px;background-color:#1F4F59;overflow:hidden;font-weight:800\"> Dashboard  </div>","metadata":{"execution":{"iopub.status.busy":"2023-02-24T04:25:28.617554Z","iopub.execute_input":"2023-02-24T04:25:28.617959Z","iopub.status.idle":"2023-02-24T04:25:28.625777Z","shell.execute_reply.started":"2023-02-24T04:25:28.617926Z","shell.execute_reply":"2023-02-24T04:25:28.624177Z"}}},{"cell_type":"markdown","source":"## <b><span style='color:#DEB078'>1 |</span><span style='color:#1F4F59'> Edit Your username</span></b>  ","metadata":{}},{"cell_type":"code","source":"Enter_Your_Username='abhi011097' # Enter_Your_Username='xyz'","metadata":{"papermill":{"duration":0.019608,"end_time":"2023-01-13T19:56:12.205792","exception":false,"start_time":"2023-01-13T19:56:12.186184","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-03T02:56:11.312392Z","iopub.execute_input":"2023-03-03T02:56:11.313434Z","iopub.status.idle":"2023-03-03T02:56:11.319532Z","shell.execute_reply.started":"2023-03-03T02:56:11.313378Z","shell.execute_reply":"2023-03-03T02:56:11.318163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <b><span style='color:#DEB078'>2 |</span><span style='color:#1F4F59'> Import Library</span></b>  ","metadata":{}},{"cell_type":"code","source":"from IPython.display import clear_output\n!pip install pyspark\nclear_output()\nfrom pyspark.sql import SparkSession\nimport numpy as np \nimport pandas as pd \nimport warnings\nfrom pyspark.sql import functions as F\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport seaborn as sns\nspark = SparkSession.builder \\\n          .master(\"local[*]\") \\\n          .appName(\"Data Analysis\") \\\n          .getOrCreate()\n\nspark.sparkContext.setLogLevel(\"ERROR\")\nclear_output()\n\nspark_df_users=spark.read.options(header=\"true\",inferSchema='True').csv('/kaggle/input/meta-kaggle/Users.csv')\nspark_df_kernelvotes=spark.read.options(header=\"true\",inferSchema='True').csv('/kaggle/input/meta-kaggle/KernelVotes.csv')\nspark_df_kernels=spark.read.options(header=\"true\",inferSchema='True').csv('/kaggle/input/meta-kaggle/Kernels.csv')\nspark_df_kernelversions=spark.read.options(header=\"true\",inferSchema='True').csv('/kaggle/input/meta-kaggle/KernelVersions.csv')\n\nspark_df_users.createOrReplaceTempView(\"users\")\nspark_df_kernels.createOrReplaceTempView(\"kernels\")\nspark_df_kernelvotes.createOrReplaceTempView(\"kernelvotes\")\nspark_df_kernelversions.createOrReplaceTempView(\"kernelversions\")\n\nresult = spark.sql(\"select * from users where upper(UserName)=upper('\"+Enter_Your_Username+\"')\" ).toPandas()\nuser_kaggle_key=result['Id'].values[0]","metadata":{"papermill":{"duration":57.474438,"end_time":"2023-01-13T19:57:09.688829","exception":false,"start_time":"2023-01-13T19:56:12.214391","status":"completed"},"tags":[],"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-03-03T02:56:13.672794Z","iopub.execute_input":"2023-03-03T02:56:13.673585Z","iopub.status.idle":"2023-03-03T02:58:09.336302Z","shell.execute_reply.started":"2023-03-03T02:56:13.673545Z","shell.execute_reply":"2023-03-03T02:58:09.335197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <b><span style='color:#DEB078'>3 |</span><span style='color:#1F4F59'> Number of Notebooks</span></b>  ","metadata":{}},{"cell_type":"code","source":"query=\"select Count(1) No_Of_Public_Kernels from kernels where AuthorUserId=\"+str(user_kaggle_key)\nspark.sql(query).show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-03-03T02:58:56.272557Z","iopub.execute_input":"2023-03-03T02:58:56.273991Z","iopub.status.idle":"2023-03-03T02:58:58.447018Z","shell.execute_reply.started":"2023-03-03T02:58:56.273942Z","shell.execute_reply":"2023-03-03T02:58:58.445533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query=\"select CurrentUrlSlug as Top_5_Kernel_Name,TotalComments from kernels where AuthorUserId=\"+str(user_kaggle_key)+\" order by TotalComments desc limit 5\"\nTotalComments = spark.sql(query).toPandas()\nquery=\"select CurrentUrlSlug as Top_5_Kernel_Name,TotalViews  from kernels where AuthorUserId=\"+str(user_kaggle_key)+\" order by TotalViews desc limit 5\"\nTotalViews = spark.sql(query).toPandas()\nquery=\"select CurrentUrlSlug as Top_5_Kernel_Name,TotalVotes from kernels where AuthorUserId=\"+str(user_kaggle_key)+\" order by TotalVotes desc limit 5\"\nTotalVotes = spark.sql(query).toPandas()\n\nfig = make_subplots(rows=3, cols=1, specs=[[{\"type\": \"table\"}], [{\"type\": \"table\"}],[{\"type\": \"table\"}]],vertical_spacing = 0.05,\n                    subplot_titles=('Based on Comments','Based on Views','Based on Votes'))\n\nfig.add_trace(\n    go.Table(\n        header=dict(values=list(TotalComments.columns),\n                align='center'),\n        cells=dict(values=TotalComments.transpose().values.tolist(),\n               align='center'),\n    ),\n    row=1,\n    col=1,\n)\nfig.add_trace(\n    go.Table(\n        header=dict(values=list(TotalViews.columns),\n                align='center'),\n        cells=dict(values=TotalViews.transpose().values.tolist(),\n               align='center'),\n    ),\n    row=2,\n    col=1,\n)\nfig.add_trace(\n    go.Table(\n        header=dict(values=list(TotalVotes.columns),\n                align='center'),\n        cells=dict(values=TotalVotes.transpose().values.tolist(),\n               align='center'),\n    ),\n    row=3,\n    col=1,\n)\nfig.update_traces(cells_font=dict(size = 11))\nfig.update_layout(\n    margin=dict(l=0 ,t=40),height=600\n)\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-03-03T02:58:58.449514Z","iopub.execute_input":"2023-03-03T02:58:58.449964Z","iopub.status.idle":"2023-03-03T02:59:02.759856Z","shell.execute_reply.started":"2023-03-03T02:58:58.449922Z","shell.execute_reply":"2023-03-03T02:59:02.758713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <b><span style='color:#DEB078'>4 |</span><span style='color:#1F4F59'> Distribution of Votes, Comments and Views Per Kernel</span></b>  ","metadata":{}},{"cell_type":"code","source":"query=\"\"\"\nselect views,percentile_views,comments,percentile_comments,votes,percentile_votes from\n(select uid,views, \nconcat(round((percent_rank(views) OVER (Order BY views))*100,3),' %') as percentile_views,\ncomments,\nconcat(round((percent_rank(comments) OVER (Order BY comments))*100,3),' %') as percentile_comments,\nvotes,\nconcat(round((percent_rank(votes) OVER (Order BY votes))*100,3),' %') as percentile_votes\n\n        from (\n        select AuthorUserId uid, \n        sum(TotalComments) comments,\n        sum(TotalViews) views,\n        sum(TotalVotes) votes \n        from kernels\n        group by 1) )\nwhere uid=\"\"\"+str(user_kaggle_key)\n\nresult = spark.sql(query).show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-03-03T02:59:06.095662Z","iopub.execute_input":"2023-03-03T02:59:06.096775Z","iopub.status.idle":"2023-03-03T02:59:11.200025Z","shell.execute_reply.started":"2023-03-03T02:59:06.096712Z","shell.execute_reply":"2023-03-03T02:59:11.198748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query=\"select TotalComments,TotalViews,TotalVotes from kernels where AuthorUserId=\"+str(user_kaggle_key)\nresult = spark.sql(query).toPandas()\nvars = ['TotalComments','TotalViews','TotalVotes']\nfig = make_subplots(rows=1, cols=len(vars), subplot_titles=['Comments Distribution','Views Distribution','Votes Distribution'])\nfor i, var in enumerate(vars):\n    fig.add_trace(\n        go.Box(y=result[var],\n        name=var),\n        row=1, col=i+1\n    )\n\nfig.update_traces(boxpoints='all', jitter=.3)\nfig.update_layout(showlegend=False)\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-02-28T07:21:36.542032Z","iopub.execute_input":"2023-02-28T07:21:36.542586Z","iopub.status.idle":"2023-02-28T07:21:37.663012Z","shell.execute_reply.started":"2023-02-28T07:21:36.542555Z","shell.execute_reply":"2023-02-28T07:21:37.661665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <b><span style='color:#DEB078'>5 |</span><span style='color:#1F4F59'> Upvoters Category Distribution</span></b>  ","metadata":{}},{"cell_type":"code","source":"query= \"\"\"select case when PerformanceTier =0  then 'Novice'\n                      when PerformanceTier =1  then 'Contributor'\n                      when PerformanceTier =2  then 'Expert'\n                      when PerformanceTier =3  then 'Master'\n                      when PerformanceTier =4  then 'GrandMaster'\n                      end PerformanceTier\n             ,count(1) votes\n             from users t1 inner join  \n                ( select UserId \n                   from kernelvotes \n                    where KernelVersionId in (select distinct Id from kernelversions where AuthorUserId=\"\"\"+str(user_kaggle_key)+\"\"\"))\n        t2\n        on t1.Id=t2.UserId\n        Group by 1 \n        order by 2 desc\n        \"\"\"\n\n\nresult = spark.sql(query).toPandas()\n\nfig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"table\"}, {'type':'domain'}]],horizontal_spacing = 0.005,\n                        subplot_titles=('Voters Category Classification',''))\n\nfig.add_trace(\n    go.Table(\n        header=dict(values=list(result.columns),\n                align='center'),\n        cells=dict(values=result.transpose().values.tolist(),\n               align='center'),\n    ),\n    row=1,\n    col=1\n)\n\nfig.add_trace(\n        go.Pie(labels=result[\"PerformanceTier\"],\n               values=result[\"votes\"],\n               showlegend=True,\n               textposition='inside',\n              ),\n    row=1,\n    col=2,  \n)\n\n\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-02-28T07:21:37.664862Z","iopub.execute_input":"2023-02-28T07:21:37.665607Z","iopub.status.idle":"2023-02-28T07:22:00.811607Z","shell.execute_reply.started":"2023-02-28T07:21:37.665566Z","shell.execute_reply":"2023-02-28T07:22:00.810793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <b><span style='color:#DEB078'>6 |</span><span style='color:#1F4F59'> Top Upvoters since 2016</span></b>  ","metadata":{}},{"cell_type":"code","source":"query=\"\"\"select t1.DisplayName VoterName, t2.No_Of_Upvotes from users t1 inner join  \n        ( select UserId ,Count(1) No_Of_Upvotes \n           from kernelvotes \n            where KernelVersionId in (select distinct Id from kernelversions \n                                        where AuthorUserId=(select min(Id) from users where upper(UserName)=upper('\"\"\"+Enter_Your_Username+\"\"\"')))\n           group by 1 order by 2 desc\n         )\n        t2\n        on t1.Id=t2.UserId\n        order by 2 desc \n        limit 15\n        \"\"\"\nresult = spark.sql(query).show()","metadata":{"papermill":{"duration":44.070789,"end_time":"2023-01-13T19:59:12.426711","exception":false,"start_time":"2023-01-13T19:58:28.355922","status":"completed"},"tags":[],"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-02-28T07:26:54.929249Z","iopub.execute_input":"2023-02-28T07:26:54.929728Z","iopub.status.idle":"2023-02-28T07:27:52.454207Z","shell.execute_reply.started":"2023-02-28T07:26:54.929694Z","shell.execute_reply":"2023-02-28T07:27:52.45276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <b><span style='color:#DEB078'>7 |</span><span style='color:#1F4F59'> Last 30 Votes</span></b>  ","metadata":{}},{"cell_type":"code","source":"query=\"\"\"select t2.Title,t1.VoteDate,t2.ScriptId, t3.UserName,case when t3.PerformanceTier =0  then 'Novice'\n                      when t3.PerformanceTier =1  then 'Contributor'\n                      when t3.PerformanceTier =2  then 'Expert'\n                      when t3.PerformanceTier =3  then 'Master'\n                      when t3.PerformanceTier =4  then 'GrandMaster'\n                      end PerformanceTier \n                      , No_Of_Upvotes as Total_Votes_By_User\n                      from\n        (select * from kernelvotes \n       where KernelVersionId in (select distinct Id from kernelversions where AuthorUserId=\"\"\"+str(user_kaggle_key)+\"\"\")) t1\n        inner join \n        (select * from kernelversions where AuthorUserId=\"\"\"+str(user_kaggle_key)+\"\"\") t2        \n        on t1.KernelVersionId=t2.id\n        inner join \n        users t3\n        on t1.UserId=t3.Id\n        inner join\n         (select UserId ,Count(1) No_Of_Upvotes \n           from kernelvotes \n            where KernelVersionId in (select distinct Id from kernelversions where AuthorUserId=\"\"\"+str(user_kaggle_key)+\"\"\") \n           group by 1 ) t4\n        on t1.UserId=t4.UserId\n        \n        order by  to_Date(t1.VoteDate,'MM/dd/yyyy') desc,t1.id desc\n        \n\"\"\"\nvots=spark.sql(query).toPandas()\nvots.loc[:30,['Title','VoteDate','UserName','PerformanceTier','Total_Votes_By_User']].style.hide_index()","metadata":{"execution":{"iopub.status.busy":"2023-02-28T07:22:37.261037Z","iopub.execute_input":"2023-02-28T07:22:37.261527Z","iopub.status.idle":"2023-02-28T07:23:16.083329Z","shell.execute_reply.started":"2023-02-28T07:22:37.26148Z","shell.execute_reply":"2023-02-28T07:23:16.081783Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]}]}