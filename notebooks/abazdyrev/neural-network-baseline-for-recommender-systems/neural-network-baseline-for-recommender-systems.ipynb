{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Recurrent Neural Network based Recommender System\nIn this kernel I'm going to show you how to implement a pretty well-performing recommender system using Keras.<br>\nDataset was provided by [MEGOGO](https://megogo.net/) in [Megogo Challenge](https://www.kaggle.com/c/megogochallenge)<br>\nTarget metric - [MAP@10](https://habr.com/ru/company/econtenta/blog/303458/) <br>\nThe main idea of this approach is to predict the next film, that user will watch, knowing the sequence of films, that user has watched earlier.<br>\nIn the terms of ML-engineering we can define this problem as multiclass (with very large amount of classes) sequences classification."},{"metadata":{},"cell_type":"markdown","source":"## Data Loading"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/train_data_full.csv')\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's find top 10 most popular films. This will be useful later to make recommendations for users, about whom we don't have historical data."},{"metadata":{"trusted":true},"cell_type":"code","source":"top_10_videos = train_data.loc[train_data.session_start_datetime >= '2018-09-01 00:00:00', \n                               'primary_video_id'].value_counts()[:10].index.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv('../input/sample_submission_full.csv')\nsample_submission.primary_video_id = ' '.join([str(v) for v in top_10_videos])\ntest_users = sample_submission.user_id.unique()\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping samples with kind of 'negative implicit feedback'\ntrain_data = train_data[train_data.watching_percentage >= 0.5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Transforming primary_video_id column in a more suitable representation <br>\nFor example, if we have primary_video_id column like [1435, 56453, 1245, 76544], we want to transform it in [2, 3, 1, 4]. Zero value will be used later to pad user-video interactions sequences."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.primary_video_id = train_data.primary_video_id.astype('category')\ntrain_data['categ_id'] = train_data.primary_video_id.cat.codes + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let`s define inverse transform dictionary\ncat_to_element_uid = dict(zip(\n    range(1, len(train_data.primary_video_id.cat.categories) + 1),\n    train_data.primary_video_id.cat.categories\n))\n\n# Assigning most popular film index to inverse transform of zero padding value\ncat_to_element_uid[0] = 29114276","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the next cell we define sequences of films for each user <br>\nExample of transformation:\n<table style=\"width:50%\">\n  <tr>\n    <th align=\"left\">Before</th>\n    <th align=\"left\">After</th> \n  </tr>\n  <tr>\n    <td><table style=\"width:100%\">\n  <tr>\n    <th>user_id</th>\n    <th>categ_id</th> \n  </tr>\n  <tr>\n    <td>12</td>\n    <td>2</td> \n  </tr>\n  <tr>\n    <td>13</td>\n    <td>1</td> \n  </tr>  \n  <tr>\n    <td>12</td>\n    <td>1</td> \n  </tr>    \n   <tr>\n    <td>13</td>\n    <td>2</td> \n  </tr>  \n  <tr>\n    <td>12</td>\n    <td>1</td> \n  </tr>    \n  <tr>\n    <td>13</td>\n    <td>3</td> \n  </tr>   \n</table></td>\n    <td><table style=\"width:50%\">\n  <tr>\n    <th>user_id</th>\n    <th>sequence</th> \n  </tr>\n  <tr>\n    <td>12</td>\n    <td>[2, 1, 1]</td> \n  </tr>\n  <tr>\n    <td>13</td>\n    <td>[1, 2, 3]</td> \n</table></td> \n  </tr>\n</table>"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nimport tqdm\ntqdm.tqdm.pandas()\nsequences = train_data.groupby('user_id')['categ_id'].progress_apply(list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sequences.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Some statistics\nprint('Median length: {}\\nMean length: {}\\nMax length: {}'.format(\n    sequences.apply(len).median(), sequences.apply(len).mean(), sequences.apply(len).max()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use users with 5 and more wathced films\nsequences2use = sequences[sequences.apply(len) >= 5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One of the most important part of this solution is to make X and y for our RNN model <br>\nFor example, if we define maxlen = 3, we transform sequence [2, 3, 3, 1, 5, 9] to \n<table style=\"width:50%\">\n  <tr>\n    <th>X</th>\n    <th>y</th> \n  </tr>\n  <tr>\n    <td>[3, 1, 5]</td>\n    <td>9</td>\n  </tr>\n  <tr>\n    <td>[3, 3, 1]</td>\n    <td>5</td> \n  </tr>\n  <tr>\n    <td>[2, 3, 3]</td>\n    <td>1</td> \n  </tr>\n</table><br>\nSo, user who watched a lot of films, will be represented by many sequences, and thus, the size of our training dataset will increase significantly."},{"metadata":{"trusted":true},"cell_type":"code","source":"maxlen = 18 # Length of sequences in X\nX = []\ny = []\n\ndef slice_sequence(seq, num_slices):\n    for i in range(1, num_slices):\n        X.append(seq[-(i+maxlen): -i])\n        y.append(seq[-i])\n        \nfor seq in tqdm.tqdm(sequences2use):\n    if len(seq) <= 5:\n        slice_sequence(seq, 2)\n    elif len(seq) <= 6:\n        slice_sequence(seq, 3)\n    elif len(seq) <= 8:\n        slice_sequence(seq, 4)\n    elif len(seq) <= 12:\n        slice_sequence(seq, 6)\n    elif len(seq) <= 16:\n        slice_sequence(seq, 8)\n    elif len(seq) <= 20:\n        slice_sequence(seq, 11)\n    elif len(seq) <= 26:\n        slice_sequence(seq, 16)\n    else:\n        slice_sequence(seq, 23)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X), len(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lens = [len(x) for x in X]\nmax(lens), min(lens), np.mean(lens), np.median(lens)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\n\n# We should pad our sequences with 0 values, so they all will have the same length\nX = pad_sequences(X, maxlen=maxlen)\ny = np.array(y)\nX.shape, y.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's define the model architecture"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Input, Embedding, SpatialDropout1D, CuDNNLSTM, Dropout, Dense\nfrom keras.models import Model\n\n# Let's set random seed\nimport tensorflow as tf\ntf.set_random_seed(42)\nnp.random.seed(42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.categ_id.unique().size + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_features = train_data.categ_id.unique().size + 1\nembed_size = 64\n\ndef lstm128():\n    inp = Input(shape=(maxlen,))\n    x = Embedding(max_features, embed_size)(inp)\n    x = SpatialDropout1D(0.05)(x)\n    x = CuDNNLSTM(128, return_sequences=False)(x)\n    x = Dropout(0.02)(x)\n    outp = Dense(max_features, activation=\"softmax\")(x)\n    model = Model(inputs=inp, outputs=outp)\n    model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop',\n                  metrics=['sparse_categorical_accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's train our film recommender system\nmodel = lstm128()\nmodel.fit(X, y, batch_size=2048*4, epochs=25, verbose=True, validation_split=0.01, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_json = model.to_json()\nwith open('lstm128.json', 'w') as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights('lstm128.h5')\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"sequences_test = sequences.apply(lambda x: x[-maxlen:])\nsequences_test = sequences_test.apply(lambda x: [0 for i in range(maxlen - len(x))] + x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_users_in_sequences = sorted(set(sequences_test.index) & set(sample_submission.user_id))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = np.array(sequences_test[test_users_in_sequences].tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom itertools import chain\nbatch_size = 2048*8\nn_batches = int(X_test.shape[0]/batch_size) + 1\npreds = []\n\nfor batch_ind in tqdm.tqdm(range(n_batches)):\n    batch = X_test[batch_ind*batch_size: (batch_ind + 1)*batch_size]\n    curr_preds = model.predict(batch)\n    curr_preds = np.argsort(-curr_preds)[:, :10]\n    curr_preds = [[cat_to_element_uid[x] for x in row] for row in curr_preds]\n    preds.append([' '.join(map(lambda x: str(x), row)) for row in curr_preds])\n    \npreds = list(chain(*preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.index = sample_submission.user_id\nsample_submission.primary_video_id[test_users_in_sequences] = preds\nsample_submission.to_csv('submission_lstm.csv', header=True, index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}