{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:32:00.284174Z","iopub.execute_input":"2023-09-06T16:32:00.284485Z","iopub.status.idle":"2023-09-06T16:32:02.35081Z","shell.execute_reply.started":"2023-09-06T16:32:00.284462Z","shell.execute_reply":"2023-09-06T16:32:02.349991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Data inspection","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/advertising-dataset/advertising.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:32:04.828359Z","iopub.execute_input":"2023-09-06T16:32:04.828893Z","iopub.status.idle":"2023-09-06T16:32:04.879167Z","shell.execute_reply.started":"2023-09-06T16:32:04.828859Z","shell.execute_reply":"2023-09-06T16:32:04.878166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-05T10:08:54.773603Z","iopub.execute_input":"2023-09-05T10:08:54.773945Z","iopub.status.idle":"2023-09-05T10:08:54.808509Z","shell.execute_reply.started":"2023-09-05T10:08:54.773916Z","shell.execute_reply":"2023-09-05T10:08:54.807425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-05T10:08:57.62737Z","iopub.execute_input":"2023-09-05T10:08:57.630833Z","iopub.status.idle":"2023-09-05T10:08:57.657153Z","shell.execute_reply.started":"2023-09-05T10:08:57.630787Z","shell.execute_reply":"2023-09-05T10:08:57.655694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-09-05T10:09:00.284472Z","iopub.execute_input":"2023-09-05T10:09:00.284826Z","iopub.status.idle":"2023-09-05T10:09:00.294481Z","shell.execute_reply.started":"2023-09-05T10:09:00.284801Z","shell.execute_reply":"2023-09-05T10:09:00.293136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_columns = list(df.select_dtypes(include=np.number).columns)\nnum=int(len(num_columns)/2) if int(len(num_columns)/2)>1 else 2\nfig ,ax = plt.subplots(num,num,figsize=(12,8))\nfor j in range(num):\n    for i in range(num):\n        try:\n            sns.histplot(data=df,x=num_columns[0],kde=True,bins=20,ax=ax[j][i])\n            num_columns.pop(0)\n        except:\n            fig.delaxes(ax=ax[j][i])\nfig.suptitle('Histograms of numerical columns', fontsize=16)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-05T16:29:38.034224Z","iopub.execute_input":"2023-09-05T16:29:38.034619Z","iopub.status.idle":"2023-09-05T16:29:39.113561Z","shell.execute_reply.started":"2023-09-05T16:29:38.034591Z","shell.execute_reply":"2023-09-05T16:29:39.112389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_columns = list(df.select_dtypes(include=np.number).columns)\nnum=int(len(num_columns)/2) if int(len(num_columns)/2)>1 else 2\nfig ,ax = plt.subplots(num,num,figsize=(12,8))\nfor j in range(num):\n    for i in range(num):\n        try:\n            sns.boxplot(data=df,x=num_columns[0],ax=ax[j][i])\n            num_columns.pop(0)\n        except:\n            fig.delaxes(ax=ax[j][i])\nfig.suptitle('Boxplots of numerical columns', fontsize=16)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:33:06.735987Z","iopub.execute_input":"2023-09-06T16:33:06.736345Z","iopub.status.idle":"2023-09-06T16:33:07.187842Z","shell.execute_reply.started":"2023-09-06T16:33:06.736322Z","shell.execute_reply":"2023-09-06T16:33:07.186699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Transforming the Data","metadata":{}},{"cell_type":"markdown","source":"**I will use this transformed data with Box-cox method to check that if it follows the assumptions better than original data**","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler,MinMaxScaler,PowerTransformer,FunctionTransformer\npt = PowerTransformer()\npt.fit(df)\ndf_pt = pt.transform(df)\ndf_pt = pd.DataFrame(df_pt,columns=df.columns)\ndf_pt.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:33:13.756025Z","iopub.execute_input":"2023-09-06T16:33:13.756437Z","iopub.status.idle":"2023-09-06T16:33:13.85552Z","shell.execute_reply.started":"2023-09-06T16:33:13.756407Z","shell.execute_reply":"2023-09-06T16:33:13.853601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_columns = list(df_pt.select_dtypes(include=np.number).columns)\nnum=int(len(num_columns)/2) if int(len(num_columns)/2)>1 else 2\nfig ,ax = plt.subplots(num,num,figsize=(12,8))\nfor j in range(num):\n    for i in range(num):\n        try:\n            sns.histplot(data=df_pt,x=num_columns[0],kde=True,bins=20,ax=ax[j][i])\n            num_columns.pop(0)\n        except:\n            fig.delaxes(ax=ax[j][i])\nfig.suptitle('Histograms of numerical columns of transformed data', fontsize=16)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:33:30.866091Z","iopub.execute_input":"2023-09-06T16:33:30.866457Z","iopub.status.idle":"2023-09-06T16:33:31.71616Z","shell.execute_reply.started":"2023-09-06T16:33:30.866433Z","shell.execute_reply":"2023-09-06T16:33:31.715233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_columns = list(df_pt.select_dtypes(include=np.number).columns)\nnum=int(len(num_columns)/2) if int(len(num_columns)/2)>1 else 2\nfig ,ax = plt.subplots(num,num,figsize=(12,8))\nfor j in range(num):\n    for i in range(num):\n        try:\n            sns.boxplot(data=df_pt,x=num_columns[0],ax=ax[j][i])\n            num_columns.pop(0)\n        except:\n            fig.delaxes(ax=ax[j][i])\nfig.suptitle('Boxplots of transformed data', fontsize=16)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:33:58.502195Z","iopub.execute_input":"2023-09-06T16:33:58.502552Z","iopub.status.idle":"2023-09-06T16:33:58.931257Z","shell.execute_reply.started":"2023-09-06T16:33:58.502524Z","shell.execute_reply":"2023-09-06T16:33:58.929998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Assumptions for Linear Regression","metadata":{}},{"cell_type":"markdown","source":"## 1.Linear relationship with Target variable","metadata":{}},{"cell_type":"markdown","source":"**According to first assumptin the relationship features and the target should be linearl. As the graph suggests that the TV is more linearly correlated with the Sales, so this will be the most important column in predicting Sales.**","metadata":{}},{"cell_type":"code","source":"sns.pairplot(df,y_vars='Sales')\nprint('correlation of features with the sale')\nprint(df.corr()['Sales'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:35:56.872822Z","iopub.execute_input":"2023-09-06T16:35:56.873167Z","iopub.status.idle":"2023-09-06T16:35:57.72482Z","shell.execute_reply.started":"2023-09-06T16:35:56.873143Z","shell.execute_reply":"2023-09-06T16:35:57.723398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.Multicollinearity","metadata":{}},{"cell_type":"markdown","source":"**Multicollinearity occurs when two or more predictor variables in a regression model are highly correlated, meaning they do not provide unique or independent information in the regression model. This can cause problems when fitting and interpreting the regression model.\nWhen two or more predictor variables are highly correlated, it becomes difficult to change one variable without changing another. This makes it difficult for the regression model to estimate the relationship between each predictor variable and the response variable independently**","metadata":{}},{"cell_type":"markdown","source":"### Detection Method","metadata":{}},{"cell_type":"markdown","source":"**The most common way to detect multicollinearity is by using the variance inflation factor (VIF), which measures the correlation and strength of correlation between the predictor variables in a regression model. VIF values higher than 10 indicate that multicollinearity is a problem. VIF should be close to 1 and is good if less than 4 generally if greater than 4 it suggest weak multicollinearity**\n\n**If you detect multicollinearity, you can resolve it by:**\n\n* **Removing one or more of the highly correlated variables.**\n* **Linearly combining the predictor variables in some way, such as adding or subtracting them from one way.**\n* **Performing an analysis that is designed to account for highly correlated variables such as principal component analysis or partial least squares (PLS) regression**","metadata":{}},{"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:37:09.413159Z","iopub.execute_input":"2023-09-06T16:37:09.413471Z","iopub.status.idle":"2023-09-06T16:37:09.553592Z","shell.execute_reply.started":"2023-09-06T16:37:09.413449Z","shell.execute_reply":"2023-09-06T16:37:09.551985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vif = []\nX = df.drop('Sales',axis=1)\nfor i in range(X.shape[1]):\n    vif.append(variance_inflation_factor(X, i))\npd.DataFrame({'vif': vif}, index=df.columns[0:3])","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:37:11.596797Z","iopub.execute_input":"2023-09-06T16:37:11.597195Z","iopub.status.idle":"2023-09-06T16:37:11.614837Z","shell.execute_reply.started":"2023-09-06T16:37:11.597166Z","shell.execute_reply":"2023-09-06T16:37:11.614137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### For transformed data","metadata":{}},{"cell_type":"code","source":"vif = []\nX = df_pt.drop('Sales',axis=1)\nfor i in range(X.shape[1]):\n    vif.append(variance_inflation_factor(X, i))\npd.DataFrame({'vif': vif}, index=df.columns[0:3])","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:37:15.723964Z","iopub.execute_input":"2023-09-06T16:37:15.724411Z","iopub.status.idle":"2023-09-06T16:37:15.740929Z","shell.execute_reply.started":"2023-09-06T16:37:15.724381Z","shell.execute_reply":"2023-09-06T16:37:15.739864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Transformed data perfomed way better than the original.**","metadata":{}},{"cell_type":"markdown","source":"### Another technique","metadata":{"execution":{"iopub.status.busy":"2023-09-05T12:33:49.231389Z","iopub.execute_input":"2023-09-05T12:33:49.231817Z","iopub.status.idle":"2023-09-05T12:33:49.239913Z","shell.execute_reply.started":"2023-09-05T12:33:49.231779Z","shell.execute_reply":"2023-09-05T12:33:49.238204Z"}}},{"cell_type":"markdown","source":"**The correlation of independent columns should be very close to zero we only have radio and newspaper that are showing some relation to each other. We can drop Newspaper because it has a correlation of only 0.15 with Sales but keeping it will not cause much problem as the data is small we will compare the results by both ways in model building section**","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1,2,figsize=(15,5))\nsns.heatmap(df.drop('Sales',axis=1).corr(),annot=True,cmap='coolwarm',ax=ax[0])\nsns.heatmap(df_pt.drop('Sales',axis=1).corr(),annot=True,cmap='coolwarm',ax=ax[1])\nax[0].set_title('Original data')\nax[1].set_title('transformed data')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:38:45.073049Z","iopub.execute_input":"2023-09-06T16:38:45.073409Z","iopub.status.idle":"2023-09-06T16:38:45.526761Z","shell.execute_reply.started":"2023-09-06T16:38:45.073387Z","shell.execute_reply":"2023-09-06T16:38:45.525609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.Normality of Residuals","metadata":{}},{"cell_type":"markdown","source":"**In linear regression analysis, one of the key assumptions is the normality of residuals, which is also known as the assumption of normality. This assumption states that the residuals(the differences between the observed and predicted values) should follow a normal distribution**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nX= df.drop('Sales',axis=1)\ny= df['Sales']\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\nlr = LinearRegression()\nlr.fit(X_train,y_train)\ny_pred = lr.predict(X_test)\nresiduals = y_test - y_pred","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:38:51.997346Z","iopub.execute_input":"2023-09-06T16:38:51.997751Z","iopub.status.idle":"2023-09-06T16:38:52.29053Z","shell.execute_reply.started":"2023-09-06T16:38:51.997719Z","shell.execute_reply":"2023-09-06T16:38:52.288728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X= df_pt.drop('Sales',axis=1)\ny= df_pt['Sales']\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\nlr = LinearRegression()\nlr.fit(X_train,y_train)\ny_pred_pt = lr.predict(X_test)\nresiduals_pt = y_test - y_pred_pt","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:38:54.9689Z","iopub.execute_input":"2023-09-06T16:38:54.96928Z","iopub.status.idle":"2023-09-06T16:38:54.983962Z","shell.execute_reply.started":"2023-09-06T16:38:54.969256Z","shell.execute_reply":"2023-09-06T16:38:54.982476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Graphical Method by KDE and QQ-plot","metadata":{}},{"cell_type":"code","source":"fig ,ax = plt.subplots(1,2,figsize=(8,5))\nsns.kdeplot(residuals,ax=ax[0])\nsns.kdeplot(residuals_pt,ax=ax[1])\nax[0].set_title('Original data')\nax[1].set_title('transformed data')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:38:59.487859Z","iopub.execute_input":"2023-09-06T16:38:59.488221Z","iopub.status.idle":"2023-09-06T16:38:59.874932Z","shell.execute_reply.started":"2023-09-06T16:38:59.488195Z","shell.execute_reply":"2023-09-06T16:38:59.873334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy import stats\nfig, ax = plt.subplots(1,2,figsize=(12,6))\nstats.probplot(residuals, plot=ax[0], fit=True)\nstats.probplot(residuals_pt, plot=ax[1] , fit=True)\nax[0].set_title('Original data')\nax[1].set_title('transformed data')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:39:03.474011Z","iopub.execute_input":"2023-09-06T16:39:03.474486Z","iopub.status.idle":"2023-09-06T16:39:03.817238Z","shell.execute_reply.started":"2023-09-06T16:39:03.474454Z","shell.execute_reply":"2023-09-06T16:39:03.816358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Statistical method Shapiro-Wilk Test","metadata":{}},{"cell_type":"code","source":"from scipy.stats import shapiro\nstat, p = shapiro(residuals)\nprint('stat=%.3f, p=%.3f' % (stat, p))\n\nif p > 0.05:\n    print('Probably Gaussian')\nelse:\n    print('Probably not Gaussian')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:39:09.026129Z","iopub.execute_input":"2023-09-06T16:39:09.026479Z","iopub.status.idle":"2023-09-06T16:39:09.034758Z","shell.execute_reply.started":"2023-09-06T16:39:09.026454Z","shell.execute_reply":"2023-09-06T16:39:09.033549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import shapiro\nstat, p = shapiro(residuals_pt)\nprint('stat=%.3f, p=%.3f' % (stat, p))\n\nif p > 0.05:\n    print('Probably Gaussian')\nelse:\n    print('Probably not Gaussian')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:39:12.165175Z","iopub.execute_input":"2023-09-06T16:39:12.165533Z","iopub.status.idle":"2023-09-06T16:39:12.172015Z","shell.execute_reply.started":"2023-09-06T16:39:12.165508Z","shell.execute_reply":"2023-09-06T16:39:12.170969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**All of these methods suggests that residuals of our original data are more normally distributed than the transformed but we can work with the transformed data it is also guassian**","metadata":{}},{"cell_type":"markdown","source":"## 4. Homoscedasticity ","metadata":{}},{"cell_type":"markdown","source":"**Homoscedasticity is one of the core assumptions of linear regression in which the variance of the residuals is assumed to be constant. In other words, the error terms should be of constant variance in the graph or errors vs. the predictor variable, and the values of the error terms should not change as the value of the predictor variable changes**\n\n**The opposite of homoscedasticity is heteroscedasticity, where the error terms or the residuals are not constant as per the predictor variable, and the error terms change rapidly as the value of the predictor variable changes**","metadata":{}},{"cell_type":"markdown","source":"### In simple term","metadata":{}},{"cell_type":"markdown","source":"**There should not be any pattern around zero in the following scatter plot of predicted values vs residuals. If the points in the scatter plot exhibit a pattern, then heteroscedasticity is present and you can try follwing methods to solve**\n* **Transform the response variable**\n* **Redefine the response variable**\n* **Use weighted regression**\n","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1,2,figsize=(12,5))\nsns.scatterplot(x=y_pred,y=residuals, ax=ax[0])\nsns.scatterplot(y=residuals_pt,x=y_pred_pt, ax=ax[1])\nax[0].set(xlabel='predicted values',ylabel='residuals')\nax[1].set(xlabel='predicted values',ylabel='residuals')\nax[0].set_title('Original data')\nax[1].set_title('transformed data')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:40:27.023628Z","iopub.execute_input":"2023-09-06T16:40:27.024019Z","iopub.status.idle":"2023-09-06T16:40:27.433387Z","shell.execute_reply.started":"2023-09-06T16:40:27.023989Z","shell.execute_reply":"2023-09-06T16:40:27.431752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Graphically there seems no clear pattern but it is better to use a statistical test if you want to confirm**","metadata":{}},{"cell_type":"markdown","source":"### Statistical Method White's Test","metadata":{}},{"cell_type":"markdown","source":"**The null hypothesis is that there is no heteroscedasticity if p-value is less than 0.05 then the null hypothesis is rejected indicating heteroscedasticity**","metadata":{}},{"cell_type":"code","source":"import statsmodels.api as sm\nimport statsmodels.formula.api as smf\nmodel = smf.ols('Sales ~ TV + Radio + Newspaper', data=df).fit()\n# for transformed data\nmodel_pt = smf.ols('Sales ~ TV + Radio + Newspaper', data=df_pt).fit()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:40:32.201258Z","iopub.execute_input":"2023-09-06T16:40:32.202613Z","iopub.status.idle":"2023-09-06T16:40:33.939033Z","shell.execute_reply.started":"2023-09-06T16:40:32.20252Z","shell.execute_reply":"2023-09-06T16:40:33.937966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.stats.diagnostic import het_white\n\n# Perform White's test\nwhite_test = het_white(model.resid, model.model.exog)\n# Print the results of White's test\nlabels = ['Test Statistic', 'Test Statistic p-value', 'F-Statistic', 'F-Test p-value']\nprint(dict(zip(labels, white_test)))","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:40:38.793317Z","iopub.execute_input":"2023-09-06T16:40:38.793827Z","iopub.status.idle":"2023-09-06T16:40:38.80139Z","shell.execute_reply.started":"2023-09-06T16:40:38.793791Z","shell.execute_reply":"2023-09-06T16:40:38.80021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### For transformed data","metadata":{}},{"cell_type":"code","source":"white_test = het_white(model_pt.resid, model_pt.model.exog)\n# Print the results of White's test\nlabels = ['Test Statistic', 'Test Statistic p-value', 'F-Statistic', 'F-Test p-value']\nprint(dict(zip(labels, white_test)))","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:43:45.710815Z","iopub.execute_input":"2023-09-06T16:43:45.711186Z","iopub.status.idle":"2023-09-06T16:43:45.719174Z","shell.execute_reply.started":"2023-09-06T16:43:45.711161Z","shell.execute_reply":"2023-09-06T16:43:45.717555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The rounded p-value upto 2 decimal places of White test for transformed data is 0.05 so we can keep the null hypothesis. So we will keep transformed data, maybe small p-value is because we have less data.**","metadata":{}},{"cell_type":"markdown","source":"## 5. Autocorrelation of Residuals","metadata":{}},{"cell_type":"markdown","source":"**We will use autocorrelation plot from the pandas plotting to check it.If the points in the plot fall randomly within the dashed lines and don't show a specific pattern, it suggests that there's no autocorrelation in the residuals. If the points fall in a specific pattern outside the dashed lines, it indicates autocorrelation.**","metadata":{}},{"cell_type":"code","source":"from pandas.plotting import autocorrelation_plot\n# Create the autocorrelation plot\nfig,ax=plt.subplots(1,2,figsize=(14,6))\nautocorrelation_plot(residuals,ax=ax[0])\nautocorrelation_plot(residuals_pt,ax=ax[1])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:43:59.575757Z","iopub.execute_input":"2023-09-06T16:43:59.576233Z","iopub.status.idle":"2023-09-06T16:43:59.977Z","shell.execute_reply.started":"2023-09-06T16:43:59.576202Z","shell.execute_reply":"2023-09-06T16:43:59.975659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Statistical method Durbin-Watson test","metadata":{}},{"cell_type":"markdown","source":"**To check the autocorrelation numerically we will use Durbin-Watson test**\n* **The test statistic is approximately equal to 2*(1-r), where r is the sample ACF of the residuals. Therefore, for r == 0, indicating no autocorrelation, the test statistic equals 2. The statistic ranges from 0 to 4, and a value close to 2 suggests there is no autocorrelation. If the statistic is significantly less than 2, there is evidence of positive autocorrelation, and if it's greater than 2, it suggests negative autocorrelation**.","metadata":{}},{"cell_type":"code","source":"model = smf.ols('Sales ~ TV + Radio + Newspaper', data=df).fit()\n\n# calculate Durbin-Watson statistic\ndw = sm.stats.durbin_watson(model.resid)\n\nprint(f'Durbin-Watson statistic for transformed data : {dw:.2f}')","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:44:04.196591Z","iopub.execute_input":"2023-09-06T16:44:04.197541Z","iopub.status.idle":"2023-09-06T16:44:04.214261Z","shell.execute_reply.started":"2023-09-06T16:44:04.197513Z","shell.execute_reply":"2023-09-06T16:44:04.212403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = smf.ols('Sales ~ TV + Radio + Newspaper', data=df_pt).fit()\n\n# calculate Durbin-Watson statistic\ndw = sm.stats.durbin_watson(model.resid)\nprint(f'Durbin-Watson statistic for transformed data : {dw:.2f}')","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:44:06.350014Z","iopub.execute_input":"2023-09-06T16:44:06.350455Z","iopub.status.idle":"2023-09-06T16:44:06.372369Z","shell.execute_reply.started":"2023-09-06T16:44:06.350424Z","shell.execute_reply":"2023-09-06T16:44:06.370983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**4/5 assumptions for linear regression supports our transformed data so we will build our final model on it.**\n\n**And if you want to read more about assumptions check the guide on statology https://www.statology.org/multiple-linear-regression-assumptions/**","metadata":{}},{"cell_type":"markdown","source":"# 3. Model Building","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:44:11.046057Z","iopub.execute_input":"2023-09-06T16:44:11.046481Z","iopub.status.idle":"2023-09-06T16:44:11.052754Z","shell.execute_reply.started":"2023-09-06T16:44:11.04645Z","shell.execute_reply":"2023-09-06T16:44:11.051232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X= df.drop(['Sales','Newspaper'],axis=1)\nX= df_pt.drop(['Sales'],axis=1)\ny= df_pt['Sales']\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:45:26.54443Z","iopub.execute_input":"2023-09-06T16:45:26.544815Z","iopub.status.idle":"2023-09-06T16:45:26.553989Z","shell.execute_reply.started":"2023-09-06T16:45:26.544784Z","shell.execute_reply":"2023-09-06T16:45:26.55264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = LinearRegression()\nlr.fit(X_train,y_train)\ny_pred = lr.predict(X_test)\nprint('MSE:',mean_squared_error(y_test,y_pred))\nprint('MAE:',mean_absolute_error(y_test,y_pred))\nprint('R2:',r2_score(y_test,y_pred))\nprint(f'Adjusted R2 score : {1 - (1-lr.score(X_test, y_test))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)}')","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:45:54.872531Z","iopub.execute_input":"2023-09-06T16:45:54.872889Z","iopub.status.idle":"2023-09-06T16:45:54.889305Z","shell.execute_reply.started":"2023-09-06T16:45:54.872864Z","shell.execute_reply":"2023-09-06T16:45:54.888039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now as I mentioned in assuption of multicollinearity that we will see results after dropping one of the features that are correlated. We will rop the feature that is most weakly correlated with the target i.e Newspaper**","metadata":{}},{"cell_type":"markdown","source":"### Dropping Newspaper to decrease multicollinearity","metadata":{}},{"cell_type":"code","source":"X= df_pt.drop(['Sales','Newspaper'],axis=1)\n# X= df.drop(['Sales'],axis=1)\ny= df_pt['Sales']\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:46:01.788902Z","iopub.execute_input":"2023-09-06T16:46:01.789326Z","iopub.status.idle":"2023-09-06T16:46:01.797806Z","shell.execute_reply.started":"2023-09-06T16:46:01.789293Z","shell.execute_reply":"2023-09-06T16:46:01.796172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = LinearRegression()\nlr.fit(X_train,y_train)\ny_pred = lr.predict(X_test)\nprint('MSE after dropping newspaper :',mean_squared_error(y_test,y_pred))\nprint('MAE after dropping newspaper :',mean_absolute_error(y_test,y_pred))\nprint('R2 after dropping newspaper :',r2_score(y_test,y_pred))\nprint(f'Adjusted R2 score after dropping newspaper : {1 - (1-lr.score(X_test, y_test))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)}')","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:46:05.140066Z","iopub.execute_input":"2023-09-06T16:46:05.140457Z","iopub.status.idle":"2023-09-06T16:46:05.157684Z","shell.execute_reply.started":"2023-09-06T16:46:05.140432Z","shell.execute_reply":"2023-09-06T16:46:05.156066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**And it improves the R-2 score. So if your data fulfill the assumptions then your model will be better. So try transforming your data always before performing Linear regression**","metadata":{}},{"cell_type":"markdown","source":"# 4. Regression visually","metadata":{}},{"cell_type":"markdown","source":"**Not only our model after dropping newspaper perform better but a dimension also reduces from 4D to 3D so we can now visually see whats happening**","metadata":{}},{"cell_type":"code","source":"coefs = lr.coef_\nintercept = lr.intercept_\nprint(f\"z = {coefs[0]:.3f}x + {coefs[1]:.3f}y + {intercept:.3f}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-06T11:37:08.642914Z","iopub.execute_input":"2023-09-06T11:37:08.643315Z","iopub.status.idle":"2023-09-06T11:37:08.649683Z","shell.execute_reply.started":"2023-09-06T11:37:08.643284Z","shell.execute_reply":"2023-09-06T11:37:08.648313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Our regression equation is\n### z = 0.897x + 0.288y + 0.011 ","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\nimport plotly.graph_objects as go","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:47:47.627274Z","iopub.execute_input":"2023-09-06T16:47:47.627673Z","iopub.status.idle":"2023-09-06T16:47:48.323264Z","shell.execute_reply.started":"2023-09-06T16:47:47.627642Z","shell.execute_reply":"2023-09-06T16:47:48.322269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_range = np.linspace(df_pt.iloc[:,0].min(), df_pt.iloc[:,0].max(), 10)\ny_range = np.linspace(df_pt.iloc[:,1].min(), df_pt.iloc[:,1].max(), 10)\nx_grid, y_grid = np.meshgrid(x_range, y_range)\nz_grid = lr.predict(np.array([x_grid.ravel(), y_grid.ravel()]).T).reshape(x_grid.shape)\nsurface = go.Surface(x=x_grid, y=y_grid, z=z_grid, colorscale='Viridis', opacity=0.8)\nscatter = go.Scatter3d(x=df_pt.iloc[:,0], y=df_pt.iloc[:,1], z=df_pt.iloc[:,-1], mode='markers', marker=dict(size=4, color='red'))\nlayout = go.Layout(scene=dict(xaxis_title='TV', yaxis_title='Radio', zaxis_title='Sales'))\nfig = go.Figure(data=[surface, scatter], layout=layout)\nfig.update_layout(\n    autosize=False,\n    width=1000,\n    height=800\n)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:48:01.586433Z","iopub.execute_input":"2023-09-06T16:48:01.586965Z","iopub.status.idle":"2023-09-06T16:48:02.630297Z","shell.execute_reply.started":"2023-09-06T16:48:01.586939Z","shell.execute_reply":"2023-09-06T16:48:02.629142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Kindly Upvote if you like and if you not suggest me some improvements","metadata":{}}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}