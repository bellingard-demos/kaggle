{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# In this Notebook we explore the Red Wine Dataset,Perform the Exploratory Data Analysis, Train 8 Regression models By Applying Grid Search CV and then Visualize the Results.","metadata":{}},{"cell_type":"markdown","source":"# About Red Wine Dataset\n\nThe dataset is pertaining to variations of Portuguese \"Vinho Verde\" wine. The source of additional information is the reference [Cortez et al., 2009].\n\nThe Dataset contain total 12 columns whose discription is as below:\n1. **fxed acidity:** The majority of acids found in wine are classified as fixed or nonvolatile, indicating that they don't evaporate easily. These acids play a significant role in shaping the wine's overall taste, mouthfeel, and balance. \n\n2. **volatile acidity:** Excessive levels of acetic acid in wine can result in an undesirable vinegar-like taste. The presence of acetic acid, when exceeding appropriate levels, negatively impacts the wine's flavor profile, leading to an unpleasant sensory experience reminiscent of vinegar. Proper control and monitoring of acetic acid content are crucial in winemaking to avoid compromising the overall quality and taste of the final product.\n\n3. **citric acid:** When present in minor amounts, citric acid can impart a sense of 'freshness' and enhance the flavor profile of wines. In small quantities, citric acid contributes to the wine's taste by adding a refreshing element.\n\n4. **residual sugar:** Residual Sugar refers to the sugar left in wine after fermentation cessation, and it's uncommon to come across wines with less than 1 gram per liter of residual sugar.\n\n5. **chlorides:** Chlorides in wine refer to the quantity of salt present in the beverage. This parameter helps measure the salt content in the wine, which can have an impact on its overall taste and flavor profile.\n\n6. **free sulphur dioxide:** Free sulfur dioxide in wine exists in a balance between molecular SO2 (as a dissolved gas) and bisulfite ion. This equilibrium helps prevent various wine-related issues and oxidation. The presence of free SO2 acts as a preservative, protecting the wine from spoilage and maintaining its freshness. \n\n7. **total sulfur dioxide:** in wine represents the combined quantity of both free and bound forms of SO2. In low concentrations, SO2 is usually not detectable in wine, but it becomes apparent when present in its free form. This compound serves as a preservative, safeguarding the wine from spoilage and oxidation.\n\n8. **density:** The density of wine is closely related to that of water and varies depending on the percentage of alcohol and sugar content. The specific gravity or density measurement can provide valuable information about the wine's composition and its alcohol and sugar levels. \n\n9. **ph:** The pH of wine indicates its level of acidity or basicity on a scale ranging from 0 (very acidic) to 14 (very basic). Typically, most wines fall within the pH range of 3 to 4. This measurement allows winemakers to understand and control the wine's acidity, which is crucial in determining its overall taste, stability, and how well it pairs with different foods.\n\n10. **sulphates:** Sulphates are wine additives that can increase the levels of sulfur dioxide gas (SO2), which acts as an antimicrobial agent and preservative. By adding sulfates to wine, winemakers enhance its ability to ward off unwanted microbial growth and oxidation, thus improving its shelf life and overall stability.\n\n11. **alcohol:**  Alcohol is a key component in wine, formed through the fermentation process when yeast converts sugar into ethanol and carbon dioxide. It plays a crucial role in defining a wine's character, affecting its body, aroma, and overall flavor profile. \n\n12. **quality:** The quality columns tells us how is the red wine quality depending on the concenterations of all other features/columns that are explained above.\n\nIn this notebook we predict the quality of red wine based on other features/columns.\n","metadata":{}},{"cell_type":"code","source":"# Importing all the necessary libraries and models used in the experiment.\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.svm import SVR\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:03.34157Z","iopub.execute_input":"2023-07-19T19:47:03.343026Z","iopub.status.idle":"2023-07-19T19:47:03.351847Z","shell.execute_reply.started":"2023-07-19T19:47:03.342967Z","shell.execute_reply":"2023-07-19T19:47:03.350487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataset read by pandas\ndf= pd.read_csv(\"/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:03.354431Z","iopub.execute_input":"2023-07-19T19:47:03.354808Z","iopub.status.idle":"2023-07-19T19:47:03.394413Z","shell.execute_reply.started":"2023-07-19T19:47:03.354777Z","shell.execute_reply":"2023-07-19T19:47:03.393072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"# Description of dataset\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:03.395793Z","iopub.execute_input":"2023-07-19T19:47:03.396107Z","iopub.status.idle":"2023-07-19T19:47:03.410481Z","shell.execute_reply.started":"2023-07-19T19:47:03.396079Z","shell.execute_reply":"2023-07-19T19:47:03.409479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:03.413087Z","iopub.execute_input":"2023-07-19T19:47:03.414238Z","iopub.status.idle":"2023-07-19T19:47:03.472892Z","shell.execute_reply.started":"2023-07-19T19:47:03.414198Z","shell.execute_reply":"2023-07-19T19:47:03.471747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To check the null values in the dataset\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:03.474271Z","iopub.execute_input":"2023-07-19T19:47:03.474597Z","iopub.status.idle":"2023-07-19T19:47:03.484207Z","shell.execute_reply.started":"2023-07-19T19:47:03.474568Z","shell.execute_reply":"2023-07-19T19:47:03.483127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dataset shape\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:03.485686Z","iopub.execute_input":"2023-07-19T19:47:03.486025Z","iopub.status.idle":"2023-07-19T19:47:03.49746Z","shell.execute_reply.started":"2023-07-19T19:47:03.485996Z","shell.execute_reply":"2023-07-19T19:47:03.496183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To check the duplicate values in the dataset\ndf.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:03.499084Z","iopub.execute_input":"2023-07-19T19:47:03.499397Z","iopub.status.idle":"2023-07-19T19:47:03.512431Z","shell.execute_reply.started":"2023-07-19T19:47:03.49937Z","shell.execute_reply":"2023-07-19T19:47:03.511231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove the duplicated rows from the dataset\ndf.drop_duplicates(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:03.514155Z","iopub.execute_input":"2023-07-19T19:47:03.514467Z","iopub.status.idle":"2023-07-19T19:47:03.523134Z","shell.execute_reply.started":"2023-07-19T19:47:03.514439Z","shell.execute_reply":"2023-07-19T19:47:03.521914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the shape of dataset after removing duplicates\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:03.524836Z","iopub.execute_input":"2023-07-19T19:47:03.525208Z","iopub.status.idle":"2023-07-19T19:47:03.535312Z","shell.execute_reply.started":"2023-07-19T19:47:03.525173Z","shell.execute_reply":"2023-07-19T19:47:03.533736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation -- tells us the relationship between two variables( here - sign  indicate the negative correlation and + sign indicate the positive correlation)\ncorr_matrix=df.corr()\ncorr_matrix","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:03.541418Z","iopub.execute_input":"2023-07-19T19:47:03.541826Z","iopub.status.idle":"2023-07-19T19:47:03.568194Z","shell.execute_reply.started":"2023-07-19T19:47:03.54178Z","shell.execute_reply":"2023-07-19T19:47:03.567289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets make the correlation matrix for easy visualisation \nplt.figure(figsize=(10,7))\nsns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt='.2f')\nplt.title(\"Correlation Matrix\", fontsize=14)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:03.569447Z","iopub.execute_input":"2023-07-19T19:47:03.570019Z","iopub.status.idle":"2023-07-19T19:47:04.414994Z","shell.execute_reply.started":"2023-07-19T19:47:03.569985Z","shell.execute_reply":"2023-07-19T19:47:04.413682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets make the histogram containing all the columns\ndf.hist(bins=10, figsize=(10,11))\nplt.suptitle(\"Data Distribution of all the columns\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:04.416581Z","iopub.execute_input":"2023-07-19T19:47:04.41696Z","iopub.status.idle":"2023-07-19T19:47:06.656143Z","shell.execute_reply.started":"2023-07-19T19:47:04.416928Z","shell.execute_reply":"2023-07-19T19:47:06.654875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's visulause the percentile and median base distribution (Boxplot helps us to see the outliers in the dataset)\ndf.boxplot(column=df.columns.tolist(), figsize=(20,20), grid=True, rot=45, fontsize=16)\nplt.suptitle(\"Percentile and Median base distribution of all the columns\", fontsize=25)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:06.658024Z","iopub.execute_input":"2023-07-19T19:47:06.658463Z","iopub.status.idle":"2023-07-19T19:47:07.335717Z","shell.execute_reply.started":"2023-07-19T19:47:06.658428Z","shell.execute_reply":"2023-07-19T19:47:07.334502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Detecting Outliers from Dataset","metadata":{}},{"cell_type":"code","source":"# Detecting outliers in daatset\ncolumns=df.columns.tolist()\noutliers=[]\n\nfor col in columns:\n    q1=np.percentile(df[col], 1)\n    q3=np.percentile(df[col],99)\n    \n    print(\"col\", col)\n    \n    for pos in range(len(df)):\n        if df[col].iloc[pos] > q3 or df[col].iloc[pos]< q1:\n            outliers.append(pos)\n            \n    print(outliers)","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:07.337483Z","iopub.execute_input":"2023-07-19T19:47:07.337843Z","iopub.status.idle":"2023-07-19T19:47:07.955868Z","shell.execute_reply.started":"2023-07-19T19:47:07.337811Z","shell.execute_reply":"2023-07-19T19:47:07.954833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing the duplicte values from outliers list\noutliers_set= set(outliers)\nfinal_outliers=list(outliers_set)","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:07.957214Z","iopub.execute_input":"2023-07-19T19:47:07.957636Z","iopub.status.idle":"2023-07-19T19:47:07.96272Z","shell.execute_reply.started":"2023-07-19T19:47:07.957605Z","shell.execute_reply":"2023-07-19T19:47:07.961425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ratio (tell us the percentage of outliers find in the dataset)\nratio_outliers=len(final_outliers)/len(df)\nratio_outliers*100","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:07.964073Z","iopub.execute_input":"2023-07-19T19:47:07.964465Z","iopub.status.idle":"2023-07-19T19:47:07.97702Z","shell.execute_reply.started":"2023-07-19T19:47:07.964437Z","shell.execute_reply":"2023-07-19T19:47:07.975824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop the outliers from our dataset\ndf.drop(df.index[final_outliers], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:07.978517Z","iopub.execute_input":"2023-07-19T19:47:07.978867Z","iopub.status.idle":"2023-07-19T19:47:07.989543Z","shell.execute_reply.started":"2023-07-19T19:47:07.978837Z","shell.execute_reply":"2023-07-19T19:47:07.988286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# length of dataset after removing outliers \nlen(df)","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:07.991649Z","iopub.execute_input":"2023-07-19T19:47:07.992041Z","iopub.status.idle":"2023-07-19T19:47:08.003553Z","shell.execute_reply.started":"2023-07-19T19:47:07.992008Z","shell.execute_reply":"2023-07-19T19:47:08.00267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here we clearly see the impact between the boxplots after removing the outliers from the dataset.\ndf.boxplot(column=df.columns.tolist(), figsize=(20,20), grid=True, rot=45, fontsize=16 )\nplt.suptitle(\"Percentile and Median base distribution of all the columns after removing Outliers \", fontsize=25)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:08.004872Z","iopub.execute_input":"2023-07-19T19:47:08.005849Z","iopub.status.idle":"2023-07-19T19:47:08.65046Z","shell.execute_reply.started":"2023-07-19T19:47:08.005768Z","shell.execute_reply":"2023-07-19T19:47:08.649279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split the dataset into train and  test set","metadata":{}},{"cell_type":"code","source":"# Split the data into train and test split and we use 20 percent data for testing\nx_train,x_test,y_train,y_test= train_test_split(df.drop(\"quality\", axis=1),\n                                                df[\"quality\"],\n                                                test_size=0.2,\n                                                random_state=42)\nx_train.shape,x_test.shape,y_train.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:08.651894Z","iopub.execute_input":"2023-07-19T19:47:08.652228Z","iopub.status.idle":"2023-07-19T19:47:08.666194Z","shell.execute_reply.started":"2023-07-19T19:47:08.652199Z","shell.execute_reply":"2023-07-19T19:47:08.665208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing step","metadata":{}},{"cell_type":"code","source":"# Data Preprocessing (--normalise the values of dataset)\nstd= StandardScaler()\nx_train= std.fit_transform(x_train)  \nx_test=std.transform(x_test)","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:08.668128Z","iopub.execute_input":"2023-07-19T19:47:08.668445Z","iopub.status.idle":"2023-07-19T19:47:08.684583Z","shell.execute_reply.started":"2023-07-19T19:47:08.668417Z","shell.execute_reply":"2023-07-19T19:47:08.683276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating 8 Regression Models that used in the Experiment","metadata":{}},{"cell_type":"code","source":"# Defining Models\nmodels=[\n        LinearRegression(),\n        RandomForestRegressor(),\n        DecisionTreeRegressor(),\n        GradientBoostingRegressor(),\n        SVR(),\n        Lasso(),\n        Ridge(),\n        ElasticNet()\n        \n       \n]","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:08.685867Z","iopub.execute_input":"2023-07-19T19:47:08.686201Z","iopub.status.idle":"2023-07-19T19:47:08.697717Z","shell.execute_reply.started":"2023-07-19T19:47:08.686172Z","shell.execute_reply":"2023-07-19T19:47:08.696741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating the Parameters List for all Regression Models","metadata":{}},{"cell_type":"code","source":"# Defining parameters\nLinear_param={'n_jobs':[-1]}\n              \n\nRandom_param={'n_estimators':[100,200],\n              'max_depth':[6,8],\n              'min_samples_split':[2,4], \n              'criterion':['squared_error'],\n                                       }\n                      \n                                       \nDecsion_param={'splitter':['best'], \n               'max_depth':[8,10], \n               'min_samples_split':[2],\n               'criterion':['squared_error'], \n                                        \n              }           \n                                       \ngradient_param={'n_estimators':[100,200], \n                   'learning_rate':[0.1, 0.01,0.001],\n                   'max_depth':[8,10],\n                   'min_samples_leaf':[2,4,5],\n                   'loss':['squared_error'],\n                    }\n                   \n        \n        \nSVR_param={'kernel':['rbf','poly'], \n      'gamma':['scale', 'auto'],\n    }\n          \nLasso_param={'alpha':[1.0,1.1],\n             'max_iter':[1000,1200],\n             'selection':['cyclic', 'random']\n}\n\nRidge_param={ 'alpha':[1.0,1.1],\n             'max_iter':[1000,1200],\n             'solver':['auto','svd','lsqr']\n    \n}\n\nElasticNet_param={'alpha':[1.0,1.1],\n                 'max_iter':[1000,1400],\n                 'selection':['cyclic', 'random']\n    \n}\n\nparameters=[ \n            Linear_param,\n            Random_param,\n            Decsion_param,\n            gradient_param,\n            SVR_param,\n            Lasso_param,\n            Ridge_param,\n            ElasticNet_param\n            ]\n                            ","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:08.699625Z","iopub.execute_input":"2023-07-19T19:47:08.700613Z","iopub.status.idle":"2023-07-19T19:47:08.714493Z","shell.execute_reply.started":"2023-07-19T19:47:08.700569Z","shell.execute_reply":"2023-07-19T19:47:08.713332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Apply GridSearchCV by passing all models and their parameters list","metadata":{}},{"cell_type":"code","source":"# Train the models using GridSearchCV\nresult={}\n    \nfor i in range(len(models)):\n    temp = []\n    regressor = GridSearchCV(models[i], parameters[i], cv=2, scoring=\"r2\", n_jobs=-1).fit(x_train, y_train)    # fitting the object\n    models[i] = models[i].__class__.__name__\n    best_parameters = regressor.best_params_\n    y_pred = regressor.predict(x_test)\n    mse = mean_squared_error(y_test, y_pred)\n    temp.append(mse)\n    result[f\"{models[i]}\"] = temp  \n","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:08.716304Z","iopub.execute_input":"2023-07-19T19:47:08.717181Z","iopub.status.idle":"2023-07-19T19:47:26.792465Z","shell.execute_reply.started":"2023-07-19T19:47:08.717138Z","shell.execute_reply":"2023-07-19T19:47:26.78943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Display the results of all models in a dictionary","metadata":{}},{"cell_type":"code","source":"result","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:26.795259Z","iopub.execute_input":"2023-07-19T19:47:26.799957Z","iopub.status.idle":"2023-07-19T19:47:26.820012Z","shell.execute_reply.started":"2023-07-19T19:47:26.79989Z","shell.execute_reply":"2023-07-19T19:47:26.818572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create a Dataframe for results ","metadata":{}},{"cell_type":"code","source":"final_results= pd.DataFrame(result)\nfinal_results=final_results.T\nfinal_results.columns = [\"MeanSquaredError\"]\nfinal_results","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:26.822Z","iopub.execute_input":"2023-07-19T19:47:26.822787Z","iopub.status.idle":"2023-07-19T19:47:26.8471Z","shell.execute_reply.started":"2023-07-19T19:47:26.822719Z","shell.execute_reply":"2023-07-19T19:47:26.845593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visulaise the Result","metadata":{}},{"cell_type":"code","source":"final_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:47:26.849411Z","iopub.execute_input":"2023-07-19T19:47:26.850355Z","iopub.status.idle":"2023-07-19T19:47:27.24778Z","shell.execute_reply.started":"2023-07-19T19:47:26.850287Z","shell.execute_reply":"2023-07-19T19:47:27.24641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" # Conclusions\n1. In the Exploratory Data Analysis, we came to know that the quality(target variable) is highly correlate with the alcohal(input feature) with the value of 0.48 followed by sulphates(0.25), which means these features plays very important role to predict the wine quality.\n2. With help of percentile capping we detect the outliers from our dataset and their are about 13% outliers in the dataset, this is visualised by boxplot with or without outliers.\n3. After performing the extensive experiment on the dataset using 8 different Regression Model, \nwe conclude that RandomForest Regressor has the least Mean Squared Error.","metadata":{}}]}