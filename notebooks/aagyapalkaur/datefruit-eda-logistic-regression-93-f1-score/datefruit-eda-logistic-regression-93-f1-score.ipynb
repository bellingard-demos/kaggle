{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Welcome to My Notebook\n","metadata":{}},{"cell_type":"markdown","source":"# In this notebook we are going to predict the class of Date Fruit with help of various Input Features.","metadata":{}},{"cell_type":"code","source":"# import all the necessary libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.svm import SVC\nimport matplotlib.pyplot as plt\nfrom xgboost import XGBClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler, LabelEncoder\nfrom sklearn.metrics import accuracy_score,roc_auc_score,precision_score, recall_score, f1_score\n\nimport warnings \nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:17.229694Z","iopub.execute_input":"2023-08-16T02:29:17.230233Z","iopub.status.idle":"2023-08-16T02:29:17.242898Z","shell.execute_reply.started":"2023-08-16T02:29:17.230187Z","shell.execute_reply":"2023-08-16T02:29:17.242094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the dataset\ndataframe= pd.read_excel(\"/kaggle/input/date-fruit-datasets/Date_Fruit_Datasets/Date_Fruit_Datasets.xlsx\")\ndataframe.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:17.305209Z","iopub.execute_input":"2023-08-16T02:29:17.305617Z","iopub.status.idle":"2023-08-16T02:29:18.063946Z","shell.execute_reply.started":"2023-08-16T02:29:17.30558Z","shell.execute_reply":"2023-08-16T02:29:18.062748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dataframe info\ndataframe.info()","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:18.066448Z","iopub.execute_input":"2023-08-16T02:29:18.066914Z","iopub.status.idle":"2023-08-16T02:29:18.082604Z","shell.execute_reply.started":"2023-08-16T02:29:18.066872Z","shell.execute_reply":"2023-08-16T02:29:18.081228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# describe the dataset\ndataframe.describe()","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:18.084074Z","iopub.execute_input":"2023-08-16T02:29:18.084423Z","iopub.status.idle":"2023-08-16T02:29:18.209529Z","shell.execute_reply.started":"2023-08-16T02:29:18.084384Z","shell.execute_reply":"2023-08-16T02:29:18.208427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the duplicate values in the dataset\ndataframe.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:18.212858Z","iopub.execute_input":"2023-08-16T02:29:18.213597Z","iopub.status.idle":"2023-08-16T02:29:18.227542Z","shell.execute_reply.started":"2023-08-16T02:29:18.213554Z","shell.execute_reply":"2023-08-16T02:29:18.226271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check Is there any null values in the dataset\ndataframe.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:18.229592Z","iopub.execute_input":"2023-08-16T02:29:18.230037Z","iopub.status.idle":"2023-08-16T02:29:18.242303Z","shell.execute_reply.started":"2023-08-16T02:29:18.229997Z","shell.execute_reply":"2023-08-16T02:29:18.240958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframe.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:18.243996Z","iopub.execute_input":"2023-08-16T02:29:18.244492Z","iopub.status.idle":"2023-08-16T02:29:18.257524Z","shell.execute_reply.started":"2023-08-16T02:29:18.244452Z","shell.execute_reply":"2023-08-16T02:29:18.256386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let see the correlation between features/columns\ncorrelation_matrix=dataframe.corr()\ncorrelation_matrix","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:18.259064Z","iopub.execute_input":"2023-08-16T02:29:18.259734Z","iopub.status.idle":"2023-08-16T02:29:18.322411Z","shell.execute_reply.started":"2023-08-16T02:29:18.259678Z","shell.execute_reply":"2023-08-16T02:29:18.321285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets visulalise the correlation matrix with the help of Heatmap","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,20))\nsns.heatmap(correlation_matrix, annot=True, fmt=\".1f\", cmap=\"YlGnBu\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:18.324105Z","iopub.execute_input":"2023-08-16T02:29:18.324806Z","iopub.status.idle":"2023-08-16T02:29:21.83207Z","shell.execute_reply.started":"2023-08-16T02:29:18.324764Z","shell.execute_reply":"2023-08-16T02:29:21.831027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check the dataset is balanced or not","metadata":{}},{"cell_type":"code","source":"dataframe.Class.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:21.833487Z","iopub.execute_input":"2023-08-16T02:29:21.844143Z","iopub.status.idle":"2023-08-16T02:29:21.858581Z","shell.execute_reply.started":"2023-08-16T02:29:21.844077Z","shell.execute_reply":"2023-08-16T02:29:21.857123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"dataframe[\"Class\"].value_counts().plot(kind=\"bar\", figsize=(6,4), rot=0, color=\"Blue\")","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:21.863187Z","iopub.execute_input":"2023-08-16T02:29:21.863575Z","iopub.status.idle":"2023-08-16T02:29:22.135567Z","shell.execute_reply.started":"2023-08-16T02:29:21.863544Z","shell.execute_reply":"2023-08-16T02:29:22.134762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets see the Data Distribution of all the columns","metadata":{}},{"cell_type":"code","source":"dataframe.hist(bins=12, figsize=(16,16), grid=True)\nplt.suptitle(\"Data Distribution of all the columns\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:22.137219Z","iopub.execute_input":"2023-08-16T02:29:22.137852Z","iopub.status.idle":"2023-08-16T02:29:28.081028Z","shell.execute_reply.started":"2023-08-16T02:29:22.13782Z","shell.execute_reply":"2023-08-16T02:29:28.079896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets Detect Outliers Using Box Plot\nHere we can only see the outliers in the feature names[Area, Perimeter, Major_axis, Minor_axis, Solidity, Convex_area, eccentricity, Compacteness and Roundness]","metadata":{}},{"cell_type":"code","source":"fig=plt.figure(figsize=(19,19))\n\nax=fig.add_subplot(331)\nsns.boxplot(data=dataframe, x=dataframe[\"Class\"], y=dataframe[\"AREA\"], hue=None ,color='c',ax=ax)\nax.set_title('Class vs Area', fontsize=16)\n\nax=fig.add_subplot(332)\nsns.boxplot(data=dataframe, x=dataframe[\"Class\"], y=dataframe[\"PERIMETER\"], hue=None ,color='red',ax=ax)\nax.set_title('Class vs Perimeter ', fontsize=16)\n\nax=fig.add_subplot(333)\nsns.boxplot(data=dataframe, x=dataframe[\"Class\"], y=dataframe[\"MAJOR_AXIS\"], hue=None ,color='yellow',ax=ax)\nax.set_title('Class vs Major_Axis', fontsize=16)\n\nax=fig.add_subplot(334)\nsns.boxplot(data=dataframe, x=dataframe[\"Class\"], y=dataframe[\"MINOR_AXIS\"], hue=None ,color='blue',ax=ax)\nax.set_title('Class vs Minor_Axis', fontsize=16)\n\nax=fig.add_subplot(335)\nsns.boxplot(data=dataframe, x=dataframe[\"Class\"], y=dataframe[\"SOLIDITY\"], hue=None ,color='purple',ax=ax)\nax.set_title('Class vs Solidity', fontsize=16)\n\nax=fig.add_subplot(336)\nsns.boxplot(data=dataframe, x=dataframe[\"Class\"], y=dataframe[\"CONVEX_AREA\"], hue=None ,color='violet',ax=ax)\nax.set_title('Class vs Convex_Area', fontsize=16)\n\nax=fig.add_subplot(337)\nsns.boxplot(data=dataframe, x=dataframe[\"Class\"], y=dataframe[\"ECCENTRICITY\"], hue=None ,color='green',ax=ax)\nax.set_title('Class vs Eccentricity', fontsize=16)\n\nax=fig.add_subplot(338)\nsns.boxplot(data=dataframe, x=dataframe[\"Class\"], y=dataframe[\"COMPACTNESS\"], hue=None ,color='grey',ax=ax)\nax.set_title('Class vs Compactess', fontsize=16)\n\nax=fig.add_subplot(339)\nsns.boxplot(data=dataframe, x=dataframe[\"Class\"], y=dataframe[\"ROUNDNESS\"], hue=None ,color='orange',ax=ax)\nax.set_title('Class vs Roundness', fontsize=16)\n\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:28.082604Z","iopub.execute_input":"2023-08-16T02:29:28.083706Z","iopub.status.idle":"2023-08-16T02:29:30.950799Z","shell.execute_reply.started":"2023-08-16T02:29:28.083662Z","shell.execute_reply":"2023-08-16T02:29:30.949587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Drop the columns that has Correlation equal to 1(Multicolinearity)","metadata":{}},{"cell_type":"code","source":"dataframe.drop([\"PERIMETER\",\"MAJOR_AXIS\",\"MINOR_AXIS\",\"CONVEX_AREA\",\"MeanRR\",\"ALLdaub4RR\",\"EntropyRG\"], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:30.952102Z","iopub.execute_input":"2023-08-16T02:29:30.952542Z","iopub.status.idle":"2023-08-16T02:29:30.960092Z","shell.execute_reply.started":"2023-08-16T02:29:30.952495Z","shell.execute_reply":"2023-08-16T02:29:30.958811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Divide the Dataset into Train and Test Set","metadata":{}},{"cell_type":"code","source":"def train_test_split_data(dataframe,target,test_size, random_state):\n    x_train,x_test, y_train, y_test= train_test_split(dataframe.drop([target], axis=1),\n                                                      dataframe[target],\n                                                      test_size=test_size,\n                                                      random_state=random_state,\n                                                      stratify=dataframe[target]\n                                                      )\n    \n    return x_train,x_test, y_train, y_test","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:30.961305Z","iopub.execute_input":"2023-08-16T02:29:30.961668Z","iopub.status.idle":"2023-08-16T02:29:30.971604Z","shell.execute_reply.started":"2023-08-16T02:29:30.961639Z","shell.execute_reply":"2023-08-16T02:29:30.970783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train,x_test, y_train, y_test= train_test_split_data(dataframe,target=\"Class\",test_size=0.3, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:30.973016Z","iopub.execute_input":"2023-08-16T02:29:30.976636Z","iopub.status.idle":"2023-08-16T02:29:30.991906Z","shell.execute_reply.started":"2023-08-16T02:29:30.976593Z","shell.execute_reply":"2023-08-16T02:29:30.990613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.shape,x_test.shape, y_train.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:30.993113Z","iopub.execute_input":"2023-08-16T02:29:30.993444Z","iopub.status.idle":"2023-08-16T02:29:31.005354Z","shell.execute_reply.started":"2023-08-16T02:29:30.993416Z","shell.execute_reply":"2023-08-16T02:29:31.00424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get the Numerical and Categorical Columns list","metadata":{}},{"cell_type":"code","source":"def get_numerical_and_categorical_columns(dataframe):\n    \n    numerical_cols = []\n    categorical_cols = []\n    for column in dataframe.columns:\n        if pd.api.types.is_numeric_dtype(dataframe[column]):\n            numerical_cols.append(column)\n        else:\n            categorical_cols.append(column)\n            \n    return numerical_cols, categorical_cols","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:31.007577Z","iopub.execute_input":"2023-08-16T02:29:31.00803Z","iopub.status.idle":"2023-08-16T02:29:31.017391Z","shell.execute_reply.started":"2023-08-16T02:29:31.007991Z","shell.execute_reply":"2023-08-16T02:29:31.016395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" numerical_cols, categorical_cols=get_numerical_and_categorical_columns(dataframe)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:31.01864Z","iopub.execute_input":"2023-08-16T02:29:31.019028Z","iopub.status.idle":"2023-08-16T02:29:31.031502Z","shell.execute_reply.started":"2023-08-16T02:29:31.018999Z","shell.execute_reply":"2023-08-16T02:29:31.030438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets Detect the outliers in the Training Data And Remove it","metadata":{}},{"cell_type":"code","source":"def Winsorization_Method(columns, x_train, y_train , a, b):\n    outliers=[]\n\n    for col in columns:\n        q1= np.percentile(x_train[col], a)\n        q2= np.percentile(x_train[col],b)\n        \n        for pos in range(len(x_train)):\n            if x_train[col].iloc[pos]>q2 or x_train[col].iloc[pos]<q1:\n                outliers.append(pos) \n                \n    outliers= set(outliers)                   # remove the duplicates from the outliers\n    outliers= list(outliers)\n    \n    ratio= round(len(outliers)/len(x_train)*100, 2)                       # Ratio of outliers\n    x_train.drop(x_train.index[outliers], inplace=True)    # remove the outliers from the training dataset\n    y_train.drop(y_train.index[outliers], inplace=True)\n    \n    \n    \n    return ratio, x_train, y_train","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:31.033171Z","iopub.execute_input":"2023-08-16T02:29:31.033896Z","iopub.status.idle":"2023-08-16T02:29:31.044743Z","shell.execute_reply.started":"2023-08-16T02:29:31.033864Z","shell.execute_reply":"2023-08-16T02:29:31.043675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ratio_of_outliers,x_train,y_train= Winsorization_Method(numerical_cols, x_train, y_train, a=0.2, b=99.2)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:31.046207Z","iopub.execute_input":"2023-08-16T02:29:31.046528Z","iopub.status.idle":"2023-08-16T02:29:31.669454Z","shell.execute_reply.started":"2023-08-16T02:29:31.0465Z","shell.execute_reply":"2023-08-16T02:29:31.668262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ratio_of_outliers","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:31.670855Z","iopub.execute_input":"2023-08-16T02:29:31.671191Z","iopub.status.idle":"2023-08-16T02:29:31.678322Z","shell.execute_reply.started":"2023-08-16T02:29:31.671161Z","shell.execute_reply":"2023-08-16T02:29:31.677146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.shape, y_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:31.680103Z","iopub.execute_input":"2023-08-16T02:29:31.680441Z","iopub.status.idle":"2023-08-16T02:29:31.693217Z","shell.execute_reply.started":"2023-08-16T02:29:31.680411Z","shell.execute_reply":"2023-08-16T02:29:31.692076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing\n1. All the features are numerical except the calss, Lets do the Numerical Encoding for numerical features\n2. And for class feature use the Categorical Encoding","metadata":{}},{"cell_type":"markdown","source":"# Numerical Encoding (Using Robust Scaler)","metadata":{}},{"cell_type":"code","source":"robust_scaler= RobustScaler()\nx_train=robust_scaler.fit_transform(x_train)\nx_test=robust_scaler.transform(x_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:31.694694Z","iopub.execute_input":"2023-08-16T02:29:31.695382Z","iopub.status.idle":"2023-08-16T02:29:31.717247Z","shell.execute_reply.started":"2023-08-16T02:29:31.695351Z","shell.execute_reply":"2023-08-16T02:29:31.716084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets do the Label Encoding on Target Variable","metadata":{}},{"cell_type":"code","source":"le = LabelEncoder()\ny_train=le.fit_transform(y_train)\ny_test=le.transform(y_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:31.719374Z","iopub.execute_input":"2023-08-16T02:29:31.719789Z","iopub.status.idle":"2023-08-16T02:29:31.725302Z","shell.execute_reply.started":"2023-08-16T02:29:31.719746Z","shell.execute_reply":"2023-08-16T02:29:31.724243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelling","metadata":{}},{"cell_type":"code","source":"def modelling(x_train, x_test, y_train, y_test):\n    # create the empty list to store the results \n    precision=[]\n    recall=[]\n    f1=[]\n\n\n    # Lets create the list of models\n    models=[LogisticRegression(),\n    GaussianNB(),\n    SVC(kernel=\"linear\"),\n    KNeighborsClassifier(n_neighbors=32),\n    DecisionTreeClassifier(criterion=\"gini\"),\n    RandomForestClassifier(n_estimators=200,criterion=\"gini\"),\n    XGBClassifier()\n     ]\n\n    # Let iterate over the list of models and train and predict it\n    for model in models:\n        model.fit(x_train, y_train)\n        y_pred = model.predict(x_test)\n        precision.append(precision_score(y_test, y_pred,average=\"micro\"))\n        recall.append(recall_score(y_test, y_pred, average=\"micro\"))\n        f1.append(f1_score(y_test, y_pred, average=\"micro\"))\n\n\n\n    model_names = ['LogisticRegression','GaussianNB','SVC','KNeighborsClassifier','DecisionTreeClassifier','RandomForestClassifier','XGBClassifier']\n    result_df = pd.DataFrame({'Recall':recall, 'Precision':precision, 'F1_Score':f1},index=model_names)\n    result_df=result_df.sort_values(by=\"Recall\", ascending=False)\n    return result_df","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:31.726952Z","iopub.execute_input":"2023-08-16T02:29:31.727375Z","iopub.status.idle":"2023-08-16T02:29:31.741954Z","shell.execute_reply.started":"2023-08-16T02:29:31.727345Z","shell.execute_reply":"2023-08-16T02:29:31.740576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_df= modelling(x_train, x_test, y_train, y_test)\nresult_df","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:31.743896Z","iopub.execute_input":"2023-08-16T02:29:31.744454Z","iopub.status.idle":"2023-08-16T02:29:33.006431Z","shell.execute_reply.started":"2023-08-16T02:29:31.744413Z","shell.execute_reply":"2023-08-16T02:29:33.005343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets visualize the Result","metadata":{}},{"cell_type":"code","source":"result_df.plot(kind=\"barh\", figsize=(10, 7), grid=True).legend(bbox_to_anchor=(1.2,1));","metadata":{"execution":{"iopub.status.busy":"2023-08-16T02:29:33.007649Z","iopub.execute_input":"2023-08-16T02:29:33.008075Z","iopub.status.idle":"2023-08-16T02:29:33.356096Z","shell.execute_reply.started":"2023-08-16T02:29:33.008046Z","shell.execute_reply":"2023-08-16T02:29:33.35496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ðŸš€ Hi Kagglers,\n\nI hope you enjoyed exploring my notebook! If you found the work insightful or helpful, I kindly invite you to show your support by giving it an upvote. Your appreciation fuels my motivation to continue sharing valuable insights with the community.\n\nMoreover, I believe in continuous improvement, and your feedback plays a crucial role in making my work even better. If you have any suggestions, comments, or thoughts, please don't hesitate to leave them in the comments section. Let's learn and grow together!\n\nThank you for being a part of this amazing journey. Here's to more exciting collaborations and knowledge sharing ahead. ðŸŒŸ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}