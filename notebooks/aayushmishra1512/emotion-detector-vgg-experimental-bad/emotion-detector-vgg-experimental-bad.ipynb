{"cells":[{"metadata":{"_uuid":"72efa413-e620-4cd1-a8dc-f4fd7d51a2ec","_cell_guid":"fb7c2aaf-783c-455e-aeca-16e741ec0205","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#importing all of our libraries and data\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport keras\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom tensorflow.keras.applications import VGG16, InceptionResNetV2, ResNet50, Xception","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#passing the path of the directory containing training and testing data\ntrain_dir = \"../input/fer2013/train\"\ntest_dir = \"../input/fer2013/test\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SIZE = 48 #defining the size of our image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#performing data augmentation on our data\ntrain_datagen = image.ImageDataGenerator(#rotation_range = 180,\n                                         width_shift_range = 0.1,\n                                         height_shift_range = 0.1,\n                                         #brightness_range = [0.1,1.1],\n                                         horizontal_flip = True,\n                                         #vertical_flip = True,\n                                         rescale = 1./255,\n                                         zoom_range = 0.2,\n                                         validation_split = 0.2\n                                        )\nvalidation_datagen = image.ImageDataGenerator(rescale = 1./255,\n                                             validation_split = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#taking the path of the directory and generating batches of our augmented data\ntrain_generator = train_datagen.flow_from_directory(directory = train_dir,\n                                                               target_size = (IMG_SIZE,IMG_SIZE),\n                                                               color_mode = \"grayscale\",\n                                                               class_mode = \"categorical\",\n                                                               batch_size = 64,\n                                                               #shuffle = False,\n                                                               subset = \"training\"\n)\n\nvalidation_generator = validation_datagen.flow_from_directory(directory = test_dir,\n                                                             target_size = (IMG_SIZE,IMG_SIZE),\n                                                             color_mode = \"grayscale\",\n                                                             class_mode = \"categorical\",\n                                                             batch_size = 64,\n                                                             #shuffle = True,\n                                                             subset = \"validation\"\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model = tf.keras.Sequential()\n#model.add(VGG16(include_top = False,weights = '../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',input_shape= (IMG_SIZE,IMG_SIZE,3)))\n#model.add(MaxPool2D(padding = 'same'))\n#model.add(BatchNormalization(axis=-1))\n#model.add(Flatten())\n#model.add(Dense(7,activation = 'softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64,(3,3),activation = 'relu',input_shape = (IMG_SIZE,IMG_SIZE,1),padding = 'same'),\n    tf.keras.layers.Conv2D(64,(3,3),activation = 'relu',padding = 'same'),\n    tf.keras.layers.MaxPool2D(pool_size=2,strides=2),\n    tf.keras.layers.Dropout(0.5),\n    \n    tf.keras.layers.Conv2D(128,(3,3),activation= 'relu',padding = 'same'),\n    tf.keras.layers.Conv2D(128,(3,3),activation= 'relu',padding = 'same'),\n    tf.keras.layers.MaxPool2D(pool_size=2,strides=2),\n    tf.keras.layers.Dropout(0.5),\n    \n    tf.keras.layers.Conv2D(256,(3,3),activation= 'relu',padding = 'same'),\n    tf.keras.layers.Conv2D(256,(3,3),activation= 'relu',padding = 'same'),\n    tf.keras.layers.Conv2D(256,(3,3),activation= 'relu',padding = 'same'),\n    tf.keras.layers.MaxPool2D(pool_size=2,strides=2),\n    tf.keras.layers.Dropout(0.5),\n    \n    tf.keras.layers.Conv2D(512,(3,3),activation= 'relu',padding = 'same'),\n    tf.keras.layers.Conv2D(512,(3,3),activation= 'relu',padding = 'same'),\n    tf.keras.layers.Conv2D(512,(3,3),activation= 'relu',padding = 'same'),\n    tf.keras.layers.MaxPool2D(pool_size=2,strides=2),\n    tf.keras.layers.Dropout(0.5),\n    \n    tf.keras.layers.Conv2D(512,(3,3),activation= 'relu',padding = 'same'),\n    tf.keras.layers.Conv2D(512,(3,3),activation= 'relu',padding = 'same'),\n    tf.keras.layers.Conv2D(512,(3,3),activation= 'relu',padding = 'same'),\n    tf.keras.layers.MaxPool2D(pool_size=2,strides=2),\n    tf.keras.layers.Dropout(0.5),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(4096,activation = 'relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(4096,activation = 'relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(7,activation = 'softmax')\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax\noptimizer = Adam(lr = 0.0001)\nmodel.compile(loss = \"categorical_crossentropy\",optimizer = optimizer,metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 30\nbatch_size = 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_generator, steps_per_epoch =22968//64, epochs = epochs,validation_data = validation_generator,validation_steps = 1432//64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}