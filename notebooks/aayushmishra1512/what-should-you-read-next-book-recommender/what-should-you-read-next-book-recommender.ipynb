{"cells":[{"metadata":{},"cell_type":"markdown","source":"Importing Project dependencies"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn import neighbors\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will start by importing our data set. It's a data set that contains information about books, who wrote these books and other relevant information. Let's take a look aat what our different columns mean - \n* bookID - Contains the unique ID for each book/series\n* title - contains the titles of the books\n* authors - contains the author of the particular book\n* average_rating - the average rating of the books, as decided by the users\n* ISBN - Another unique number to identify the book, the International Standard Book Number.\n* ISBN 13 - A 13-digit ISBN to identify the book, instead of the standard 11-digit ISBN.\n* language_code - Helps understand what is the primary language of the book. For instance, eng is standard for                     English.\n* Num_pages - Number of pages the book contains.\n* Ratings_count - Total number of ratings the book received.\n* text_reviews_count - Total number of written text reviews the book received."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/goodreadsbooks/books.csv',error_bad_lines = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head() #checking the head of our data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we know how what our data looks like, lets go ahead and look for any null values present in our data."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum() #checking for any null values present in the data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes #checking the data types of each column","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe() #checking for hidden values such as the maximum rating of our books, the average number of ratings","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above results, we can see that our our ratings all lie between 0 and 5. We get know more about the other columns as well, such as the mean of average ratings and some other information that might help us in the future steps. We also checked the data types of each column and also saw that there are no null values present in our data."},{"metadata":{"trusted":true},"cell_type":"code","source":"top_ten = df[df['ratings_count'] > 1000000]\ntop_ten.sort_values(by='average_rating', ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above results show us the top 10 books present in our data. We saw that the maximum rating in our data was 5.0 but we dont see any books in the above result with 5.0 rating. This is because we filtered these books on the basis of the number of ratings. We made sure that all the books that we have in the above results have a decent amount of rating. There can be books in the data that can have only 1 or 2 ratings can be rated 5.0. We want to avoid such books hence this sort of filtering. Let's go ahead and visualize this outcome in form of a graph."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('seaborn-whitegrid')\nplt.figure(figsize=(10, 10))\ndata = top_ten.sort_values(by='average_rating', ascending=False).head(10)\nsns.barplot(x=\"average_rating\", y=\"title\", data=data, palette='inferno')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's go ahead and take a look at some top authors present in our data. We will rank them according to the number of books they have written provided these books are present in the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"most_books = df.groupby('authors')['title'].count().reset_index().sort_values('title', ascending=False).head(10).set_index('authors')\nplt.figure(figsize=(15,10))\nax = sns.barplot(most_books['title'], most_books.index, palette='inferno')\nax.set_title(\"Top 10 authors with most books\")\nax.set_xlabel(\"Total number of books\")\ntotals = []\nfor i in ax.patches:\n    totals.append(i.get_width())\ntotal = sum(totals)\nfor i in ax.patches:\n    ax.text(i.get_width()+.2, i.get_y()+.2,str(round(i.get_width())), fontsize=15,color='black')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to our graphs, Stephen king and P.G. Wodehouse have the most number of books in the data. Both the authors have 40 books in our data set followed by Rumiko Takahashi and Orson scott Card."},{"metadata":{"trusted":true},"cell_type":"code","source":"#df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next we will take a look at the books that have been reviewed the most. We have the average ratings column in our data and also the number of times a particular book has been rated. We will try to use this column to find out most reviewed Books present in our data."},{"metadata":{"trusted":true},"cell_type":"code","source":"most_rated = df.sort_values('ratings_count', ascending = False).head(10).set_index('title')\nplt.figure(figsize=(15,10))\nax = sns.barplot(most_rated['ratings_count'], most_rated.index, palette = 'inferno')\ntotals = []\nfor i in ax.patches:\n    totals.append(i.get_width())\ntotal = sum(totals)\nfor i in ax.patches:\n    ax.text(i.get_width()+.2, i.get_y()+.2,str(round(i.get_width())), fontsize=15,color='black')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that Twilight has been rated more number of times as compared to any other book! Also, these ratings are all in Millions! So that means twilight was rated more than 4 Million times followed by The Hobbit or There and Back Again and The Catcher in the Rye which have been reviewed more than 2 Million times!"},{"metadata":{},"cell_type":"markdown","source":"Now we know that these books can be written in many different languages. We will use the language code to check how many books were written in each language."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1, figsize=(25,10))\nplt.title(\"Languages\")\nsns.countplot(x = \"language_code\", order=df['language_code'].value_counts().index[0:10] ,data=df,palette='inferno')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see most of the Books are written in english be it US or UK which was quite obvious but in order to check it thoroughly, we had to make this plot. We also have languages like Japanese and German but these aren't very prominent."},{"metadata":{},"cell_type":"markdown","source":"There are tons of great and famous authors present in our data. Our next goal is to figure out the top 10 authors present in our data based on on the average ratings on their books. We will filter out the authors based upon how many of their books have average rating above 4.4."},{"metadata":{"trusted":true},"cell_type":"code","source":"highly_rated_author =df[df['average_rating']>4.4]\nhighly_rated_author = highly_rated_author.groupby('authors')['title'].count().reset_index().sort_values('title',ascending=False).head(10).set_index('authors')\nplt.subplots(figsize=(15,10))\nax = highly_rated_author['title'].sort_values().plot.barh(width=0.9,color=sns.color_palette('inferno',12))\nax.set_xlabel(\"Total books \", fontsize=15)\nax.set_ylabel(\"Authors\", fontsize=15)\nax.set_title(\"Top 10 highly rated authors\",fontsize=20,color='black')\ntotals = []\nfor i in ax.patches:\n    totals.append(i.get_width())\ntotal = sum(totals)\nfor i in ax.patches:\n    ax.text(i.get_width()+.2, i.get_y()+.2,str(round(i.get_width())), fontsize=15,color='black')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above graph we can see that Hiromu arkawa is the highest rated author in our data set follwed by J.K Rowling and some other big names. Now that we know about our authors, we will go and take a look at our top publishers as well."},{"metadata":{"trusted":true},"cell_type":"code","source":"top_publishers = df.groupby('publisher')['title'].count().reset_index().sort_values('title',ascending=False).head(10).set_index('publisher')\nplt.subplots(figsize=(15,10))\nax = top_publishers['title'].sort_values().plot.barh(width=0.9,color=sns.color_palette('inferno',12))\nax.set_xlabel(\"Total books \", fontsize=15)\nax.set_ylabel(\"Publishers\", fontsize=15)\nax.set_title(\"Top 10 Publishers Present in our data\",fontsize=20,color='black')\ntotals = []\nfor i in ax.patches:\n    totals.append(i.get_width())\ntotal = sum(totals)\nfor i in ax.patches:\n    ax.text(i.get_width()+.2, i.get_y()+.2,str(round(i.get_width())), fontsize=15,color='black')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vintage are the Most famous publishers present in our data followed by Penguin Books and Penguin Classics."},{"metadata":{},"cell_type":"markdown","source":"Next up, we will have a look at the distribution of average ratings, this will be very important for us when we go on to make our recommender."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.average_rating = df.average_rating.astype(float)\nfig, ax = plt.subplots(figsize=[15,10])\nsns.distplot(df['average_rating'],ax=ax)\nax.set_title('Average rating distribution for all books',fontsize=20)\nax.set_xlabel('Average rating',fontsize=13)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So as we can see, majority of our rating fall between 3 and 4.5. There are hardly any books that have been rated a 1 or a 2 and same goes with 5."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's try and find some relation between our average rating and the rating counts. We are doing this to see how we can use these columns in our recommender. We will also check the distribution of average ratings with Number of pages of a book, the language used in the Book and the Number of Text reviews."},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.relplot(data=df, x=\"average_rating\", y=\"ratings_count\", color = 'red', sizes=(100, 200), height=7, marker='o')\nplt.title(\"Relation between Rating counts and Average Ratings\",fontsize = 15)\nax.set_axis_labels(\"Average Rating\", \"Ratings Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nax = sns.relplot(x=\"average_rating\", y=\"  num_pages\", data = df, color = 'red',sizes=(100, 200), height=7, marker='o')\nax.set_axis_labels(\"Average Rating\", \"Number of Pages\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nax = sns.relplot(x=\"average_rating\", y=\"language_code\", data = df, color = 'red',sizes=(100, 200), height=7, marker='o')\nax.set_axis_labels(\"Average Rating\", \"Languages\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nax = sns.relplot(x=\"average_rating\", y=\"text_reviews_count\", data = df, color = 'red',sizes=(100, 200), height=7, marker='o')\nax.set_axis_labels(\"Average Rating\", \"Text Reviews Count\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After comparing the average rating with the different columns, we can go ahead with using the Language and the Rating counts for our recommender system. Rest other colummns weren't making much sense and using them might not help us in a big way so we can omit them."},{"metadata":{},"cell_type":"markdown","source":"We will create a copy of our original data just to be safe so that we are safe in case we mess up something."},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = df.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will now create a new column called 'rating_between'. We will divide our average rating column into various categories such as rating between 0 and 1, 1 and 2 and so on. This will work as one of the features that we will feed to our model so that it can make better predictions."},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.loc[ (df2['average_rating'] >= 0) & (df2['average_rating'] <= 1), 'rating_between'] = \"between 0 and 1\"\ndf2.loc[ (df2['average_rating'] > 1) & (df2['average_rating'] <= 2), 'rating_between'] = \"between 1 and 2\"\ndf2.loc[ (df2['average_rating'] > 2) & (df2['average_rating'] <= 3), 'rating_between'] = \"between 2 and 3\"\ndf2.loc[ (df2['average_rating'] > 3) & (df2['average_rating'] <= 4), 'rating_between'] = \"between 3 and 4\"\ndf2.loc[ (df2['average_rating'] > 4) & (df2['average_rating'] <= 5), 'rating_between'] = \"between 4 and 5\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will now create two new data frames that contain the different values for the rating_between column we just made. We will assign the value 1 if a rating falls under a particular group lets say 4 and 5 and rest others will be given the value of 0. We will apply the same approach to divide the language code column to retrive  these languages individually and give them the value of 1 and 0 as well where 1 will be assigned if the book is written in a particular language for example, English and 0 if it's not written in English."},{"metadata":{"trusted":true},"cell_type":"code","source":"rating_df = pd.get_dummies(df2['rating_between'])\nrating_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"language_df = pd.get_dummies(df2['language_code'])\nlanguage_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will now concatenate these two data frames into one and name it features. This Data frame will be the features that we will feed to the mmodel. It will contain the values of rating_df and language_df and will also have the values of average rating and ratings count."},{"metadata":{"trusted":true},"cell_type":"code","source":"features = pd.concat([rating_df, language_df, df2['average_rating'], df2['ratings_count']], axis=1)\nfeatures.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we have our features ready, we will now use the Min-Max scaler to scale these values down. It will help in reducing the bias for some of the books that have too many features. It will basically find the median for all and equalize it,"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min_max_scaler = MinMaxScaler()\nfeatures = min_max_scaler.fit_transform(features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have scaled down our features and now we will use KNN to create our Recommender system."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = neighbors.NearestNeighbors(n_neighbors=6, algorithm='ball_tree')\nmodel.fit(features)\ndist, idlist = model.kneighbors(features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We fit all the features to our model and now we will have to create a custom method. When this method will be called, we will have to pass the name of the book in it. The model will try and find the books based on the features that we have passed in it. We will store these book names that the system recommends in a list and return it at the end."},{"metadata":{"trusted":true},"cell_type":"code","source":"def BookRecommender(book_name):\n    book_list_name = []\n    book_id = df2[df2['title'] == book_name].index\n    book_id = book_id[0]\n    for newid in idlist[book_id]:\n        book_list_name.append(df2.loc[newid].title)\n    return book_list_name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BookNames = BookRecommender('Harry Potter and the Half-Blood Prince (Harry Potter  #6)')\nBookNames","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BookNames = BookRecommender('The Lord of the Rings: Weapons and Warfare')\nBookNames","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With this we come to an end to our Recommender system. As we can see, our model is showing some pretty decent result. We passed in the name of one of the Harry potter books and our system quickly recommended us books based upon the average ratings. The books that we recieved have almost the same ratings and we have also recieved books such as the The Fellowhip of the Ring, which again is a fantasy based story line somewhat similar to the Harry Potter books. So we can say that our model is giving decent results. I would like to thank - [Shivam Ralli](https://www.kaggle.com/hoshi7) whose notebook i referenced. It is a  very well written kernel and everyone should have a look at it once."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pickle.dump(model,open('model.pkl','wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}