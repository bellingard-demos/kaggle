{"cells":[{"metadata":{},"cell_type":"markdown","source":"**KNN - BEGINNER'S GUIDE**","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets import our data set and take a look at it","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/Classified Data')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most companies dont provide a person with their exact company data during an interview. They changethe column names and make the data completely random for the person.This dataset  is one of those data set where we cant correlate any column with the other and have to apply KNN on.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head() #checking the head of our data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Taking a look at our data, we can see that the unnamed column is unecessary and we can work well wihtout it. Hence, we will drop it.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['Unnamed: 0'],axis = 1,inplace = True) #dropping the column","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets go on check for any null values in our data that might affect our final result.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum() #checking for null values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,10)) #getting a visual of our data\nsns.heatmap(df.corr(),annot = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see we have many varying values in our data. Even though we cannot correlate any column with the other, lets try to find some trend in our data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='WTT',y='PTI',data = df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='EQW',y='SBI',data = df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='LQE',y='QWG',data = df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='FDJ',y='PJF',data = df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='HQE',y='NXJ',data = df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the plots we can say that all of our data lies between 0 and 2. We have no negative values in our data.We couldn't deduce much from the data that we have but we can get a few insights from such data just by plotting a few graphs and maybe even the sector in which the company works can help you  correlate the data that is given to you. So lets start working on our model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split #importing our libraries\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report,confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will standard scale our data inorder to have better results from our data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler.fit(df.drop('TARGET CLASS',axis = 1)) #standard sccaling our data for better results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_features = scaler.transform(df.drop('TARGET CLASS',axis = 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_feat = pd.DataFrame(scaled_features,columns = df.columns[:-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_feat.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we have oour data scaled properly, lets  define our features and target and fit the model to it","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df_feat\ny = df['TARGET CLASS']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state = 101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = knn.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,pred))\nprint('\\n')\nprint(confusion_matrix(y_test,pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We were able to predict the Target with 92% accuracy.Even though this is a decent accuracy, we can get better results than this by defining a better n_neighbors value. This n_neighbours is just a hyper parameter that we set and this is  never same for two data sets. Every model requires various n_neighbours value depending on the type of data.Now, lets improve our model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"error = []\nfor i in  range(1,100):\n    knn = KNeighborsClassifier(n_neighbors= i)\n    knn.fit(x_train,y_train)\n    pred_i = knn.predict(x_test)\n    error.append(np.mean(pred_i != y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We computed the error v/s the K values for our model and we can plot a graph that shows us these values and analyse our K value better","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,6))\nplt.plot(range(1,100),error)\nplt.title('K-values')\nplt.xlabel('K')\nplt.ylabel('Error')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To get the best result possible we should select a value that has low error. We can see our graph and determine which value is the lowest for us and that should give us the best result possible","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=40)\nknn.fit(x_train,y_train)\npred1 = knn.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,pred1))\nprint('\\n')\nprint(confusion_matrix(y_test,pred1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see we were able to find the best K value by looking at the error and choosing n_neighbours as 40 gave us 96% accuracy as compared to the 92% accuracy that we got using n_neighbours = 1. This is pretty much. KNN is a very  powerful algorithm that is used many times and understanding how it works is very helpful","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"This problem can also be solved using Clustering and SVM and they too might give good results.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}