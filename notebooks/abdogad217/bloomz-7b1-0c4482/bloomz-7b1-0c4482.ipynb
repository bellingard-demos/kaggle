{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        \n        print(os.path.join(dirname, filename))\n\n        ","metadata":{"papermill":{"duration":0.73626,"end_time":"2023-10-28T13:41:22.664288","exception":false,"start_time":"2023-10-28T13:41:21.928028","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-08T14:55:18.733556Z","iopub.execute_input":"2023-11-08T14:55:18.73384Z","iopub.status.idle":"2023-11-08T14:55:19.139089Z","shell.execute_reply.started":"2023-11-08T14:55:18.733815Z","shell.execute_reply":"2023-11-08T14:55:19.138185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7","metadata":{"execution":{"iopub.status.busy":"2023-11-08T14:55:19.140993Z","iopub.execute_input":"2023-11-08T14:55:19.14209Z","iopub.status.idle":"2023-11-08T14:55:45.509982Z","shell.execute_reply.started":"2023-11-08T14:55:19.142061Z","shell.execute_reply":"2023-11-08T14:55:45.508941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import LoraConfig, PeftModel\nfrom trl import SFTTrainer","metadata":{"papermill":{"duration":30.087603,"end_time":"2023-10-28T13:43:59.99579","exception":false,"start_time":"2023-10-28T13:43:29.908187","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-08T14:55:45.511437Z","iopub.execute_input":"2023-11-08T14:55:45.511728Z","iopub.status.idle":"2023-11-08T14:56:00.190817Z","shell.execute_reply.started":"2023-11-08T14:55:45.511697Z","shell.execute_reply":"2023-11-08T14:56:00.189939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The model that you want to train from the Hugging Face hub\nmodel_name = \"bigscience/bloomz-7b1\"\n\n# The instruction dataset to use\ndataset_name = \"mlabonne/guanaco-llama2-1k\"\n\n# Fine-tuned model name\nnew_model = \"bigscience/bloomz-7b1\"\n# LoRA attention dimension\nlora_r = 8\nlora_alpha = 32\n\n# Dropout probability for LoRA layers\nlora_dropout = 0.1\nuse_4bit = True\n\n# Compute dtype for 4-bit base models\nbnb_4bit_compute_dtype = \"float16\"\n\n# Quantization type (fp4 or nf4)\nbnb_4bit_quant_type = \"nf4\"\n\nuse_nested_quant = False\n\noutput_dir = \"./results\"\n\n# Number of training epochs\nnum_train_epochs = 1\nfp16 = False\nbf16 = False\n\nper_device_train_batch_size = 1\n\nper_device_eval_batch_size = 4\n\ngradient_accumulation_steps = 8\n\ngradient_checkpointing = True\n\nmax_grad_norm = 0.3\n\nlearning_rate = 2e-5\n\nweight_decay = 0.001\n\noptim = \"adamw_hf\"\n\n\nmax_steps = -1\nwarmup_ratio = 0.03\ngroup_by_length = True\n\nsave_steps = 0\n\nlogging_steps = 25\n\nmax_seq_length = False\npacking = False\n#device_map = {\"\": 0}","metadata":{"execution":{"iopub.status.busy":"2023-11-08T14:56:00.193107Z","iopub.execute_input":"2023-11-08T14:56:00.193411Z","iopub.status.idle":"2023-11-08T14:56:00.200771Z","shell.execute_reply.started":"2023-11-08T14:56:00.193386Z","shell.execute_reply":"2023-11-08T14:56:00.199863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load dataset (you can process it here)\ndataset = load_dataset(dataset_name, split=\"train\")\n\n# Load tokenizer and model with QLoRA configuration\ncompute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=use_4bit,\n    bnb_4bit_quant_type=bnb_4bit_quant_type,\n    bnb_4bit_compute_dtype=compute_dtype,\n    bnb_4bit_use_double_quant=use_nested_quant,\n)\n\n# Check GPU compatibility with bfloat16\nif compute_dtype == torch.float16 and use_4bit:\n    major, _ = torch.cuda.get_device_capability()\n    if major >= 8:\n        print(\"=\" * 80)\n        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n        print(\"=\" * 80)\n\n# Load base model\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n)\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1\n\n# Load LLaMA tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\" # Fix weird overflow issue with fp16 training\npeft_config = LoraConfig(\n    lora_alpha=lora_alpha,\n    lora_dropout=lora_dropout,\n    r=lora_r,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-08T14:56:00.201777Z","iopub.execute_input":"2023-11-08T14:56:00.202038Z","iopub.status.idle":"2023-11-08T14:59:50.447975Z","shell.execute_reply.started":"2023-11-08T14:56:00.202015Z","shell.execute_reply":"2023-11-08T14:59:50.447074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.113747,"end_time":"2023-10-28T13:44:12.260357","exception":false,"start_time":"2023-10-28T13:44:12.14661","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ntrain_df = pd.read_csv(\"/kaggle/input/expect-answer-true-false-answer-wrong-similrty/train.csv\")\nvalid_df = pd.read_csv(\"/kaggle/input/expect-answer-true-false-answer-wrong-similrty/valid.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/expect-answer-true-false-answer-wrong-similrty/valid.csv\")\n","metadata":{"id":"M9nKf_Rq_DmB","papermill":{"duration":7.182899,"end_time":"2023-10-28T13:44:19.463101","exception":false,"start_time":"2023-10-28T13:44:12.280202","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-08T14:59:50.450335Z","iopub.execute_input":"2023-11-08T14:59:50.450657Z","iopub.status.idle":"2023-11-08T14:59:55.857604Z","shell.execute_reply.started":"2023-11-08T14:59:50.450629Z","shell.execute_reply":"2023-11-08T14:59:55.856478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['input']=\"give answer of next quetion using context below:\"+ f\"\\n\\ncontext: \"+train_df['context']+f\".\\n\\n quetion: \" +train_df['question']+ f\".\\n\\n student: \"+train_df['answer']+f\"\\n\\n answer \\n\\n\"+train_df['label']\nvalid_df['input']=\"give answer of next quetion using context below:\"+f\"\\n\\ncontext: \"+valid_df['context']+f\".\\n\\n quetion: \" +valid_df['question']+ f\".\\n\\n student: \"+valid_df['answer']+f\" \\n\\n answer \\n\\n \"+valid_df['label']\nvalid_df['input2']=\"give answer of next quetion using context below:\"+f\"\\n\\ncontext: \"+valid_df['context']+f\".\\n\\n quetion: \" +valid_df['question']+ f\".\\n\\n student: \"+valid_df['answer']+f\" \\n\\n answer \\n\\n \"","metadata":{"papermill":{"duration":1.076472,"end_time":"2023-10-28T13:44:20.560638","exception":false,"start_time":"2023-10-28T13:44:19.484166","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-08T14:59:55.858839Z","iopub.execute_input":"2023-11-08T14:59:55.859162Z","iopub.status.idle":"2023-11-08T14:59:57.147909Z","shell.execute_reply.started":"2023-11-08T14:59:55.859111Z","shell.execute_reply":"2023-11-08T14:59:57.147046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"","metadata":{"execution":{"iopub.status.busy":"2023-11-08T14:59:57.149412Z","iopub.execute_input":"2023-11-08T14:59:57.149713Z","iopub.status.idle":"2023-11-08T14:59:57.154223Z","shell.execute_reply.started":"2023-11-08T14:59:57.149687Z","shell.execute_reply":"2023-11-08T14:59:57.153085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"papermill":{"duration":0.020639,"end_time":"2023-10-28T13:44:24.527047","exception":false,"start_time":"2023-10-28T13:44:24.506408","status":"completed"},"tags":[]}},{"cell_type":"code","source":"m=-12\nw=np.zeros(len(train_df))\no=0\nfor i in train_df['input']:\n    t=len(tokenizer(i)['input_ids'])\n    w[o]=t\n    o+=1\nm=-12\na=np.zeros(len(valid_df))\no=0\nfor i in valid_df['input']:\n    t=len(tokenizer(i)['input_ids'])\n    a[o]=t\n    o+=1    \ntrain_df=train_df.loc[w<600]\nvalid_df=valid_df.loc[a<600]   \ntrain_texts=train_df\nvalid_texts=valid_df","metadata":{"execution":{"iopub.status.busy":"2023-11-08T14:59:57.155585Z","iopub.execute_input":"2023-11-08T14:59:57.155899Z","iopub.status.idle":"2023-11-08T15:04:08.265179Z","shell.execute_reply.started":"2023-11-08T14:59:57.155872Z","shell.execute_reply":"2023-11-08T15:04:08.26428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Datasets and Dataloaders\nfrom torch.utils.data import Dataset, DataLoader\n\nclass QADataset(Dataset):\n    def __init__(self, encodings):\n        self.inputs = encodings['input']\n        \n    def __getitem__(self, idx):\n        a=tokenizer(self.inputs[idx] , truncation=True, padding='max_length', return_tensors=\"pt\", max_length=600)\n        return {\n            \n            \"input_ids\": a[\"input_ids\"][0],\n            \"attention_mask\": a[\"attention_mask\"][0],\n            \"labels\":a['input_ids'][0]\n        }\n    def __len__(self):\n        return len(self.inputs)\n\ntrain_dataset = QADataset(train_texts.iloc[12000:2*12000].reset_index(drop=True))\nval_dataset = QADataset(valid_texts.iloc[:100].reset_index(drop=True))\n","metadata":{"id":"zZydmxRxKK6j","outputId":"d26160fb-59ed-4e0e-fb2e-0d2f3546743c","papermill":{"duration":0.035718,"end_time":"2023-10-28T13:44:24.58275","exception":false,"start_time":"2023-10-28T13:44:24.547032","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-08T15:04:08.268372Z","iopub.execute_input":"2023-11-08T15:04:08.268723Z","iopub.status.idle":"2023-11-08T15:04:08.282725Z","shell.execute_reply.started":"2023-11-08T15:04:08.268696Z","shell.execute_reply":"2023-11-08T15:04:08.281979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n!pip install wandb\nimport wandb\nwandb.login(key=\"14459c516497ab76a78f7fc1278bfe60d301d250\")","metadata":{"papermill":{"duration":14.026469,"end_time":"2023-10-28T13:44:38.629031","exception":false,"start_time":"2023-10-28T13:44:24.602562","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-08T15:04:08.283924Z","iopub.execute_input":"2023-11-08T15:04:08.284216Z","iopub.status.idle":"2023-11-08T15:04:26.639648Z","shell.execute_reply.started":"2023-11-08T15:04:08.284191Z","shell.execute_reply":"2023-11-08T15:04:26.638637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.037939,"end_time":"2023-10-28T13:44:38.688916","exception":false,"start_time":"2023-10-28T13:44:38.650977","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model= PeftModel.from_pretrained(model,\"/kaggle/input/bloomz-7b11/results/checkpoint-2400\")\nmodel.enable_input_require_grads()\nmodel.train()","metadata":{"execution":{"iopub.status.busy":"2023-11-08T15:04:26.64087Z","iopub.execute_input":"2023-11-08T15:04:26.641538Z","iopub.status.idle":"2023-11-08T15:04:40.851957Z","shell.execute_reply.started":"2023-11-08T15:04:26.641502Z","shell.execute_reply":"2023-11-08T15:04:40.851046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_arguments = TrainingArguments(\n    output_dir=output_dir,\n    num_train_epochs=num_train_epochs,\n    per_device_train_batch_size=per_device_train_batch_size,\n    gradient_accumulation_steps=gradient_accumulation_steps,\n    optim=optim,\n    save_steps=600,\n    logging_steps=5,\n    learning_rate=learning_rate,\n    weight_decay=weight_decay,\n    fp16=fp16,\n    bf16=bf16,\n    max_grad_norm=max_grad_norm,\n    max_steps=max_steps,\n    warmup_ratio=warmup_ratio,\n    group_by_length=False,\n    lr_scheduler_type='constant',\n)\n\n# Set supervised fine-tuning parameters\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=train_dataset,\n        eval_dataset=val_dataset,\n\n    peft_config=peft_config,\n    dataset_text_field=\"text\",\n    args=training_arguments,\n    packing=False,\n)\ntrainer.train()\ntrainer.model.save_pretrained(new_model)","metadata":{"id":"yqq_9dT1_nn7","papermill":{"duration":8.04449,"end_time":"2023-10-28T13:44:46.754051","exception":false,"start_time":"2023-10-28T13:44:38.709561","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-08T15:04:40.85347Z","iopub.execute_input":"2023-11-08T15:04:40.854297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.06975,"end_time":"2023-10-28T19:29:07.515132","exception":false,"start_time":"2023-10-28T19:29:07.445382","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.evaluate()\n","metadata":{"papermill":{"duration":699.247728,"end_time":"2023-10-28T19:40:46.786544","exception":false,"start_time":"2023-10-28T19:29:07.538816","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install evaluate\n","metadata":{"papermill":{"duration":12.363574,"end_time":"2023-10-28T19:40:59.174346","exception":false,"start_time":"2023-10-28T19:40:46.810772","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install rouge_score","metadata":{"papermill":{"duration":13.908888,"end_time":"2023-10-28T19:41:13.11008","exception":false,"start_time":"2023-10-28T19:40:59.201192","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.padding_side = \"left\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import evaluate\nimport numpy as np\nfrom datasets import load_from_disk\nfrom tqdm import tqdm\n\n# Metric\nmetric= evaluate.load(\"rouge\")\nmetric2= evaluate.load(\"bleu\")\n\npredictions, references = [] , []\no=0\ns=0\nl=1000\nfor i in range(l):\n        inp2=\"give answer of next quetion using context below:\"+ f\"\\n\\ncontext: \"+valid_df.iloc[i,1]+f\".\\n\\n quetion: \" +valid_df.iloc[i,2]+ f\".\\n\\n student: \"+valid_df.iloc[i,3]+f\"\\n\\n answer \\n\\n\"\n        w=tokenizer(inp2, add_special_tokens=True,\n            pad_to_max_length=True,\n            return_attention_mask=True,\n            return_tensors='pt',    max_length=600\n\n        )\n        e=tokenizer.batch_decode(model.generate(input_ids=w['input_ids'].cuda()),skip_special_tokens=True)[0]\n        e=e[e.find(f'\\n\\n answer \\n\\n')+len(f'\\n\\n answer \\n\\n'):]\n        s+=int((e+' ,').split()[0]==valid_df['label'].iloc[i].split()[0])\n        print(f'{i} : {s/(i+1)}',end='\\r')\n        predictions+=[e]\n        references+=[valid_df['label'].iloc[i]]\n# compute metric\nrogue = metric.compute(predictions=predictions, references=references)\nbelu=metric2.compute(predictions=predictions, references=references)\n# print results\nprint(f\"Rogue1: {rogue['rouge1']* 100:2f}%\")\nprint(f\"rouge2: {rogue['rouge2']* 100:2f}%\")\nprint(f\"rougeL: {rogue['rougeL']* 100:2f}%\")\nprint(f\"rougeLsum: {rogue['rougeLsum']* 100:2f}%\")\nprint(\"belu: \",belu)","metadata":{"papermill":{"duration":3016.084022,"end_time":"2023-10-28T20:31:29.221828","exception":true,"start_time":"2023-10-28T19:41:13.137806","status":"failed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rogue = metric.compute(predictions=predictions, references=references)\nbelu=metric2.compute(predictions=predictions, references=references)\n# print results\nprint(f\"Rogue1: {rogue['rouge1']* 100:2f}%\")\nprint(f\"rouge2: {rogue['rouge2']* 100:2f}%\")\nprint(f\"rougeL: {rogue['rougeL']* 100:2f}%\")\nprint(f\"rougeLsum: {rogue['rougeLsum']* 100:2f}%\")\nprint(\"belu: \",belu)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"accuracy : {s/l }\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"peft_model_id=\"results\"\ntrainer.model.save_pretrained(peft_model_id)\ntokenizer.save_pretrained(peft_model_id)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}