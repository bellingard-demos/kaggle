{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport cv2\nimport os\nimport time\nimport shutil\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom tqdm.auto import tqdm\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport keras \nfrom keras.applications import VGG16\nfrom keras.applications import DenseNet121\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras.applications.vgg16 import preprocess_input as preprocess_input_vgg\nfrom keras.applications.densenet import preprocess_input as preprocess_input_densenet\nfrom keras.layers.experimental.preprocessing import Rescaling\nfrom keras.layers import Input, Dense, BatchNormalization, GlobalAveragePooling2D, Dropout, Conv2D, MaxPooling2D, GlobalMaxPooling2D\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nimport pickle\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.preprocessing.image import image_dataset_from_directory\n\nimport seaborn as sns\nfrom scipy import signal\nfrom scipy import ndimage\n# \nimport copy\nimport warnings\nfrom sklearn.utils import class_weight\n\nfrom tensorflow.compat.v1 import ConfigProto\nfrom tensorflow.compat.v1 import InteractiveSession\n\nconfig = ConfigProto()\nconfig.gpu_options.allow_growth = True\nsession = InteractiveSession(config=config)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categories = ['Baeolophusbicolorq_A', 'Cardellinacanadensisq_A', 'Cardinaliscardinalisq_A', 'Catharusminimusq_A', 'Catharusustulatusq_A', 'Geothlypisphiladelphiaq_A', 'Geothlypistrichasq_A',\n              'Melanerpeserythrocephalusq_A', 'Passerculussandwichensisq_A', 'Pheucticusludovicianusq_A', 'Poecileatricapillusq_A', 'Seiurusaurocapillaq_A', 'Setophagacaerulescensq_A',\n              'Setophagacastaneaq_A', 'Setophagaruticillaq_A', 'Spinustristisq_A', 'Spizellapasserinaq_A', 'Spizelloidesarboreaq_A', 'Zonotrichiaalbicollisq_A']\n\n\n\n\nmy_files = r'../input/new-england-labeled-bird-species-spectrograms/LabeledSpectrograms'\n\n\n\nimage_generator = ImageDataGenerator(rescale=1/256)\n\nfull_dataset = image_generator.flow_from_directory(batch_size=32,\n                                                    directory=my_files,\n                                                    shuffle=True,\n                                                    target_size=(251, 251),\n                                                    classes=categories,\n                                                   color_mode='grayscale')\n\n\nclasses = np.unique(full_dataset.classes)\n_class_weight = class_weight.compute_class_weight('balanced',classes,full_dataset.classes)\n\nclass_weights = {}\ni = 0\nfor i in range(len(classes)):\n    class_weights[classes[i]] = _class_weight[i]\n    i+=1\n\n\n\nimage_generator = ImageDataGenerator(validation_split=0.1, rescale=1/256)\nimage_generator2 = ImageDataGenerator(validation_split=0.1, rescale=1/256, horizontal_flip=False)\n\ntrain_dataset = image_generator.flow_from_directory(batch_size=32,\n                                                    directory=my_files,\n                                                    shuffle=True,\n                                                    target_size=(251, 251),\n                                                    subset='training',\n                                                    classes=categories)\n\ntest_dataset = image_generator2.flow_from_directory(batch_size=32,\n                                                    directory=my_files,\n                                                    shuffle=True,\n                                                    target_size=(251, 251),\n                                                    subset='validation',\n                                                    classes=categories)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"METRICS = [\n        'accuracy',\n        tf.keras.metrics.Precision(name='precision'),\n        tf.keras.metrics.Recall(name='recall')\n    ]\n\n# Define my model\nURL = r'https://tfhub.dev/google/imagenet/resnet_v2_152/feature_vector/4'\n# URL = r'https://tfhub.dev/agripredict/disease-classification/1'\n# URL = r'https://tfhub.dev/google/bit/m-r152x4/imagenet21k_classification/1'\n\n\nfeature_extractor = hub.KerasLayer(URL, input_shape=(224,224,3))\nfeature_extractor.trainable = False\n\ndeep_model = tf.keras.models.Sequential([    \n    feature_extractor,\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dropout(0.1),\n    tf.keras.layers.Dense(19,activation='sigmoid')    \n])\ndeep_model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001), loss='CategoricalCrossentropy', metrics=METRICS )\ndeep_model.summary()\n\n# deep_model = tf.keras.models.Sequential([\n    \n#     tf.keras.Input(shape=(251, 251, 1)),\n#     tf.keras.layers.Conv2D(64, 5, strides=2, activation=\"relu\"),\n#     tf.keras.layers.Conv2D(64, 3, strides=2, activation=\"relu\"),\n#     tf.keras.layers.MaxPooling2D(3),\n#     tf.keras.layers.Conv2D(64, 3, activation=\"relu\"),\n#     tf.keras.layers.Conv2D(64, 3, activation=\"relu\"),\n#     tf.keras.layers.MaxPooling2D(3),\n#     tf.keras.layers.Conv2D(64, 3, activation=\"relu\"),\n#     tf.keras.layers.MaxPooling2D(2),\n#     tf.keras.layers.GlobalMaxPooling2D(),\n#     tf.keras.layers.Dense(64, activation='relu'),\n#     tf.keras.layers.Dropout(0.2),\n#     tf.keras.layers.Dense(32, activation='relu'),\n#     tf.keras.layers.Dropout(0.1),\n#     tf.keras.layers.Dense(19,activation='sigmoid')  \n    \n              \n# #     tf.keras.layers.Conv2D(38, 8, strides=1, activation=\"relu\"),\n# #     tf.keras.layers.MaxPooling2D(2),\n# #     tf.keras.layers.GlobalMaxPooling2D(),\n# #     tf.keras.layers.Dense(19,activation='sigmoid')   \n# ])\n\n# deep_model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.000000001), loss='CategoricalCrossentropy', metrics=METRICS)\n# # deep_model.build((None, 251, 251, 1))\n# deep_model.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class myCallback(tf.keras.callbacks.Callback):\n#   def on_epoch_end(self,epoch,logs={}):\n#     if(logs['accuracy']>=0.99):\n#       self.model.stop_training=True\n\n# callbacks=myCallback()\n\n# checkpoint_callback = ModelCheckpoint('model1', monitor='val_accuracy', verbose = True, save_best_only = True, save_weights_only = False, mode= 'max')\n# early_stopping_callback = EarlyStopping(monitor='val_accuracy', patience=3)\n\n# METRICS = [\n#         'accuracy',\n#         tf.keras.metrics.Precision(name='precision'),\n#         tf.keras.metrics.Recall(name='recall')\n#     ]\n# model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001), loss='CategoricalCrossentropy', metrics=METRICS )\n\n# # How many epochs should I use?\n# history = model.fit(train_dataset, epochs=20 , callbacks=[callbacks, checkpoint_callback, early_stopping_callback], validation_data=test_dataset)\n\n\ndeep_checkpoint_callback = ModelCheckpoint('deep_model_augs.h5', monitor='val_accuracy', verbose = True, save_best_only = True, save_weights_only = False, mode= 'max')\ndeep_early_stopping_callback = EarlyStopping(monitor='val_accuracy', patience=10)\nwith tf.device('/GPU:0'):\n    deep_fit = deep_model.fit(train_dataset,\n                              class_weight=class_weights,\n                              validation_data=test_dataset,\n                              steps_per_epoch= (train_dataset.samples // 32),\n                              validation_steps = (test_dataset.samples // 32),\n                              use_multiprocessing=True,\n                              workers=-1,\n                              verbose = True,\n                              epochs = 20,\n                              callbacks = [deep_checkpoint_callback, deep_early_stopping_callback])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(np.array(deep_fit.history['loss']),color='blue')\nplt.plot(np.array(deep_fit.history['val_loss']),color='red')\nplt.title('Model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\n\nplt.plot(np.array(deep_fit.history['accuracy']),color='blue')\nplt.plot(np.array(deep_fit.history['val_accuracy']),color='red')\nplt.title('Model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = deep_model.predict(test_dataset)\npredictions = tf.argmax(predictions, axis=-1)\n# predictions\nactuals = test_dataset.classes\n\ncm = tf.math.confusion_matrix(actuals, predictions)\ncm = cm/cm.numpy().sum(axis=1)[:, tf.newaxis]\n\nplt.figure(figsize=(20, 20))\nsns.heatmap(\n    cm, annot=True,\n    xticklabels=categories,\n    yticklabels=categories)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}