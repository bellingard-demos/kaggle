{"cells":[{"metadata":{},"cell_type":"markdown","source":"# The following datasets are used:\n\n- [COVID19 Global Forecasting (Week 1)](https://www.kaggle.com/c/covid19-global-forecasting-week-1/data)\n- [Big Five Personality Test](https://www.kaggle.com/tunguz/big-five-personality-test)\n- [Countries ISO Codes](https://www.kaggle.com/juanumusic/countries-iso-codes\n\n# This code is based on this notebook\n- [Notebook](https://www.kaggle.com/bluewizard/covid-19-and-the-big-5-personality-test)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom scipy.stats import pearsonr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"days = 3\ncases = 15","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# COVID-19 Data\n\nFor the COVID-19 data, we'll get the number of cases at 2-weeks after the first 15 confirmed cases."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-1/train.csv')\ntest = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-1/test.csv')\n\n# Join the training and test sets\ncovid19 = pd.concat([train, test])\n# Sort by date\ncovid19.sort_values('Date')\n# Filter to the columns we need\ncovid19 = covid19.loc[:, ['Country/Region', 'Date', 'ConfirmedCases']]\n\ncovid19.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Filter\n\nNext we'll filter to countries that reached at least 15 confirmed cases, and had at least 3 days of data beyond reaching that point."},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19 = covid19[covid19.ConfirmedCases > 15]\ncovid19_numdays = covid19.loc[:, ['Country/Region', 'Date']]\\\n    .drop_duplicates()\\\n    .groupby('Country/Region')\\\n    .count()\\\n    .rename_axis('country')\\\n    .reset_index()\nprint(covid19_numdays.head())\n\ncovid19_mindays = covid19_numdays[covid19_numdays.Date >= 3]\ncovid19 = covid19[covid19['Country/Region'].isin(covid19_mindays.country)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What/how many countries does that leave us with?"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(list(set(covid19['Country/Region'].values))))\nprint(set(covid19['Country/Region'].values))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obviously \"Cruise Ship\" isn't a country. I won't worry about it at this point, since it will get filtered out in later steps."},{"metadata":{},"cell_type":"markdown","source":"## Compute growth over 3 days\n\nNext, we'll compute the growth in cases for each country, from the date they reached 15 Confirmed Cases to the 3th day following that date. First we'll need to collapse over province, since some countries are represented multiple times under different provinces."},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19[covid19['Country/Region'] == 'China'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19_collapse_province = covid19\\\n    .groupby(['Country/Region', 'Date'])\\\n    .sum()\\\n    .reset_index()\ncovid19_collapse_province[covid19_collapse_province['Country/Region'] == 'China'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19 = covid19_collapse_province\\\n    .groupby('Country/Region')\\\n    .head(days)\\\n    .groupby('Country/Region')\\\n    .tail(1)\n\ncovid19","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Country Abbreviations\n\nNext we'll join in the country abbreviation codes. The source data here comes from the Kaggle [Countries ISO Codes dataset](https://www.kaggle.com/juanumusic/countries-iso-codes), and the original source is Wikipedia. This will allow us to join to the Big 5 dataset later."},{"metadata":{"trusted":true},"cell_type":"code","source":"country_isos = pd.read_csv('/kaggle/input/countries-iso-codes/wikipedia-iso-country-codes.csv')\ncountry_isos = country_isos.rename(columns={\"English short name lower case\": \"Country/Region\", \n                                            \"Alpha-2 code\": \"country_abbr\"})\ncountry_isos = country_isos.loc[:, ['Country/Region', 'country_abbr']]\ncountry_isos.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19 = covid19.merge(country_isos, left_on='Country/Region', right_on='Country/Region')\ncovid19 = covid19.dropna()\ncovid19.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Big Five Personality Data\n\nNext, we'll fetch the [Big Five Personality Test data from Kaggle](https://www.kaggle.com/tunguz/big-five-personality-test). This dataset contains ~1M answers collected online by [Open Psychometrics](https://openpsychometrics.org/tests/IPIP-BFFM). I'm interested in this dataset because it also labels the country in which the respondant is located. We can use this dataset to get country-level aggregate data on personality traits, and then see if those traits map onto the COVID-19 outcomes that we're seeing."},{"metadata":{"trusted":true},"cell_type":"code","source":"big5 = pd.read_csv('/kaggle/input/big-five-personality-test/IPIP-FFM-data-8Nov2018/data-final.csv', sep='\\t')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Scoring the Big Five Personality Test items\n\nThe Big 5 personality inventory contains 5 factors. Like most personality scales, the Big 5 has a mix of items that positively and negatively load onto these personality factors. For example, the factor Extraversion describes someone who is outgoing, energetic, talkative, and enjoys human interaction. The first Extraversion item [`EXT1`] is \"I am the life of the party.\", a positively-keyed item; whereas the second item [`EXT2`] is \"I don't talk a lot.\", a negatively-keyed item.\n\nTo find out which items are positively or negatively keyed, we can look at the scale documentation on the IPIP website: https://ipip.ori.org/newBigFive5broadKey.htm\n\n## Reverse-coding\n\nBefore analyzing the data from a personality test, a psychologist will generally \"reverse-code\" the items that are negatively-keyed. This results in a dataset where the item values all have a common direction and interpretetion (i.e., a higher value corresponds with more of that trait). Mathematically, it allows you to then compute sums and averages for each of the factors. For example, after scoring the test items, we could compute an individual's average for Extraversion items to get their Extraversion score.\n\nThis version of the Big 5 scale asks individuals to rate their level of agreement from 1 to 5, where 1 is strong disagreement and 5 is strong agreement. Reverse-coding is as simple as subtracting 6 from every reverse-keyed item.\n\nThe code below will accomplish this task."},{"metadata":{"trusted":true},"cell_type":"code","source":"positively_keyed = ['EXT1', 'EXT3', 'EXT5', 'EXT7', 'EXT9',\n                    'EST1', 'EST3', 'EST5', 'EST6', 'EST7', 'EST8', 'EST9', 'EST10',\n                    'AGR2', 'AGR4', 'AGR6', 'AGR8', 'AGR9', 'AGR10',\n                    'CSN1', 'CSN3', 'CSN5', 'CSN7', 'CSN9', 'CSN10', \n                    'OPN1', 'OPN3', 'OPN5', 'OPN7', 'OPN8', 'OPN9', 'OPN10']\n\nnegatively_keyed = ['EXT2', 'EXT4', 'EXT6', 'EXT8', 'EXT10',\n                    'EST2', 'EST4',\n                    'AGR1', 'AGR3', 'AGR5', 'AGR7', \n                    'CSN2', 'CSN4', 'CSN6', 'CSN8', \n                    'OPN2', 'OPN4', 'OPN6']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"big5.loc[:, negatively_keyed] = 6 - big5.loc[:, negatively_keyed]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Country-Level Big 5 Aggregates"},{"metadata":{},"cell_type":"markdown","source":"First, we should eliminate any country that doesn't have very many observations. Somewhat arbitrarily, we'll draw a line at N = 1000."},{"metadata":{"trusted":true},"cell_type":"code","source":"big5_country_count = big5.country\\\n    .value_counts()\\\n    .rename_axis('country')\\\n    .reset_index(name='counts')\n\nprint(len(big5_country_count[big5_country_count.counts > 1000]))\nprint(big5_country_count[big5_country_count.counts > 1000].country.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 58 countries with at least 1000 observations. Let's go with these."},{"metadata":{"trusted":true},"cell_type":"code","source":"big5 = big5[big5.country.isin(big5_country_count[big5_country_count.counts > 1000].country.values)]\n\n# Filter on the columns we're going to use\nbig5 = big5.loc[:,['country'] + positively_keyed + negatively_keyed]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Factor aggregation\n\nNext, we'll compute averages for each of the five factors at the level of the individual."},{"metadata":{"trusted":true},"cell_type":"code","source":"EXT = ['EXT' + str(i) for i in range(1,11)]\nEST = ['EST' + str(i) for i in range(1,11)]\nAGR = ['AGR' + str(i) for i in range(1,11)]\nCSN = ['CSN' + str(i) for i in range(1,11)]\nOPN = ['OPN' + str(i) for i in range(1,11)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"big5['EXT'] = big5.loc[:, EXT].mean(axis=1)\nbig5['EST'] = big5.loc[:, EST].mean(axis=1)\nbig5['AGR'] = big5.loc[:, AGR].mean(axis=1)\nbig5['CSN'] = big5.loc[:, CSN].mean(axis=1)\nbig5['OPN'] = big5.loc[:, OPN].mean(axis=1)\nbig5 = big5.loc[:, ['country', 'EXT', 'EST', 'AGR', 'CSN', 'OPN']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop NAs, and any with country = 'NONE'"},{"metadata":{"trusted":true},"cell_type":"code","source":"big5 = big5.dropna()\nbig5 = big5[big5.country != 'NONE']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Country-level averages\n\nNow we can calculate the country-level averages."},{"metadata":{"trusted":true},"cell_type":"code","source":"big5_cavgs = big5.groupby('country')\\\n                    .mean()\\\n                    .rename_axis('country')\\\n                    .reset_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Just to illustrate, these are the top 5 countries by country-level Extraversion scores."},{"metadata":{"trusted":true},"cell_type":"code","source":"big5_cavgs.loc[:, ['country', 'EXT']]\\\n    .sort_values(by=['EXT'])\\\n    .tail()\\\n    .plot(x = 'country', \n          y = 'EXT', \n          kind='barh', \n          legend=False)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Joining Big 5 Country Data to COVID-19 Data\n\nNext we'll merge the COVID-19 dataset to the Big 5, country-level dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19_big5 = covid19.merge(big5_cavgs, left_on='country_abbr', right_on='country')\ncovid19_big5.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"factors = ['EXT', 'EST', 'AGR', 'CSN', 'OPN']\nfactor_names = ['Extraversion', 'Emotional Stability', 'Agreeableness', 'Conscientiousness', 'Openness']\n\nfor i, factor in enumerate(['EXT', 'EST', 'AGR', 'CSN', 'OPN']):\n    # Compute the correlation coefficient\n    corr = pearsonr(covid19_big5[factor], covid19_big5.ConfirmedCases)\n    corr = [np.round(c, 2) for c in corr]\n    text = 'r=%s, p=%s' % (corr[0], corr[1])\n    \n    ax = sns.regplot(x=factor, \n                y=\"ConfirmedCases\", \n                data=covid19_big5)\n    \n    ax.set_title(f\"Confirmed cases at {days} days after first {cases} cases \" + \n                 \"\\n by average score on Big 5 factor \" + factor_names[i] + \n                 \"\\n\" + text)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"China is perhaps an atypical outlier here because it was where the outbreak started.\n\nLet's see the plots again without China."},{"metadata":{"trusted":true},"cell_type":"code","source":"factors = ['EXT', 'EST', 'AGR', 'CSN', 'OPN']\nfactor_names = ['Extraversion', 'Emotional Stability', 'Agreeableness', 'Conscientiousness', 'Openness']\n\nfor i, factor in enumerate(['EXT', 'EST', 'AGR', 'CSN', 'OPN']):\n    # Compute the correlation coefficient\n    corr = pearsonr(covid19_big5[covid19_big5.country != 'CN'][factor], \n                    covid19_big5[covid19_big5.country != 'CN'].ConfirmedCases)\n    corr = [np.round(c, 2) for c in corr]\n    text = 'r=%s, p=%s' % (corr[0], corr[1])\n    \n    ax = sns.regplot(x=factor, \n                y=\"ConfirmedCases\", \n                data=covid19_big5[covid19_big5.country != 'CN'])\n    \n    ax.set_title(f\"Confirmed cases at {days} days after first {cases} cases \" + \n                 \"\\n by average score on Big 5 factor \" + factor_names[i] + \n                 \"\\n\" + text)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* As we see here, the only Big 5 factor that seems to show a pattern was Openness: Countries with higher levels of openness saw more growth over the 3-day period. Although I think it could be argued that the countries lower on OPN may have had too much influence in the model, given how far they are set apart from the other data points."},{"metadata":{"trusted":true},"cell_type":"code","source":"covid19_big5\\\n    .loc[:, ['country', 'OPN', 'ConfirmedCases']]\\\n    .sort_values('OPN', ascending=False)\\\n    .merge(country_isos, \n           left_on='country', \n           right_on='country_abbr')\\\n    .drop(['country_abbr', 'country'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file_name = r'./dataset.csv'\ncovid19_big5.to_csv(file_name, sep=',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we need to combine the COVID-19 data with the world happiness report data\n# Load this data\nworld_happiness_report = pd.read_csv(\"/kaggle/input/world-happiness-report/2020.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"world_happiness_report = world_happiness_report.rename(columns={\"Country name\": \"Country/Region\"})\n\ncombined = pd.merge(covid19, world_happiness_report, on=\"Country/Region\")\ncombined","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file_name = r'./dataset.csv'\ncombined.to_csv(file_name, sep=',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# big5.head\n# combined.head\ncombined2 = pd.merge(combined, big5, left_on='country_abbr', right_on='country')\ncombined2.head\n\n\ncombined3 = combined2[combined2['ConfirmedCases'] > 75]\nprint(combined3.country_abbr.unique())\n\ncombined2 = combined2[combined2['ConfirmedCases'] < 75]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file_name = r'./dataset.csv'\ncombined2.to_csv(file_name, sep=',')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}