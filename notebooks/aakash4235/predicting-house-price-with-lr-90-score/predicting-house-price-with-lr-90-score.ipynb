{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Importing some libraries.\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting train and test datasets.\ntrain = pd.read_csv(r'/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\ntest = pd.read_csv(r'/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\n\n#Combining the train and test dataFrame to save time.\ny = train['SalePrice'] # naming output(Saleprice) as another dataframe and will be joined \n                       # to original dataset later.\ntrain.drop('SalePrice', axis=1, inplace=True)\ndf = pd.concat([train,test])\ndf = df.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Most of the missing values can be filled using the text file given with dataset.\n# Let's get this text file.\nwith open(r'/kaggle/input/house-prices-advanced-regression-techniques/data_description.txt') as f:\n    a = f.read()\n    print(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Formula to get missing values from the data.\n\nn_missing = pd.DataFrame({'isnull':df.isnull().sum().sort_values(ascending=False).head(35), \n                 'percent':df.isnull().sum().sort_values(ascending=False).head(35)/len(df)*100})\nn_missing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data points whose only 1 or 2 values are missing are filled using mode.\n\nlst = ['BsmtHalfBath','Functional','Utilities','BsmtFullBath','Electrical','BsmtFinSF1','Exterior1st',\n       'Exterior2nd','GarageCars','GarageArea','KitchenQual','SaleType','TotalBsmtSF','BsmtUnfSF',\n       'BsmtFinSF2','ExterQual']\nfor i in lst:\n    df[i].replace(np.nan, df[i].mode()[0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filling none to some columns.\n\ndf['Alley'].fillna(value='no alley',inplace=True)\ndf['PoolQC'].fillna(value='No pool',inplace=True)\ndf['MiscFeature'].fillna(value='no feature',inplace=True)\ndf['Fence'].fillna(value='no fence',inplace=True)\ndf['FireplaceQu'].fillna(value='no fireplace',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# columns with no garge values.\ngar_fill = ['GarageType','GarageCond','GarageFinish','GarageQual']\n\nfor i in gar_fill:\n    df[i].replace(np.nan, 'no garage',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Columns with no basements.\n\nbsmt_fill = ['BsmtExposure','BsmtFinType2','BsmtFinType1','BsmtCond','BsmtQual']\n\nfor i in bsmt_fill:\n    df[i].replace(np.nan, 'no bsmt',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['GarageYrBlt'].fillna(value=0,inplace=True)\ndf['MasVnrArea'].fillna(value=0, inplace=True)\ndf['MasVnrType'].fillna(value='None',inplace=True)\n\n# filling these two variables using mode.\ndf['MSZoning'] = df.groupby('MSSubClass')['MSZoning'].apply(lambda x: x.fillna(x.mode()[0]))\ndf['LotFrontage'] = df.groupby('Neighborhood')['LotFrontage'].apply(lambda x: x.fillna(x.median()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the missing values.\ndf.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Some of the categorical variables are filled with numeric values to convert there datatypes from \n# object to int. Other way to convert datatypes is using dummy variables method which is used \n# later in this notebook.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"value_map = {'TA':5,'Gd':7,'Ex':9,'Fa':3,'no bsmt':0,'Po':2,'GLQ':1, 'ALQ':2, 'Unf':3, 'Rec':4,\n             'BLQ':5, 'LwQ':6,'no fireplace':0,'no garage':0,'No pool':0,'no fence':0, 'MnPrv':3, \n             'GdWo':2, 'GdPrv':4, 'MnWw':1}\n\ndf['KitchenQual'] = df['KitchenQual'].map(value_map).astype('int')\n\ndf['BsmtCond'] = df['BsmtCond'].map(value_map).astype('int')\ndf['BsmtQual'] = df['BsmtQual'].map(value_map).astype('int')\n\ndf['BsmtFinType1'] = df['BsmtFinType1'].map(value_map).astype('int')\ndf['BsmtFinType2'] = df['BsmtFinType2'].map(value_map).astype('int')\n\ndf['FireplaceQu'] = df['FireplaceQu'].map(value_map).astype('int')\n\ndf['GarageCond'] = df['GarageCond'].map(value_map).astype('int')\ndf['GarageQual'] = df['GarageQual'].map(value_map).astype('int')\n\ndf['PoolQC'] = df['PoolQC'].map(value_map).astype('int')\n\ndf['Fence'] = df['Fence'].map(value_map).astype('int')\n\ndf['ExterCond'] = df['ExterCond'].map(value_map).astype('int')\ndf['ExterQual'] = df['ExterQual'].map(value_map).astype('int')\ndf['HeatingQC'] = df['HeatingQC'].map(value_map).astype('int')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Outliers Treatment\n\nHere we will treat oultiers graphically."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting only numeric data for plotting and getting better understanding of outliers.\n\nnumerical_data = df.select_dtypes(exclude =['object'])\n\n# Creating a new dataFrame and joining y variable for pairplot.\ntrain_graph = df.iloc[ :len(y), : ]\ntrain_graph = train_graph.join(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data=train_graph, y_vars=['SalePrice'], x_vars=['LotFrontage', 'LotArea', 'OverallQual','OverallCond','MasVnrArea'])\nsns.pairplot(data=train_graph,y_vars=['SalePrice'],x_vars=['BsmtFinSF1','BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF','MiscVal'])\nsns.pairplot(data=train_graph,y_vars=['SalePrice'],x_vars=['LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath'])\nsns.pairplot(data=train_graph,y_vars=['SalePrice'],x_vars=['FullBath','HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd',])\nsns.pairplot(data=train_graph,y_vars=['SalePrice'],x_vars=['Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF'])\nsns.pairplot(data=train_graph,y_vars=['SalePrice'],x_vars=['OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea'])\n#sns.pairplot(data=train_graph,y_vars=['SalePrice'],x_vars=[ 'SalePrice'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.join(y)\n# Dropping outliers manually using pairplot.\n\ndf = df.drop(df[(df['OverallCond']<0.8)&(df['SalePrice']>300000)].index)\ndf = df.drop(df[(df['OverallCond']>1)&(df['SalePrice']>700000)].index)\ndf = df.drop(df[(df['OverallQual']>9)&(df['SalePrice']<300000)].index)\ndf = df.drop(df[(df['MasVnrArea']<1)&(df['SalePrice']>700000)].index)\ndf = df.drop(df[(df['BsmtHalfBath']>0.5)&(df['SalePrice']>600000)].index)\ndf = df.drop(df[(df['PoolArea']>1.5)&(df['SalePrice']>600000)].index)\n\ndf.reset_index(drop=True,inplace=True)\ny = df['SalePrice']\ny.dropna(inplace=True)\ndf.drop('SalePrice',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Categorical data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting dummmy variables for the categorical data since machine cannot read text.\n\ncategorical_data = df.select_dtypes(include=['object'])\n\ncat_dum = pd.get_dummies(categorical_data, drop_first=True)\ndf.drop(categorical_data.columns, axis=1, inplace=True)\ndf = pd.concat([df,cat_dum],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seperating train and test datasets for Training the model.\n\ntrain_df = df.iloc[ : len(y)]\ntest_df = df.iloc[len(y): ]\n\ntrain_df = train_df.join(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = train_df.drop('SalePrice',axis=1)\ny = train_df['SalePrice']\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nlr = LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = lr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score\n\nprint(r2_score(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And thats it. We have a model with 89% score."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}