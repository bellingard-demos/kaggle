{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing Libraries:\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/amazon-reviews-unlocked-mobile-phones/Amazon_Unlocked_Mobile.csv')\nprint('Total Rows ==',df.shape[0])\nprint('-'*80)\nprint('Missing values: ','\\n',df.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Since we only need Review and Rating column so let's drop rest of the columns:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping unecessary columns.\ndf.drop(['Product Name','Brand Name','Price','Review Votes'], axis=1,inplace=True)\n\n# Missing Values\ndf = df.dropna() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We will classify Rating into 2 classes:\n1. Positive (1)\n2. Negative (0)\n\n### So, Rating with 1 and 2 will be 0(negative) and rating with 4 and 5 will be 1(positive)."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[(df['Rating']<=2) | (df['Rating']>=4)] # Taking all rows other than 3 rating rows.\n\n# Assigning 0 and 1 value to rating column.\ndf = df.replace({1:0, 2:0, 4:1, 5:1})\ndf.reset_index(drop=True, inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We will be using Tf-idf Vectorizer for text.\nIt will transform words to tokens, remove stop words and will give ngram range to the text all at once."},{"metadata":{"trusted":true},"cell_type":"code","source":"trans = TfidfVectorizer(stop_words='english', ngram_range=(1,3), max_features=100000)\nX = trans.fit_transform(df['Reviews'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test, y_train, y_test = train_test_split(X, df['Rating'], test_size=0.15,\n                                                  random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(max_iter=10000)\nlr.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = lr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,accuracy_score\nprint(classification_report(y_test, prediction))\nprint('-'*80)\nprint('Accuracy', accuracy_score(y_test, prediction))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Good to go!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}