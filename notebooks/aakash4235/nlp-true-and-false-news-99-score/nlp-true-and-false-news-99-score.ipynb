{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Importing some libraries.\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport nltk\nimport re\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nporter_stemmer = PorterStemmer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake_df = pd.read_csv(r'/kaggle/input/fake-and-real-news-dataset/Fake.csv')\nvalid_df = pd.read_csv(r'/kaggle/input/fake-and-real-news-dataset/True.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combining the fake and true news datasets.\n\nfake_df['result'] = 0\nvalid_df['result'] = 1\ndf = pd.concat([fake_df, valid_df], axis=0)\ndf.reset_index(inplace=True, drop=True)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We only need 'text' and 'result' column therefore dropping other columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['title','subject','date'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The true news has company's name(Reuters) and locaion of news in the beginning which will help model in classification."},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['result']==1]['text'].apply(lambda x: x.split('-')[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### This next function will help in cleaning the text column for further actions. There are multiple ways to do this step. It will remove special characters, punctuations, stopwords and I have also added stemming to it."},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_mess_s(a):\n    lower_ = a.lower() \n    sp_chars = re.sub(\"\\\\W\",\" \", lower_) #Removing any special characters.\n    \n    nopunc = [x for x in sp_chars if x not in string.punctuation] #Removing punctuations.\n    nopunc = ''.join(nopunc) # This code is to change list back to string.\n    \n    stop_word= [x for x in nopunc.split() if x.lower() not in stopwords.words('english')] \n    # Removing stop words.\n    stop_word = ' '.join(stop_word)\n    \n    # Stemming the words in the text(Stemming helps in achieving root forms of inflected words).\n    words = re.split(\"\\\\s+\",stop_word)\n    stemmed_words = [porter_stemmer.stem(word) for word in words]\n    return ' '.join(stemmed_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying the above function to text column. (This may take a while.)\n\ndf['text'] = df['text'].apply(clean_mess_s)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(df['text'], df['result'],\n                                                 test_size=0.3,random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Count Vectorizer us used to transfrom a corpora of words/text to vector of token counts."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = cv.fit_transform(X_train)\nX_test = cv.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We'll not fit count vectorizer to test set rather we'll only transfrom it."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(max_iter=10000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = lr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}