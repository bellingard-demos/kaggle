{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport random\nimport cv2\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"common_dir = '/kaggle/input/brain-mri-images-for-brain-tumor-detection/brain_tumor_dataset/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = os.path.join(common_dir, 'no/')\nim_loc = random.choice(os.listdir(path))\nim = cv2.imread(os.path.join(path, im_loc))\nprint('Shape of Image:',im.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# displaying healthy brain image:\npath_0 = os.path.join(common_dir, 'no/')\nplt.figure(figsize=(15,15))\nprint('-'*20, 'Healthy Brain Images','-'*20)\nfor i in range(1,9):\n    plt.subplot(2,4,i)\n    img_loc = random.choice(os.listdir(path_0))\n    img = cv2.imread(os.path.join(path_0, img_loc))\n    plt.imshow(img)\n    plt.xticks([]), plt.yticks([])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# displaying tumor brain image:\npath_1 = os.path.join(common_dir, 'yes/')\nplt.figure(figsize=(15,15))\nprint('-'*20, 'Tumor Brain Images','-'*20)\nfor i in range(1,9):\n    plt.subplot(2,4,i)\n    img_loc = random.choice(os.listdir(path_1))\n    img = cv2.imread(os.path.join(path_1, img_loc))\n    plt.imshow(img)\n    plt.xticks([]), plt.yticks([])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing Libraries for training the model:\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization\nfrom keras.models import Model, Sequential\nfrom keras.applications import MobileNetV2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(rescale=1.0/255.0,\n                            brightness_range=[0.2,1],\n                            zoom_range=(0.2,1),\n                            vertical_flip=True,\n                            horizontal_flip=True,\n                            validation_split=0.1)\n\ntrain_set = datagen.flow_from_directory(common_dir,\n                                       target_size=(224,224),\n                                       class_mode='binary',\n                                       subset='training')\n\ntest_set = datagen.flow_from_directory(common_dir,\n                                      target_size=(224,224),\n                                      class_mode='binary',\n                                      subset='validation')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = MobileNetV2(weights='imagenet',input_shape=(224,224,3), include_top=False,pooling='avg.')\n\nbase_model.trainable=False\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(BatchNormalization()) # faster computational.\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_set, epochs=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}