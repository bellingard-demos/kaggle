{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install xlwt","metadata":{"_kg_hide-input":true,"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearnex import patch_sklearn  #This is a library to accelerate existing scikit-learn code\npatch_sklearn() #For more info: https://github.com/intel/scikit-learn-intelex\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\nimport xgboost as xgb\nfrom mlxtend.classifier import StackingCVClassifier\n\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score, ConfusionMatrixDisplay, f1_score, precision_score, recall_score, accuracy_score, average_precision_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.model_selection import RandomizedSearchCV, cross_val_score, KFold, StratifiedKFold, train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.ensemble import VotingClassifier, RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.naive_bayes import MultinomialNB, BernoulliNB\nfrom imblearn.pipeline import make_pipeline\nfrom imblearn.under_sampling import RandomUnderSampler, NearMiss\nfrom imblearn.over_sampling import ADASYN\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom wordcloud import WordCloud\nimport re\nimport spacy\nfrom nltk.corpus import stopwords\nimport warnings\n\nwarnings.filterwarnings('ignore')\nnp.random.seed(0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/reviews/Restaurant_Reviews.tsv\", sep=\"\\t\")\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let' see if there are any null. (There isn't.)","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Liked needed to be categorical.","metadata":{}},{"cell_type":"code","source":"df[\"Liked\"]=df[\"Liked\"].astype(\"category\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_axes_list(length, column_number=2):\n    fig, axes_list = get_fig_and_axes_list(length, column_number=column_number )\n    return axes_list","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_fig_and_axes_list(plot_count, column_number=2):\n    \"\"\"\n    This function takes in the number of subplots to be plotted and the desired number of columns for the subplot grid. \n    It then calculates the number of rows required and generates a matplotlib figure with the given number of subplots \n    in a grid with the desired number of columns.\n    \n    Args:\n    - plot_count: int, the number of subplots to be plotted\n    - column_number: int, the number of columns in the subplot grid. Default value is 2.\n    \n    Returns:\n    - fig: matplotlib Figure object, the generated figure\n    - axes_list: list of matplotlib Axes objects, the axes of the subplots in the figure\n    \"\"\"\n    reminder_num = plot_count % column_number\n    row_num = (plot_count // column_number) + (reminder_num > 0)\n    axes_list = []\n    row_number_alignment = np.ones((row_num, column_number), dtype=\"int\")\n    if reminder_num != 0:\n        row_number_alignment[-1,-(column_number - reminder_num):] = 0\n    coefficient = (3.5 if plot_count==1 else 4.2)\n    col_size = coefficient*column_number\n    row_size = coefficient*row_num\n    fig = plt.figure(figsize=(col_size, row_size), layout=\"constrained\")\n    spec = fig.add_gridspec(row_num, column_number)\n    for i in range(row_num):\n        for j in range(column_number):\n            if row_number_alignment[i,j] == 1:\n                ax = fig.add_subplot(spec[i,j])\n                axes_list.append(ax)\n    return fig,axes_list","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Liked\"].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = get_axes_list(1)[0]\nsns.set_palette(\"PuRd_r\")\nbar = sns.countplot(x=df[\"Liked\"],ax=ax)\nax.set_xticklabels(['Not Liked', 'Liked'])\nax.set_xlabel(None)\nax.set_ylabel(\"Count\")\nbar.set_title('Distribution of Restaurant Reviews')\nplt.show()","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Review'] = df['Review'].str.lower()","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stopwords","metadata":{}},{"cell_type":"markdown","source":"A stopword is a commonly used word in a language that is usually removed from text data because it is not considered useful for natural language processing tasks such as text classification or sentiment analysis. Examples of stopwords in English include \"a,\" \"an,\" \"the,\" \"and,\" \"or,\" \"but,\" and \"is\".Since these words are so common and do not carry much meaning on their own, they are often removed from text data to improve the efficiency and accuracy of natural language processing algorithms. But in this project, i will be using a custom stopwords list that doesn't contain neggative words because we need them. If we don't the sentences of \"It is not good\" and \"It is good\" will be same.","metadata":{}},{"cell_type":"code","source":"stopwords = stopwords.words(\"english\")","metadata":{"_kg_hide-input":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_stopwords = \\\n['i','me','my','myself','we','our','ours','ourselves','you',\"you're\",\"you've\",\"you'll\",\"you'd\",'your','yours','yourself','yourselves','he','him','his','himself','she',\"she's\",'her','hers','herself','it',\"it's\",'its','itself','they','them','their','theirs','themselves','what','which','who','whom','this','that',\"that'll\",'these','those','am','is','are','was','were','be','been','being','have','has','had','having','do','does','did','doing','a','an','the','and','if','or','because','as','until','while','of','at','by','for','with','about','against','between','into','through','during','before','after','above','below','to','from','up','down','in','out','on','over','under','again','further','then','once','here','there','when','where','why','how','all','both','each','few','more','most','other','some','such','own','same','so','than','too','s','can','will','just','should',\"should've\",'now','d','ll','m','o','re','ve','y','ma']","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the en_core_web_sm model using its package name\nnlp = spacy.load(\"en_core_web_sm\")","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lemmatization ","metadata":{}},{"cell_type":"markdown","source":"Lemmatization is a process of reducing words to their base or dictionary form, which is called a lemma. The main purpose of lemmatization is to group together different inflected forms of a word, such as \"run,\" \"runs,\" and \"running,\" so that they can be analyzed as a single item. This is often used in natural language processing to improve the accuracy of text analysis and machine learning models.\n\nUnlike stemming, which simply chops off the end of words to get to their base form, lemmatization uses a vocabulary and morphological analysis of words to reduce them to their base form. This means that the resulting lemmas are actual words that can be found in a dictionary, rather than just truncated versions of the original words. For example, the lemma of \"I'm\" is \"I\" and \"am,\" and the lemma of \"went\" is \"go.\" If the word \"I'm\" is used in stemming, only the word \"I\" will be extracted, which is not desirable.","metadata":{}},{"cell_type":"code","source":"string = \"Hello! I don't know what I'm doing here.\"\nprint(\"Original sentence: \",string)\ndoc = nlp(string)\nlemmas = [token.lemma_ for token in doc]\nprint(\"After lemmatization: \",lemmas)","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Review_tokenized'] = df['Review'].apply(lambda x: \" \".join([token.lemma_ for token in nlp(x)])).str.lower()\ndf['Review_tokenized'] = df['Review_tokenized'] \\\n.apply(lambda x: \" \".join([word for word in re.sub(\"[^a-zA-Z]\",\" \",x).split() if not word in set(custom_stopwords)]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's have a look at our DataFrame's tokenized version.","metadata":{}},{"cell_type":"code","source":"pd.options.display.min_rows = 15\npd.options.display.max_colwidth = 50\ndf[['Review_tokenized',\"Liked\"]] ","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Wordcloud","metadata":{}},{"cell_type":"markdown","source":"A word cloud is a visual representation of text data, where the most frequently occurring words in a given set of text are displayed in a way that highlights their prominence.Word clouds can be useful for quickly identifying the key themes or topics in a large body of text.","metadata":{}},{"cell_type":"code","source":"spacy_stopwords = nlp.Defaults.stop_words\ndf['Review_tokenized_restrict_stopwords'] = df['Review_tokenized'] \\\n.apply(lambda x: \" \".join([word for word in re.sub(\"[^a-zA-Z]\",\" \",x).split() if not word in set(spacy_stopwords)]))\ntext = \" \".join(i for i in df.Review_tokenized_restrict_stopwords)\nwordcloud = WordCloud(max_font_size=100,\n                      max_words=200,\n                      background_color=\"black\").generate(text)\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df[\"Review_tokenized\"]\ny = df[\"Liked\"]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer = CountVectorizer(ngram_range=(1,2))\nX_count = vectorizer.fit_transform(X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf_idf_vectorizer = TfidfVectorizer(ngram_range=(1, 2))\nX_tf_idf = tf_idf_vectorizer.fit_transform(X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rand_state=42\nX_train, X_test, y_train, y_test = train_test_split(X_count, y, test_size=0.2,random_state=rand_state, stratify=y)","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Our results DataFrame\nresults = pd.DataFrame(columns=[\"Function Name\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\",\n                               \"TN\", \"FP\", \"FN\", \"TP\", \"ROC-AUC Score\", \"Precision-Recall Score\", \"Train CV Score\"])\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=rand_state)\nkf_for_test = StratifiedKFold(n_splits=6, shuffle=True, random_state=0) #We use another one for testing different cross validations","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cross_val_score_for_sampling(model, X_train, y_train, cv=kf_for_test, \n                                 results=results, undersample=False, \n                                 oversample=False, stack=False, other=False):  \n    scoring_metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc', 'average_precision']\n    scores_dict = {metric: [] for metric in scoring_metrics}\n    sampling_methods = {'undersample': NearMiss(sampling_strategy='majority', n_jobs=-1, version=3),\n                        'oversample': ADASYN(random_state=rand_state)}\n    sample_pipeline = make_pipeline(model)\n    if undersample:\n        sample_pipeline.steps.insert(0, ('undersample', sampling_methods['undersample']))\n    if oversample:\n        sample_pipeline.steps.insert(0, ('oversample', sampling_methods['oversample']))\n    for train_idx, test_idx in cv.split(X_train, y_train):\n        sample_model = sample_pipeline.fit(X_train[train_idx], y_train[train_idx])\n        sample_prediction_proba = sample_model.predict_proba(X_train[test_idx])[:,1]\n        sample_prediction = np.round(sample_prediction_proba)\n        scores_dict[\"accuracy\"].append(accuracy_score(y_train[test_idx], sample_prediction))\n        scores_dict[\"precision\"].append(precision_score(y_train[test_idx], sample_prediction))\n        scores_dict[\"recall\"].append(recall_score(y_train[test_idx], sample_prediction))\n        scores_dict[\"f1\"].append(f1_score(y_train[test_idx], sample_prediction))\n        scores_dict[\"roc_auc\"].append(roc_auc_score(y_train[test_idx], sample_prediction_proba))\n        scores_dict[\"average_precision\"].append(average_precision_score(y_train[test_idx], sample_prediction_proba))\n    return  scores_dict","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_scoring_name(scoring):\n    equal = {\"accuracy\": \"Accuracy\", \n             \"precisione\": \"Precision\", \n             \"recall\": \"Recall\", \n             \"f1\": \"F1\", \n             \"roc_auc\": \"ROC AUC\", \n             \"average_precision\": \"AP AUC\"} \n    return equal[scoring]","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_training_cross_validated_score(model, X_train, y_train, undersample=False, oversample=False, stack=False, other=False, scoring=\"Accuracy\"):\n    try:\n        if undersample or oversample or stack:\n            training_cross_validated_score = np.mean(\n                cross_val_score_for_sampling(\n                    model, X_train, y_train, undersample=undersample, oversample=oversample, stack=stack, other=other)[scoring])\n        elif other:\n            return None\n        else:\n            training_cross_validated_score = cross_val_score(\n                model, X_train, y=y_train, cv=kf, scoring=scoring, n_jobs=-1).mean()\n        return training_cross_validated_score\n    except Exception as e:\n        return None","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_scores(models, X_train=X_train, X_test=X_test, y_train=y_train, \n                 y_test=y_test, result_prefix=\"\",results=results, undersample=False, \n                 oversample=False, stack=False, other=False, scoring=\"roc_auc\"):\n    \"\"\"\n    Plot confusion matrices and evaluation metrics for a dictionary of models.\n\n    Parameters:\n    -----------\n    models : dict\n        A dictionary of scikit-learn models to evaluate.\n    X_train : array-like, shape (n_samples, n_features), default=X_train_scaled\n        The training input samples.\n    X_test : array-like, shape (n_samples, n_features), default=X_test_scaled\n        The testing input samples.\n    y_train : array-like, shape (n_samples,), default=y_train\n        The target values of the training input samples.\n    y_test : array-like, shape (n_samples,), default=y_test\n        The target values of the testing input samples.\n    result_prefix : str, default=\"\"\n        A prefix to add to the function name in the results DataFrame.\n    results : pandas.DataFrame, default=results\n        A DataFrame to store the results.\n    undersample : bool, default=False\n        Whether to perform undersampling during cross-validation on training set.\n    oversample : bool, default=False\n        Whether to perform oversampling during cross-validation on training set.\n    stack : bool, default=False\n        Whether Stacking Classifier will be used during cross-validation on training set.\n    other : bool, default=False\n        Whether cross-validation will be used on training set.\n    scoring : str or callable, default=\"roc_auc\"\n        The scoring metric to use for cross validation .\n\n    Returns:\n    --------\n    None\n    \"\"\"\n    ax_list =get_axes_list(len(models))\n    ax_counter = 0\n    for i, (name, model) in enumerate(models.items()):\n        model_name = model.__class__.__name__\n        ax_of_model = ax_list[i]\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        y_pred = np.round(y_pred)\n        accuracy = accuracy_score(y_test, y_pred)\n        precision = precision_score(y_test, y_pred)\n        recall = recall_score(y_test, y_pred)\n        f1 = f1_score(y_test, y_pred)\n        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n        if hasattr(model, \"predict_proba\"):\n            predicted_prob = model.predict_proba(X_test)[:, 1]\n            roc_auc = roc_auc_score(y_test, predicted_prob)\n            average_precision = average_precision_score(y_test, predicted_prob)\n        else:\n            predicted_prob = None\n            roc_auc = None\n            average_precision = None\n        training_cross_validated_score = get_training_cross_validated_score(\n            model, X_train, y_train, undersample=undersample, oversample=oversample, stack=stack, other=other, scoring=scoring)\n        scoring_name = get_scoring_name(scoring)\n        scoring_variable = locals()[scoring]\n        if training_cross_validated_score and scoring_variable:\n            ax_of_model.set_title(f\"{model_name} \\n ({scoring_name}: {scoring_variable:3.2f} || Train {scoring_name}: {scoring_variable:3.2f})\",\n                                  fontdict={'fontsize':10})\n        elif scoring_variable:\n            ax_of_model.set_title(f\"{model_name} \\n ({scoring_name} score: {scoring_variable:3.2f})\")\n        else:\n            ax_of_model.set_title(f\"{model_name}\")\n        function_name = f\"{model_name}{result_prefix}\"    \n        function_location = results[results[\"Function Name\"] == function_name].index\n        index_to_insert=(len(results.index) if function_location.empty else function_location[0])\n        results.loc[index_to_insert] = [function_name, accuracy,\n                                        precision, recall, f1, tn, fp, fn, tp, roc_auc, \n                                        average_precision, training_cross_validated_score] \n        labels_ = ['No Fraud', 'Fraud']\n        ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=labels_, \n                                                ax=ax_of_model, cmap='Blues', xticks_rotation=\"vertical\")\n        #print(classification_report(y_test, y_pred)) #If you want to get classification report.\n    plt.show()","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = {\"Random Forest\":RandomForestClassifier(n_jobs=-1, random_state=rand_state),\n          \"BernoulliNB\":BernoulliNB(),\n          \"MultinomialNB\":MultinomialNB(),\n          \"Extra\":ExtraTreesClassifier(n_jobs=-1),}\nprint_scores(models)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### And try Voting Classifier.","metadata":{}},{"cell_type":"markdown","source":"A voting classifier is a machine learning technique that combines the predictions of multiple models to make a final prediction. This ensemble approach can improve the accuracy and stability of predictions, especially when individual models are prone to error or have biases. ","metadata":{}},{"cell_type":"code","source":"clf_meta=RandomForestClassifier(n_jobs=-1, random_state=rand_state)\nclassifiers_stack=[ExtraTreesClassifier(n_jobs=-1),\n                   RandomForestClassifier(n_jobs=-1),\n                   xgb.XGBClassifier(eval_metric=average_precision_score, n_jobs=-1, \n                                     tree_method=\"hist\", random_state=rand_state),\n                   xgb.XGBRFClassifier(objective=\"binary:logistic\", eval_metric=average_precision_score,\n                                       n_jobs=-1, tree_method=\"hist\", random_state=rand_state),\n                   LogisticRegression(solver=\"liblinear\",n_jobs=-1,max_iter=int(1e9), class_weight=\"balanced\"),\n                   KNeighborsClassifier(n_jobs=-1),\n                   SGDClassifier(loss=\"modified_huber\", n_jobs=-1,max_iter=int(1e9))]\nclf_stack = StackingCVClassifier(classifiers=classifiers_stack,\n                                 meta_classifier=clf_meta,\n                                 cv=kf,\n                                 verbose=False,\n                                 use_probas=True,\n                                 use_features_in_secondary=True)","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vc ={\"Stack\": clf_stack }\nprint_scores(vc, stack=True, result_prefix=\"_voting_stack\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bonus: TPOT","metadata":{}},{"cell_type":"markdown","source":"Last but not least. Let's try TPOT. It's is a Python Automated Machine Learning tool that optimizes machine learning pipelines using genetic programming. Let's try it.","metadata":{}},{"cell_type":"code","source":"try: \n    from tpot import TPOTClassifier\n    # If you have time, then don't hesitate increasing generations ,offspring_size and population_size\n    TPOT_model_us = TPOTClassifier(generations=30,offspring_size=20, scoring='accuracy', cv=kf, \n                                     population_size=20, verbosity=0, n_jobs=-1, random_state=rand_state)\n    models = {\"TPOT\": TPOT_model_us}\n    print_scores(models, X_train=X_train.toarray(), X_test=X_test.toarray(), y_train=y_train, \n                 y_test=y_test, other=True, result_prefix=\"_us_TPOT\") \nexcept Exception as e:\n    print(e,\"Packages have conficlict.\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TPOT_model_us.fitted_pipeline_ ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results.sort_values(by=\"ROC-AUC Score\",ascending=False).style.format(precision=3)\\\n                    .highlight_max(subset=[\"Accuracy\",\"Precision-Recall Score\",\"ROC-AUC Score\",\"Train CV Score\"], color ='lightgreen')","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Best results highlited. I will be waiting for your feedback :)","metadata":{}},{"cell_type":"code","source":"results.to_excel('results_1.1.xls', index=False)","metadata":{"_kg_hide-output":true,"_kg_hide-input":true},"execution_count":null,"outputs":[]}]}