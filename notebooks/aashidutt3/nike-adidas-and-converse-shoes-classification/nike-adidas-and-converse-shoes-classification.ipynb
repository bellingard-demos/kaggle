{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https://thumbs.gfycat.com/RelievedRectangularIcefish-max-1mb.gif\" alt=\"Heat beating\" style=\"height:366px;margin-top:3rem;\"> </div>","metadata":{}},{"cell_type":"markdown","source":"# <h1 style='background:#FAC213; border:0; color:white'><center>üëüNike, Adidas and Converse Shoes Classificationüëû</center></h1> ","metadata":{}},{"cell_type":"markdown","source":"# **<span style=\"color:#cd486b;\">üì∞About the Dataset</span>**\n\nThe dataset contains images of shoes from Nike, Adidas and Converse to make multi-class classification.\n\n# **<span style=\"color:#cd486b;\">üìÅAbout the files</span>**\n\nThe dataset contains 2 folders: one with the test data and the other one with train data.\nThe test-train-split ratio is 0.14, with the test dataset containing 114 images and the train dataset containing 711.\nThe images have a resolution of 240x240 pixels in RGB color model.\nBoth the folders contain 3 classes:\n\n> Adidas\n\n> Converse\n\n> Nike","metadata":{}},{"cell_type":"code","source":"#Environment check\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-08-28T12:16:36.06635Z","iopub.execute_input":"2022-08-28T12:16:36.066727Z","iopub.status.idle":"2022-08-28T12:16:36.071723Z","shell.execute_reply.started":"2022-08-28T12:16:36.066694Z","shell.execute_reply":"2022-08-28T12:16:36.0706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Imports\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras import optimizers, losses\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","metadata":{"execution":{"iopub.status.busy":"2022-08-28T12:16:37.049051Z","iopub.execute_input":"2022-08-28T12:16:37.049439Z","iopub.status.idle":"2022-08-28T12:16:43.569714Z","shell.execute_reply.started":"2022-08-28T12:16:37.049408Z","shell.execute_reply":"2022-08-28T12:16:43.568648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:#cd486b;\">üì∞Get Data and apply some augmentation</span>**\n","metadata":{}},{"cell_type":"code","source":"train_dir = \"../input/nike-adidas-and-converse-imaged/train\"\ntest_dir = \"../input/nike-adidas-and-converse-imaged/test\"","metadata":{"execution":{"iopub.status.busy":"2022-08-28T12:16:43.571295Z","iopub.execute_input":"2022-08-28T12:16:43.571942Z","iopub.status.idle":"2022-08-28T12:16:43.579359Z","shell.execute_reply.started":"2022-08-28T12:16:43.571909Z","shell.execute_reply":"2022-08-28T12:16:43.577475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale = 1./ 255, rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2,\n                                  shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True, fill_mode = 'nearest')","metadata":{"execution":{"iopub.status.busy":"2022-08-28T12:16:45.452612Z","iopub.execute_input":"2022-08-28T12:16:45.453808Z","iopub.status.idle":"2022-08-28T12:16:45.45983Z","shell.execute_reply.started":"2022-08-28T12:16:45.453755Z","shell.execute_reply":"2022-08-28T12:16:45.459036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale = 1./ 255)","metadata":{"execution":{"iopub.status.busy":"2022-08-28T12:16:45.855742Z","iopub.execute_input":"2022-08-28T12:16:45.856489Z","iopub.status.idle":"2022-08-28T12:16:45.860711Z","shell.execute_reply.started":"2022-08-28T12:16:45.856449Z","shell.execute_reply":"2022-08-28T12:16:45.859738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = train_datagen.flow_from_directory(directory = train_dir, batch_size = 32, target_size = (240,240), class_mode = \"categorical\", shuffle = False)\ntest_data = test_datagen.flow_from_directory(directory = test_dir, batch_size = 32, target_size = (240,240), class_mode = \"categorical\")","metadata":{"execution":{"iopub.status.busy":"2022-08-28T12:16:50.337818Z","iopub.execute_input":"2022-08-28T12:16:50.338207Z","iopub.status.idle":"2022-08-28T12:16:50.560592Z","shell.execute_reply.started":"2022-08-28T12:16:50.338161Z","shell.execute_reply":"2022-08-28T12:16:50.55971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:#cd486b;\">üåüModel</span>**\n","metadata":{}},{"cell_type":"code","source":"model = tf.keras.models.Sequential([\n    Conv2D(16, (3,3), activation = 'relu', input_shape = (240,240, 3)),\n    MaxPooling2D(2,2),\n    Conv2D(32, (3,3), activation = 'relu'),\n    MaxPooling2D(2,2),\n    Conv2D(32, (3,3), activation = 'relu'),\n    MaxPooling2D(2,2),\n    Conv2D(32, (3,3), activation = 'relu'),\n    MaxPooling2D(2,2),\n    Flatten(),\n    Dense(512, activation = 'relu'),\n    Dropout(0.2),\n    Dense(3, activation = 'softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2022-08-28T12:16:53.076282Z","iopub.execute_input":"2022-08-28T12:16:53.076938Z","iopub.status.idle":"2022-08-28T12:16:53.266296Z","shell.execute_reply.started":"2022-08-28T12:16:53.076893Z","shell.execute_reply":"2022-08-28T12:16:53.265433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-28T12:16:55.151244Z","iopub.execute_input":"2022-08-28T12:16:55.153985Z","iopub.status.idle":"2022-08-28T12:16:55.160663Z","shell.execute_reply.started":"2022-08-28T12:16:55.153945Z","shell.execute_reply":"2022-08-28T12:16:55.159566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:#cd486b;\">üòìFailed Experiment</span>**\n","metadata":{}},{"cell_type":"code","source":"model.compile(loss = 'categorical_crossentropy', optimizer = tf.keras.optimizers.Adam(), metrics = ['accuracy'])\nhistory = model.fit(train_data, epochs = 20, steps_per_epoch = len(train_data), \n                    validation_data = test_data, validation_steps = int(0.25 * len(test_data)))","metadata":{"execution":{"iopub.status.busy":"2022-08-28T12:16:57.780346Z","iopub.execute_input":"2022-08-28T12:16:57.780725Z","iopub.status.idle":"2022-08-28T12:23:31.641821Z","shell.execute_reply.started":"2022-08-28T12:16:57.780693Z","shell.execute_reply":"2022-08-28T12:23:31.640872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:#cd486b;\">ü§©Try Transfer Learning</span>**\n","metadata":{}},{"cell_type":"code","source":"#transfer learning\n\nbase_model = tf.keras.applications.ResNet50V2(include_top = False)\nbase_model.trainable = False\n\ninputs = tf.keras.layers.Input(shape = (240, 240, 3), name = 'InputLayer')\nx = base_model(inputs)\nx = tf.keras.layers.GlobalAveragePooling2D(name = 'global_average_pooling_layer')(x)\nx = tf.keras.layers.Dense(512, activation = 'softmax', name = 'Dense_layer')(x)\nx = Dropout(0.2)(x)\noutputs = tf.keras.layers.Dense(3, activation = 'softmax', name = 'output_layer')(x)\n\nmodel = tf.keras.Model(inputs, outputs)\nmodel.compile(loss = 'categorical_crossentropy', optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), metrics = ['accuracy'])\nhistory = model.fit(train_data, epochs = 20, steps_per_epoch = len(train_data), \n                    validation_data = test_data, validation_steps = int(0.25 * len(test_data)))","metadata":{"execution":{"iopub.status.busy":"2022-08-28T12:48:04.785731Z","iopub.execute_input":"2022-08-28T12:48:04.786141Z","iopub.status.idle":"2022-08-28T13:08:18.319567Z","shell.execute_reply.started":"2022-08-28T12:48:04.786098Z","shell.execute_reply":"2022-08-28T13:08:18.318412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:#cd486b;\">üìäPlots</span>**\n","metadata":{}},{"cell_type":"code","source":"def plot_loss_curves(history):\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    \n    accuracy = history.history['accuracy']\n    val_accuracy = history.history['val_accuracy']\n    \n    epochs = range(len(history.history['loss']))\n    \n    plt.plot(epochs, loss, label = 'training_loss')\n    plt.plot(epochs, val_loss, label = 'val_loss')\n    plt.title('loss')\n    plt.xlabel('epochs')\n    plt.legend()\n    \n    plt.figure()\n    plt.plot(epochs, accuracy, label = 'training_accuracy')\n    plt.plot(epochs, val_accuracy, label = 'val_accuracy')\n    plt.title('accuracy')\n    plt.xlabel('epochs')\n    plt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-08-28T13:13:51.173923Z","iopub.execute_input":"2022-08-28T13:13:51.174381Z","iopub.status.idle":"2022-08-28T13:13:51.182356Z","shell.execute_reply.started":"2022-08-28T13:13:51.174341Z","shell.execute_reply":"2022-08-28T13:13:51.181118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss_curves(history)","metadata":{"execution":{"iopub.status.busy":"2022-08-28T13:13:52.202422Z","iopub.execute_input":"2022-08-28T13:13:52.202825Z","iopub.status.idle":"2022-08-28T13:13:52.594502Z","shell.execute_reply.started":"2022-08-28T13:13:52.20279Z","shell.execute_reply":"2022-08-28T13:13:52.593273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-08-28T13:14:00.232469Z","iopub.execute_input":"2022-08-28T13:14:00.232874Z","iopub.status.idle":"2022-08-28T13:14:10.630217Z","shell.execute_reply.started":"2022-08-28T13:14:00.232838Z","shell.execute_reply":"2022-08-28T13:14:10.629162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:#850E35;\">üî•Conclusion</span>**\n\nClearly, we see there is some overfitting which we can overcome. Rest the ResNet50 did some good work, next we can try inception or mobilenet models as well.\n\n-----------------------------------------------------------------------\n\n**<span style=\"color:#A77979;\">This is my very first Computer Vision Notebook. Some code snippets are inspired by a notebook by Emre Cicekyurt.</span>**\n\n**<span style=\"color:#A77979;\">This is the not the end of üëüüëûNike, Adidas and Converse Shoes Classification</span>**\n\n**<span style=\"color:#A77979;\">Stay Tuned for more on this notebook</span>**\n\n**<span style=\"color:#A77979;\">Please share your feedback and suggestions and help me improve üòá</span>**","metadata":{}}]}