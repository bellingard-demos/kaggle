{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **This notebook contains code to classify a whether a candidate is a credit risk or not?**\nI have implemented following algorithms using grid search with Cross validation to find optimal solution:\n\n1. SVM\n2. Decision Tree with Pruning\n3. K nearest neighbor\n4. AdaBoost\n5. Neural Net using MLP Classifier\n6. Custom Neural Net\n","metadata":{"id":"81YqoSv89qpE"}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nimport re\nimport seaborn\nimport time\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nfrom sklearn.utils import shuffle\n\n# Plots and stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Label Encoding & Scaling\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, OneHotEncoder\n\n# Model Building\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import confusion_matrix,classification_report,accuracy_score,f1_score,precision_score\nfrom sklearn.pipeline import Pipeline\n\n# Models\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import GridSearchCV,StratifiedKFold,KFold,train_test_split,cross_val_score,cross_val_predict\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n#Oversampling\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport itertools","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(42)","metadata":{"id":"M6itnMMJ9r-x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2 = pd.read_csv('/kaggle/input/credit-risk-customers')","metadata":{"id":"yOH_SXsr95FA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.head()","metadata":{"id":"BCGw82n296nm","outputId":"6ff67d3b-0e7c-4704-98dc-8c2af59f34c6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2['gender'] = 'Unknown'\ngender_pattern = re.compile(r'(male|female)', flags=re.IGNORECASE)\n\nfor index, row in df2.iterrows():\n    match = gender_pattern.search(row['personal_status'])\n    if match:\n        df2.at[index, 'gender'] = match.group()\n        row['personal_status'] = gender_pattern.sub('', row['personal_status'])\n\ndef drop_words(s, words):\n    for word in words:\n        s = s.replace(word, '')\n    return s.strip()\n\nwords_to_drop = ['male', 'female', 'fe']\ndf2['personal_status'] = df2['personal_status'].apply(lambda x: drop_words(x, words_to_drop))","metadata":{"id":"Yn4GBBoF98NF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_map = {'bad': 0, 'good': 1}\ndf2['class'] = df2['class'].map(class_map)","metadata":{"id":"0727FTRz-BRz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def object_to_categorical(df):\n    object_cols = df.select_dtypes(include='object').columns\n    for col in object_cols:\n        df[col] = df[col].astype('category')\n    return df\ndf = object_to_categorical(df2)","metadata":{"id":"QmQR-KqW-DSC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for column in df.columns:\n    unique_values = df[column].nunique()\n    print(f\"{column}: {unique_values}\")","metadata":{"id":"1USXs1Q8-Eug","outputId":"ef0d73c6-6e6a-4b57-af1a-f033a4f54751"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"id":"rT2Zp-vo-GJK","outputId":"efa5183b-716c-4985-d5e6-6d0ce063c04d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numeric_columns = df.select_dtypes(include=['float64', 'int64'])","metadata":{"id":"-CuSDQWS-H2c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Q1 = df.quantile(0.25)\nQ3 = df.quantile(0.75)\nIQR = Q3 - Q1\nlower_bound = Q1 - 1.5 * IQR\nupper_bound = Q3 + 1.5 * IQR\ndf = df[~((df[numeric_columns.columns] < lower_bound) | (df[numeric_columns.columns] > upper_bound)).any(axis=1)]","metadata":{"id":"yaGlYQET-JZT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_matrix = df.corr()\nplt.figure(figsize=(8, 5))\nsns.heatmap(df.corr(), annot=True, cmap='coolwarm')\nplt.title('Correlation before feature Engg')\nplt.savefig('Correlation before feature Engg')\nplt.show()","metadata":{"id":"I0y7Gqp7-MK4","outputId":"00587c92-ffc9-4351-c11a-19bc3198de9c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# FEATURE ENGINEERING","metadata":{"id":"Cdo_YDTDu4fX"}},{"cell_type":"code","source":"df['debt_to_income_ratio'] = df['credit_amount'] / (df['duration'] * df['installment_commitment'])\n\nbins = [0, 20, 30, 40, 50, 60, 70, 120]\nlabels = ['0-20', '21-30', '31-40', '41-50', '51-60', '61-70', '70+']\ndf['age_group'] = pd.cut(df['age'], bins=bins, labels=labels, include_lowest=True)\ndel df['age']\ndf['credit_utilization'] = df['credit_amount'] / df['existing_credits']","metadata":{"id":"I8HwO8ry-Nyp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_matrix = df.corr()\nplt.figure(figsize=(8, 5))\nsns.heatmap(df.corr(), annot=True, cmap='coolwarm')\nplt.title('Correlation after feature Engg')\nplt.savefig('Correlation_after_feature_engg')\nplt.show()","metadata":{"id":"h3Em64Lx-PWr","outputId":"49a43ea8-53d4-4a03-85ff-d7b7c71d5bfe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df['num_dependents']\ndel df['foreign_worker']","metadata":{"id":"m0uRl7K1-Qws"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = MinMaxScaler()\nnum_cols = ['duration', 'credit_amount', 'installment_commitment', 'residence_since',\n            'debt_to_income_ratio' ,'credit_utilization', 'existing_credits' ]\ndf[num_cols] = scaler.fit_transform(df[num_cols])","metadata":{"id":"-mWCNkuH-SUZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_cols = ['checking_status', 'credit_history', 'purpose', 'savings_status', 'employment', 'personal_status',\n            'other_parties', 'property_magnitude', 'other_payment_plans', 'housing', 'job', 'own_telephone',\n            'gender', 'age_group']\nle = LabelEncoder()\nfor col in cat_cols:\n    df[col] = le.fit_transform(df[col])","metadata":{"id":"G_VXZHy5-TpF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"smote = SMOTE()\nX = df.drop('class', axis=1)\ny = df['class']\nX, y = smote.fit_resample(X, y)\ndf = pd.concat([X, y], axis=1)","metadata":{"id":"9HA1IQCR-VH8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df.drop('class', axis=1), df['class'], test_size=0.2, random_state=42)","metadata":{"id":"4UxvObdo-W2t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ros = RandomOverSampler()\n# X_train, y_train = ros.fit_resample(X_train, y_train)","metadata":{"id":"6QBlJYFigzlj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_results = []\ntest_results = []","metadata":{"id":"5Zf5Zo7O-Yso"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"execution_times = []\ndef evaluate_model(model, X_train, y_train, X_test, y_test):\n    start_time = time.time()\n    model.fit(X_train, y_train)\n\n    train_preds = model.predict(X_train)\n    test_preds = model.predict(X_test)\n    train_acc = accuracy_score(y_train, train_preds)\n    test_acc = accuracy_score(y_test, test_preds)\n\n    end_time = time.time()\n    execution_time = end_time - start_time\n\n    execution_times.append(execution_time)\n\n    return train_acc, test_acc, test_preds","metadata":{"id":"c5SOIvO9-dA3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","metadata":{"id":"WAIiqFsu-ekU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"GRID SEARCH","metadata":{"id":"Bs7QlJJd-hxr"}},{"cell_type":"code","source":"# decision tree\nimport pandas as pd\nparam_grid = {\n    'max_depth': [2,3, 5,7,9,10, 15],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'criterion': ['gini', 'entropy'],\n}\n\nclf = DecisionTreeClassifier(random_state=42)\n\ngrid_search = GridSearchCV(clf, param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\n\nresults = pd.DataFrame(grid_search.cv_results_)\n\nresults = results[['param_max_depth', 'param_min_samples_split', 'param_min_samples_leaf', 'param_criterion', 'mean_test_score']]\n\nresults.rename(columns={\n    'param_max_depth': 'Max Depth',\n    'param_min_samples_split': 'Min Samples Split',\n    'param_min_samples_leaf': 'Min Samples Leaf',\n    'param_criterion': 'Criterion',\n    'mean_test_score': 'Mean Test Score'\n}, inplace=True)\n\nresults.sort_values(by='Mean Test Score', ascending=False, inplace=True)\n\nresults.to_csv('grid_search_results_2.csv', index=False)\n\nprint(\"Best Hyperparameters:\")\nprint(grid_search.best_params_)\n\nbest_model = grid_search.best_estimator_\naccuracy = best_model.score(X_test, y_test)\nprint(f'The accuracy of the best model is: {accuracy}')\n","metadata":{"id":"B-WJtqWy-gBu","outputId":"4852282d-4636-48b7-f8bd-bb470c8f5fdd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# KNN\nimport pandas as pd\nparam_grid = {\n    'n_neighbors': [3, 5, 7, 9],\n    'weights': ['uniform', 'distance'],\n    'p': [1, 2],\n}\n\nclf = KNeighborsClassifier()\n\ngrid_search = GridSearchCV(clf, param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\n\nresults = pd.DataFrame(grid_search.cv_results_)\n\nresults = results[['param_n_neighbors', 'param_weights', 'param_p', 'mean_test_score']]\n\nresults.rename(columns={\n    'param_n_neighbors': 'Number of Neighbors',\n    'param_weights': 'Weights',\n    'param_p': 'p',\n    'mean_test_score': 'Mean Test Score (Accuracy)'\n}, inplace=True)\n\nresults.sort_values(by='Mean Test Score (Accuracy)', ascending=False, inplace=True)\n\nresults.to_csv('knn_grid_search_results_2.csv', index=False)\n\nprint(\"Best Hyperparameters:\")\nprint(grid_search.best_params_)\n\nbest_model = grid_search.best_estimator_\naccuracy = best_model.score(X_test, y_test)\nprint(f'The accuracy of the best model is: {accuracy}')\n","metadata":{"id":"nypGXCWy-kKb","outputId":"82342c34-60bd-4374-ab54-2aa57a0bc7a2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SVM\nparam_grid = {\n    # 'C': [0.1, 1, 10],\n    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n    'gamma': ['scale', 'auto', 0.1, 0.01, 0.001],\n}\n\nclf = SVC(random_state=42)\ngrid_search = GridSearchCV(clf, param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\nresults = pd.DataFrame(grid_search.cv_results_)\nresults = results[['param_kernel', 'param_gamma', 'mean_test_score']]\n\nresults.rename(columns={\n    'param_kernel': 'Kernel',\n    'param_gamma': 'Gamma',\n    'mean_test_score': 'Mean Test Score (Accuracy)'\n}, inplace=True)\n\nresults.sort_values(by='Mean Test Score (Accuracy)', ascending=False, inplace=True)\nresults.to_csv('svm_grid_search_results_2.csv', index=False)\n\nbest_model = grid_search.best_estimator_\ny_pred = best_model.predict(X_test)\naccuracy = best_model.score(X_test, y_test)\nprint(f'The accuracy of the best model is: {accuracy}')\nprint(\"Best Hyperparameters:\")\nprint(grid_search.best_params_)","metadata":{"id":"uKNKQYRP-mpk","outputId":"62bfde78-ce99-469f-b66d-4c0c94d31ebc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ADABOOST\nparam_grid = {\n    'n_estimators': [50, 100, 200],\n    'learning_rate': [0.001, 0.01, 0.1],\n    'base_estimator__max_depth': [1, 2, 3],\n}\n\nbase_classifier = DecisionTreeClassifier(random_state=42)\nclf = AdaBoostClassifier(base_classifier)\ngrid_search = GridSearchCV(clf, param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\nresults = pd.DataFrame(grid_search.cv_results_)\nresults = results[['param_n_estimators', 'param_learning_rate', 'param_base_estimator__max_depth', 'mean_test_score']]\nresults.rename(columns={\n    'param_n_estimators': 'Number of Estimators',\n    'param_learning_rate': 'Learning Rate',\n    'param_base_estimator__max_depth': 'Base Estimator Max Depth',\n    'mean_test_score': 'Mean Test Score (Accuracy)'\n}, inplace=True)\n\nresults.sort_values(by='Mean Test Score (Accuracy)', ascending=False, inplace=True)\n\nresults.to_csv('adaboost_grid_search_results_2.csv', index=False)\nbest_model = grid_search.best_estimator_\ny_pred = best_model.predict(X_test)\naccuracy = best_model.score(X_test, y_test)\nprint(f'The accuracy of the best model is: {accuracy}')\nprint(\"Best Hyperparameters:\")\nprint(grid_search.best_params_)\n","metadata":{"id":"KFvEDUkB-o0q","outputId":"9aca759f-3e60-4343-8902-83dd2b5b0200"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MLP Classifier\nparam_grid = {\n    'hidden_layer_sizes': [(5,), (10,), (15,), (20,), (30,), (40,), (50,), (60,), (80,)],\n    'learning_rate_init': [0.0001, 0.001, 0.01],\n}\n\nclf = MLPClassifier(random_state=42)\n\ngrid_search = GridSearchCV(clf, param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\nresults = pd.DataFrame(grid_search.cv_results_)\nresults = results[['param_hidden_layer_sizes', 'param_learning_rate_init', 'mean_test_score']]\nresults.rename(columns={\n    'param_hidden_layer_sizes': 'Hidden Layer Sizes',\n    'param_learning_rate_init': 'Learning Rate Init',\n    'mean_test_score': 'Mean Test Score (Accuracy)'\n}, inplace=True)\nresults.sort_values(by='Mean Test Score (Accuracy)', ascending=False, inplace=True)\n\nresults.to_csv('mlp_classifier_grid_search_results_2.csv', index=False)\nbest_model = grid_search.best_estimator_\n\nprint(\"Best Hyperparameters:\")\nprint(grid_search.best_params_)\n\ny_pred = best_model.predict(X_test)\naccuracy = best_model.score(X_test, y_test)\nprint(f'The accuracy of the best model is: {accuracy}')","metadata":{"id":"tGixzoUa-qM_","outputId":"6d6e04aa-7656-45ba-a9ab-55616dddf7f8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"APPLY RESULT TO MODELS","metadata":{"id":"nymj5Bq--tyN"}},{"cell_type":"code","source":"# SVM - Support Vector Machines (SVMs)\n\n# model_1 = SVC(gamma = 'scale', kernel = 'rbf')\nmodel_1 = SVC(gamma = 0.1, kernel = 'rbf', random_state=42)\ntrain_acc, test_acc, y_pred = evaluate_model(model_1, X_train, y_train, X_test, y_test)\ntrain_results.append(train_acc)\ntest_results.append(test_acc)\ncm = confusion_matrix(y_test, y_pred)\nacc_SVM=accuracy_score(y_test,y_pred)\nf1_SVM=f1_score(y_test,y_pred)\nclf_SVM=classification_report(y_test,y_pred)\n\nprint('***********SVM***********')\nprint('\\n')\nprint('Accuracy : ',acc_SVM)\nprint('F1 Score : ',f1_SVM)\nprint(10*'=====')\nprint('Confusion Matrix :\\n',cm)\nprint(10*'=====')\nprint('Classification Report :\\n',clf_SVM)\nprint(30*'========')\n\nplot_confusion_matrix(cm, classes=['Good', 'Bad'], title=model_1.__class__.__name__)\nplt.savefig('confusion_matrix_svm_2.png')\nplt.show()\n","metadata":{"id":"VZ2IH28j-rpS","outputId":"d57d1b34-b2df-4cb2-b42a-994bcc6f83e0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#KNN\nknn_params = {\n    'n_neighbors': 3,\n    'p': 1,\n    'weights': 'distance'\n}\n\nmodel_2 = KNeighborsClassifier(**knn_params)\ntrain_acc, test_acc, y_pred = evaluate_model(model_2, X_train, y_train, X_test, y_test)\ntrain_results.append(train_acc)\ntest_results.append(test_acc)\ncm = confusion_matrix(y_test, y_pred)\nacc_knn = accuracy_score(y_test, y_pred)\nf1_knn = f1_score(y_test, y_pred)\nclf_knn = classification_report(y_test, y_pred)\n\nprint('***********KNN with Single Set of Parameters***********')\nprint('\\n')\nprint('Accuracy : ', acc_knn)\nprint('F1 Score : ', f1_knn)\nprint(10 * '=====')\nprint('Confusion Matrix :\\n', cm)\nprint(10 * '=====')\nprint('Classification Report :\\n', clf_knn)\nprint(30 * '========')\n\nplot_confusion_matrix(cm, classes=['Good', 'Bad'], title=model_2.__class__.__name__)\nplt.title(f'Confusion Matrix for KNN with Single Set of Parameters')\nplt.savefig('confusion_matrix_knn_2.png')\nplt.show()","metadata":{"id":"-KDub6Ar-wL9","outputId":"a18d14ee-20ba-4f6e-d444-2e6117a492a4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Decision tree\n# tree_params = {\n#     'criterion': 'gini',\n#     'max_depth': 10,\n#     'min_samples_leaf': 2,\n#     'min_samples_split': 2,\n#     'ccp_alpha': 0.01\n# }\ntree_params = {\n    'criterion': 'entropy',\n    'max_depth': 15,\n    'min_samples_leaf': 1,\n    'min_samples_split': 2,\n    'ccp_alpha': 0.01\n}\nmodel_3 = DecisionTreeClassifier(**tree_params, random_state=42)\ntrain_acc, test_acc, y_pred = evaluate_model(model_3, X_train, y_train, X_test, y_test)\ntrain_results.append(train_acc)\ntest_results.append(test_acc)\ncm = confusion_matrix(y_test, y_pred)\nacc_dt = accuracy_score(y_test, y_pred)\nf1_dt = f1_score(y_test, y_pred)\nclf_dt = classification_report(y_test, y_pred)\n\nprint('***********Decision Tree with Pruned Parameters and Early Stopping***********')\nprint('\\n')\nprint('Accuracy : ', acc_dt)\nprint('F1 Score : ', f1_dt)\nprint(10 * '=====')\nprint('Confusion Matrix :\\n', cm)\nprint(10 * '=====')\nprint('Classification Report :\\n', clf_dt)\nprint(30 * '========')\n\nplot_confusion_matrix(cm, classes=['Good', 'Bad'], title=model_3.__class__.__name__)\nplt.title(f'Confusion Matrix for Pruned Parameters and Early Stopping')\nplt.savefig('confusion_matrix_pruned_early_stopping_2.png')\nplt.show()\n","metadata":{"id":"QFQL7faQ-yOR","outputId":"957d2e9b-e084-488c-d7c7-47d162b41eae"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Boosting with AdaBoost\nbase_classifier = DecisionTreeClassifier(max_depth=3)\n\nmodel_4 = AdaBoostClassifier(\n    base_classifier,\n    n_estimators=100,\n    learning_rate=0.1, # 0.1\n    random_state=42\n)\n\ntrain_acc, test_acc, y_pred = evaluate_model(model_4, X_train, y_train, X_test, y_test)\ntrain_results.append(train_acc)\ntest_results.append(test_acc)\ncm = confusion_matrix(y_test, y_pred)\nacc_b = accuracy_score(y_test, y_pred)\nf1_b = f1_score(y_test, y_pred)\nclf_b = classification_report(y_test, y_pred)\n\nprint('***********AdaBoost***********')\nprint('\\n')\nprint('Accuracy : ', acc_b)\nprint('F1 Score : ', f1_b)\nprint(10 * '=====')\nprint('Confusion Matrix :\\n', cm)\nprint(10 * '=====')\nprint('Classification Report :\\n', clf_b)\nprint(30 * '========')\n\nplot_confusion_matrix(cm, classes=['Good', 'Bad'], title=model_4.__class__.__name__)\nplt.savefig('confusion_matrix AdaBoost 2.png')\nplt.show()","metadata":{"id":"oslhH7wH-z-c","outputId":"6b3ebaa6-2992-403f-831e-751e56c1d07a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Neural Network\nmodel_5 = MLPClassifier(hidden_layer_sizes =  (60,),learning_rate_init = 0.01, random_state=42, alpha=0.001)\n# model_5 = MLPClassifier(hidden_layer_sizes =  (40,),learning_rate_init = 0.001)\n\ntrain_acc, test_acc, y_pred = evaluate_model(model_5, X_train, y_train, X_test, y_test)\ntrain_results.append(train_acc)\ntest_results.append(test_acc)\ncm = confusion_matrix(y_test, y_pred)\nacc_nn=accuracy_score(y_test,y_pred)\nf1_nn=f1_score(y_test,y_pred)\nclf_nn=classification_report(y_test,y_pred)\n\nprint('***********Neural Network***********')\nprint('\\n')\nprint('Accuracy : ',acc_nn)\nprint('F1 Score : ',f1_nn)\nprint(10*'=====')\nprint('Confusion Matrix :\\n',cm)\nprint(10*'=====')\nprint('Classification Report :\\n',clf_nn)\nprint(30*'========')\n\nplot_confusion_matrix(cm, classes=['Good', 'Bad'], title=model_5.__class__.__name__)\nplt.savefig('confusion_matrix_mlp2.png')\nplt.show()","metadata":{"id":"mCZuY_uw-1wD","outputId":"1440467b-e7a6-49f6-85a0-d9fa122adf01"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Neural Network\nclass NeuralNetwork(tf.keras.Model):\n    def __init__(self):\n        super(NeuralNetwork, self).__init__()\n        self.dense1 = tf.keras.layers.Dense(100, activation='relu') #80\n        self.dense2 = tf.keras.layers.Dense(1, activation='sigmoid')\n\n    def call(self, inputs):\n        x = self.dense1(inputs)\n        return self.dense2(x)\n\nmodel = NeuralNetwork()\nlearning_rate = 0.01\ncustom_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n\nmodel.compile(optimizer=custom_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\nstart_time = time.time()\nhistory = model.fit(X_train, y_train, epochs=20, validation_split=0.2)\n\nloss, accuracy = model.evaluate(X_test, y_test)\n\nend_time = time.time()\nexecution_time = end_time - start_time\nexecution_times.append(execution_time)\n\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'], label='Training Loss', color='b')\nplt.plot(history.history['val_loss'], label='Validation Loss', color='r')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['accuracy'], label='Training Accuracy', color='b')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='r')\nplt.axhline(y=accuracy, color='g', linestyle='-', label='Test Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\nfinal_val_loss = history.history['val_loss'][-1]\nfinal_val_accuracy = history.history['val_accuracy'][-1]\n\nprint(\"Validation Loss:\", final_val_loss)\nprint(\"Validation Accuracy:\", final_val_accuracy)\n\ntrain_results.append(final_val_accuracy)\ntest_results.append(accuracy)\n\nprint(\"Test Loss:\", loss)\nprint(\"Test Accuracy:\", accuracy)\n\ny_pred = model.predict(X_test)\ny_pred_binary = (y_pred >= 0.5).astype(int)\n\ncm = confusion_matrix(y_test, y_pred_binary)\nacc_Cnn = accuracy_score(y_test, y_pred_binary)\nf1_Cnn = f1_score(y_test, y_pred_binary)\nclf_Cnn = classification_report(y_test, y_pred_binary)\n\nprint('***********Custom Neural Network ***********')\nprint('\\n')\nprint('Accuracy : ', acc_Cnn)\nprint('F1 Score : ', f1_Cnn)\nprint(10 * '=====')\nprint('Confusion Matrix :\\n', cm)\nprint(10 * '=====')\nprint('Classification Report :\\n', clf_Cnn)\nprint(30 * '========')\n\nplot_confusion_matrix(cm, classes=['Good', 'Bad'], title=model.__class__.__name__)\nplt.savefig('Custom NN confusion_matrix2.png')\nplt.show()\n","metadata":{"id":"xqJ3wXm4-3e6","outputId":"ec99134d-5db8-43be-c89a-fdeec3479de9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"MODEL COMPARISION\n","metadata":{"id":"rgDlV_Ct-7ip"}},{"cell_type":"code","source":"model_names = [\"SVM\",\"KNN\", \"Decision Trees\",\"AdaBoost\",\"MLPClassifier\",\"Custom Neural_Network\"]\n\nplt.figure(figsize=(10,5))\nplt.plot(model_names, train_results, 'o-', label=\"Training Accuracy\", color='b')\nplt.plot(model_names, test_results, 'o-', label=\"Testing Accuracy\", color='r')\nplt.ylabel(\"Accuracy\")\nplt.xticks(rotation=45)\nplt.legend()\nplt.title(\"Model Comparisons - Accuracy\")\nplt.savefig(\"Model Comparisons - Accuracy2\")\nplt.show()","metadata":{"id":"kn_1o_2T-5UI","outputId":"7a29989a-ea4b-4577-a2b9-e96950d435ba"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_names = [ \"SVM\",\"KNN_1\", \"Decision Trees\",\"AdaBoost\",\"MLP Classifier\",\"Custom Neural_Network\"]\nplt.figure(figsize=(10,5))\nplt.plot(model_names, execution_times, 'o-', label=\"Wall Clock Time\", color='b')\nplt.ylabel(\"Time\")\nplt.xticks(rotation=45)\nplt.legend()\nplt.title(\"Model Comparisons - Wall clock time\")\nplt.savefig(\"Model Comparisons - Wall clock time2\")\nplt.show()","metadata":{"id":"bXBChsRm--WE","outputId":"5f4c8058-dd5a-494e-c95f-1cb0a4da4e34"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tbl=pd.DataFrame()\ntbl['Model']=pd.Series(['SVM','Decision Tree','KNN','AdaBoost', 'MLP Classifier','Custom Neural Network'])\ntbl['Accuracy']=pd.Series([acc_SVM,acc_dt,acc_knn,acc_b, acc_nn, acc_Cnn])\ntbl['F1_Score']=pd.Series([f1_SVM,f1_dt,f1_knn,f1_b, f1_nn, f1_Cnn])\ntbl.set_index('Model')","metadata":{"id":"RFcwbRSt-_7q","outputId":"2875c580-fa89-4eb5-80fd-86ce029aecf0"},"execution_count":null,"outputs":[]}]}