{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom tensorflow.keras import layers, models\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\nfrom keras.callbacks import EarlyStopping\nfrom tensorflow.keras.regularizers import l2\n\nimport keras_tuner as kt\nfrom keras import regularizers\n\nimport gc","metadata":{"id":"pV4nXnLPw8TZ","execution":{"iopub.status.busy":"2023-06-26T16:12:03.300367Z","iopub.execute_input":"2023-06-26T16:12:03.301094Z","iopub.status.idle":"2023-06-26T16:12:08.416977Z","shell.execute_reply.started":"2023-06-26T16:12:03.301057Z","shell.execute_reply":"2023-06-26T16:12:08.415938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing and transforming dataset","metadata":{"id":"9pcRqwAsw8Tk"}},{"cell_type":"code","source":"def label_counter(inpt, data_name):\n    c = 0\n    u = 0\n    for i in inpt:\n        if i == 1:\n            c = c+1\n        elif i == 0:\n            u = u + 1\n    print(f'{data_name} --> Traffic related: {c}, Traffic unrelated: {u}')\n\ndef import_dataset(split_seed):\n\n    #First dataset\n    # traffic_related = pl.read_csv('/content/drive/MyDrive/congestion_detector_datasets/model1_traffic_related_dataset.csv')\n\n    #Second dtaset\n    # traffic_unrelated = pl.read_csv('/content/drive/MyDrive/congestion_detector_datasets/model1_traffic_unrelated_dataset.csv')\n\n    #Combining first and second dataset\n    df = pl.concat([\n        pl.read_csv('/kaggle/input/traffic-related-vs-unrelated-datasets/model1_traffic_related_dataset.csv'),\n        pl.read_csv('/kaggle/input/traffic-related-vs-unrelated-datasets/model1_traffic_unrelated_dataset.csv')]\n        , how=\"vertical\")\n\n    y = df[:, 0] # Getting labels as series\n    y = y.to_numpy()\n\n    df = df[:, 1:]/255.0 # Normalizing pixels value to range of 0 to 1\n    df = df.to_numpy().reshape(-1, 222, 296, 1) #reshaping to 296 by 222\n\n    # Split data into train and test sets\n    X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.1, random_state=split_seed) #42\n\n    # Split train data into train and validation sets\n    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=split_seed)\n\n    label_counter(y_train, 'y_train')\n    label_counter(y_test, 'y_test')\n    label_counter(y_val, 'y_val')\n\n    return X_train, y_train, X_test, y_test, X_val, y_val\n\nX_train, y_train, X_test, y_test, X_val, y_val = import_dataset(13)","metadata":{"id":"5XwNDhz0w8Tm","outputId":"6cf33b70-91d6-4ad4-9640-92336826d3a7","execution":{"iopub.status.busy":"2023-06-26T16:12:08.422746Z","iopub.execute_input":"2023-06-26T16:12:08.423079Z","iopub.status.idle":"2023-06-26T16:12:46.565095Z","shell.execute_reply.started":"2023-06-26T16:12:08.423047Z","shell.execute_reply":"2023-06-26T16:12:46.563907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploring dataset","metadata":{"id":"dmVl2-v0w8Tp"}},{"cell_type":"code","source":"import numpy as np\nimport plotly.graph_objects as go\n\n# Define class labels\nclass_labels = {0: 'Traffic unrelated images', 1: 'Traffic related images'}\n\n# Map class labels for visualization\ntrain_classes = np.array([class_labels[label] for label in y_train])\ntest_classes = np.array([class_labels[label] for label in y_test])\nval_classes = np.array([class_labels[label] for label in y_val])\n\n# Calculate class frequencies\ntrain_class_counts = np.unique(train_classes, return_counts=True)\ntest_class_counts = np.unique(test_classes, return_counts=True)\nval_class_counts = np.unique(val_classes, return_counts=True)\n\n# Create bar chart data\ndata = [\n    go.Bar(x=train_class_counts[0], y=train_class_counts[1], name='Train'),\n    go.Bar(x=test_class_counts[0], y=test_class_counts[1], name='Test'),\n    go.Bar(x=val_class_counts[0], y=val_class_counts[1], name='Validation')\n]\n\n# Set layout\nlayout = go.Layout(\n    title='Occurrences of Binary Classes',\n    xaxis=dict(title='Class'),\n    yaxis=dict(title='Count'),\n    barmode='group'\n)\n\n# Create figure\nfig = go.Figure(data=data, layout=layout)\n\n# Show the bar chart\nfig.show()","metadata":{"id":"esXvo-XEw8Tp","outputId":"06de5c6c-fe90-4684-c10b-397fd96a5437","execution":{"iopub.status.busy":"2023-06-26T16:12:46.566928Z","iopub.execute_input":"2023-06-26T16:12:46.567308Z","iopub.status.idle":"2023-06-26T16:12:46.630951Z","shell.execute_reply.started":"2023-06-26T16:12:46.567271Z","shell.execute_reply":"2023-06-26T16:12:46.629921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport plotly.graph_objects as go\n\n# Define class labels\nclass_labels = {\n    0: 'Traffic Unrelated',\n    1: 'Traffic Related'\n}\n\n# Calculate total class counts\nclass_counts = {\n    class_labels[0]: np.sum([np.sum(y_train == 0), np.sum(y_test == 0), np.sum(y_val == 0)]),\n    class_labels[1]: np.sum([np.sum(y_train == 1), np.sum(y_test == 1), np.sum(y_val == 1)])\n}\n\n# Create bar chart data\ndata = [\n    go.Bar(x=list(class_counts.keys()), y=list(class_counts.values()))\n]\n\n# Set layout\nlayout = go.Layout(\n    title='Total Occurrences of Binary Classes',\n    xaxis=dict(title='Class'),\n    yaxis=dict(title='Count')\n)\n\n# Create figure\nfig = go.Figure(data=data, layout=layout)\n\n# Show the bar chart\nfig.show()","metadata":{"id":"Zqq8CFPnw8Tq","outputId":"1002c9bc-2c31-401d-eabd-224d3df7c67b","execution":{"iopub.status.busy":"2023-06-26T16:12:46.63456Z","iopub.execute_input":"2023-06-26T16:12:46.634902Z","iopub.status.idle":"2023-06-26T16:12:46.651105Z","shell.execute_reply.started":"2023-06-26T16:12:46.634876Z","shell.execute_reply":"2023-06-26T16:12:46.649281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def image_visualizer(X, y, row_number):\n    X = X[row_number]\n    y = y[row_number]\n\n    plt.imshow(X, cmap='gray')\n    lbl = None\n    if y == 0:\n        lbl = 'Traffic unrelated'\n    elif y == 1:\n        lbl = 'Traffic related'\n    plt.title(lbl)\n    plt.show()\n\nimage_visualizer(X_train, y_train, 5)\nimage_visualizer(X_train, y_train, 225)\nimage_visualizer(X_train, y_train, 512)\nimage_visualizer(X_train, y_train, 995)","metadata":{"id":"0D3iR76Uw8Tr","outputId":"1cb46f73-9b71-4a91-bdf8-c7fedaea317e","execution":{"iopub.status.busy":"2023-06-26T16:12:46.652496Z","iopub.execute_input":"2023-06-26T16:12:46.653307Z","iopub.status.idle":"2023-06-26T16:12:48.275747Z","shell.execute_reply.started":"2023-06-26T16:12:46.653274Z","shell.execute_reply":"2023-06-26T16:12:48.274788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Further data transformations","metadata":{"id":"-8aezJPPw8Tr"}},{"cell_type":"code","source":"import numpy as np\n\ndef transformer_func(X):\n  datagen = keras.preprocessing.image.ImageDataGenerator(\n      rotation_range=15,\n      width_shift_range=0.1,\n      height_shift_range=0.1,\n      shear_range=0.1,\n      zoom_range=0.1,\n      horizontal_flip=True,\n      vertical_flip=True,\n      fill_mode='nearest'\n  )\n\n  # Create empty list for augmented data\n  X_augmented = []\n\n  transformed_image_counter = 0\n\n  # Define probability threshold\n  probability_threshold = 0.5\n\n  # Apply data augmentation to each image individually\n  for i in range(len(X)):\n      # Generate a random number between 0 and 1\n      random_probability = np.random.uniform(0, 1)\n\n      # Apply transformations only if random_probability is above the threshold\n      if random_probability > probability_threshold:\n          augmented_image = datagen.apply_transform(X[i], datagen.get_random_transform(X[i].shape))\n          X_augmented.append(augmented_image)\n          transformed_image_counter += 1\n      else:\n          X_augmented.append(X_train[i])\n\n  # Convert augmented data to array\n  X_train_augmented = np.array(X_augmented)\n\n  return np.array(X_augmented), transformed_image_counter\n\nX_train, transformed_image_counter = transformer_func(X_train)\n\nprint(f'{transformed_image_counter} images transformed.')","metadata":{"id":"fZZ61yTkw8Ts","outputId":"4f1a3777-26d5-4074-e788-d462b93ca51f","execution":{"iopub.status.busy":"2023-06-26T16:12:48.277116Z","iopub.execute_input":"2023-06-26T16:12:48.278088Z","iopub.status.idle":"2023-06-26T16:12:56.185673Z","shell.execute_reply.started":"2023-06-26T16:12:48.278054Z","shell.execute_reply":"2023-06-26T16:12:56.184512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"id":"5jj2FogKw8Tt","outputId":"43355aa1-61de-4566-8ca0-bbc94568876b","execution":{"iopub.status.busy":"2023-06-26T16:12:56.187172Z","iopub.execute_input":"2023-06-26T16:12:56.187784Z","iopub.status.idle":"2023-06-26T16:12:56.194581Z","shell.execute_reply.started":"2023-06-26T16:12:56.187747Z","shell.execute_reply":"2023-06-26T16:12:56.193632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils import to_categorical\n\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\ny_val = to_categorical(y_val)","metadata":{"id":"PG2AcSLCAdN7","execution":{"iopub.status.busy":"2023-06-26T16:12:56.195859Z","iopub.execute_input":"2023-06-26T16:12:56.196408Z","iopub.status.idle":"2023-06-26T16:12:56.205687Z","shell.execute_reply.started":"2023-06-26T16:12:56.196371Z","shell.execute_reply":"2023-06-26T16:12:56.204492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# image_visualizer(X_train, y_train, 5)\n# image_visualizer(X_train, y_train, 3005)\n# image_visualizer(X_train, y_train, 662)\n# image_visualizer(X_train, y_train, 2235)","metadata":{"id":"mvHP3SN6w8Tt","execution":{"iopub.status.busy":"2023-06-26T16:12:56.207354Z","iopub.execute_input":"2023-06-26T16:12:56.207919Z","iopub.status.idle":"2023-06-26T16:12:56.214969Z","shell.execute_reply.started":"2023-06-26T16:12:56.207882Z","shell.execute_reply":"2023-06-26T16:12:56.213858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model hyperparameter tuning","metadata":{"id":"3P1u2Epuw8Tt"}},{"cell_type":"code","source":"# from tensorflow.keras.models import Sequential\n# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n# from tensorflow.keras.optimizers import Adam\n# from tensorflow.keras.callbacks import ReduceLROnPlateau\n\n# cnn = Sequential()\n\n# # Block 1\n# cnn.add(Conv2D(115, (3, 3), activation='relu', padding='same', input_shape=(222, 296, 1)))\n# cnn.add(Conv2D(115, (3, 3), activation='relu', padding='same'))\n# cnn.add(MaxPooling2D((2, 2), strides=(2, 2)))\n# cnn.add(Dropout(0.1))\n\n# # Block 2\n# cnn.add(Conv2D(40, (3, 3), activation='relu', padding='same'))\n# cnn.add(Conv2D(40, (3, 3), activation='relu'))\n# cnn.add(MaxPooling2D((2, 2), strides=(2, 2)))\n# cnn.add(Dropout(0.1))\n\n# # Block 3\n# cnn.add(Conv2D(25, (3, 3), activation='relu', padding='same'))\n# cnn.add(Conv2D(25, (3, 3), activation='relu'))\n# cnn.add(Conv2D(25, (2, 2), activation='relu'))\n# cnn.add(MaxPooling2D((2, 2), strides=(2, 2)))\n# cnn.add(Dropout(0.1))\n\n# # Block 4\n# cnn.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n# cnn.add(Conv2D(64, (2, 2), activation='relu', padding='same'))\n# cnn.add(MaxPooling2D((2, 2), strides=(1, 1)))\n# cnn.add(Conv2D(64, (2, 2), activation='relu', padding='same'))\n# cnn.add(MaxPooling2D((2, 2), strides=(2, 2)))\n# cnn.add(Dropout(0.1))\n\n# # Block 5\n# cnn.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n# cnn.add(Conv2D(128, (2, 2), activation='relu', padding='same'))\n# cnn.add(MaxPooling2D((2, 2), strides=(2, 2)))\n# cnn.add(Conv2D(128, (2, 2), activation='relu', padding='same'))\n# cnn.add(MaxPooling2D((1, 1), strides=(2, 2)))\n# cnn.add(Dropout(0.1))\n\n# # Classification block\n# cnn.add(Flatten())\n# cnn.add(Dense(64, activation='relu'))\n# cnn.add(BatchNormalization())\n# cnn.add(Dropout(0.2))\n# cnn.add(Dense(128, activation='relu'))\n# cnn.add(BatchNormalization())\n# cnn.add(Dropout(0.4))\n# cnn.add(Dense(2, activation='sigmoid'))\n\n# optimizer = Adam(learning_rate=0.001)\n# # compile the model\n# cnn.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n# cnn.summary()","metadata":{"id":"_7JgnMHI5lj8","outputId":"2b7ffdc3-4a76-4e74-8408-59012f3dde94","execution":{"iopub.status.busy":"2023-06-26T16:12:56.216635Z","iopub.execute_input":"2023-06-26T16:12:56.217046Z","iopub.status.idle":"2023-06-26T16:12:56.228355Z","shell.execute_reply.started":"2023-06-26T16:12:56.217011Z","shell.execute_reply":"2023-06-26T16:12:56.227731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\ncnn = Sequential()\n\n# Block 1\ncnn.add(Conv2D(115, (4, 4), strides=(2, 2), activation='relu', padding='same', input_shape=(222, 296, 1)))\ncnn.add(Conv2D(115, (3, 3), strides=(2, 2), activation='relu', padding='same'))\ncnn.add(MaxPooling2D((2, 2), strides=(2, 2)))\ncnn.add(Dropout(0.1))\n\n# Block 2\ncnn.add(Conv2D(84, (3, 3), activation='relu', padding='same'))\ncnn.add(Conv2D(64, (3, 3), activation='relu'))\ncnn.add(MaxPooling2D((2, 2), strides=(2, 2)))\ncnn.add(Dropout(0.1))\n\n# Block 3\ncnn.add(Conv2D(126, (3, 3), activation='relu', padding='same'))\ncnn.add(Conv2D(126, (3, 3), activation='relu'))\ncnn.add(MaxPooling2D((2, 2), strides=(2, 2)))\ncnn.add(Dropout(0.1))\n\n# # Block 4\n# cnn.add(Conv2D(128, (3, 3), strides=(2, 2), activation='relu', padding='same'))\n# cnn.add(Conv2D(128, (2, 2), strides=(2, 2), activation='relu', padding='same'))\n# cnn.add(MaxPooling2D((2, 2), strides=(2, 2)))\n# cnn.add(Dropout(0.1))\n\n# # Block 5\n# cnn.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n# cnn.add(Conv2D(128, (2, 2), activation='relu', padding='same'))\n# cnn.add(MaxPooling2D((2, 2), strides=(2, 2)))\n# cnn.add(Conv2D(128, (2, 2), activation='relu', padding='same'))\n# cnn.add(MaxPooling2D((1, 1), strides=(2, 2)))\n# cnn.add(Dropout(0.1))\n\n# Classification block\ncnn.add(Flatten())\ncnn.add(Dense(128, activation='relu'))\ncnn.add(Dropout(0.3))\ncnn.add(Dense(256, activation='relu'))\ncnn.add(Dropout(0.4))\ncnn.add(Dense(2, activation='sigmoid'))\n\noptimizer = Adam(learning_rate=0.001)\n\n# compile the model\ncnn.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\ncnn.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-26T16:12:56.229387Z","iopub.execute_input":"2023-06-26T16:12:56.229882Z","iopub.status.idle":"2023-06-26T16:12:59.166703Z","shell.execute_reply.started":"2023-06-26T16:12:56.229849Z","shell.execute_reply":"2023-06-26T16:12:59.165933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# del history\n# gc.collect()","metadata":{"id":"S-f9NT5DpmrV","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add ReduceLROnPlateau callback\nreduce_lr = ReduceLROnPlateau(factor=0.1, patience=4, min_lr=0.00001)\n\nhistory = cnn.fit(X_train, y_train,\n                    validation_data=(X_val, y_val),\n                    epochs=45,\n                    batch_size=80,\n                    callbacks=[reduce_lr])","metadata":{"execution":{"iopub.status.busy":"2023-06-26T16:13:47.131136Z","iopub.execute_input":"2023-06-26T16:13:47.131548Z","iopub.status.idle":"2023-06-26T16:21:12.520394Z","shell.execute_reply.started":"2023-06-26T16:13:47.131514Z","shell.execute_reply":"2023-06-26T16:21:12.519292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Train the model\n# history = cnn.fit(X_train, y_train,\n#                     validation_data=(X_val, y_val),\n#                     epochs=45,\n#                     batch_size=80)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn.save('/kaggle/working/model')\n\nloss, accuracy = cnn.evaluate(X_test, y_test)\nprint('Loss:', loss)\nprint('Accuracy:', accuracy)","metadata":{"id":"TxCpBj6eEo9P","outputId":"adc8e702-3bdc-458c-e64f-054eaa8d8b55","execution":{"iopub.status.busy":"2023-06-26T16:23:34.502109Z","iopub.execute_input":"2023-06-26T16:23:34.502493Z","iopub.status.idle":"2023-06-26T16:23:37.330096Z","shell.execute_reply.started":"2023-06-26T16:23:34.502454Z","shell.execute_reply":"2023-06-26T16:23:37.328986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# val_acc_per_epoch = history.history['val_accuracy']\n# best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n# print('Best epoch: %d' % (best_epoch,))","metadata":{"id":"PFf8JO6Rw8Tx","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}