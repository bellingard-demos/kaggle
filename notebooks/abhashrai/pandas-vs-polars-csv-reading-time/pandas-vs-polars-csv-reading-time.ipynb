{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1132674,"sourceType":"datasetVersion","datasetId":637580},{"sourceId":2109006,"sourceType":"datasetVersion","datasetId":1346},{"sourceId":4471234,"sourceType":"datasetVersion","datasetId":1031},{"sourceId":6488828,"sourceType":"datasetVersion","datasetId":3749643},{"sourceId":6633070,"sourceType":"datasetVersion","datasetId":3829273},{"sourceId":6809685,"sourceType":"datasetVersion","datasetId":3917310},{"sourceId":6882235,"sourceType":"datasetVersion","datasetId":3954154},{"sourceId":6890527,"sourceType":"datasetVersion","datasetId":3942644},{"sourceId":6914813,"sourceType":"datasetVersion","datasetId":3926891},{"sourceId":6960429,"sourceType":"datasetVersion","datasetId":3998410},{"sourceId":7020106,"sourceType":"datasetVersion","datasetId":3990170}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook with visualize the effectiveness of `pandas` and `polars` at reading CSV files of different sizes.\n\nTo import csv using `pandas` the function used is:\n```\nimport pandas as pd\npd.read_csv()\n```\n\nAnd, for `polars` is:\n```\nimport polars as pl\npl.read_csv()\n```","metadata":{}},{"cell_type":"code","source":"all_csv_path = [\n    '/kaggle/input/football-players-data/fifa_players.csv', # 3.6 MB\n    '/kaggle/input/crop-production-in-india/Crop_production.csv', # 10 MB\n    '/kaggle/input/e-commerece-sales-data-2023-24/product_details.csv', # 20 MB\n    '/kaggle/input/global-fire-burned-area/GlobalFireBurnedArea_2022.csv', # 40 MB\n    '/kaggle/input/daigt-proper-train-dataset/train_drcat_01.csv', # 74 MB\n    '/kaggle/input/daigt-proper-train-dataset/train_drcat_04.csv', # 103 MB\n    '/kaggle/input/bitcoin-historical-data/bitstampUSD_1-min_data_2012-01-01_to_2021-03-31.csv', # 317 MB\n    '/kaggle/input/ecommerce-dataset/item_properties_part1.csv', # 484 MB\n    '/kaggle/input/product-titles-text-classification/titles_to_categories.csv', # 788 MB\n    '/kaggle/input/job-description-dataset/job_descriptions.csv', #1.74 GB\n    '/kaggle/input/political-advertisements-from-facebook/fbpac-ads-en-US.csv' # 3.22 GB\n]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-22T08:45:10.114301Z","iopub.execute_input":"2023-11-22T08:45:10.116531Z","iopub.status.idle":"2023-11-22T08:45:10.126244Z","shell.execute_reply.started":"2023-11-22T08:45:10.116446Z","shell.execute_reply":"2023-11-22T08:45:10.124445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport time\nimport pandas as pd\nimport polars as pl\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-11-22T08:07:11.753559Z","iopub.execute_input":"2023-11-22T08:07:11.755443Z","iopub.status.idle":"2023-11-22T08:07:11.775913Z","shell.execute_reply.started":"2023-11-22T08:07:11.755378Z","shell.execute_reply":"2023-11-22T08:07:11.772211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number_of_times_to_read = 7 # Change this to whatever number of times you want to read each files\nall_csv = {}","metadata":{"execution":{"iopub.status.busy":"2023-11-22T08:07:11.780184Z","iopub.execute_input":"2023-11-22T08:07:11.781129Z","iopub.status.idle":"2023-11-22T08:07:11.800262Z","shell.execute_reply.started":"2023-11-22T08:07:11.781043Z","shell.execute_reply":"2023-11-22T08:07:11.798568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for csv_file in all_csv_path:\n    file_size_bytes = os.path.getsize(csv_file)\n    file_size_mb = file_size_bytes / (1024 * 1024)\n    all_csv[csv_file] = [f'{file_size_mb:.2f}']\n\nall_csv","metadata":{"execution":{"iopub.status.busy":"2023-11-22T08:07:11.801896Z","iopub.execute_input":"2023-11-22T08:07:11.802404Z","iopub.status.idle":"2023-11-22T08:07:11.841478Z","shell.execute_reply.started":"2023-11-22T08:07:11.802366Z","shell.execute_reply":"2023-11-22T08:07:11.840028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**So, the first element (str dtype) of every value of each key is the size in MB**","metadata":{}},{"cell_type":"code","source":"for csv_file in all_csv_path:\n    trials = {\n        'pandas': [],\n        'polars': []\n    }\n    \n    for _ in range(number_of_times_to_read):\n        try:\n            start_time = time.time()\n            pd_df = pd.read_csv(csv_file)\n            end_time = time.time()\n            elapsed_time = end_time - start_time\n            trials['pandas'].append(round(elapsed_time, 2))\n        except:\n            print(f\"Error reading {csv_file} with pandas\")\n\n        try:\n            start_time = time.time()\n            pl_df = pl.read_csv(csv_file)\n            end_time = time.time()\n            elapsed_time = end_time - start_time\n            trials['polars'].append(round(elapsed_time, 2))\n        except:\n            print(f\"Error reading {csv_file} with polars\")\n        \n    all_csv[csv_file].append(trials)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T08:07:11.845004Z","iopub.execute_input":"2023-11-22T08:07:11.845964Z","iopub.status.idle":"2023-11-22T08:07:41.404381Z","shell.execute_reply.started":"2023-11-22T08:07:11.845908Z","shell.execute_reply":"2023-11-22T08:07:41.403084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_csv","metadata":{"execution":{"iopub.status.busy":"2023-11-22T08:15:07.442929Z","iopub.execute_input":"2023-11-22T08:15:07.44349Z","iopub.status.idle":"2023-11-22T08:15:07.457014Z","shell.execute_reply.started":"2023-11-22T08:15:07.443451Z","shell.execute_reply":"2023-11-22T08:15:07.455378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Stats = []\n\nfor csv_file_path, file_info in all_csv.items():\n    \n    file_size_in_mb = file_info[0]\n    \n    pandas_trials = file_info[1]['pandas']\n    \n    polars_trials = file_info[1]['polars']\n    \n    for x, y in zip(pandas_trials, polars_trials):\n        Stats.append(\n            {\n                'size': float(file_size_in_mb),\n                'pandas_import_time': x,\n                'polars_import_time': y\n            }\n    )\n    \nStats =  pd.DataFrame(Stats)\nStats","metadata":{"execution":{"iopub.status.busy":"2023-11-22T08:37:53.968361Z","iopub.execute_input":"2023-11-22T08:37:53.969681Z","iopub.status.idle":"2023-11-22T08:37:54.001105Z","shell.execute_reply.started":"2023-11-22T08:37:53.969611Z","shell.execute_reply":"2023-11-22T08:37:53.999636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Stats.to_csv('PandasPolarsCsvReadingTimes.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T08:40:55.528336Z","iopub.execute_input":"2023-11-22T08:40:55.528886Z","iopub.status.idle":"2023-11-22T08:40:55.542644Z","shell.execute_reply.started":"2023-11-22T08:40:55.528847Z","shell.execute_reply":"2023-11-22T08:40:55.541107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Stats['size'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-11-22T08:38:59.228334Z","iopub.execute_input":"2023-11-22T08:38:59.228872Z","iopub.status.idle":"2023-11-22T08:38:59.240824Z","shell.execute_reply.started":"2023-11-22T08:38:59.228831Z","shell.execute_reply":"2023-11-22T08:38:59.238966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.style.use('ggplot')\n# sns.set(style=\"whitegrid\")\n\nfig, ax = plt.subplots(figsize=(12, 6))\n\nax = sns.lineplot(\n    data=Stats, \n    x=\"size\", \n    y=\"pandas_import_time\", \n    errorbar=\"sd\", \n    label='Pandas', \n    marker='o', \n    linestyle='-'\n)\n\nax = sns.lineplot(\n    data=Stats, \n    x=\"size\", \n    y=\"polars_import_time\", \n    errorbar=\"sd\", \n    label='Polars', \n    marker='o', \n    linestyle='-'\n)\n\nax.set_xlabel('CSV Size (MB)')\nax.xaxis.label.set_color('black')\nax.xaxis.label.set_bbox({'facecolor': 'white', 'edgecolor': 'white'})\n\nax.set_ylabel('Mean Reading Time (Seconds)')\nax.yaxis.label.set_color('black')\nax.yaxis.label.set_bbox({'facecolor': 'white', 'edgecolor': 'white'})\n\nplt.title('Pandas and Polars CSV file reading time with Error Band\\n')\n\nlegend = ax.legend()\nlegend.set_frame_on(True)\nlegend.get_frame().set_facecolor('white')\n\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-22T08:37:55.7752Z","iopub.execute_input":"2023-11-22T08:37:55.775693Z","iopub.status.idle":"2023-11-22T08:37:56.387955Z","shell.execute_reply.started":"2023-11-22T08:37:55.775658Z","shell.execute_reply":"2023-11-22T08:37:56.38597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}