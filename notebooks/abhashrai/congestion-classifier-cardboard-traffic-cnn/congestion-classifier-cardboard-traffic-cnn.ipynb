{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install keras-tuner","metadata":{"id":"SOkELFJLxFKN","outputId":"cc9d3239-729c-47b7-8fb3-fbc27caddb58","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install --upgrade tensorflow keras-tuner","metadata":{"id":"HZwT68fQEb87","outputId":"353825b0-9e2b-407f-e0d7-a45b6fcfd5fa","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom tensorflow.keras import layers, models\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\nfrom keras.callbacks import EarlyStopping\nfrom tensorflow.keras.regularizers import l2\n\nimport keras_tuner as kt\nfrom keras import regularizers\n\nimport gc","metadata":{"id":"pV4nXnLPw8TZ","execution":{"iopub.status.busy":"2023-07-20T03:52:48.168127Z","iopub.execute_input":"2023-07-20T03:52:48.168691Z","iopub.status.idle":"2023-07-20T03:52:59.581582Z","shell.execute_reply.started":"2023-07-20T03:52:48.168649Z","shell.execute_reply":"2023-07-20T03:52:59.580497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing and transforming dataset","metadata":{"id":"9pcRqwAsw8Tk"}},{"cell_type":"code","source":"def label_counter(inpt, data_name):\n    c = 0\n    u = 0\n    for i in inpt:\n        if i == 1:\n            c = c+1\n        elif i == 0:\n            u = u + 1\n    print(f'{data_name} --> Traffic related: {c}, Traffic unrelated: {u}')\n\ndef import_dataset(split_seed):\n\n    #First dataset\n    # traffic_related = pl.read_csv('/content/drive/MyDrive/congestion_detector_datasets/model1_traffic_related_dataset.csv')\n\n    #Second dtaset\n    # traffic_unrelated = pl.read_csv('/content/drive/MyDrive/congestion_detector_datasets/model1_traffic_unrelated_dataset.csv')\n\n    #Combining first and second dataset\n#     df = pl.concat([\n#         pl.read_csv('/kaggle/input/cardboard-congested-uncongested-dataset/congested_cardboard.csv'),\n#         pl.read_csv('/kaggle/input/cardboard-congested-uncongested-dataset/uncongested_cardboard.csv')]\n#         , how=\"vertical\")\n    df = pl.read_csv('/kaggle/input/cardboard-congestion-detector/congested_uncongested_cardboard.csv')\n\n    y = df[:, 0] # Getting labels as series\n    y = y.to_numpy()\n\n    df = df[:, 1:]/255.0 # Normalizing pixels value to range of 0 to 1\n    df = df.to_numpy().reshape(-1, 222, 296, 1) #reshaping to 296 by 222\n\n    # Split data into train and test sets\n    X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.1, random_state=split_seed) #42\n\n    # Split train data into train and validation sets\n    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=split_seed)\n\n    label_counter(y_train, 'y_train')\n    label_counter(y_test, 'y_test')\n    label_counter(y_val, 'y_val')\n\n    return X_train, y_train, X_test, y_test, X_val, y_val\n\nX_train, y_train, X_test, y_test, X_val, y_val = import_dataset(123)","metadata":{"id":"5XwNDhz0w8Tm","outputId":"d1a1680f-2f15-4bb7-e684-fa122182d596","execution":{"iopub.status.busy":"2023-07-20T03:52:59.58335Z","iopub.execute_input":"2023-07-20T03:52:59.584162Z","iopub.status.idle":"2023-07-20T03:53:43.999326Z","shell.execute_reply.started":"2023-07-20T03:52:59.584132Z","shell.execute_reply":"2023-07-20T03:53:43.998296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploring dataset","metadata":{"id":"dmVl2-v0w8Tp"}},{"cell_type":"code","source":"import numpy as np\nimport plotly.graph_objects as go\n\n# Define class labels\nclass_labels = {0: 'Uncongested', 1: 'Congested'}\n\n# Map class labels for visualization\ntrain_classes = np.array([class_labels[label] for label in y_train])\ntest_classes = np.array([class_labels[label] for label in y_test])\nval_classes = np.array([class_labels[label] for label in y_val])\n\n# Calculate class frequencies\ntrain_class_counts = np.unique(train_classes, return_counts=True)\ntest_class_counts = np.unique(test_classes, return_counts=True)\nval_class_counts = np.unique(val_classes, return_counts=True)\n\n# Create bar chart data\ndata = [\n    go.Bar(x=train_class_counts[0], y=train_class_counts[1], name='Train'),\n    go.Bar(x=test_class_counts[0], y=test_class_counts[1], name='Test'),\n    go.Bar(x=val_class_counts[0], y=val_class_counts[1], name='Validation')\n]\n\n# Set layout\nlayout = go.Layout(\n    title='Occurrences of Binary Classes',\n    xaxis=dict(title='Class'),\n    yaxis=dict(title='Count'),\n    barmode='group'\n)\n\n# Create figure\nfig = go.Figure(data=data, layout=layout)\n\n# Show the bar chart\nfig.show()","metadata":{"id":"esXvo-XEw8Tp","outputId":"d4afa374-7101-4283-b503-7e45f91e7175","execution":{"iopub.status.busy":"2023-07-20T03:48:30.897666Z","iopub.execute_input":"2023-07-20T03:48:30.898043Z","iopub.status.idle":"2023-07-20T03:48:31.210046Z","shell.execute_reply.started":"2023-07-20T03:48:30.898011Z","shell.execute_reply":"2023-07-20T03:48:31.209087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport plotly.graph_objects as go\n\n# Define class labels\nclass_labels = {0: 'Uncongested', 1: 'Congested'}\n\n# Calculate total class counts\nclass_counts = {\n    class_labels[0]: np.sum([np.sum(y_train == 0), np.sum(y_test == 0), np.sum(y_val == 0)]),\n    class_labels[1]: np.sum([np.sum(y_train == 1), np.sum(y_test == 1), np.sum(y_val == 1)])\n}\n\n# Create bar chart data\ndata = [\n    go.Bar(x=list(class_counts.keys()), y=list(class_counts.values()))\n]\n\n# Set layout\nlayout = go.Layout(\n    title='Total Occurrences of Binary Classes',\n    xaxis=dict(title='Class'),\n    yaxis=dict(title='Count')\n)\n\n# Create figure\nfig = go.Figure(data=data, layout=layout)\n\n# Show the bar chart\nfig.show()","metadata":{"id":"Zqq8CFPnw8Tq","outputId":"45aa4648-8005-4893-85a2-83e7e9b213b2","execution":{"iopub.status.busy":"2023-07-20T03:48:31.787506Z","iopub.execute_input":"2023-07-20T03:48:31.787882Z","iopub.status.idle":"2023-07-20T03:48:31.807457Z","shell.execute_reply.started":"2023-07-20T03:48:31.787851Z","shell.execute_reply":"2023-07-20T03:48:31.806558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def image_visualizer(X, y, row_number):\n    X = X[row_number]\n    y = y[row_number]\n\n    plt.imshow(X, cmap='gray')\n    lbl = None\n    if y == 0:\n        lbl = 'Uncongested'\n    elif y == 1:\n        lbl = 'congested'\n    plt.title(lbl)\n    plt.show()\n\nimage_visualizer(X_train, y_train, 5)\nimage_visualizer(X_train, y_train, 1345)\nimage_visualizer(X_train, y_train, 512)\nimage_visualizer(X_train, y_train, 688)","metadata":{"id":"0D3iR76Uw8Tr","outputId":"40802b84-d6bc-46a1-ee21-4488c942ffe0","execution":{"iopub.status.busy":"2023-07-20T03:48:32.554916Z","iopub.execute_input":"2023-07-20T03:48:32.555317Z","iopub.status.idle":"2023-07-20T03:48:34.139912Z","shell.execute_reply.started":"2023-07-20T03:48:32.555282Z","shell.execute_reply":"2023-07-20T03:48:34.139017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Further data transformations","metadata":{"id":"-8aezJPPw8Tr"}},{"cell_type":"code","source":"import numpy as np\n\ndef transformer_func(X):\n  datagen = keras.preprocessing.image.ImageDataGenerator(\n      rotation_range=15,\n      width_shift_range=0.1,\n      height_shift_range=0.1,\n      shear_range=0.1,\n      zoom_range=0.1,\n      horizontal_flip=True,\n      vertical_flip=True,\n      fill_mode='nearest'\n  )\n\n  # Create empty list for augmented data\n  X_augmented = []\n\n  transformed_image_counter = 0\n\n  # Define probability threshold\n  probability_threshold = 0.5\n\n  # Apply data augmentation to each image individually\n  for i in range(len(X)):\n      # Generate a random number between 0 and 1\n      random_probability = np.random.uniform(0, 1)\n\n      # Apply transformations only if random_probability is above the threshold\n      if random_probability > probability_threshold:\n          augmented_image = datagen.apply_transform(X[i], datagen.get_random_transform(X[i].shape))\n          X_augmented.append(augmented_image)\n          transformed_image_counter += 1\n      else:\n          X_augmented.append(X_train[i])\n\n  # Convert augmented data to array\n  X_train_augmented = np.array(X_augmented)\n\n  return np.array(X_augmented), transformed_image_counter\n\nX_train, transformed_image_counter = transformer_func(X_train)\n\nprint(f'{transformed_image_counter} images transformed.')","metadata":{"id":"fZZ61yTkw8Ts","outputId":"22739e91-05d4-491f-bd23-2e4bae16e4d5","execution":{"iopub.status.busy":"2023-07-20T03:48:34.468905Z","iopub.execute_input":"2023-07-20T03:48:34.469867Z","iopub.status.idle":"2023-07-20T03:48:45.071381Z","shell.execute_reply.started":"2023-07-20T03:48:34.469826Z","shell.execute_reply":"2023-07-20T03:48:45.070472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"id":"5jj2FogKw8Tt","outputId":"3d7b0322-fd60-4c1b-a859-1dc690dfd114","execution":{"iopub.status.busy":"2023-07-20T03:48:46.986792Z","iopub.execute_input":"2023-07-20T03:48:46.987141Z","iopub.status.idle":"2023-07-20T03:48:46.995945Z","shell.execute_reply.started":"2023-07-20T03:48:46.987113Z","shell.execute_reply":"2023-07-20T03:48:46.995009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from keras.utils import to_categorical\n\n# y_train = to_categorical(y_train)\n# y_test = to_categorical(y_test)\n# y_val = to_categorical(y_val)","metadata":{"id":"PG2AcSLCAdN7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# image_visualizer(X_train, y_train, 5)\n# image_visualizer(X_train, y_train, 3005)\n# image_visualizer(X_train, y_train, 662)\n# image_visualizer(X_train, y_train, 2235)","metadata":{"id":"mvHP3SN6w8Tt","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model hyperparameter tuning","metadata":{"id":"3P1u2Epuw8Tt"}},{"cell_type":"code","source":"# Trial 21 Complete [00h 00m 54s]\n# val_accuracy: 0.9497607946395874\n\n# Best val_accuracy So Far: 0.9497607946395874\n# Total elapsed time: 00h 10m 29s\n\n# Search: Running Trial #22\n\n# Value             |Best Value So Far |Hyperparameter\n# 75                |35                |filter_1\n# 5                 |5                 |filter_size_1\n# 2                 |3                 |kernel_size_1\n# 30                |40                |filter_2\n# 2                 |3                 |filter_size_2\n# 1                 |2                 |kernel_size_2\n# 30                |25                |filter_3\n# 2                 |2                 |filter_size_3\n# 1                 |3                 |kernel_size_3\n# 35                |35                |filter_4\n# 2                 |2                 |filter_size_4\n# 3                 |3                 |kernel_size_4\n# 50                |30                |filter_5\n# 2                 |2                 |filter_size_5\n# 3                 |1                 |kernel_size_5\n# 70                |60                |filter_6\n# 3                 |3                 |filter_size_6\n# 1                 |2                 |kernel_size_6\n# 25                |65                |units_1\n# 0.2               |0.1               |dropout_rate\n# 20                |15                |units_2\n# 0.0003            |0.0003            |learning_rate\n# 10                |10                |tuner/epochs\n# 4                 |4                 |tuner/initial_epoch\n# 1                 |1                 |tuner/bracket\n# 1                 |1                 |tuner/round\n# 0018              |0017              |tuner/trial_id\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### import tensorflow as tf\nimport keras_tuner as kt\n\ndef model_builder(hp):\n    model = keras.Sequential()\n    \n    model.add(keras.layers.Conv2D(hp.Int('filter_1', min_value=16, max_value=126, step=16), hp.Choice('filter_size_1', values=[2,3]), activation='relu', input_shape=(222, 296, 1)))\n    model.add(keras.layers.Conv2D(hp.Int('filter_2', min_value=16, max_value=126, step=16), hp.Choice('filter_size_2', values=[2,3]), strides=hp.Choice('stride_size1_', values=[2,3]), padding='same', activation='relu'))\n    model.add(keras.layers.MaxPooling2D(hp.Choice('kernel_size_1', values=[2,3]), strides=(2, 2)))\n    \n    model.add(keras.layers.Conv2D(hp.Int('filter_3', min_value=8, max_value=64, step=8), hp.Choice('filter_size_3', values=[2,3]), strides=hp.Choice('stride_size_2', values=[1,2]), kernel_regularizer=regularizers.l2(hp.Float('l2_rate_1', min_value=0.0, max_value=0.05, step=0.01)), padding='valid', activation='relu'))\n    model.add(keras.layers.Conv2D(hp.Int('filter_4', min_value=8, max_value=64, step=8), hp.Choice('filter_size_4', values=[2,3]), strides=hp.Choice('stride_size_3', values=[1,2]), padding='valid', activation='relu'))\n    model.add(keras.layers.MaxPooling2D(hp.Choice('kernel_size_2', values=[2,3]), strides=(2,2)))\n     \n    model.add(keras.layers.Conv2D(hp.Int('filter_5', min_value=4, max_value=32, step=4), hp.Choice('filter_size_5', values=[1,2]), strides=hp.Choice('stride_size_4', values=[1,2]), padding='valid', activation='relu'))\n    model.add(keras.layers.Conv2D(hp.Int('filter_6', min_value=4, max_value=32, step=4), hp.Choice('filter_size_6', values=[1,2]), strides=hp.Choice('stride_size_5', values=[1,2]), padding='valid', activation='relu'))\n    model.add(keras.layers.MaxPooling2D(hp.Choice('kernel_size_3', values=[1,2]), strides=(1,1)))\n    \n    model.add(keras.layers.Conv2D(hp.Int('filter_7', min_value=4, max_value=126, step=16), hp.Choice('filter_size_7', values=[1,2]), strides=hp.Choice('stride_size_6', values=[1,2]), kernel_regularizer=regularizers.l2(hp.Float('l2_rate_2', min_value=0.0, max_value=0.05, step=0.01)), padding='valid', activation='relu'))\n    model.add(keras.layers.Conv2D(hp.Int('filter_8', min_value=4, max_value=126, step=16), hp.Choice('filter_size_8', values=[1,2]), strides=hp.Choice('stride_size_7', values=[1,2]), padding='same', activation='relu'))\n    model.add(keras.layers.MaxPooling2D(hp.Choice('kernel_size_4', values=[1,2]), strides=(1,1)))\n              \n    model.add(keras.layers.Flatten())\n    model.add(keras.layers.Dense(units=hp.Int('units_1', min_value=4, max_value=64, step=8), activation='relu'))\n    \n    hp_dropout_rate = hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1)\n    model.add(keras.layers.Dropout(hp_dropout_rate))\n    \n    model.add(keras.layers.Dense(hp.Int('units_2', min_value=4, max_value=126, step=8), activation='relu'))\n    \n    model.add(keras.layers.Dense(2, activation='softmax'))\n#     model.add(keras.layers.Dense(1, activation='sigmoid'))\n\n    hp_learning_rate = hp.Choice('learning_rate', values=[0.01, 0.001, 0.0003, 0.0001])\n\n    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n                  loss=keras.losses.SparseCategoricalCrossentropy(),\n                  metrics=['accuracy'])\n\n    return model\n\ntuner = kt.Hyperband(model_builder,\n                     objective='val_accuracy',\n                     max_epochs=10,\n                     factor=3,\n                     directory='/kaggle/working/',\n                     project_name='congested_vs_uncongested_traffic_detector9')\n              \nstop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n\ntuner.search(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_val, y_val), callbacks=[stop_early])","metadata":{"execution":{"iopub.status.busy":"2023-07-20T04:31:32.25914Z","iopub.execute_input":"2023-07-20T04:31:32.259536Z","iopub.status.idle":"2023-07-20T04:33:10.151479Z","shell.execute_reply.started":"2023-07-20T04:31:32.259499Z","shell.execute_reply":"2023-07-20T04:33:10.149125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import tensorflow as tf\n# import keras_tuner as kt\n\n# def model_builder(hp):\n#     model = keras.Sequential()\n    \n#     model.add(keras.layers.Conv2D(\n#         hp.Int('filter_1', min_value=5, max_value=200, step=10), \n#         hp.Choice('filter_size_1', values=[3, 4, 5]), \n#         activation='relu', \n#         input_shape=(222, 296, 1)))\n#     model.add(keras.layers.Conv2D(\n#         hp.Int('filter_2', min_value=5, max_value=150, step=5), \n#         hp.Choice('filter_size_2', values=[3, 4]), \n# #         padding = (2,2),\n# #         kernel_regularizer=regularizers.l2(hp.Float('l2_rate_1', min_value=0.0, max_value=0.05, step=0.01))\n#     ))\n#     model.add(keras.layers.MaxPooling2D(\n#         hp.Choice('kernel_size_1', values=[3, 4]), \n#         strides=(2, 2)))\n    \n#     model.add(keras.layers.Conv2D(\n#         hp.Int('filter_3', min_value=5, max_value=64, step=10), \n#         hp.Choice('filter_size_3', values=[3, 4]),\n#         activation='relu'))\n#     model.add(keras.layers.Conv2D(\n#         hp.Int('filter_4', min_value=5, max_value=64, step=10), \n#         hp.Choice('filter_size_4', values=[3, 4]), \n# #         padding = (2,2),\n# #         kernel_regularizer=regularizers.l2(hp.Float('l2_rate_2', min_value=0.0, max_value=0.2, step=0.06))\n#     ))\n#     model.add(keras.layers.MaxPooling2D(\n#         hp.Choice('kernel_size_2', values=[3, 4]), \n#         strides=(3, 3)))\n              \n# #     model.add(keras.layers.Conv2D(\n# #         hp.Int('filter_5', min_value=5, max_value=65, step=5), \n# #         hp.Choice('filter_size_5', values=[3, 4]), \n# #         activation='relu'))\n# #     model.add(keras.layers.Conv2D(\n# #         hp.Int('filter_6', min_value=5, max_value=65, step=5), \n# #         hp.Choice('filter_size_6', values=[3, 4]))) \n# # #         kernel_regularizer=regularizers.l2(hp.Float('l2_rate_3', min_value=0.0, max_value=0.05, step=0.01))))\n# #     model.add(keras.layers.MaxPooling2D(\n# #         hp.Choice('kernel_size_3', values=[3, 4]), \n# #         strides=(3, 3)))\n              \n#     model.add(keras.layers.Conv2D(\n#         hp.Int('filter_7', min_value=5, max_value=100, step=5), \n#         hp.Choice('filter_size_7', values=[2, 3]), \n#         activation='relu'))\n#     model.add(keras.layers.Conv2D(\n#         hp.Int('filter_8', min_value=5, max_value=100, step=5), \n#         hp.Choice('filter_size_8', values=[2, 3]), \n# #         padding = (2,2),\n# #         kernel_regularizer=regularizers.l2(hp.Float('l2_rate_4', min_value=0.0, max_value=0.05, step=0.01))\n#     ))\n#     model.add(keras.layers.MaxPooling2D(\n#         hp.Choice('kernel_size_4', values=[2, 3]), \n#         strides=(2, 2)))\n              \n#     model.add(keras.layers.Flatten())\n#     model.add(keras.layers.Dense(units=hp.Int('units_1', min_value=10, max_value=200, step=10), activation='relu'))\n    \n#     hp_dropout_rate = hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1)\n#     model.add(keras.layers.Dropout(hp_dropout_rate))\n    \n#     model.add(keras.layers.Dense(hp.Int('units_2', min_value=5, max_value=100, step=10), activation='relu'))\n    \n# #     model.add(keras.layers.Dense(2, activation='softmax'))\n#     model.add(keras.layers.Dense(1, activation='sigmoid'))\n\n#     hp_learning_rate = hp.Choice('learning_rate', values=[0.01, 0.001, 0.0003, 0.0001])\n\n#     model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n#                   loss=keras.losses.SparseCategoricalCrossentropy(),\n#                   metrics=['accuracy'])\n\n#     return model\n\n# tuner = kt.Hyperband(model_builder,\n#                      objective='val_accuracy',\n#                      max_epochs=10,\n#                      factor=3,\n#                      directory='/kaggle/working/',\n#                      project_name='congested_vs_uncongested_traffic_detector')\n              \n# stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n\n# tuner.search(X_train, y_train, epochs=15, validation_data=(X_val, y_val), callbacks=[stop_early])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building Model","metadata":{}},{"cell_type":"code","source":"# Get the optimal hyperparameters\nbest_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n\nbest_hps.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tuner.hypermodel.build(best_hps)\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train, y_train,\n                    validation_data=(X_val, y_val),\n                    batch_size=64,\n                    epochs=50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.save(f'/kaggle/working/{accuracy:.3f}accuracy_{loss:.3f}loss_cardboard_model')\n\nmodel.save(f'/kaggle/working/model1')\n\nloss, accuracy = model.evaluate(X_test, y_test)\nprint('Loss:', loss)\nprint('Accuracy:', accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Re-instantiate the hypermodel with the optimal number of epochs","metadata":{}},{"cell_type":"code","source":"val_acc_per_epoch = history.history['val_accuracy']\nbest_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\nprint('Best epoch: %d' % (best_epoch,))","metadata":{"id":"PFf8JO6Rw8Tx","outputId":"0fbb07f8-e446-4bb2-d7f4-1a91279aa9ab","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hypermodel = tuner.hypermodel.build(best_hps)\n\n# Retrain the model\nhypermodel.fit(X_train, y_train,\n                    epochs=best_epoch,\n                    batch_size=64,\n                    validation_data=(X_val, y_val))","metadata":{"id":"pLdedaO6gk3E","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss1, accuracy1 = hypermodel.evaluate(X_test, y_test)\nprint('Loss:', loss1)\nprint('Accuracy:', accuracy1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cnn.save(f'{accuracy:.3f}accuracy_{loss:.3f}loss_cardboard_model')\nhypermodel.save(f'/kaggle/working/model2')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}