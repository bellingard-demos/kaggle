{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\nimport numpy as np\nimport pandas as pd\nimport polars as pl\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models\nfrom keras.callbacks import EarlyStopping\nfrom tensorflow.keras.regularizers import l2\n\nimport keras_tuner as kt\n\nimport gc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-18T09:24:25.485755Z","iopub.execute_input":"2023-06-18T09:24:25.488873Z","iopub.status.idle":"2023-06-18T09:24:34.069279Z","shell.execute_reply.started":"2023-06-18T09:24:25.488832Z","shell.execute_reply":"2023-06-18T09:24:34.068274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing and transforming dataset","metadata":{}},{"cell_type":"code","source":"def label_counter(inpt, data_name):\n    c = 0\n    u = 0\n    for i in inpt:\n        if i == 1:\n            c = c+1\n        elif i == 0:\n            u = u + 1\n    print(f'{data_name} --> Congested: {c}, Uncongested: {u}')\n\ndef import_dataset(split_seed):\n    \n    #First dataset\n    congested = pl.read_csv('/kaggle/input/traffic-images-data/model2_congested_traffic_dataset.csv')\n    \n    #Second dtaset\n    uncongested = pl.read_csv('/kaggle/input/traffic-images-data/model2_uncongested_traffic_dataset.csv')\n    \n    #Combining first and second dataset\n    df = pl.concat([congested, uncongested], how=\"vertical\")\n    \n    y = df[:, 0] # Getting labels as series\n    y = y.to_numpy()\n    \n    df = df[:, 1:]/255.0 # Normalizing pixels value to range of 0 to 1\n    df = df.to_numpy().reshape(-1, 222, 296, 1) #reshaping to 296 by 222\n\n    # Split data into train and test sets\n    X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.1, random_state=split_seed) #42\n\n    # Split train data into train and validation sets\n    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=split_seed)\n    \n    label_counter(y_train, 'y_train')\n    label_counter(y_test, 'y_test')\n    label_counter(y_val, 'y_val')\n    \n    return X_train, y_train, X_test, y_test, X_val, y_val\n\nX_train, y_train, X_test, y_test, X_val, y_val = import_dataset(25)","metadata":{"execution":{"iopub.status.busy":"2023-06-18T07:50:23.398289Z","iopub.execute_input":"2023-06-18T07:50:23.398866Z","iopub.status.idle":"2023-06-18T07:51:10.348775Z","shell.execute_reply.started":"2023-06-18T07:50:23.398838Z","shell.execute_reply":"2023-06-18T07:51:10.34771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploring dataset","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport plotly.graph_objects as go\n\n# Define class labels\nclass_labels = {0: 'Congested images', 1: 'Uncongested images'}\n\n# Map class labels for visualization\ntrain_classes = np.array([class_labels[label] for label in y_train])\ntest_classes = np.array([class_labels[label] for label in y_test])\nval_classes = np.array([class_labels[label] for label in y_val])\n\n# Calculate class frequencies\ntrain_class_counts = np.unique(train_classes, return_counts=True)\ntest_class_counts = np.unique(test_classes, return_counts=True)\nval_class_counts = np.unique(val_classes, return_counts=True)\n\n# Create bar chart data\ndata = [\n    go.Bar(x=train_class_counts[0], y=train_class_counts[1], name='Train'),\n    go.Bar(x=test_class_counts[0], y=test_class_counts[1], name='Test'),\n    go.Bar(x=val_class_counts[0], y=val_class_counts[1], name='Validation')\n]\n\n# Set layout\nlayout = go.Layout(\n    title='Occurrences of Binary Classes',\n    xaxis=dict(title='Class'),\n    yaxis=dict(title='Count'),\n    barmode='group'\n)\n\n# Create figure\nfig = go.Figure(data=data, layout=layout)\n\n# Show the bar chart\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-18T08:56:14.707481Z","iopub.execute_input":"2023-06-18T08:56:14.708473Z","iopub.status.idle":"2023-06-18T08:56:14.732742Z","shell.execute_reply.started":"2023-06-18T08:56:14.708437Z","shell.execute_reply":"2023-06-18T08:56:14.731669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport plotly.graph_objects as go\n\n# Define class labels\nclass_labels = {\n    0: 'Congested',\n    1: 'Uncongested'\n}\n\n# Calculate total class counts\nclass_counts = {\n    class_labels[0]: np.sum([np.sum(y_train == 0), np.sum(y_test == 0), np.sum(y_val == 0)]),\n    class_labels[1]: np.sum([np.sum(y_train == 1), np.sum(y_test == 1), np.sum(y_val == 1)])\n}\n\n# Create bar chart data\ndata = [\n    go.Bar(x=list(class_counts.keys()), y=list(class_counts.values()))\n]\n\n# Set layout\nlayout = go.Layout(\n    title='Total Occurrences of Binary Classes',\n    xaxis=dict(title='Class'),\n    yaxis=dict(title='Count')\n)\n\n# Create figure\nfig = go.Figure(data=data, layout=layout)\n\n# Show the bar chart\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-18T08:58:16.381377Z","iopub.execute_input":"2023-06-18T08:58:16.381787Z","iopub.status.idle":"2023-06-18T08:58:16.397024Z","shell.execute_reply.started":"2023-06-18T08:58:16.381753Z","shell.execute_reply":"2023-06-18T08:58:16.39598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def image_visualizer(X, y, row_number):\n    X = X[row_number]\n    y = y[row_number]\n\n    plt.imshow(X, cmap='gray')\n    lbl = None\n    if y == 0:\n        lbl = 'Uncongested'\n    elif y == 1:\n        lbl = 'Congested'\n    plt.title(lbl)\n    plt.show()\n\nimage_visualizer(X_train, y_train, 5)\nimage_visualizer(X_train, y_train, 225)\nimage_visualizer(X_train, y_train, 512)\nimage_visualizer(X_train, y_train, 995)","metadata":{"execution":{"iopub.status.busy":"2023-06-18T08:51:20.866222Z","iopub.execute_input":"2023-06-18T08:51:20.866593Z","iopub.status.idle":"2023-06-18T08:51:22.262411Z","shell.execute_reply.started":"2023-06-18T08:51:20.866561Z","shell.execute_reply":"2023-06-18T08:51:22.261544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model hyperparameter tuning","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport keras_tuner as kt\n\ndef model_builder(hp):\n    model = keras.Sequential()\n    \n    model.add(keras.layers.Conv2D(hp.Int('filter_1', min_value=5, max_value=100, step=10), hp.Choice('filter_size_1', values=[3, 4, 5]), activation='relu', input_shape=(222, 296, 1)))\n    model.add(keras.layers.MaxPooling2D(hp.Choice('kernel_size_1', values=[1, 2])))\n    \n    model.add(keras.layers.Conv2D(hp.Int('filter_2', min_value=5, max_value=70, step=5), hp.Choice('filter_size_2', values=[1, 2]), activation='relu'))\n    model.add(keras.layers.MaxPooling2D(hp.Choice('kernel_size_2', values=[1, 2])))\n    \n    model.add(keras.layers.Conv2D(hp.Int('filter_3', min_value=5, max_value=70, step=5), hp.Choice('filter_size_3', values=[1, 2]), activation='relu'))\n    model.add(keras.layers.MaxPooling2D(hp.Choice('kernel_size_3', values=[1, 2])))\n    \n    model.add(keras.layers.Conv2D(hp.Int('filter_4', min_value=5, max_value=70, step=5), hp.Choice('filter_size_4', values=[1, 2]), activation='relu'))\n    model.add(keras.layers.MaxPooling2D(hp.Choice('kernel_size_4', values=[1, 2])))\n              \n    model.add(keras.layers.Conv2D(hp.Int('filter_5', min_value=5, max_value=70, step=5), hp.Choice('filter_size_5', values=[1, 2]), activation='relu'))\n    model.add(keras.layers.MaxPooling2D(hp.Choice('kernel_size_5', values=[1, 2])))\n        \n    model.add(keras.layers.Conv2D(hp.Int('filter_6', min_value=5, max_value=80, step=5), hp.Choice('filter_size_6', values=[1, 2]), activation='relu'))\n    model.add(keras.layers.MaxPooling2D(hp.Choice('kernel_size_6', values=[1, 2])))\n              \n    model.add(keras.layers.Flatten())\n    model.add(keras.layers.Dense(units=hp.Int('units_1', min_value=5, max_value=100, step=10), activation='relu'))\n    \n    hp_dropout_rate = hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1)\n    model.add(keras.layers.Dropout(hp_dropout_rate))\n    \n    model.add(keras.layers.Dense(hp.Int('units_2', min_value=5, max_value=55, step=5), activation='relu'))\n    \n    model.add(keras.layers.Dense(2, activation='softmax'))\n\n    hp_learning_rate = hp.Choice('learning_rate', values=[0.01, 0.001, 0.0003, 0.0001])\n\n    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n                  loss=keras.losses.SparseCategoricalCrossentropy(),\n                  metrics=['accuracy'])\n\n    return model\n\ntuner = kt.Hyperband(model_builder,\n                     objective='val_accuracy',\n                     max_epochs=10,\n                     factor=3,\n                     directory='/kaggle/working/',\n                     project_name='congested_vs_uncongested_traffic_detector')\n              \nstop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n\ntuner.search(X_train, y_train, epochs=15, validation_data=(X_val, y_val), callbacks=[stop_early])","metadata":{"execution":{"iopub.status.busy":"2023-06-18T07:51:10.352122Z","iopub.execute_input":"2023-06-18T07:51:10.352413Z","iopub.status.idle":"2023-06-18T08:04:36.215385Z","shell.execute_reply.started":"2023-06-18T07:51:10.352388Z","shell.execute_reply":"2023-06-18T08:04:36.214342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the optimal hyperparameters\nbest_hps=tuner.get_best_hyperparameters(num_trials=1)[0]","metadata":{"execution":{"iopub.status.busy":"2023-06-18T08:04:36.21822Z","iopub.execute_input":"2023-06-18T08:04:36.21876Z","iopub.status.idle":"2023-06-18T08:04:36.224276Z","shell.execute_reply.started":"2023-06-18T08:04:36.218715Z","shell.execute_reply":"2023-06-18T08:04:36.223056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training optimum model on dataset","metadata":{}},{"cell_type":"code","source":"model = tuner.hypermodel.build(best_hps)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-18T08:04:36.225965Z","iopub.execute_input":"2023-06-18T08:04:36.22656Z","iopub.status.idle":"2023-06-18T08:04:36.432823Z","shell.execute_reply.started":"2023-06-18T08:04:36.226526Z","shell.execute_reply":"2023-06-18T08:04:36.431938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data augmentation\ndatagen = keras.preprocessing.image.ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode='nearest'\n)\n\nhistory = model.fit(datagen.flow(X_train, y_train),\n                    validation_data=(X_val, y_val),\n                    epochs=60)","metadata":{"execution":{"iopub.status.busy":"2023-06-18T08:04:36.433969Z","iopub.execute_input":"2023-06-18T08:04:36.434328Z","iopub.status.idle":"2023-06-18T08:24:48.886373Z","shell.execute_reply.started":"2023-06-18T08:04:36.434292Z","shell.execute_reply":"2023-06-18T08:24:48.885291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_acc_per_epoch = history.history['val_accuracy']\nbest_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\nprint('Best epoch: %d' % (best_epoch,))","metadata":{"execution":{"iopub.status.busy":"2023-06-18T08:24:48.887833Z","iopub.execute_input":"2023-06-18T08:24:48.88817Z","iopub.status.idle":"2023-06-18T08:24:48.89464Z","shell.execute_reply.started":"2023-06-18T08:24:48.888144Z","shell.execute_reply":"2023-06-18T08:24:48.893629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Re-instantiate the hypermodel with the optimal number of epochs","metadata":{}},{"cell_type":"code","source":"hypermodel = tuner.hypermodel.build(best_hps)\n\n# Retrain the model\nhypermodel.fit(datagen.flow(X_train, y_train),\n                    epochs=best_epoch,\n                    validation_data=(X_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2023-06-18T08:24:48.896434Z","iopub.execute_input":"2023-06-18T08:24:48.89724Z","iopub.status.idle":"2023-06-18T08:43:21.29188Z","shell.execute_reply.started":"2023-06-18T08:24:48.897143Z","shell.execute_reply":"2023-06-18T08:43:21.290699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating","metadata":{}},{"cell_type":"code","source":"loss, accuracy = hypermodel.evaluate(X_test, y_test)\nprint('Loss:', loss)\nprint('Accuracy:', accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-06-18T08:43:21.294958Z","iopub.execute_input":"2023-06-18T08:43:21.295333Z","iopub.status.idle":"2023-06-18T08:43:22.672864Z","shell.execute_reply.started":"2023-06-18T08:43:21.295297Z","shell.execute_reply":"2023-06-18T08:43:22.671743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index = 1\nprint(y_test[index])\nhypermodel.predict(X_test[index].reshape(-1, 222, 296, 1))","metadata":{"execution":{"iopub.status.busy":"2023-06-18T08:46:07.123539Z","iopub.execute_input":"2023-06-18T08:46:07.124447Z","iopub.status.idle":"2023-06-18T08:46:07.29266Z","shell.execute_reply.started":"2023-06-18T08:46:07.124413Z","shell.execute_reply":"2023-06-18T08:46:07.291655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index = 108\nprint(y_test[index])\nhypermodel.predict(X_test[index].reshape(-1, 222, 296, 1))","metadata":{"execution":{"iopub.status.busy":"2023-06-18T08:46:09.099985Z","iopub.execute_input":"2023-06-18T08:46:09.100345Z","iopub.status.idle":"2023-06-18T08:46:09.171595Z","shell.execute_reply.started":"2023-06-18T08:46:09.100313Z","shell.execute_reply":"2023-06-18T08:46:09.170687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index = 233\nprint(y_test[index])\nhypermodel.predict(X_test[index].reshape(-1, 222, 296, 1))","metadata":{"execution":{"iopub.status.busy":"2023-06-18T08:46:11.889126Z","iopub.execute_input":"2023-06-18T08:46:11.889508Z","iopub.status.idle":"2023-06-18T08:46:11.961822Z","shell.execute_reply.started":"2023-06-18T08:46:11.889477Z","shell.execute_reply":"2023-06-18T08:46:11.960791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index = 154\nprint(y_test[index])\nhypermodel.predict(X_test[index].reshape(-1, 222, 296, 1))","metadata":{"execution":{"iopub.status.busy":"2023-06-18T08:46:15.458659Z","iopub.execute_input":"2023-06-18T08:46:15.459025Z","iopub.status.idle":"2023-06-18T08:46:15.525757Z","shell.execute_reply.started":"2023-06-18T08:46:15.458995Z","shell.execute_reply":"2023-06-18T08:46:15.524699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving","metadata":{}},{"cell_type":"code","source":"hypermodel.save('/kaggle/working/model')","metadata":{"execution":{"iopub.status.busy":"2023-06-18T08:46:25.088366Z","iopub.execute_input":"2023-06-18T08:46:25.088747Z","iopub.status.idle":"2023-06-18T08:46:29.617358Z","shell.execute_reply.started":"2023-06-18T08:46:25.088715Z","shell.execute_reply":"2023-06-18T08:46:29.616315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}