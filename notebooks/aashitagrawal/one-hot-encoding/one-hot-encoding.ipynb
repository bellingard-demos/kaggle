{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-25T07:27:33.922552Z","iopub.execute_input":"2023-05-25T07:27:33.922975Z","iopub.status.idle":"2023-05-25T07:27:33.938681Z","shell.execute_reply.started":"2023-05-25T07:27:33.922943Z","shell.execute_reply":"2023-05-25T07:27:33.937841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# One Hot Encoding\n![](https://www.researchgate.net/publication/344409939/figure/fig1/AS:940907041918978@1601341128930/An-example-of-one-hot-encoding.png)\n\n<p>These resulting columns from OneHotEncoding are referred to as <em>dummy variables</em>. The creation of these dummy variables introduces multicollinearity, which is known as the <em>\"dummy variable trap.\"</em> To avoid falling into this trap, we remove one column.</p>\n<p>In Machine Learning, it is important to ensure that your columns are not dependent on or have mathematical relationships with each other, which is known as <em>multicollinearity</em>. Hence, your columns should not exhibit multicollinearity.</p>\n\nTo address multicollinearity, we remove one column, in OneHotEncoding. If you have 'n' categories in a column, after OneHotEncoding, you will have 'n-1' columns remaining.","metadata":{}},{"cell_type":"markdown","source":"#   Let's start coding","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/cars-dataset/cars.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T07:27:33.971133Z","iopub.execute_input":"2023-05-25T07:27:33.972312Z","iopub.status.idle":"2023-05-25T07:27:33.992535Z","shell.execute_reply.started":"2023-05-25T07:27:33.972254Z","shell.execute_reply":"2023-05-25T07:27:33.991482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = df.drop(['selling_price'],axis=1)\ny = df.selling_price\nX_train, X_valid, y_train, y_valid = train_test_split(X,y,test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T07:27:34.008134Z","iopub.execute_input":"2023-05-25T07:27:34.008786Z","iopub.status.idle":"2023-05-25T07:27:34.018381Z","shell.execute_reply.started":"2023-05-25T07:27:34.008756Z","shell.execute_reply":"2023-05-25T07:27:34.017162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h4>Handling large category column</h4>","metadata":{}},{"cell_type":"code","source":"cat_cols = [col for col in X_train.columns if X_train[col].dtype==\"object\"]\n\nhigh_cat_cols = [col for col in X_train.columns if X_train[col].dtype==\"object\" and X_train[col].nunique() > 9]\n\n#Lets say one column - brand is high categorical column so, all brand names will be replaced by 'uncommon', who have less-than-equals 100 occurence\nthreshold = 100\ncounts = X_train[high_cat_cols].value_counts()\nreplace_cols = counts[counts <= threshold].index\n\nX_train[high_cat_cols] = X_train[high_cat_cols].replace(replace_cols, 'uncommon')\nX_valid[high_cat_cols] = X_valid[high_cat_cols].replace(replace_cols, 'uncommon')","metadata":{"execution":{"iopub.status.busy":"2023-05-25T07:27:34.045725Z","iopub.execute_input":"2023-05-25T07:27:34.046275Z","iopub.status.idle":"2023-05-25T07:27:34.071527Z","shell.execute_reply.started":"2023-05-25T07:27:34.046238Z","shell.execute_reply":"2023-05-25T07:27:34.070341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h4>One Hot Encoding using Pandas</h4>","metadata":{}},{"cell_type":"code","source":"ohe_cols = ['brand','fuel','owner']\n\nX_train_encoded = X_train.copy()\nX_valid_encoded = X_valid.copy()\n\nX_train_encoded = pd.get_dummies(X_train_encoded, columns=ohe_cols, drop_first=True)\nX_valid_encoded = pd.get_dummies(X_valid_encoded, columns=ohe_cols, drop_first=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T07:27:34.085423Z","iopub.execute_input":"2023-05-25T07:27:34.085848Z","iopub.status.idle":"2023-05-25T07:27:34.104243Z","shell.execute_reply.started":"2023-05-25T07:27:34.08582Z","shell.execute_reply":"2023-05-25T07:27:34.102604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h4>One Hot Encoding using sklearn</h4>","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\nX_train_encoded2 = X_train.copy()\nX_valid_encoded2 = X_valid.copy()\n\n# Use handle_unknown=\"ignore\" - To avoid inconsistency of no_of_categories in any column between X_train and X_valid\nohe = OneHotEncoder(handle_unknown='ignore', drop='first', dtype=np.int32, sparse=False)\n\nX_train_encoded2 = pd.DataFrame(ohe.fit_transform(X_train[ohe_cols]))\nX_valid_encoded2 = pd.DataFrame(ohe.transform(X_valid[ohe_cols]))\n\n# One-hot encoding removed index; put it back\nX_train_encoded2.index = X_train.index\nX_valid_encoded2.index = X_valid.index\n\nX_train_encoded2.columns = ohe.get_feature_names_out()\nX_valid_encoded2.columns = ohe.get_feature_names_out()\n\nnum_X_train = X_train.drop(columns=ohe_cols)\nnum_X_valid = X_valid.drop(columns=ohe_cols)\nX_train_encoded2 = pd.concat([num_X_train, X_train_encoded2], axis=1)\nX_valid_encoded2 = pd.concat([num_X_valid, X_valid_encoded2], axis=1)\n\n# Ensure all columns have string type\nX_train_encoded2.columns = X_train_encoded2.columns.astype(str)\nX_valid_encoded2.columns = X_valid_encoded2.columns.astype(str)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T07:27:34.139498Z","iopub.execute_input":"2023-05-25T07:27:34.13993Z","iopub.status.idle":"2023-05-25T07:27:34.169878Z","shell.execute_reply.started":"2023-05-25T07:27:34.139897Z","shell.execute_reply":"2023-05-25T07:27:34.167737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h4>Result</h4>","metadata":{}},{"cell_type":"code","source":"print(X_train.shape)\nprint(X_valid.shape)\nprint(X_train_encoded.shape)\nprint(X_valid_encoded.shape)\nprint(X_train_encoded2.shape)\nprint(X_valid_encoded2.shape)\n\nprint(\"\\n\\nUSING PANDAS\")\nprint(\"\\nX_train \\n\", X_train.head(5))\nprint(\"\\nX_train_encoded \\n\", X_train_encoded.head(5))\nprint(\"\\nX_valid \\n\", X_valid.head(5))\nprint(\"\\nX_valid_encoded \\n\", X_valid_encoded.head(5))\n\nprint(\"\\n\\nUSING SKLEARN\")\nprint(\"\\nX_train \\n\", X_train.head(5))\nprint(\"\\nX_train_encoded2 \\n\", X_train_encoded2.head(5))\nprint(\"\\nX_valid \\n\", X_valid.head(5))\nprint(\"\\nX_valid_encoded2 \\n\", X_valid_encoded2.head(5))","metadata":{"execution":{"iopub.status.busy":"2023-05-25T07:27:34.232493Z","iopub.execute_input":"2023-05-25T07:27:34.232892Z","iopub.status.idle":"2023-05-25T07:27:34.263174Z","shell.execute_reply.started":"2023-05-25T07:27:34.232862Z","shell.execute_reply":"2023-05-25T07:27:34.26185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h5>\nðŸ‘‡ðŸ‘‡ How the large category columns were handled ðŸ‘‡ðŸ‘‡ <br>\nthe less frequent one were clubbed into 'uncommon'\n</h5>","metadata":{}},{"cell_type":"code","source":"df.brand.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T07:27:34.299014Z","iopub.execute_input":"2023-05-25T07:27:34.299362Z","iopub.status.idle":"2023-05-25T07:27:34.311952Z","shell.execute_reply.started":"2023-05-25T07:27:34.299335Z","shell.execute_reply":"2023-05-25T07:27:34.310477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.brand.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T07:27:34.313719Z","iopub.execute_input":"2023-05-25T07:27:34.314055Z","iopub.status.idle":"2023-05-25T07:27:34.327515Z","shell.execute_reply.started":"2023-05-25T07:27:34.314026Z","shell.execute_reply":"2023-05-25T07:27:34.326055Z"},"trusted":true},"execution_count":null,"outputs":[]}]}