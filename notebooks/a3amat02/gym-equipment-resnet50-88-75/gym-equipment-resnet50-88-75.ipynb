{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style='text-align:center;\n            font-size:180%;'>\n    <h1 style='display:inline-block;'>Introduction</h1>\n    <p style='display:inline-block;text-align:center;'>\n        In this Notebook I fine-tuned ResNet-50 model\n        <br>\n        In my previous <a href='https://www.kaggle.com/code/a3amat02/gym-equipment-image-classifier-from-scratch'>work</a> I built a simple Image Classification model based on CNN using BatchNormalization, MaxPooling and ReLU layers\n        <br>\n        But results were bad, ax expected, since the model is trained from scratch and there is a low number of instances\n        <br>\n        Hence I suggested to use pre-trained models for Image Classification\n        <br>\n        Thus it is Transfer Learning task\n    </p>\n</div>","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nimport time\nfrom copy import deepcopy\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport torchvision.transforms as transforms\nfrom torchvision.models import resnet50\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-06T12:45:02.84709Z","iopub.execute_input":"2023-06-06T12:45:02.847434Z","iopub.status.idle":"2023-06-06T12:45:02.853799Z","shell.execute_reply.started":"2023-06-06T12:45:02.847408Z","shell.execute_reply":"2023-06-06T12:45:02.85249Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dataset(path):\n    dumbells = os.path.join(path, 'Dumbells')\n    dums = [x[2] for x in os.walk(dumbells)]\n    d_arr = [os.path.join(dumbells, x) for x in dums[0]]\n    emachines = os.path.join(path, 'Elliptical Machine')\n    emac = [x[2] for x in os.walk(emachines)]\n    e_arr = [os.path.join(emachines, x) for x in emac[0]]\n    hmachines = os.path.join(path, 'Home Machine')\n    hmac = [x[2] for x in os.walk(hmachines)]\n    h_arr = [os.path.join(hmachines, x) for x in hmac[0]]\n    rbikes = os.path.join(path, 'Recumbent Bike')\n    rbik = [x[2] for x in os.walk(rbikes)]\n    r_arr = [os.path.join(rbikes, x) for x in rbik[0]]\n    label = ['dumbell']*len(d_arr) + ['elliptical machine']*len(e_arr) + ['home machine']*len(h_arr) + ['recumbent bike']*len(r_arr)\n    dd = {'images': d_arr+e_arr+h_arr+r_arr,\n         'labels': label}\n    \n    return pd.DataFrame(dd)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T12:02:50.234292Z","iopub.execute_input":"2023-06-06T12:02:50.234749Z","iopub.status.idle":"2023-06-06T12:02:50.244511Z","shell.execute_reply.started":"2023-06-06T12:02:50.234726Z","shell.execute_reply":"2023-06-06T12:02:50.243193Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"/kaggle/input/4-gym-equipment-types-classification-dataset/Gym Data\"\ndf = create_dataset(path)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T12:02:50.245683Z","iopub.execute_input":"2023-06-06T12:02:50.245986Z","iopub.status.idle":"2023-06-06T12:02:50.397256Z","shell.execute_reply.started":"2023-06-06T12:02:50.245964Z","shell.execute_reply":"2023-06-06T12:02:50.395852Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_index = {'dumbell': 0,\n              'elliptical machine': 1,\n              'home machine': 2,\n              'recumbent bike': 3}\n\nindex_label = dict()\nk = 0\nfor i in label_index.keys():\n    index_label[k] = i\n    k += 1\n    \nprint(label_index)\nprint(index_label)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T12:02:50.398884Z","iopub.execute_input":"2023-06-06T12:02:50.399673Z","iopub.status.idle":"2023-06-06T12:02:50.405662Z","shell.execute_reply.started":"2023-06-06T12:02:50.399644Z","shell.execute_reply":"2023-06-06T12:02:50.404582Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['labels'] = df['labels'].map(label_index)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T12:02:50.408962Z","iopub.execute_input":"2023-06-06T12:02:50.409259Z","iopub.status.idle":"2023-06-06T12:02:50.427985Z","shell.execute_reply.started":"2023-06-06T12:02:50.409236Z","shell.execute_reply":"2023-06-06T12:02:50.426618Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CreatePipeline(Dataset):\n    def __init__(self, data, transform):\n        super(CreatePipeline, self).__init__()\n        self.data = data.values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, x):\n        image, label = self.data[x]\n        im = np.asarray(Image.open(image).convert('RGB'))\n        if self.transform is not None:\n            im = self.transform(im)\n        \n        return im, label","metadata":{"execution":{"iopub.status.busy":"2023-06-06T12:02:50.4301Z","iopub.execute_input":"2023-06-06T12:02:50.430623Z","iopub.status.idle":"2023-06-06T12:02:50.439278Z","shell.execute_reply.started":"2023-06-06T12:02:50.430584Z","shell.execute_reply":"2023-06-06T12:02:50.438285Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH = 24\nEPOCHS = 15\nLR = 0.1\nsize = 224","metadata":{"execution":{"iopub.status.busy":"2023-06-06T12:02:50.440322Z","iopub.execute_input":"2023-06-06T12:02:50.44059Z","iopub.status.idle":"2023-06-06T12:02:50.455515Z","shell.execute_reply.started":"2023-06-06T12:02:50.440567Z","shell.execute_reply":"2023-06-06T12:02:50.45481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([transforms.ToPILImage(),\n                               transforms.ToTensor(),\n                               transforms.Resize((size, size)),\n                               transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))])","metadata":{"execution":{"iopub.status.busy":"2023-06-06T12:02:50.456234Z","iopub.execute_input":"2023-06-06T12:02:50.45646Z","iopub.status.idle":"2023-06-06T12:02:50.466775Z","shell.execute_reply.started":"2023-06-06T12:02:50.45644Z","shell.execute_reply":"2023-06-06T12:02:50.465739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, test = train_test_split(df, random_state=42, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T12:02:50.467884Z","iopub.execute_input":"2023-06-06T12:02:50.46817Z","iopub.status.idle":"2023-06-06T12:02:50.480144Z","shell.execute_reply.started":"2023-06-06T12:02:50.468148Z","shell.execute_reply":"2023-06-06T12:02:50.479349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = CreatePipeline(train, transform)\nval_ds = CreatePipeline(test, transform)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T12:02:50.481639Z","iopub.execute_input":"2023-06-06T12:02:50.481952Z","iopub.status.idle":"2023-06-06T12:02:50.491168Z","shell.execute_reply.started":"2023-06-06T12:02:50.481923Z","shell.execute_reply":"2023-06-06T12:02:50.490323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dl = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\nval_dl = DataLoader(val_ds, batch_size=BATCH, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T12:02:50.492256Z","iopub.execute_input":"2023-06-06T12:02:50.492553Z","iopub.status.idle":"2023-06-06T12:02:50.501635Z","shell.execute_reply.started":"2023-06-06T12:02:50.492526Z","shell.execute_reply":"2023-06-06T12:02:50.500486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = resnet50(weights='IMAGENET1K_V1')\nnum_ftrs = model.fc.in_features\nmodel.fc = torch.nn.Linear(num_ftrs, 4)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T12:03:16.680837Z","iopub.execute_input":"2023-06-06T12:03:16.681246Z","iopub.status.idle":"2023-06-06T12:03:17.134639Z","shell.execute_reply.started":"2023-06-06T12:03:16.681197Z","shell.execute_reply":"2023-06-06T12:03:17.133975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\noptimizer = torch.optim.SGD(model.parameters(), lr=LR)\ncriterion = torch.nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2023-06-06T12:03:17.13603Z","iopub.execute_input":"2023-06-06T12:03:17.136485Z","iopub.status.idle":"2023-06-06T12:03:17.150157Z","shell.execute_reply.started":"2023-06-06T12:03:17.136459Z","shell.execute_reply":"2023-06-06T12:03:17.149055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model = deepcopy(model)\nal_start = time.time()\nbest_acc = 0\ntrain_history = []\nval_history = []\nacc_history = []\n\nfor i in range(1, EPOCHS+1):\n    start = time.time()\n    model.train()\n    \n    train_loss = 0\n    train_total = 0\n    for idx, (image, label) in enumerate(train_dl):\n        optimizer.zero_grad()\n        out = model(image)\n        loss = criterion(out, label)\n        loss.backward()\n        train_loss += loss.item()\n        train_total += out.size(0)\n        optimizer.step()\n        \n    train_res = train_loss/train_total\n    \n    model.eval()\n    val_loss = 0\n    val_total = 0\n    val_acc = 0\n    with torch.no_grad():\n        for idx, (image, label) in enumerate(val_dl):\n            out = model(image)\n            loss = criterion(out, label)\n            val_loss += loss.item()\n            val_total += out.size(0)\n            val_acc += (label == out.argmax(1)).sum().item()\n    val_res = val_loss/val_total\n    acc_val = val_acc/val_total\n    \n    if acc_val > best_acc:\n        best_acc = acc_val\n        best_model = deepcopy(model)\n        \n    end = time.time()\n    \n    train_history += [train_res]\n    val_history += [val_res]\n    acc_history += [acc_val]\n        \n    print(\"Epoch {} || train loss: {} || val loss: {} || val acc: {} || time: {}\".format(i,\n                                                                                        train_res,\n                                                                                        val_res,\n                                                                                        acc_val,\n                                                                                        end-start))\n    \n    \nal_end = time.time()\nprint(\"Total time {}\".format(al_end - al_start))","metadata":{"execution":{"iopub.status.busy":"2023-06-06T12:03:17.151809Z","iopub.execute_input":"2023-06-06T12:03:17.152195Z","iopub.status.idle":"2023-06-06T12:41:16.775477Z","shell.execute_reply.started":"2023-06-06T12:03:17.152162Z","shell.execute_reply":"2023-06-06T12:41:16.774513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style='font-size:150%;'>\n    <h1 style='text-align:center;'>🚀 Training results 📉📈</h1>\n    <p style='text-align:center;font-size:130%'>The Best accuracy score is 88.75%\n        <br>\n        I posted Notebook where I implemeneted my own Image Classifier using simple CNN based structure\n        <br>\n        The best accuracy I could get was 36%, due to two facts:\n    </p>\n    <div style='text-align:center;'>\n        <ul style='display:inline-block;text-align:left;'>\n            <li>Model is not pre-trained, it is being trained from total scratch</li>\n            <li>Due to lack of instances and taking previous point into consideration might lead to poor training and low accracy 📉</li>\n        </ul>\n    </div>\n    <p>Then it was suggested to use pre-trained models such as ResNet or VGGNet<br>\n        I prefer ResNet over VGGNet, because\n    </p>\n    <div style='text-align:center;'>\n        <ul style='display:inline-block;'>\n            <li>ResNet is faster than VGG</li>\n            <li>ResNet is deeper and due to global average pooling is lighter(102MB for ResNet50)</li>\n        </ul>\n    </div>\n</div>","metadata":{}},{"cell_type":"code","source":"epochs = list(range(1, EPOCHS+1))\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 8))\naxes[0].plot(epochs, train_history)\naxes[0].plot(epochs, val_history)\naxes[0].legend(['Train Loss', 'Validation Loss'])\naxes[0].set_title(\"Train and Validation loss progression\")\naxes[1].plot(epochs, acc_history)\naxes[1].set_title(\"Accuracy progression\")\nplt.suptitle(\"Results\", size=30)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-06T12:46:27.977383Z","iopub.execute_input":"2023-06-06T12:46:27.977755Z","iopub.status.idle":"2023-06-06T12:46:28.390361Z","shell.execute_reply.started":"2023-06-06T12:46:27.977726Z","shell.execute_reply":"2023-06-06T12:46:28.388803Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style='font-size:180%;\n            text-align:center;'>\n    <h1>Model tested ✅</h1>\n</div>","metadata":{}},{"cell_type":"code","source":"def predict(path):\n    im = np.asarray(Image.open(path).convert(\"RGB\"))\n    im = transform(im)\n    with torch.no_grad():\n        model.eval()\n        out = model(im.reshape(1, 3, size, size))\n        \n    return index_label[out.argmax(1).detach().numpy()[0]]","metadata":{"execution":{"iopub.status.busy":"2023-06-06T13:24:24.604876Z","iopub.execute_input":"2023-06-06T13:24:24.605247Z","iopub.status.idle":"2023-06-06T13:24:24.611427Z","shell.execute_reply.started":"2023-06-06T13:24:24.605221Z","shell.execute_reply":"2023-06-06T13:24:24.610335Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show1 = df.iloc[0, 0]\ne1 = df.iloc[0, 1]\nshow2 = df.iloc[240, 0]\ne2 = df.iloc[240, 1]\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 10))\nimage1 = np.asarray(Image.open(show1).convert(\"RGB\"))\naxes[0].imshow(image1)\naxes[0].set_title(\"Predicted value: {}\\nExpected: {}\".format(predict(show1), index_label[e1]))\nimage2 = np.asarray(Image.open(show2).convert(\"RGB\"))\naxes[1].imshow(image2)\naxes[1].set_title(\"Predicted value: {}\\nExpected: {}\".format(predict(show2), index_label[e2]))\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-06T13:24:26.360209Z","iopub.execute_input":"2023-06-06T13:24:26.360591Z","iopub.status.idle":"2023-06-06T13:24:27.237533Z","shell.execute_reply.started":"2023-06-06T13:24:26.360559Z","shell.execute_reply":"2023-06-06T13:24:27.236582Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]}]}