{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n\nfrom copy import deepcopy\nimport time\nfrom sklearn.model_selection import train_test_split\nfrom torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator\nfrom torch.utils.data import DataLoader\n\nimport torch\n\nfrom sklearn.metrics import accuracy_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-28T14:08:42.201311Z","iopub.execute_input":"2023-06-28T14:08:42.201742Z","iopub.status.idle":"2023-06-28T14:08:42.211319Z","shell.execute_reply.started":"2023-06-28T14:08:42.201707Z","shell.execute_reply":"2023-06-28T14:08:42.210359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -m spacy download es_core_news_sm","metadata":{"execution":{"iopub.status.busy":"2023-06-28T13:36:58.043577Z","iopub.execute_input":"2023-06-28T13:36:58.044235Z","iopub.status.idle":"2023-06-28T13:37:28.023212Z","shell.execute_reply.started":"2023-06-28T13:36:58.044201Z","shell.execute_reply":"2023-06-28T13:37:28.021976Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/spanish-lang-suicide-tendency-texts/data_raw.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-06-28T13:37:28.028322Z","iopub.execute_input":"2023-06-28T13:37:28.031089Z","iopub.status.idle":"2023-06-28T13:37:29.65491Z","shell.execute_reply.started":"2023-06-28T13:37:28.031047Z","shell.execute_reply":"2023-06-28T13:37:29.653989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_index = {'suicida': 1, 'no_suicida': 0}\nindex_label = {1: 'suicida', 0: 'no suicida'}","metadata":{"execution":{"iopub.status.busy":"2023-06-28T13:37:29.65773Z","iopub.execute_input":"2023-06-28T13:37:29.658124Z","iopub.status.idle":"2023-06-28T13:37:29.665222Z","shell.execute_reply.started":"2023-06-28T13:37:29.658089Z","shell.execute_reply":"2023-06-28T13:37:29.662611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-06-28T13:37:29.666496Z","iopub.execute_input":"2023-06-28T13:37:29.66762Z","iopub.status.idle":"2023-06-28T13:37:29.746481Z","shell.execute_reply.started":"2023-06-28T13:37:29.667587Z","shell.execute_reply":"2023-06-28T13:37:29.745592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"freqs = df['class'].value_counts()\nplt.pie(freqs, labels=freqs.index,autopct='%0.2f%%')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-28T13:37:29.747677Z","iopub.execute_input":"2023-06-28T13:37:29.748035Z","iopub.status.idle":"2023-06-28T13:37:29.900008Z","shell.execute_reply.started":"2023-06-28T13:37:29.748Z","shell.execute_reply":"2023-06-28T13:37:29.898775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['class'] = df['class'].map(label_index)","metadata":{"execution":{"iopub.status.busy":"2023-06-28T13:37:29.905359Z","iopub.execute_input":"2023-06-28T13:37:29.908854Z","iopub.status.idle":"2023-06-28T13:37:29.942739Z","shell.execute_reply.started":"2023-06-28T13:37:29.908803Z","shell.execute_reply":"2023-06-28T13:37:29.941669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, late = train_test_split(df.values, random_state=42, test_size=0.25)\n\nval, test = train_test_split(late, random_state=42, test_size=0.01)","metadata":{"execution":{"iopub.status.busy":"2023-06-28T13:37:29.948029Z","iopub.execute_input":"2023-06-28T13:37:29.951378Z","iopub.status.idle":"2023-06-28T13:37:29.983395Z","shell.execute_reply.started":"2023-06-28T13:37:29.951342Z","shell.execute_reply":"2023-06-28T13:37:29.982778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building vocabulary and tokenizing data with text pipeline","metadata":{}},{"cell_type":"code","source":"tokenizer = get_tokenizer(tokenizer='spacy', language='es')\n\ndef yield_tokens(batch):\n    for _text, _label in batch:\n        yield tokenizer(_text)\n        \nvocab = build_vocab_from_iterator(yield_tokens(train), specials=['<unk>'])\nvocab.set_default_index(vocab['<unk>'])","metadata":{"execution":{"iopub.status.busy":"2023-06-28T13:37:29.985096Z","iopub.execute_input":"2023-06-28T13:37:29.985436Z","iopub.status.idle":"2023-06-28T13:38:11.733382Z","shell.execute_reply.started":"2023-06-28T13:37:29.985406Z","shell.execute_reply":"2023-06-28T13:38:11.732383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_pipeline = lambda x: vocab(tokenizer(x))","metadata":{"execution":{"iopub.status.busy":"2023-06-28T13:38:11.737241Z","iopub.execute_input":"2023-06-28T13:38:11.739582Z","iopub.status.idle":"2023-06-28T13:38:11.744137Z","shell.execute_reply.started":"2023-06-28T13:38:11.73955Z","shell.execute_reply":"2023-06-28T13:38:11.74299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Parameters for DataLoader and model training","metadata":{}},{"cell_type":"code","source":"EPOCHS = 35\nLR=0.1\nSTEP=5\nGAMMA = 0.1\nBATCH=32\nDECAY=0.9\nepochs = list(range(1, EPOCHS+1))\nEM_SIZE=64\nNUM_CLASSES=2\nVOCAB_SIZE=len(vocab)","metadata":{"execution":{"iopub.status.busy":"2023-06-28T13:38:11.745959Z","iopub.execute_input":"2023-06-28T13:38:11.746969Z","iopub.status.idle":"2023-06-28T13:38:11.756385Z","shell.execute_reply.started":"2023-06-28T13:38:11.746917Z","shell.execute_reply":"2023-06-28T13:38:11.755356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Batch collate function for DataLoader","metadata":{}},{"cell_type":"code","source":"def collate_batch(batch):\n    text_list, label_list, offsets = [], [], [0]\n    for _text, _label in batch:\n        processed = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n        text_list += [processed]\n        label_list += [_label]\n        offsets += [processed.size(0)]\n        \n    text_list = torch.cat(text_list)\n    label_list = torch.tensor(label_list, dtype=torch.int64)\n    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n    \n    return text_list, label_list, offsets","metadata":{"execution":{"iopub.status.busy":"2023-06-28T13:38:11.757895Z","iopub.execute_input":"2023-06-28T13:38:11.758262Z","iopub.status.idle":"2023-06-28T13:38:11.76761Z","shell.execute_reply.started":"2023-06-28T13:38:11.758231Z","shell.execute_reply":"2023-06-28T13:38:11.766688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dl = DataLoader(train, batch_size=BATCH, shuffle=True, collate_fn=collate_batch)\nval_dl = DataLoader(val, batch_size=BATCH, shuffle=False, collate_fn=collate_batch)","metadata":{"execution":{"iopub.status.busy":"2023-06-28T13:38:11.769082Z","iopub.execute_input":"2023-06-28T13:38:11.769418Z","iopub.status.idle":"2023-06-28T13:38:11.777578Z","shell.execute_reply.started":"2023-06-28T13:38:11.769386Z","shell.execute_reply":"2023-06-28T13:38:11.776577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Architecture","metadata":{}},{"cell_type":"code","source":"class SpanishClassifier(torch.nn.Module):\n    def __init__(self, vocab_size, em_size, num_classes):\n        super(SpanishClassifier, self).__init__()\n        self.em = torch.nn.EmbeddingBag(vocab_size, em_size)\n        self.layers = torch.nn.Sequential(torch.nn.Linear(em_size, 256),\n                                          torch.nn.ReLU(),\n                                          torch.nn.Dropout(p=0.2),\n                                         torch.nn.BatchNorm1d(256),\n                                         torch.nn.Linear(256, 512),\n                                         torch.nn.ReLU(),\n                                          torch.nn.Dropout(p=0.2),\n                                         torch.nn.BatchNorm1d(512))\n        \n        self.fc = torch.nn.Linear(512, num_classes)\n        \n    def forward(self, x, offset):\n        x = self.em(x, offset)\n        x = self.layers(x)\n        return self.fc(x)","metadata":{"execution":{"iopub.status.busy":"2023-06-28T13:42:11.249234Z","iopub.execute_input":"2023-06-28T13:42:11.24961Z","iopub.status.idle":"2023-06-28T13:42:11.258215Z","shell.execute_reply.started":"2023-06-28T13:42:11.24958Z","shell.execute_reply":"2023-06-28T13:42:11.257197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining model, device, optimizer and criterion","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = SpanishClassifier(VOCAB_SIZE, EM_SIZE, NUM_CLASSES)\nmodel = model.to(device)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)\n\ncriterion = torch.nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2023-06-28T13:44:29.25086Z","iopub.execute_input":"2023-06-28T13:44:29.251278Z","iopub.status.idle":"2023-06-28T13:44:29.359018Z","shell.execute_reply.started":"2023-06-28T13:44:29.251243Z","shell.execute_reply":"2023-06-28T13:44:29.358071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model = deepcopy(model)\nbest_acc = 0\ntrain_history = []\nacc_history = []\nval_history = []\n\nfor i in range(1, EPOCHS+1):\n    model.train()\n    \n    train_loss = 0\n    train_total = 0\n    for idx, (text, label, offset) in enumerate(train_dl):\n        if torch.cuda.is_available():\n            text, label, offset = text.cuda(), label.cuda(), offset.cuda()\n        optimizer.zero_grad()\n        out = model(text, offset)\n        loss = criterion(out, label)\n        train_loss += loss.item()\n        train_total += out.size(0)\n        loss.backward()\n        optimizer.step()\n        \n    train_end = train_loss/train_total\n    \n    val_loss = 0\n    val_total = 0\n    acc_loss = 0\n    model.eval()\n    for idx, (text, label, offset) in enumerate(val_dl):\n        if torch.cuda.is_available():\n            text, label, offset = text.cuda(), label.cuda(), offset.cuda()\n            \n        out = model(text, offset)\n        loss = criterion(out, label)\n        val_loss += loss.item()\n        val_total += out.size(0)\n        acc_loss += (out.argmax(1)==label).sum().item()\n        \n        \n    val_end = val_loss/val_total\n    acc_end = acc_loss/val_total\n    \n    train_history += [train_end]\n    val_history += [val_end]\n    acc_history += [acc_end]\n    \n    if acc_end > best_acc:\n        best_model = deepcopy(model)\n        best_acc = acc_end\n        \n    print(\"Epoch {} || train loss: {} || val loss: {} || acc loss: {}\".format(i,\n                                                                             train_end,\n                                                                             val_end,\n                                                                             acc_end))\n    \n    scheduler.step()","metadata":{"execution":{"iopub.status.busy":"2023-06-28T13:44:30.963758Z","iopub.execute_input":"2023-06-28T13:44:30.964138Z","iopub.status.idle":"2023-06-28T14:04:49.493289Z","shell.execute_reply.started":"2023-06-28T13:44:30.964107Z","shell.execute_reply":"2023-06-28T14:04:49.492105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 8))\naxes[0].plot(epochs, train_history)\naxes[1].plot(epochs, val_history)\naxes[2].plot(epochs, acc_history)\naxes[0].set_title(\"Train loss\")\naxes[1].set_title(\"Val loss\")\naxes[2].set_title(\"Accuracy\")\nplt.suptitle(\"Model training and evaluation performance\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-28T14:04:55.019752Z","iopub.execute_input":"2023-06-28T14:04:55.02013Z","iopub.status.idle":"2023-06-28T14:04:55.845397Z","shell.execute_reply.started":"2023-06-28T14:04:55.020098Z","shell.execute_reply":"2023-06-28T14:04:55.844495Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The best accuracy during training and evaluation is","metadata":{}},{"cell_type":"code","source":"best_acc","metadata":{"execution":{"iopub.status.busy":"2023-06-28T14:18:27.432039Z","iopub.execute_input":"2023-06-28T14:18:27.432594Z","iopub.status.idle":"2023-06-28T14:18:27.447246Z","shell.execute_reply.started":"2023-06-28T14:18:27.432547Z","shell.execute_reply":"2023-06-28T14:18:27.446058Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(text):\n    best_model.eval()\n    with torch.no_grad():\n        txt = torch.tensor(text_pipeline(text), dtype=torch.int64)\n        offset = torch.tensor([0])\n        if torch.cuda.is_available():\n            txt, offset = txt.cuda(), offset.cuda()\n        out = best_model(txt, offset)\n        \n        prediction = out.argmax(1).cpu().detach().numpy()\n        \n        return prediction[0]","metadata":{"execution":{"iopub.status.busy":"2023-06-28T14:07:30.704416Z","iopub.execute_input":"2023-06-28T14:07:30.70481Z","iopub.status.idle":"2023-06-28T14:07:30.711889Z","shell.execute_reply.started":"2023-06-28T14:07:30.704779Z","shell.execute_reply":"2023-06-28T14:07:30.710954Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[0, 0]","metadata":{"execution":{"iopub.status.busy":"2023-06-28T14:05:42.123756Z","iopub.execute_input":"2023-06-28T14:05:42.124127Z","iopub.status.idle":"2023-06-28T14:05:42.129973Z","shell.execute_reply.started":"2023-06-28T14:05:42.124097Z","shell.execute_reply":"2023-06-28T14:05:42.129143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Prediciton is \", index_label[predict(test[0, 0])])\nprint(\"Truth value is \", index_label[test[0, 1]])","metadata":{"execution":{"iopub.status.busy":"2023-06-28T14:07:55.121095Z","iopub.execute_input":"2023-06-28T14:07:55.121501Z","iopub.status.idle":"2023-06-28T14:07:55.130709Z","shell.execute_reply.started":"2023-06-28T14:07:55.121466Z","shell.execute_reply":"2023-06-28T14:07:55.129796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = [predict(x) for x in test[:, 0]]\npredicted = np.array(preds).astype('object')\nreal = test[:, -1]","metadata":{"execution":{"iopub.status.busy":"2023-06-28T14:13:54.701638Z","iopub.execute_input":"2023-06-28T14:13:54.70201Z","iopub.status.idle":"2023-06-28T14:13:54.917129Z","shell.execute_reply.started":"2023-06-28T14:13:54.701979Z","shell.execute_reply":"2023-06-28T14:13:54.916216Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = 0\nfor i, j in zip(predicted, real):\n    if i == j:\n        count += 1\ncount/len(predicted)","metadata":{"execution":{"iopub.status.busy":"2023-06-28T14:15:10.672621Z","iopub.execute_input":"2023-06-28T14:15:10.673002Z","iopub.status.idle":"2023-06-28T14:15:10.681709Z","shell.execute_reply.started":"2023-06-28T14:15:10.672968Z","shell.execute_reply":"2023-06-28T14:15:10.680841Z"},"trusted":true},"execution_count":null,"outputs":[]}]}