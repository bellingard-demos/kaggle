{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport torch\nimport torchaudio\nimport os\nfrom torch.utils.data import DataLoader\n\nfrom sklearn.model_selection import train_test_split\n\nfrom scipy.io.wavfile import read as read_wav\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-18T15:04:30.065981Z","iopub.execute_input":"2023-05-18T15:04:30.066377Z","iopub.status.idle":"2023-05-18T15:04:30.073105Z","shell.execute_reply.started":"2023-05-18T15:04:30.066349Z","shell.execute_reply":"2023-05-18T15:04:30.0715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_excel(\"/kaggle/input/it-spectrum-dataset/sample_audio.xlsx\")","metadata":{"execution":{"iopub.status.busy":"2023-05-18T15:04:30.092428Z","iopub.execute_input":"2023-05-18T15:04:30.093904Z","iopub.status.idle":"2023-05-18T15:04:30.156706Z","shell.execute_reply.started":"2023-05-18T15:04:30.093856Z","shell.execute_reply":"2023-05-18T15:04:30.155275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-05-18T15:04:30.15923Z","iopub.execute_input":"2023-05-18T15:04:30.159622Z","iopub.status.idle":"2023-05-18T15:04:30.177153Z","shell.execute_reply.started":"2023-05-18T15:04:30.159569Z","shell.execute_reply":"2023-05-18T15:04:30.17565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['text'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-05-18T15:04:30.179239Z","iopub.execute_input":"2023-05-18T15:04:30.179646Z","iopub.status.idle":"2023-05-18T15:04:30.190577Z","shell.execute_reply.started":"2023-05-18T15:04:30.179563Z","shell.execute_reply":"2023-05-18T15:04:30.18914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"values = df['text'].unique()\ni = 0\nlabel_id = dict()\nid_label = dict()\nfor j in values:\n    label_id[j] = i\n    id_label[i] = j\n    i += 1","metadata":{"execution":{"iopub.status.busy":"2023-05-18T15:04:30.192002Z","iopub.execute_input":"2023-05-18T15:04:30.192815Z","iopub.status.idle":"2023-05-18T15:04:30.201499Z","shell.execute_reply.started":"2023-05-18T15:04:30.192782Z","shell.execute_reply":"2023-05-18T15:04:30.199753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['text'] = df['text'].map(label_id)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T15:04:30.204673Z","iopub.execute_input":"2023-05-18T15:04:30.205109Z","iopub.status.idle":"2023-05-18T15:04:30.215262Z","shell.execute_reply.started":"2023-05-18T15:04:30.205071Z","shell.execute_reply":"2023-05-18T15:04:30.212862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = \"/kaggle/input/it-spectrum-dataset/sample/eu.0124f456-13b8-4765-936a-36bfd483683e.wav\"\nrate, data = read_wav(temp)\nprint(rate)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T15:04:30.217385Z","iopub.execute_input":"2023-05-18T15:04:30.21785Z","iopub.status.idle":"2023-05-18T15:04:30.228583Z","shell.execute_reply.started":"2023-05-18T15:04:30.217809Z","shell.execute_reply":"2023-05-18T15:04:30.227461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transforming audio to tensors","metadata":{}},{"cell_type":"code","source":"old_rate = rate\nnew_rate = 8000\ndef audio_process(x):\n    x, _ = torchaudio.load(x)\n    tr = torchaudio.transforms.Resample(orig_freq=old_rate, new_freq=new_rate)\n    return tr(x)\ntransforms = lambda x: audio_process(x)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T15:04:30.229812Z","iopub.execute_input":"2023-05-18T15:04:30.230234Z","iopub.status.idle":"2023-05-18T15:04:30.238083Z","shell.execute_reply.started":"2023-05-18T15:04:30.230166Z","shell.execute_reply":"2023-05-18T15:04:30.23659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pad_sequence(batch):\n    # Make all tensor in a batch the same length by padding with zeros\n    batch = [item.t() for item in batch]\n    batch = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=0.)\n    return batch.permute(0, 2, 1)\n\ndef collate_batch(batch):\n    tensors = []\n    targets = []\n    dir_path = \"/kaggle/input/it-spectrum-dataset\"\n    for target, audio in batch:\n        path = os.path.join(dir_path, audio+\".wav\")\n        tensors += [transforms(path)]\n        targets += [torch.tensor(target, dtype=torch.int64)]\n        \n    tensors = pad_sequence(tensors)\n    targets = torch.stack(targets)\n    \n    return tensors, targets","metadata":{"execution":{"iopub.status.busy":"2023-05-18T15:04:30.239721Z","iopub.execute_input":"2023-05-18T15:04:30.240096Z","iopub.status.idle":"2023-05-18T15:04:30.252414Z","shell.execute_reply.started":"2023-05-18T15:04:30.240063Z","shell.execute_reply":"2023-05-18T15:04:30.251093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = df.iloc[:, [0, 5]]","metadata":{"execution":{"iopub.status.busy":"2023-05-18T15:04:30.329684Z","iopub.execute_input":"2023-05-18T15:04:30.330069Z","iopub.status.idle":"2023-05-18T15:04:30.336584Z","shell.execute_reply.started":"2023-05-18T15:04:30.33004Z","shell.execute_reply":"2023-05-18T15:04:30.335412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE=8\nEPOCHS = 10\nLR = 0.001","metadata":{"execution":{"iopub.status.busy":"2023-05-18T15:36:02.700622Z","iopub.execute_input":"2023-05-18T15:36:02.701061Z","iopub.status.idle":"2023-05-18T15:36:02.706324Z","shell.execute_reply.started":"2023-05-18T15:36:02.701028Z","shell.execute_reply":"2023-05-18T15:36:02.705381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset pipeline","metadata":{}},{"cell_type":"code","source":"y = dataset.iloc[:, 0].values\nx = dataset.iloc[:, 1].values\ntrain, test = train_test_split(dataset.values, random_state=42, test_size=0.1)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nif device == \"cuda\":\n    num_workers = 1\n    pin_memory = True\nelse:\n    num_workers = 0\n    pin_memory = False\n\ntrain_loader = torch.utils.data.DataLoader(\n    train,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    collate_fn=collate_batch,\n    num_workers=num_workers,\n    pin_memory=pin_memory,\n)\n    \n    \ntest_loader = torch.utils.data.DataLoader(\n    test,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    drop_last=False,\n    collate_fn=collate_batch,\n    num_workers=num_workers,\n    pin_memory=pin_memory,\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T15:35:38.372738Z","iopub.execute_input":"2023-05-18T15:35:38.37416Z","iopub.status.idle":"2023-05-18T15:35:38.383586Z","shell.execute_reply.started":"2023-05-18T15:35:38.374112Z","shell.execute_reply":"2023-05-18T15:35:38.382383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining model","metadata":{}},{"cell_type":"code","source":"class SpeechRecognition(torch.nn.Module):\n    def __init__(self, n_input=1, n_output=11, stride=16, n_channel=32):\n        super().__init__()\n        self.conv1 = torch.nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n        self.bn1 = torch.nn.BatchNorm1d(n_channel)\n        self.pool1 = torch.nn.MaxPool1d(4)\n        self.conv2 = torch.nn.Conv1d(n_channel, n_channel, kernel_size=3)\n        self.bn2 = torch.nn.BatchNorm1d(n_channel)\n        self.pool2 = torch.nn.MaxPool1d(4)\n        self.conv3 = torch.nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n        self.bn3 = torch.nn.BatchNorm1d(2 * n_channel)\n        self.pool3 = torch.nn.MaxPool1d(4)\n        self.conv4 = torch.nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n        self.bn4 = torch.nn.BatchNorm1d(2 * n_channel)\n        self.pool4 = torch.nn.MaxPool1d(4)\n        self.fc1 = torch.nn.Linear(2 * n_channel, n_output)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = torch.nn.functional.relu(self.bn1(x))\n        x = self.pool1(x)\n        x = self.conv2(x)\n        x = torch.nn.functional.relu(self.bn2(x))\n        x = self.pool2(x)\n        x = self.conv3(x)\n        x = torch.nn.functional.relu(self.bn3(x))\n        x = self.pool3(x)\n        x = self.conv4(x)\n        x = torch.nn.functional.relu(self.bn4(x))\n        x = self.pool4(x)\n        x = torch.nn.functional.avg_pool1d(x, x.shape[-1])\n        x = x.permute(0, 2, 1)\n        x = self.fc1(x)\n        return torch.nn.functional.log_softmax(x, dim=2)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T15:35:39.750167Z","iopub.execute_input":"2023-05-18T15:35:39.750541Z","iopub.status.idle":"2023-05-18T15:35:39.765999Z","shell.execute_reply.started":"2023-05-18T15:35:39.750512Z","shell.execute_reply":"2023-05-18T15:35:39.764322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SpeechRecognition()","metadata":{"execution":{"iopub.status.busy":"2023-05-18T15:36:31.387307Z","iopub.execute_input":"2023-05-18T15:36:31.387791Z","iopub.status.idle":"2023-05-18T15:36:31.396979Z","shell.execute_reply.started":"2023-05-18T15:36:31.387755Z","shell.execute_reply":"2023-05-18T15:36:31.395707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Optimizers, loss functions","metadata":{}},{"cell_type":"code","source":"model = model.to(device)\noptimizer = torch.optim.SGD(model.parameters(), lr=LR)\ncriterion = torch.nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2023-05-18T15:36:32.491493Z","iopub.execute_input":"2023-05-18T15:36:32.491876Z","iopub.status.idle":"2023-05-18T15:36:32.4989Z","shell.execute_reply.started":"2023-05-18T15:36:32.491846Z","shell.execute_reply":"2023-05-18T15:36:32.49731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from copy import deepcopy","metadata":{"execution":{"iopub.status.busy":"2023-05-18T15:36:33.678892Z","iopub.execute_input":"2023-05-18T15:36:33.67925Z","iopub.status.idle":"2023-05-18T15:36:33.685744Z","shell.execute_reply.started":"2023-05-18T15:36:33.679225Z","shell.execute_reply":"2023-05-18T15:36:33.683772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Low accuracy model, just benchmark","metadata":{}},{"cell_type":"code","source":"best_model = deepcopy(model)\naccs = 0\nfor i in range(1, EPOCHS+1):\n    model.train()\n    \n    train_loss = 0\n    train_count = 0\n    \n    for ids, (value, label) in enumerate(train_loader):\n        optimizer.zero_grad()\n        output = model(value)\n#         print(output.shape)\n        loss = criterion(output.squeeze(1), label)\n        loss.backward()\n        optimizer.step()\n        train_loss = loss.item()\n        train_count += output.size(0)\n        \n    print(\"Epoch {} training loss: {} || \".format(i, train_loss/train_count), end='')\n        \n    model.eval()\n    val_acc = 0\n    val_count = 0\n    with torch.no_grad():\n        for ids, (value, label) in enumerate(test_loader):\n            output = model(value)\n            loss = criterion(output.squeeze(1), label)\n            val_acc += (output.squeeze().argmax(1) == label).sum().item()\n            val_count += label.size(0)\n            \n    if val_acc/val_count > accs:\n        accs = val_acc/val_count\n        best_model = deepcopy(model)\n            \n    print(\"val accuracy: {}\".format(val_acc/val_count))","metadata":{"execution":{"iopub.status.busy":"2023-05-18T15:36:34.766867Z","iopub.execute_input":"2023-05-18T15:36:34.767233Z","iopub.status.idle":"2023-05-18T15:36:47.546197Z","shell.execute_reply.started":"2023-05-18T15:36:34.767205Z","shell.execute_reply":"2023-05-18T15:36:47.545049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"case = os.path.join(\"/kaggle/input/it-spectrum-dataset\", df.iloc[0, -1]+\".wav\")\nsample = pad_sequence([transforms(case)])\nres = best_model(sample)\nid_label[res.squeeze(1).argmax(1).item()]","metadata":{"execution":{"iopub.status.busy":"2023-05-18T15:37:06.771085Z","iopub.execute_input":"2023-05-18T15:37:06.771919Z","iopub.status.idle":"2023-05-18T15:37:06.78951Z","shell.execute_reply.started":"2023-05-18T15:37:06.771875Z","shell.execute_reply":"2023-05-18T15:37:06.788223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Afterword\n\nThis is the first time I am doing Speech Recognition Task\n\nGiven bigger dataset with more values - that would lead to better model and higher accuracy","metadata":{}}]}