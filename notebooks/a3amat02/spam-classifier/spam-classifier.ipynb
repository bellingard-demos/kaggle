{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport torch\nfrom torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator\nfrom torch.utils.data import DataLoader\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport time\nfrom copy import deepcopy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-02T16:44:26.112561Z","iopub.execute_input":"2023-08-02T16:44:26.112925Z","iopub.status.idle":"2023-08-02T16:44:26.118987Z","shell.execute_reply.started":"2023-08-02T16:44:26.112895Z","shell.execute_reply":"2023-08-02T16:44:26.117967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(r\"/kaggle/input/email-spam-classification/email_spam.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-08-02T16:44:26.129259Z","iopub.execute_input":"2023-08-02T16:44:26.130224Z","iopub.status.idle":"2023-08-02T16:44:26.140977Z","shell.execute_reply.started":"2023-08-02T16:44:26.13019Z","shell.execute_reply":"2023-08-02T16:44:26.140069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-02T16:44:26.143185Z","iopub.execute_input":"2023-08-02T16:44:26.143869Z","iopub.status.idle":"2023-08-02T16:44:26.150759Z","shell.execute_reply.started":"2023-08-02T16:44:26.143837Z","shell.execute_reply":"2023-08-02T16:44:26.149785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['type'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-02T16:44:26.152552Z","iopub.execute_input":"2023-08-02T16:44:26.153572Z","iopub.status.idle":"2023-08-02T16:44:26.164228Z","shell.execute_reply.started":"2023-08-02T16:44:26.153539Z","shell.execute_reply":"2023-08-02T16:44:26.163294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mp = {'spam': 1,\n     'not spam': 0}\ndp = {1: 'spam',\n     0: 'not spam'}","metadata":{"execution":{"iopub.status.busy":"2023-08-02T16:44:26.165571Z","iopub.execute_input":"2023-08-02T16:44:26.166165Z","iopub.status.idle":"2023-08-02T16:44:26.17526Z","shell.execute_reply.started":"2023-08-02T16:44:26.166126Z","shell.execute_reply":"2023-08-02T16:44:26.174339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['type'] = df['type'].map(mp)\ndf['full'] = df['title'] + \". \" + df['text']\ndt = df[['type', 'full']]","metadata":{"execution":{"iopub.status.busy":"2023-08-02T16:44:26.177915Z","iopub.execute_input":"2023-08-02T16:44:26.178529Z","iopub.status.idle":"2023-08-02T16:44:26.194044Z","shell.execute_reply.started":"2023-08-02T16:44:26.178491Z","shell.execute_reply":"2023-08-02T16:44:26.193085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, test = train_test_split(dt.values, random_state=42, test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T16:44:26.19557Z","iopub.execute_input":"2023-08-02T16:44:26.196237Z","iopub.status.idle":"2023-08-02T16:44:26.20602Z","shell.execute_reply.started":"2023-08-02T16:44:26.196203Z","shell.execute_reply":"2023-08-02T16:44:26.205131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = get_tokenizer(\"basic_english\")\n\ndef yield_tokenizer(x):\n    for _, text in x:\n        yield tokenizer(text)\n        \n        \nvocab = build_vocab_from_iterator(yield_tokenizer(train), specials=[\"<unk>\"])\nvocab.set_default_index(vocab['<unk>'])","metadata":{"execution":{"iopub.status.busy":"2023-08-02T16:44:26.207678Z","iopub.execute_input":"2023-08-02T16:44:26.208011Z","iopub.status.idle":"2023-08-02T16:44:26.321027Z","shell.execute_reply.started":"2023-08-02T16:44:26.20798Z","shell.execute_reply":"2023-08-02T16:44:26.319991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_pipeline = lambda x: vocab(tokenizer(x))","metadata":{"execution":{"iopub.status.busy":"2023-08-02T16:44:26.322601Z","iopub.execute_input":"2023-08-02T16:44:26.322987Z","iopub.status.idle":"2023-08-02T16:44:26.330125Z","shell.execute_reply.started":"2023-08-02T16:44:26.322951Z","shell.execute_reply":"2023-08-02T16:44:26.329141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def collate_batch(batch):\n    text_list, labels_list, offsets = [], [], [0]\n    for label, text in batch:\n        process = torch.tensor(text_pipeline(text), dtype=torch.int64)\n        text_list += [process]\n        labels_list += [label]\n        offsets += [process.size(0)]\n        \n    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n    labels_list = torch.tensor(labels_list, dtype=torch.int64)\n    text_list = torch.cat(text_list)\n    return text_list, labels_list, offsets","metadata":{"execution":{"iopub.status.busy":"2023-08-02T16:44:26.334688Z","iopub.execute_input":"2023-08-02T16:44:26.335012Z","iopub.status.idle":"2023-08-02T16:44:26.342535Z","shell.execute_reply.started":"2023-08-02T16:44:26.334987Z","shell.execute_reply":"2023-08-02T16:44:26.341461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH = 4\nEPOCHS = 20\nNUM_CLASSES = 2\nVOCAB_SIZE = len(vocab)\nEMSIZE = 64","metadata":{"execution":{"iopub.status.busy":"2023-08-02T16:44:26.344051Z","iopub.execute_input":"2023-08-02T16:44:26.344441Z","iopub.status.idle":"2023-08-02T16:44:26.353502Z","shell.execute_reply.started":"2023-08-02T16:44:26.344408Z","shell.execute_reply":"2023-08-02T16:44:26.352655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dl = DataLoader(train, batch_size=BATCH, shuffle=True, collate_fn=collate_batch)\ntest_dl = DataLoader(test, batch_size=BATCH, shuffle=False, collate_fn=collate_batch)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T16:44:26.355126Z","iopub.execute_input":"2023-08-02T16:44:26.355497Z","iopub.status.idle":"2023-08-02T16:44:26.368019Z","shell.execute_reply.started":"2023-08-02T16:44:26.355465Z","shell.execute_reply":"2023-08-02T16:44:26.367125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Block(torch.nn.Module):\n    def __init__(self, _in, _out):\n        super(Block, self).__init__()\n        self.layer1 = torch.nn.Linear(_in, _out)\n        self.layer2 = torch.nn.Dropout(p=0.4)\n        self.layer3 = torch.nn.BatchNorm1d(_out)\n        \n    def forward(self, x):\n        return self.layer3(self.layer2(self.layer1(x)))\n\nclass SpamClassifier(torch.nn.Module):\n    def __init__(self, vocab_size, emsize, num_classes):\n        super(SpamClassifier, self).__init__()\n        self.embed = torch.nn.EmbeddingBag(vocab_size, emsize, sparse=False)\n        self.layers = torch.nn.Sequential(Block(emsize, 128),\n                                         Block(128, 256),\n                                         Block(256, 256),\n                                         Block(256, 128),\n                                         Block(128, 64))\n        self.fc = torch.nn.Linear(64, num_classes)\n        \n        \n    def forward(self, x, offset):\n        x = self.embed(x, offset)\n        x = self.layers(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-08-02T16:44:26.36925Z","iopub.execute_input":"2023-08-02T16:44:26.369645Z","iopub.status.idle":"2023-08-02T16:44:26.380924Z","shell.execute_reply.started":"2023-08-02T16:44:26.369613Z","shell.execute_reply":"2023-08-02T16:44:26.380002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = SpamClassifier(VOCAB_SIZE, EMSIZE, NUM_CLASSES)\nmodel = model.to(device)\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T16:44:26.38229Z","iopub.execute_input":"2023-08-02T16:44:26.382655Z","iopub.status.idle":"2023-08-02T16:44:26.399806Z","shell.execute_reply.started":"2023-08-02T16:44:26.382594Z","shell.execute_reply":"2023-08-02T16:44:26.398918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model = deepcopy(model)\nbest_acc = 0\ntrain_history = []\nval_history = []\nstart = time.time()\n\nfor i in range(1, EPOCHS+1):\n    start1 = time.time()\n    train_loss = 0\n    train_total = 0\n    model.train()\n    for text, label, offset in train_dl:\n        optimizer.zero_grad()\n        if torch.cuda.is_available():\n            text, label, offset = text.cuda(), label.cuda(), offset.cuda()\n        \n        out = model(text, offset)\n        loss = criterion(out, label)\n        train_loss += loss.item()\n        train_total += out.size(0)\n        loss.backward()\n        optimizer.step()\n        \n    train_con = train_loss/train_total\n    model.eval()\n    total_acc = 0\n    acc_total = 0\n    for text, label, offset in test_dl:\n        if torch.cuda.is_available():\n            text, label, offset = text.cuda(), label.cuda(), offset.cuda()\n        out = model(text, offset)\n        total_acc += (out.argmax(1) == label).sum().item()\n        acc_total += out.size(0)\n    acc_con = total_acc/acc_total\n    if acc_con > best_acc:\n        best_model = deepcopy(model)\n        best_acc = acc_con\n        \n    train_history += [train_con]\n    val_history += [acc_con]\n    \n    end1 = time.time()\n    print(\"Epoch {} || train loss: {} || accuracy: {} || time: {}\".format(i,\n                                                                         train_con,\n                                                                         acc_con, end1-start1))\nend = time.time()\nprint(\"Total time: {}\".format(end-start))","metadata":{"execution":{"iopub.status.busy":"2023-08-02T16:44:26.401152Z","iopub.execute_input":"2023-08-02T16:44:26.40184Z","iopub.status.idle":"2023-08-02T16:44:27.99813Z","shell.execute_reply.started":"2023-08-02T16:44:26.401808Z","shell.execute_reply":"2023-08-02T16:44:27.997167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_acc","metadata":{"execution":{"iopub.status.busy":"2023-08-02T16:44:27.999451Z","iopub.execute_input":"2023-08-02T16:44:27.999925Z","iopub.status.idle":"2023-08-02T16:44:28.007442Z","shell.execute_reply.started":"2023-08-02T16:44:27.999886Z","shell.execute_reply":"2023-08-02T16:44:28.006339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = list(range(1, EPOCHS+1))","metadata":{"execution":{"iopub.status.busy":"2023-08-02T16:44:28.008833Z","iopub.execute_input":"2023-08-02T16:44:28.009805Z","iopub.status.idle":"2023-08-02T16:44:28.017844Z","shell.execute_reply.started":"2023-08-02T16:44:28.009771Z","shell.execute_reply":"2023-08-02T16:44:28.016877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 5))\naxes[0].plot(epochs, train_history)\naxes[1].plot(epochs, val_history)\naxes[0].set_title(\"Train loss progression\")\naxes[1].set_title(\"Accuracy history\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-02T16:44:28.019272Z","iopub.execute_input":"2023-08-02T16:44:28.019802Z","iopub.status.idle":"2023-08-02T16:44:28.498912Z","shell.execute_reply.started":"2023-08-02T16:44:28.01977Z","shell.execute_reply":"2023-08-02T16:44:28.497474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(x):\n    with torch.no_grad():\n        text = torch.tensor(text_pipeline(x))\n        offset = 0\n        if torch.cuda.is_available():\n            text, offset = text.cuda(), torch.tensor([0]).cuda()\n        out = best_model(text, offset)\n        return out.argmax(1).item()","metadata":{"execution":{"iopub.status.busy":"2023-08-02T16:44:28.50052Z","iopub.execute_input":"2023-08-02T16:44:28.500866Z","iopub.status.idle":"2023-08-02T16:44:28.507158Z","shell.execute_reply.started":"2023-08-02T16:44:28.500833Z","shell.execute_reply":"2023-08-02T16:44:28.506108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[0, -1]","metadata":{"execution":{"iopub.status.busy":"2023-08-02T16:44:28.509005Z","iopub.execute_input":"2023-08-02T16:44:28.509467Z","iopub.status.idle":"2023-08-02T16:44:28.524947Z","shell.execute_reply.started":"2023-08-02T16:44:28.509435Z","shell.execute_reply":"2023-08-02T16:44:28.524067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dp[predict(test[0, -1])]","metadata":{"execution":{"iopub.status.busy":"2023-08-02T16:44:28.529884Z","iopub.execute_input":"2023-08-02T16:44:28.530375Z","iopub.status.idle":"2023-08-02T16:44:28.54192Z","shell.execute_reply.started":"2023-08-02T16:44:28.53035Z","shell.execute_reply":"2023-08-02T16:44:28.541022Z"},"trusted":true},"execution_count":null,"outputs":[]}]}