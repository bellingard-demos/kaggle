{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nimport time\nfrom copy import deepcopy\nfrom PIL import Image\n\nimport torchvision.transforms as transforms\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-06T08:05:51.631732Z","iopub.execute_input":"2023-06-06T08:05:51.632063Z","iopub.status.idle":"2023-06-06T08:05:55.409266Z","shell.execute_reply.started":"2023-06-06T08:05:51.632042Z","shell.execute_reply":"2023-06-06T08:05:55.4081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style='background-color:#F5FAF5;\n            color:#22584A;\n            padding:20px;\n            padding-left:5%;\n            font-size:140%;'>\n    <h1 style='text-align:center;'><b>Creating pandas DataFrame for training</b></h1>\n</div>","metadata":{}},{"cell_type":"code","source":"def create_dataset(path):\n    dumbells = os.path.join(path, 'Dumbells')\n    dums = [x[2] for x in os.walk(dumbells)]\n    d_arr = [os.path.join(dumbells, x) for x in dums[0]]\n    emachines = os.path.join(path, 'Elliptical Machine')\n    emac = [x[2] for x in os.walk(emachines)]\n    e_arr = [os.path.join(emachines, x) for x in emac[0]]\n    hmachines = os.path.join(path, 'Home Machine')\n    hmac = [x[2] for x in os.walk(hmachines)]\n    h_arr = [os.path.join(hmachines, x) for x in hmac[0]]\n    rbikes = os.path.join(path, 'Recumbent Bike')\n    rbik = [x[2] for x in os.walk(rbikes)]\n    r_arr = [os.path.join(rbikes, x) for x in rbik[0]]\n    label = ['dumbell']*len(d_arr) + ['elliptical machine']*len(e_arr) + ['home machine']*len(h_arr) + ['recumbent bike']*len(r_arr)\n    dd = {'images': d_arr+e_arr+h_arr+r_arr,\n         'labels': label}\n    \n    return pd.DataFrame(dd)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:05:55.411142Z","iopub.execute_input":"2023-06-06T08:05:55.411977Z","iopub.status.idle":"2023-06-06T08:05:55.420845Z","shell.execute_reply.started":"2023-06-06T08:05:55.411942Z","shell.execute_reply":"2023-06-06T08:05:55.419938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"/kaggle/input/4-gym-equipment-types-classification-dataset/Gym Data\"\ndf = create_dataset(path)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:05:55.423555Z","iopub.execute_input":"2023-06-06T08:05:55.423905Z","iopub.status.idle":"2023-06-06T08:05:55.849471Z","shell.execute_reply.started":"2023-06-06T08:05:55.423832Z","shell.execute_reply":"2023-06-06T08:05:55.848476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style='background-color:#F5FAF5;\n            color:#22584A;\n            padding:20px;\n            padding-left:5%;\n            font-size:140%;'>\n    <h1 style='text-align:center;'><b>Mapping</b></h1>\n    <p style='text-align:center;font-size:120%'>\n        Label to index<br>Index to label\n    </p>\n</div>","metadata":{}},{"cell_type":"code","source":"label_index = {'dumbell': 0,\n              'elliptical machine': 1,\n              'home machine': 2,\n              'recumbent bike': 3}\n\nindex_label = dict()\nk = 0\nfor i in label_index.keys():\n    index_label[k] = i\n    k += 1\n    \nprint(label_index)\nprint(index_label)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:05:55.853727Z","iopub.execute_input":"2023-06-06T08:05:55.85405Z","iopub.status.idle":"2023-06-06T08:05:55.862237Z","shell.execute_reply.started":"2023-06-06T08:05:55.854028Z","shell.execute_reply":"2023-06-06T08:05:55.861245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['labels'] = df['labels'].map(label_index)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:05:55.863913Z","iopub.execute_input":"2023-06-06T08:05:55.864481Z","iopub.status.idle":"2023-06-06T08:05:55.88257Z","shell.execute_reply.started":"2023-06-06T08:05:55.864453Z","shell.execute_reply":"2023-06-06T08:05:55.88143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style='background-color:#F5FAF5;\n            color:#22584A;\n            padding:20px;\n            padding-left:5%;\n            font-size:140%;'>\n    <h1 style='text-align:center;'><b>Dataset pipeline for training</b></h1>\n</div>","metadata":{}},{"cell_type":"code","source":"class CreatePipeline(Dataset):\n    def __init__(self, data, transform):\n        super(CreatePipeline, self).__init__()\n        self.data = data.values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, x):\n        image, label = self.data[x]\n        im = np.asarray(Image.open(image).convert('RGB'))\n        if self.transform is not None:\n            im = self.transform(im)\n        \n        return im, label","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:05:55.884099Z","iopub.execute_input":"2023-06-06T08:05:55.884798Z","iopub.status.idle":"2023-06-06T08:05:55.891283Z","shell.execute_reply.started":"2023-06-06T08:05:55.88477Z","shell.execute_reply":"2023-06-06T08:05:55.890481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH = 24\nEPOCHS = 15\nLR = 0.1\nsize = 224","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:05:55.892701Z","iopub.execute_input":"2023-06-06T08:05:55.89336Z","iopub.status.idle":"2023-06-06T08:05:55.90901Z","shell.execute_reply.started":"2023-06-06T08:05:55.89328Z","shell.execute_reply":"2023-06-06T08:05:55.907816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([transforms.ToPILImage(),\n                               transforms.ToTensor(),\n                               transforms.Resize((size, size)),\n                               transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))])","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:05:55.912598Z","iopub.execute_input":"2023-06-06T08:05:55.913435Z","iopub.status.idle":"2023-06-06T08:05:55.921352Z","shell.execute_reply.started":"2023-06-06T08:05:55.913395Z","shell.execute_reply":"2023-06-06T08:05:55.920121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, test = train_test_split(df, random_state=42, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:05:55.922638Z","iopub.execute_input":"2023-06-06T08:05:55.923118Z","iopub.status.idle":"2023-06-06T08:05:55.939098Z","shell.execute_reply.started":"2023-06-06T08:05:55.923092Z","shell.execute_reply":"2023-06-06T08:05:55.937935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = CreatePipeline(train, transform)\nval_ds = CreatePipeline(test, transform)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:05:55.941708Z","iopub.execute_input":"2023-06-06T08:05:55.942235Z","iopub.status.idle":"2023-06-06T08:05:55.952591Z","shell.execute_reply.started":"2023-06-06T08:05:55.942183Z","shell.execute_reply":"2023-06-06T08:05:55.95136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dl = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\nval_dl = DataLoader(val_ds, batch_size=BATCH, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:05:55.953681Z","iopub.execute_input":"2023-06-06T08:05:55.954895Z","iopub.status.idle":"2023-06-06T08:05:55.966467Z","shell.execute_reply.started":"2023-06-06T08:05:55.954848Z","shell.execute_reply":"2023-06-06T08:05:55.964608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style='background-color:#F5FAF5;\n            color:#22584A;\n            padding:20px;\n            padding-left:5%;\n            font-size:140%;'>\n    <h1 style='text-align:center;'><b>Model</b> ðŸš€</h1>\n    <p style='text-align:center;\n              font-size:120%;'>\n        My model is a simple Image Classification model with CNNs<br>There are 3 block</p>\n    <h2 style='text-align:center;'>Blocks</h2>\n    <p style='text-align:center;'><b>Each block consists of</b></p>\n    <div style='text-align:center;'>\n        <ul style='display: inline-block;\n                   text-align: left;'>\n            <li> Convolution layer</li>\n            <li>Batch Normalization layer</li>\n            <li>Max Pooling layer</li>\n            <li>ReLU activation layer</li>\n        </ul>\n    </div>\n</div>","metadata":{}},{"cell_type":"code","source":"class Block(torch.nn.Module):\n    def __init__(self, in_channels, out_channels, kernel):\n        super(Block, self).__init__()\n        self.conv = torch.nn.Conv2d(in_channels, out_channels, kernel)\n        self.batch = torch.nn.BatchNorm2d(out_channels)\n        self.pool = torch.nn.MaxPool2d(kernel+1)\n        self.relu = torch.nn.ReLU()\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.batch(x)\n        x = self.pool(x)\n        x = self.relu(x)\n        \n        return x\n\n\nclass ImgClassifier(torch.nn.Module):\n    def __init__(self, in_channels, num_classes):\n        super(ImgClassifier, self).__init__()\n        self.layers = torch.nn.Sequential(Block(in_channels, 32, 3),\n                                         Block(32, 64, 3),\n                                         Block(64, 128, 3))\n        \n        self.fc = torch.nn.Linear(128, num_classes)\n        \n    def forward(self, x):\n        x = self.layers(x)\n        x = x.permute(0, 2, 3, 1)\n        \n        x = self.fc(x)\n        x = torch.flatten(x, 1)\n        \n        return torch.nn.functional.softmax(x, dim=1)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:05:55.968138Z","iopub.execute_input":"2023-06-06T08:05:55.968488Z","iopub.status.idle":"2023-06-06T08:05:55.980411Z","shell.execute_reply.started":"2023-06-06T08:05:55.968463Z","shell.execute_reply":"2023-06-06T08:05:55.979285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = ImgClassifier(3, 4)\nmodel = model.to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\ncriterion = torch.nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:05:55.982696Z","iopub.execute_input":"2023-06-06T08:05:55.983263Z","iopub.status.idle":"2023-06-06T08:05:56.056362Z","shell.execute_reply.started":"2023-06-06T08:05:55.983222Z","shell.execute_reply":"2023-06-06T08:05:56.055272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model = deepcopy(model)\nal_start = time.time()\nbest_acc = 0\n\nfor i in range(1, EPOCHS+1):\n    start = time.time()\n    model.train()\n    \n    train_loss = 0\n    train_total = 0\n    for idx, (image, label) in enumerate(train_dl):\n        optimizer.zero_grad()\n        out = model(image)\n        loss = criterion(out, label)\n        loss.backward()\n        train_loss += loss.item()\n        train_total += out.size(0)\n        optimizer.step()\n        \n    train_res = train_loss/train_total\n    \n    model.eval()\n    val_loss = 0\n    val_total = 0\n    val_acc = 0\n    with torch.no_grad():\n        for idx, (image, label) in enumerate(val_dl):\n            out = model(image)\n            loss = criterion(out, label)\n            val_loss += loss.item()\n            val_total += out.size(0)\n            val_acc += (label == out.argmax(1)).sum().item()\n            \n    \n    val_res = val_loss/val_total\n    acc_val = val_acc/val_total\n    \n    if acc_val > best_acc:\n        best_acc = acc_val\n        best_model = deepcopy(model)\n        \n    end = time.time()\n        \n    print(\"Epoch {} || train loss: {} || val loss: {} || val acc: {} || time: {}\".format(i,\n                                                                                        train_res,\n                                                                                        val_res,\n                                                                                        acc_val,\n                                                                                        end-start))\n    \n    \nal_end = time.time()\nprint(\"Total time {}\".format(al_end - al_start))","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:05:56.059268Z","iopub.execute_input":"2023-06-06T08:05:56.059655Z","iopub.status.idle":"2023-06-06T08:12:51.690805Z","shell.execute_reply.started":"2023-06-06T08:05:56.059628Z","shell.execute_reply":"2023-06-06T08:12:51.689951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style='background-color:#F5FAF5;\n            color:#22584A;\n            padding:20px;\n            padding-left:10%;\n            font-size:140%;'>\n    <h1 style='text-align:center;'><b>Results</b> ðŸš€</h1>\n    <p style='text-align:center;\n              font-size:120%;'>\n        So the model trained on a small dataset like this has a very poor accuracy. Its best accuracy score ever is 36% ðŸ˜¥ <br> In my opinion it is <br></p><ul style='text-align:center;'>\n    <li>because the model is implemented by myself and trained from scratch</li>\n    <li>considering previous point the dataset is very small to train a model from scratch</li>\n    </ul>\n    <h2 style='text-align:center;'>Suggestions</h2>\n    <p style='text-align:center;'><b>Transfer Learning</b>. <br>I suggest to take pre-trained model such as ResNet, VGGNet etc. and fine-tune it to recognize gym equipment</p>\n</div>","metadata":{}}]}